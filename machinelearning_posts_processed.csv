Author,Subreddit,Date,Title,Post
SisyphusGuy,MachineLearning,1617898792.0,[D] Are there any reliable open-source out-of-the-box Face Anti-Spoofing detectors?,i look face anti spoof section http paperswithcod com task face anti spoof latest paper with code i find reliabl implement open sourc face anti spoof detector rgb imag some implement i found paper with code requir depth imag other make pre train weight avail other even make wrong pre train weight avail the one i actual use box model present good gener for project ideal i would like reliabl passiv face anti spoof detector e detector activ challeng user
dadadidi,MachineLearning,1616942192.0,"[P] Guide: Finetune GPT2-XL (1.5 Billion Parameters, the biggest model) on a single 16 GB VRAM V100 Google Cloud instance with Huggingface Transformers using DeepSpeed",i need finetun gptnmbr nmbr billion paramet model project model fit gpu so figur run deepspe gradient checkpoint reduc requir gpu memori now fit one gpu here explain setup command get run http github com xirid finetun gptnmbrxl http github com xirid finetun gptnmbrxl i also abl fit current largest gpt neo model nmbr b paramet one nmbr gb vram gpu finetun think might issu huggingfac implement i hope help peopl also want finetun gptnmbr want set distribut train
mroc_lak,MachineLearning,1616579417.0,[D] How does one test for shortcut learning of deep neural networks in computer vision?,hi i come across review covid nmbr diagnosi base chest x ray mani studi flaw some learn shortcut e g use hospit specif token imag how one systemat test neural net use shortcut
jafioti,MachineLearning,1617299891.0,[D] Adaptive Computation Time Uses?,i read paper adapt comput time http arxiv org ab nmbr http arxiv org ab nmbr alex grave ago i play around basic question use the mainstream project i seen albert one version use adapt comput time determin number copi layer run it seem like would huge import allow iter refin specul output like mani network dynam number time decid network origin implement rnn i think pretti trivial implement architectur i would sure think could implement mixtur expert model model rerun layer choos differ expert time could allow big paramet space without constrain use one two expert forward pass mayb i overhyp act realli use reason seen widespread adopt
goktugkt,MachineLearning,1618608106.0,[P] Minimal PyTorch Library for Natural Evolution Strategies,http github com goktugnmbr ne torch my main goal project test new configur system librari pipc http github com goktugnmbr pipc see practic write librari also act exampl pipc it also support mpinmbrpi without chang anyth run script mpirun train parallel
Yuqing7,MachineLearning,1618587259.0,[N] ETH Zurich & UC Berkeley Method Automates Deep Reward-Learning by Simulating the Past,a research team eth uc berkeley propos deep reward learn simul past deep rlsp algorithm repres reward directli linear combin featur learn self supervis represent learn enabl agent simul human action backward time infer must done here quick read eth zurich uc berkeley method autom deep reward learn simul past http syncedreview com nmbr nmbr nmbr eth zurich uc berkeley method autom deep reward learn simul past the paper learn what to do simul past arxiv http arxiv org pdf nmbr pdf
BRadoslaw,MachineLearning,1620071706.0,[D] Transformer Positional Embeddings for the nth time - are the representations unique?,hi i tri get intuit behind posit embed describ famou paper attent need http arxiv org ab nmbr it make total sens i notic one caveat i make case particular token word posit x might result vector anoth word anoth posit let make case representation_nmbr token learn positional_embed posit nmbr representation_nmbr token positional_embed posit nmbr representation_nmbr representation_nmbr it would mean word represent uniqu if model learn sequenti natur input is case valid http kazemnejad com blog transform _architectur _posit _encod http preview redd tjrnmbrziednywnmbr png width nmbr format png auto webp nmbrebnmbranmbranmbrdnmbrbadnmbrdnmbrfnmbrdnmbr
limarg,MachineLearning,1618568522.0,[D] Marginal Likelihood Estimation based on VAE,whi margin likelihood estim propos vae base import sampl i would expect straightforward way estim margin likelihood base import sampl ùëù ùë• ùëßùëù ùëß ùëù ùë• ùëß ùëû ùëß ùë• ùëû ùëß ùë• ùëëùëß ùîº ùëû ùëß ùë• ùëù ùë• ùëß ùëù ùëß ùëû ùëß ùë• howev nmbr origin vae paper author suggest differ method appendix d base import sampl is good reason nmbr the author furthermor suggest estim ùëû ùëß ùë• densiti estim draw sampl whi necessari know ùëû ùëß ùë• explicitli
mistermysterioyster,MachineLearning,1617448235.0,[D] Paper Reading Group #016 - Tackling climate change with machine learning. (Link to full slides in comments!),
yaxu,MachineLearning,1617265002.0,[D] Non-automated machine learning?,machin learn bit unfathom peopl what machin learn ai algorithm reason work paper is way understand ann get nmbr peopl togeth exchang number adjust state is way machin learn without machin i guess lot system complex work scale but would interest least de autom least part machin learn system kid learn sort algorithm like bubblesort school stand line follow algorithm is anyth like possibl ml algorithm
Tuba202,MachineLearning,1617219025.0,My fork of RameenAbdal's StyleFlow! [P],for know styleflow super cool ai http youtu ltnmbrznmbrooaeey edit facial paramet like age gender the issu run after week work i final got work decid share work form fork project my styleflow fork http github com tubanmbr styleflow made easi as long window comput cuda compat gpu pleas take time check an exampl http preview redd nmbrlhtfnmbreqnmbrfqnmbr png width nmbr format png auto webp bnmbrdnmbrecdcnmbranmbrdfadnmbrfenmbrbnmbrdbnmbranmbrenmbrfenmbrb
Vegetable_Ganache_37,MachineLearning,1616679356.0,[R] New Pre-Print: Bio-Inspired Robustness: A Review,hello everyon we recent ad new pre print human visual system inspir compon help adversari robust we studi recent attempt area analyz properti evalu criteria robust pleas let us know think paper feedback highli appreci p s pleas forgiv word format tt tt first last time i life els latex way titl bio inspir robust a review arxiv link http arxiv org ab nmbr http co mnmbrlzbqqhew amp nmbr abstract deep convolut neural network dcnn revolution comput vision often advoc good model human visual system howev current mani shortcom dcnn preclud model human vision for exampl case adversari attack ad small amount nois imag includ object lead strong misclassif object but human nois often invis if vulner adversari nois fix dcnn taken seriou model human vision mani studi tri add featur human visual system dcnn make robust adversari attack howev fulli clear whether human vision inspir compon increas robust perform evalu novel compon dcnn often inconclus we propos set criteria proper evalu analyz differ model accord criteria we final sketch futur effort make dccn one step closer model human vision
Seankala,MachineLearning,1618615742.0,[D] If I can't reproduce the exact reported scores of a paper (1-2% difference) then is it okay to report the scores I obtained or should I copy the originally reported scores?,sorri titl littl confus i sure mani peopl experienc i refer situat take code releas author particular model set virtual environ match still reproduc exact report score by exact i refer differ mayb nmbr nmbr a particular sota baselin i use show behavior i get nmbr nmbr differ is fine use score i copi past origin report score thank
Shoulder_Feeling,MachineLearning,1619417114.0,[Project] DataTap provides droplets ( containers for datasets) to make working on popular deep learning datasets easy.,excit share datatap http www datatap dev an open sourc dataset manag tool make easi container dataset let focu machin learn data op datatap let build data set droplet think droplet docker contain data a droplet encapsul dataset easili use import share across differ team project each data droplet consist nmbr item droplet templat similar docker file specifi dataset schema dataset annot metadata media typic imag video rich media learn start use http github com zensor datatap python http github com zensor datatap python mani machin learn project use proprietari data format requir tool util written scratch accommod not slow develop substanti also increas probabl develop introduc bug code valid model perform as part datatap effort allow machin learn engin focu machin learn introduc open sourc data interchang format call droplet the data contain format call annot provid standard way describ imag datatap design data platform softwar nmbr machin learn reach media like imag audio video need special data pipelin version manag data much like mlop tool version manag model current project common dataset avail download stream nmbr line code coco open image ai food dataset larg person dataset combin vehicl dataset see full list http app datatap dev databas nmbrbnmbrecnmbra bnmbr nmbrcfnmbr banmbr nmbrenmbrcadanmbr http app datatap dev databas nmbrbnmbrecnmbra bnmbr nmbrcfnmbr banmbr nmbrenmbrcadanmbr request your ad use open sourc tool import data droplet format use exampl http zensor typeform com wxonmbrzlsn http zensor typeform com wxonmbrzlsn
s-lilo,MachineLearning,1620223692.0,[N] Call for Participation in a Shared Task about occupations detection in clinical texts,hi everyon i research text mine unit barcelona supercomput center i want share inform meddoprof share task current organ focus detect normal profess employ statu clinic text spanish even type entiti might seem realli nich everi day learn import just think someon occup radic impact physic mental health habit lifestyl choic there even entir medic specialti occup medicin center around topic in context current pandem mani peopl specif occup special affect instanc health profession essenti worker the detect term help research better character health risk specif occup outsid medicin forese system result meddoprof may use field social care human resourc legal nlp even gender studi person i think one main contribut task inclus employ statu broad sens we annot unemploy retir peopl famili caregiv peopl homeless peopl depend govern subsidi etc strengthen social side project addit mention corpu includ nmbr document nmbr differ medic specialti normal either european skill compet qualif occup classif esco snome ct these multilingu vocabulari hope might inspir similar task languag best knowledg similar task yet we releas train set week ago june nmbrst releas test set if interest task want see annot exampl data annot guidelin pleas check task websit http temu bsc es meddoprof http temu bsc es meddoprof thank read i hope see least task
jj4646,MachineLearning,1619072260.0,"[D] is this the ""unanswered question"" of machine learning?",gener perform classifi deep learn recent becom subject intens studi deep model typic heavili parametr tend fit train data exactli despit overfit perform well test data phenomenon yet fulli understood sourc http proceed mlr press vnmbr belkinnmbra belkinnmbra pdf http proceed mlr press vnmbr belkinnmbra belkinnmbra pdf what consensu question statist commun is equival big bang dinosaur go extinct question statist machin learn commun is fundament imposs answer question extrem difficult my na√Øv answer question e deep learn model gener well unseen data a unseen data appar level well repres complex e g non linear combin seen data deep learn model good recogn figur complex combin b show nmbr closest friend i tell level data probabl display nearest neighbor principl big complex data set small pocket homogen data model use step stone gener thi cours explain mathemat deep learn model abl gener unseen data basic essenc matter deep learn model abl gener unseen data level unseen data similar seen data a silli extrem exampl unlik even strongest recurr neural network provid data certain stock nmbr nmbr would abl predict today weather data fundament differ allow even best model gener or suppos want use regular statist model predict inform normal distribut variabl certain mean standard deviat drastic chang mean standard deviat variabl ask previous train model continu make predict assum model know anyth chang natur expect predict less accur statist model matter great abl gener unseen data long unseen data come ballpark seen data am i understand correctli
RandomTensor,MachineLearning,1618938639.0,[N] Workshop on the Theory of Overparameterized Machine Learning **Going on right now!!**,just fyi workshop theori overparameter machin learn topml happen right lot big name hard hit talk fascin phenomenon registr free although i sure still open http topml rice edu http topml rice edu
universome,MachineLearning,1618499655.0,[P] Aligning Latent and Image Spaces to Connect the Unconnectable,hi want share latest project infinit imag gener http universom github io ali http universom github io ali the method work without condit learn dataset unrel squar imag http reddit com link mrgrdn video nmbrapkxnmbrasctnmbr player basic work follow way we put latent code posit coordin grid imag pixel locat comput pixel interpol nearbi latent code dure train gener frame random posit coordin grid feed discrimin at test time allow us produc imag posit infinit plane stitch seamlessli one anoth our gener comput imag independ patch like cocogan http arxiv org ab nmbr less extrem version inr gan http arxiv org ab nmbr cip http arxiv org ab nmbr independ pixel level thi technic tweak coordin embed make period spatial equivari shift coordin output imag shift accordingli pixel valu common coordin equal numer precis illustr ùõø valu coordin shift pixel valu insid circl equal differ gener numer precis http preview redd nmbrwbquwfgsctnmbr jpg width nmbr format pjpg auto webp bnmbrenmbrffecnmbranmbranmbrcdabanmbrbnmbrfnmbranmbrebfnmbrd a surpris thing approach work dataset natur landscap spatial invari imag statist also extent lsun bedroom difficult dataset infinit imag gener wall close object they make hard imposs extrapol imag left right sinc dataset pictur wall close object middl model nowher learn knowledg result lsun bedroom http preview redd ugyrknposctnmbr jpg width nmbr format pjpg auto webp nmbrenmbrcnmbrbnmbrcnmbrfnmbranmbrdnmbrafcnmbranmbracnmbrc besid also collect preprocess high qualiti dataset nmbrk landscap imag landscap hq unsplash flickr releas soon drawback approach gener patch complet independ limit gener qualiti nmbr experi moreov due patchwis gener model learnt ignor nois inject power tool imag edit also happen inr gan cip not dataset connect for lsun bedroom work filter away imag contain spatial invari statist see sec nmbr appendix c for ffhq imagenet i imagin work see studi tabl nmbr nmbr appendix c project page http universom github io ali http universom github io ali code http github com universom ali http github com universom ali paper http arxiv org ab nmbr http arxiv org ab nmbr
pmp-dash1,MachineLearning,1619732343.0,[R] Improving ETA Prediction Accuracy for Long-tail Events - Doordash ML Blogpost,if interest improv accuraci long tail event ml model check blog articl i wrote make doordash deliveri eta nmbr accur some order take longer expect arriv ad key histor real time featur mix iter custom loss function improv accuraci predict overal custom experi check technic detail learn long tail predict problem link http doordash engin nmbr nmbr nmbr improv eta predict accuraci long tail event machinelearn http www linkedin com feed hashtag keyword machinelearn highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr datasci http www linkedin com feed hashtag keyword datasci highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr eta http www linkedin com feed hashtag keyword eta highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr map http www linkedin com feed hashtag keyword map highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr logist http www linkedin com feed hashtag keyword logist highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr
amasterblaster,MachineLearning,1619128441.0,[Discussion] Any new / good hyperparam tuning approaches?,i look tune slow function one call take nmbr min nmbrhr how guy handl optim someth slow have good advanc new librari problem i feel like techniqu i use suck look see everyon
grid_world,MachineLearning,1617182279.0,[R] Dataset for research paper,i process publish paper deep learn compress compar model origin size perform vs compress size perform dataset major research paper either focu cifar nmbr imagenet imagenet becom infrastructur challeng sinc dataset size upward nmbr gb the problem cifar nmbr smaller dataset nmbrk imag scale well model size grow think resnet nmbr bigger therefor suggest dataset sit somewher whose result accept journal confer etc academ point view
regalalgorithm,MachineLearning,1619187929.0,[D] Your Favorite AI Podcasts / Blogs / Newsletters / YouTube Channels?,hi i want write littl blog post summar differ way keep ai way podcast blog newslett youtub channel yeah million well curat miss lot stuff date criteria still activ focus primarili ai high qualiti here i far would appreci suggest addit podcast machin learn street talk http www youtub com channel ucmltbahinmbrdmrtnmbrnpvdsoirq lex fridman mainli first nmbr ep gigaom voic ai data skeptic eye ai gradient dissent robot brain re work podcast ai today podcast chat time data scienc let talk ai in machin we trust public the gradient toward data scienc analyt vidhya distil person blog lil log http lilianweng github io lil log gwern sebastian ruder alex irpan chri olah democrat autom approxim correct off convex path arg min blog i bandit academ blog sail blog berkeley ai blog machin learn berkeley blog cmu ml blog ml mit ml georgia tech googl facebook salesforc microsoft baidu openai deepmind journalist karen hao cade metz will knight khari johnson newslett last week ai batch ai sebast ruder artifici intellig weekli new wire ai newslett paper code the algorithm ai weekli weekli robot import ai deep learn weekli h weekli chinai newslett the europeanai newslett youtub channel talk amii intellig http www youtub com channel ucxxisinvrnmbrupxvnmbryuhsgdba cmu ai seminar http www youtub com channel uclhnmbroumbgenmbrwpyvziinmbrng robot institut seminar seri http www youtub com playlist list plcfdnmbrbcnmbrfenmbrdf machin learn center georgia tech http www youtub com channel ucuginmbrcnmbrsnmbr yvinmbrkfdkdunmbraw video robot today http www youtub com channel uctfixxnmbrnjnmbrqz zxgewdcynmbra stanford mlsi seminar http www youtub com channel uczznmbrructabnmbrunmbrqpinmbrhpzeq mit embodi intellig http www youtub com channel ucnxgbvgunmbrinmbrkofooncaw interview see podcast paper summari ai coffe break letitia http www youtub com c aicoffeebreak featur henri ai lab http www youtub com channel uchbnmbrvepynmbrkyvzjjnmbrbgxnpbw yannic kilcher http www youtub com channel uczhmqknmbrmsjgfcctnnmbrxbfew arxiv insight lesson nmbrbluenmbrbrown http www youtub com c nmbrbluenmbrbrown featur jordan harrod http www youtub com channel ucnmbrhnmbrnwntgnmbrxinmbrptnmbrykvsha vcubingx http www youtub com channel ucvnmbrnfnmbrzwevessvcmznmbrmlwnmbra leo isikdogan http www youtub com channel uc yaxubpanmbrhvryfjbkfncja demo bycloud http www youtub com channel ucgfenmbroozdnmbrvjpbnmbrajanuqng two minut paper http www youtub com channel ucbfypyitq nmbrlnmbrupoxnmbrnvctg code bullet http www youtub com channel ucnmbrenmbrqhiyukixghnmbrvvpkhhnmbrq what ai http www youtub com c whatsai video
New_Date5540,MachineLearning,1618921283.0,[P] I have created a script to convert video into slides (ppt) for StatQuest,i wonder i get slide video content awesom i decid creat script extract slide video use opencv gener ppt slide you check code ani feedback would highli appreci repo http github com ninjakx youtub videonmbrppt
VerySecretCactus,MachineLearning,1618782264.0,"[D] Is the ""Super Harsh Guide to ML"" reddit post out of date yet? (2021 version)",last time post year ago wonder anyth chang origin post http www reddit com r machinelearn comment nmbrznmbr d_a_super_harsh_guide_to_machine_learn last year updat http www reddit com r machinelearn comment emmxpnmbr d_is_the_super_harsh_guide_to_ml_reddit_post_out
L-MK,MachineLearning,1620290611.0,[R] Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet,tl dr got scoop mlp mixer i releas writeup code model i hope someon find interest use late i tri coupl variant simpl vision transform better understand make perform well about month ago i found could replac attent layer feed forward layer get quit good result last week i start short writeup experi page i see full paper today googl put paper mlp mixer propos exactli architectur when i saw paper earlier today i consid scrap i done i figur i might well put for interest github repo http github com lukemela even need attent pretrain model w b log http wandb ai lukemelasnmbr deit experi report do you even need attent vmlldzonmbrnjuxmzi accesstoken nmbrkebvweuenmbrgdnmbrsnmbrqiavnmbrorconmbrvnmbrglogsinmbrinmbrjnmbrbbnmbrgnmbrenmbrpxnmbrlkknmbrzu experi nmbr page writeup http github com lukemela even need attent blob main do you even need attent pdf also anyon stori get scoop feel free share i imagin peopl crazi stori edit wow thank support i realli expect base suggest i also upload version report arxiv http arxiv org ab nmbr http arxiv org ab nmbr
patrickkidger,MachineLearning,1617795134.0,"[P] torchtyping -- documentation + runtime type checking of tensor shapes (and dtypes, ...)",hello everyon i excit announc torchtyp http github com patrick kidger torchtyp way document check pytorch tensor correct shape dtype name layout turn def batch_outer_product x torch tensor torch tensor torch tensor x shape batch x_channel shape batch y_channel return shape batch x_channel y_channel return x unsqueez nmbr unsqueez nmbr def batch_outer_product x tensortyp batch x_channel tensortyp batch y_channel tensortyp batch x_channel y_channel return x unsqueez nmbr unsqueez nmbr runtim check size channel line consist bye bye bug say hello enforc clear document code person i find i leav comment shape tensor code keep track function expect torchtyp design fix check document github http github com patrick kidger torchtyp usag exampl way extend torchtyp final curiou look torchtyp faq librari similar thing e g jax torchtyp quit option
Transit-Strike,MachineLearning,1616942574.0,[D] Does Dataset balance matter for a Style GAN?,when look classifi class nmbr domin class nmbr a lot sampl realli hurt accuraci model sinc strong bia toward one class our model blindli assum sampl class nmbr would right often with style gan i look i fear i similar issu i need convert photo fake paint i would say easi i lot photo paint would someth like affect binari cross entropi i think would sinc one class better repres but time sinc fake imag gener base real imag could ensur gener number fake imag number real imag class if nmbr paint gener nmbr fake paint the number photo may may matter i sure but case would wasserstein loss bce help mitig issu sinc care distribut class label
jj4646,MachineLearning,1619072295.0,[D] why did kernel methods become less popular than neural networks?,i read today earlier neural network popular choic activ function neural network radial basi function rbf thi appar earlier neural network call kernel approxim thi bit surpris see peopl right away assum popular choic activ function neural network relu it seem transit away rbf activ function happen around time neural network overtook svm term popular doe anyon know happen i read neural network rbf function also along standard neural network univers approxim properti e theoret abl approxim target function level accuraci effici anoth question is reason rbf lost popular doe anyon know relu go activ function neural network day just guess perhap neural network relu activ abl better consist converg approxim target function compar rbf given resourc e g number neuron layer thank
zhangboknight,MachineLearning,1617946769.0,[P] Colorizing the legacy videos with attention mechanism,we recent releas code paper deep exemplar base video color the code along colab demo avail http github com zhangmozh deep exemplar base video color http github com zhangmozh deep exemplar base video color welcom tri http preview redd qsxnmbramqnmbrsnmbr png width nmbr format png auto webp nmbreeenmbrcenmbrdbnmbrcnmbrfnmbrcfnmbrbnmbrfnmbrdefnmbrdnmbrf youtub demo avail http youtub com watch v hxwrnmbrhnmbrvvyi featur share http youtub com watch v hxwrnmbrhnmbrvvyi featur share
rafcy,MachineLearning,1617542304.0,[P] Object Detection and Tracking,share project github sinc version publish codeocean well note chang darknet yolo train weight yolo detector use repositori detector tracker object choic languag python project refer paper http arxiv org ab nmbr http arxiv org ab nmbr also ieee public found repo descript github repositori http github com rafci harpytm http github com rafci harpytm brief descript the main purpos applic extract traffic data vehicl road use aerial footag taken static uav to process footag deep neural network detector use yolo alongsid opencv librari order execut python furthermor multipl algorithm use kalman hungarian order match detect sequenti frame extract vehicl trajectori henc veloc move direct vehicl also calcul vehicl everi frame you free discuss suggest improv featur
Yungpastorphillswift,MachineLearning,1616744476.0,[D] Is it possible to combine the weights of multiple CNN Models?,first i want thank guy help given sinc i first took dive data scienc machin learn i post often i gone almost materi resourc data scienc wiki i lurk around almost everyday pick littl jewel inform i clock nmbr dedic hour learn i super excit wild interest thing i still know the deeper i go i realiz rabbit hole never end so real honestli thank guy now question i current work semi larg scale facial recognit project small group we scrape compil label huge dataset imag file aprox nmbrmil imag we store cloud databas train model batch download unzip directli cloud notebook i idea would extrem time effici everyon group pull differ batch imag train model respect machin combin save weight final model in theori idea sound good howev search around googl bit clear possibl even benefici idea look input direct toward resourc help advic gener thank advanc
optimized-adam,MachineLearning,1620252116.0,[D] Sub-pixel convolutions vs. transposed convolutions,i tri understand differ type convolut use upsampl in particular differ sub pixel convolut transpos convolut lack thereof my current understand equival oper understand author sub pixel convolut shown equival origin paper http arxiv org ab nmbr http arxiv org ab nmbr howev differ sub pixel convolut implement effici is understand correct if peopl e g http github com atriumlt subpixel http github com atriumlt subpixel strongli recommend sub pixel convolut transpos convolut seem reason perform
natalieberlin,MachineLearning,1618937360.0,[P] Applied our research (ML on dynamic knowledge graphs) to files and documents,we built first smart featur app now show similar content like need chang say nmbr file invoic contract job post includ address compani descript name iban rout number legal claus you open one edit claus chang address iban compani descript our engin say nmbr file probabl requir chang we use lsh minhash file similar run ml dynam knowledg graph determin nmbr similar file still activ paper a quick graphic http preview redd imrsumxnmbrxcunmbr png width nmbr format png auto webp nmbrenmbrdnmbrdbbanmbrdnmbrcbfnmbrenmbranmbr paper http dl acm org doi ab nmbr nmbr http dl acm org doi ab nmbr nmbr http arxiv org ab nmbr http arxiv org ab nmbr http proceed mlr press vnmbr tabibiannmbra http proceed mlr press vnmbr tabibiannmbra http www pna org content nmbr nmbr nmbr short http www pna org content nmbr nmbr nmbr short http dl acm org doi ab nmbr nmbr http dl acm org doi ab nmbr nmbr http dl acm org doi ab nmbr nmbr http dl acm org doi ab nmbr nmbr http arxiv org ab nmbr http arxiv org ab nmbr good measur build littl commun r reason http www reddit com r reason get survey get access close beta reason al http reason al utm_sourc reddit com utm_medium referr utm_campaign comm rd nmbr nmbr mling
svij137,MachineLearning,1620442366.0,[D] Number of businesses that actually spend money on training their own AI models?,i look data seem report heavili skew toward larger compani like amazon googl or get gener answer compani spent nmbrb last year but answer look nmbr spend could top nmbr compani what best way get around
designer1one,MachineLearning,1618667070.0,[P] *Semantic* Video Search with OpenAI‚Äôs CLIP Neural Network,i made simpl tool let search video semant ai live web app http whichfram com http whichfram com exampl which video frame person sunglass earphon the queri power openai clip neural network perform zero shot imag classif interfac built streamlit tri search text imag text imag pleas share discoveri more exampl http twitter com chuanenlin statu nmbr http twitter com chuanenlin statu nmbr
ykilcher,MachineLearning,1618150557.0,"[D] Paper Explained - DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning (Full Video Analysis)",http youtu qtunmbrastdenmbri http youtu qtunmbrastdenmbri classic machin learn struggl shot gener task human easili gener hand exampl exampl sort list number human come short program algorithm explain data point compact way dreamcod emul use neural guid search languag primit librari build time by iter construct complex program build abstract therefor solv difficult task shot manner gener short program solv given datapoint the result system gener quickli also deliv explain solut problem form modular hierarch learn librari combin classic deep learn low level percept promis futur direct outlin nmbr nmbr intro overview nmbr nmbr dreamcod system architectur nmbr nmbr wake phase neural guid search nmbr nmbr abstract phase extend intern librari nmbr nmbr dream phase train neural search fiction program replay nmbr nmbr abstract compress program refactor nmbr nmbr experiment result logo draw nmbr nmbr ablat studi nmbr nmbr re discov physic law nmbr nmbr discov recurs program algorithm nmbr nmbr conclus discuss paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com ellisknmbr ec http github com ellisknmbr ec
RyanAI100,MachineLearning,1618164984.0,[D] NER for Social Media Texts with Semantic Augmentation | Research Papers Summary 013,
eatpasta_runfastah,MachineLearning,1619618374.0,[D] Masking gradients before the update,hello i read paper learn explan hard vari http arxiv org ab nmbr found rel github repo http github com gibiparanmbr learn explan hard vari blob main notebook linear_regression_ilc ipynb to keep short updat paramet theta theta lr final_grad pytorch cuda comput default arithmet mean gradient wherea i want comput geometr mean appli mask shown code is way leverag pytorch autograd cuda without need write custom train loop
prestodigitarium,MachineLearning,1619288479.0,"[P] Gourdian Free Dataset Download: OpenStreetMap Points of Interest (Restaurants, Bars, Grocery Stores, Transit, Shops, Swingers Clubs, Hospitals, etc)",hi a friend i work someth help peopl search filter download subset dataset we excit share incorpor point interest openstreetmap broken group ontolog http wiki openstreetmap org wiki key amen http wiki openstreetmap org wiki key shop the group tag went what peopl think might use mayb make version walkscor perhap cross referenc real estat list find hous within walk distanc bakeri librari cafe pyrotechn shop lovehotelmapp com the possibl endless restaur bar http gourdian net g eric osm_points_of_interest restaurants_and_bar amen point interest label bar biergarten cafe fast_food food_court ice_cream pub restaur educ servic http gourdian net g eric osm_points_of_interest education_servic amen point interest label colleg driving_school kindergarten language_school librari toy_librari music_school school univers transport relat http gourdian net g eric osm_points_of_interest transportation_rel amen point interest label bicycle_park bicycle_repair_st bicycle_rent boat_rent boat_shar bus_stat car_rent car_shar car_wash vehicle_inspect charging_st ferry_termin fuel grit_bin motorcycle_park park parking_entr parking_spac taxi financi http gourdian net g eric osm_points_of_interest financi amen point interest label atm bank bureau_de_chang healthcar facil http gourdian net g eric osm_points_of_interest healthcare_facil amen point interest label baby_hatch clinic dentist doctor hospit nursing_hom pharmaci social_facil veterinari entertain http gourdian net g eric osm_points_of_interest entertain amen point interest label arts_centr brothel casino cinema community_centr conference_centr events_venu fountain gambl love_hotel nightclub planetarium public_bookcas social_centr stripclub studio swingerclub theatr public servic http gourdian net g eric osm_points_of_interest public_servic amen point interest label courthous embassi fire_st polic post_box post_depot post_offic prison ranger_st townhal facil http gourdian net g eric osm_points_of_interest facil amen point interest label bbq bench dog_toilet drinking_wat give_box shelter shower telephon toilet water_point watering_plac wast manag http gourdian net g eric osm_points_of_interest waste_manag amen point interest label sanitary_dump_st recycl waste_basket waste_dispos waste_transfer_st other amen http gourdian net g eric osm_points_of_interest other_amen amen point interest label animal_board animal_breed animal_shelt baking_oven childcar clock crematorium dive_centr funeral_hal grave_yard gym hunting_stand internet_caf kitchen kneipp_water_cur lounger marketplac monasteri photo_booth place_of_mourn place_of_worship public_bath public_build refugee_sit vending_machin food shop http gourdian net g eric osm_points_of_interest food_shop shop point interest label alcohol bakeri beverag brewing_suppli butcher chees chocol coffe confectioneri conveni deli dairi farm frozen_food greengroc health_food ice_cream organ pasta pastri seafood spice tea wine water gener shop http gourdian net g eric osm_points_of_interest general_shop shop point interest label department_stor gener kiosk mall supermarket wholesal cloth shop http gourdian net g eric osm_points_of_interest clothing_shop shop point interest label baby_good bag boutiqu cloth fabric fashion fashion_accessori jewelri leather sew shoe tailor watch wool second hand shop http gourdian net g eric osm_points_of_interest second_hand_shop shop point interest label chariti second_hand variety_stor health beauti shop http gourdian net g eric osm_points_of_interest health_and_beauty_shop shop point interest label beauti chemist cosmet drugstor erot hairdress hairdresser_suppli hearing_aid herbalist massag medical_suppli nutrition_suppl optician perfumeri tattoo hardwar shop http gourdian net g eric osm_points_of_interest hardware_shop shop point interest label agrarian applianc bathroom_furnish doityourself electr energi fireplac florist garden_centr garden_furnitur ga glazieri groundskeep hardwar housewar locksmith paint secur trade window furnish shop http gourdian net g eric osm_points_of_interest furnishing_shop shop point interest label antiqu bed candl carpet curtain door floor furnitur household_linen interior_decor kitchen lamp light tile window_blind electron shop http gourdian net g eric osm_points_of_interest electronics_shop shop point interest label comput electron hifi mobile_phon radiotechn vacuum_clean vehicl outdoor shop http gourdian net g eric osm_points_of_interest vehicle_and_outdoor_shop shop point interest label atv bicycl boat car car_repair car_part caravan fuel fish golf hunt jetski military_surplu motorcycl outdoor scuba_div ski snowmobil sport swimming_pool trailer tyre hobbi shop http gourdian net g eric osm_points_of_interest hobby_shop shop point interest label art collector craft frame game model music musical_instru photo camera trophi video video_gam stationari gift shop http gourdian net g eric osm_points_of_interest stationary_and_gift_shop shop point interest label anim book gift lotteri newsag stationeri ticket other shop http gourdian net g eric osm_points_of_interest other_shop shop point interest label bookmak cannabi copyshop dry_clean e cigarett funeral_director laundri money_lend parti pawnbrok pet pet_groom pest_control pyrotechn religion storage_rent tobacco toy travel_ag vacant weapon outpost user defin a bit tri build filter option click button csv arriv hard drive download alway singl csv bundl weird directori structur format csv index filter column type lat long date time moment download part want open licens dataset free download no signup requir download open dataset search within across dataset feedback welcom if dataset like see ad let us know also like updat put dataset got twitter gourdiandata http twitter com gourdiandata
spot4992,MachineLearning,1619196341.0,[D] Going From 4 Core/8 Thread CPU To 32 Core/64 Thread CPU,what kind speed could expect go nmbrc nmbrt cpu nmbrc nmbrt cpu train run parallel thread the specif method use catboost cpu train i consid upgrad cpu significantli thread current cpu want make sure worth i find anyth googl
everybody_wants_some,MachineLearning,1618599546.0,[P] Is such a project/task doable using machine learning?,hello everyon i hope right subreddit kind question if i want apologis advanc so problem i offer solv problem machin learn i sure actual possibl i could find literatur so background stori i offer research internship topic univers it would nmbr week full time from expect level bachelor thesi master thesi my supervisor much knowledg machin learn sinc main focu work therefor help much i undergrad knowledg machin learn my main knowledg classic ml algorithm svm knn etc dl mainli cnn howev i sure topic solv machin learn ye i go describ goal internship expect good possibl the goal get accur wind veloc valu small area region use machin learn those thing i so i mera dataset hourli weather data like wind veloc pressur etc entir world the resolut data nmbr km time nmbr km i go refer nmbr km nmbr squar big squar so one divid europ big squar howev sinc squar big accuraci wind veloc good therefor i second dataset wind atla dataset higher resolut the squar nmbr km time nmbr km i go name squar small squar so big squar divid mani small squar approxim nmbr small squar fit one big squar howev squar hourli data they one wind veloc valu per year addit i topolog data e g height forest mountain etc lie thi i suppos i somehow suppos predict help ml small squar wind speed time past for exampl small squar wind veloc may nmbr nmbr option nmbr nmbr pm as test set i valu weather station those cours accur small region but number weather station small i like mayb nmbr weather station entir germani meanwhil germani consist approxim nmbr big squar nmbr nmbr small squar so question i much knowledg regard kind problem can actual done machin learn my gut instinct sinc seem utopian the task seem difficult hardli use test data but i would like verifi way experienc is doabl gener machin learn without mathemat method can someon knowledg someth like nmbr week and doabl method algorithm p s i sorri format good i someon usual post reddit but i realli need help also i sorri grammar error sinc i nativ speaker
SQL_beginner,MachineLearning,1619582066.0,"[D] understanding the ""bottleneck"" principle in machine learning",http openreview net forum id ry_wpg a can someon pleas tri explain simpl term bottleneck principl machin learn import thank
Massive-Marzipan,MachineLearning,1617927599.0,[P] Feedback requested on nlp project related to news story chains changing over time,thi sub help past i hope i get feedback for project i essenti tri find way detect chang time news narr at stage i appli algorithm success group togeth stori follow develop event so i need find way track analyz mayb quantifi event coverag chang my current approach use topic model find import keyword articl then i use key word map stori chang overtim so basic term i identifi key word first articl narr chain compar keyword chang differ key word identifi subsequ articl event doe approach sound reason is anyth els i tri instead thank everyon
kanxx030,MachineLearning,1616756076.0,[D] How to get into prestigious research labs,hi i complet master would like explor phd opportun howev hard get touch anyon research group i interest not mention i recent move countri current uk would love get advic commun get notic top research lab way start convers research besid cold email thank advanc
Arioxel_,MachineLearning,1620586861.0,[P] How do you cope with very little data ?,i current work project machin learn interpol less know classif output vector float issu i littl data i uniqu set data around nmbr item train test model that noth fortun quit simpl pictur whatsoev how think i could cope issu especi divid set train test i thought mayb i could build new data thin air exampl averag two data
trackerFF,MachineLearning,1616484384.0,[D] What's the most comprehensive book on mathematical theory behind Deep Learning?,hi i look book math behind current deep learn topic lot paper i read simpli refer ian goodfellow et al book come mathemat proof ha releas comprehens book focus mathemat rigor behind deep learn anyth past nmbr nmbr year worth check
QueasyArm8328,MachineLearning,1619987846.0,[Discussion] Graphics in Python,hello i wonder librari use graphic python profession ml i use pygam pet project someth tell industri standard thank
Yuqing7,MachineLearning,1617841746.0,"[N] DeepMind, Microsoft, Allen AI & UW Researchers Convert Pretrained Transformers into RNNs, Lowering Memory Cost While Retaining High Accuracy",a research team univers washington microsoft deepmind allen institut ai develop method convert pretrain transform effici rnn the transform rnn tnmbrr approach speed gener reduc memori cost here quick read deepmind microsoft allen ai uw research convert pretrain transform rnn lower memori cost while retain high accuraci http syncedreview com nmbr nmbr nmbr deepmind microsoft allen ai uw research convert pretrain transform rnn lower memori cost retain high accuraci the paper finetun pretrain transform rnn arxiv http arxiv org pdf nmbr pdf
study_ai,MachineLearning,1616922070.0,[D][R] Best way to pick up functional analysis for kernel methods' research,i look appli phd ml it quit possibl research area would kernel method the problem i never cours function analysi my background cs master ml self learn real analysi level babi rudin chapter nmbr nmbr abstract algebra statist probabl stat depart current read casella berger i look concis book function analysi nmbr option i found kreiszig introductori function analysi applic axler measur integr real analysi the problem i sure much effort book i would like rigor materi but simpl exercis someth way simpler babi rudin term exercis would recommend book or mayb approach problem incorrectli how you learn kernel method prerequisit
kaiser_17,MachineLearning,1617537298.0,[D] How is the current research in Long tailed classification?,i go lot literatur long tail distribut base classif recent it seem cluster paper like belong one nmbr type nmbr sampl base nmbr class weight loss nmbr meta learn base new trend my question paper go beyond nmbr categori research limit nmbr
yourpaljon,MachineLearning,1619119971.0,[D] Why isn't quantile regression used more in neural networks?,isn quantil regress good solut estim uncertainti neural network i seen much use reason
craffel,MachineLearning,1620323975.0,"[R] ICLR Workshop on Enormous Language Models - May 7th, 2021 (livestream)",the iclr workshop enorm languag model take place may nmbrth nmbr virtual the workshop includ talk panel expert train larg lm the goal answer question like will scale lead model outperform human text base task limit scalabl model should focu simpli scale model design sophist architectur train scheme do current benchmark effect test capabl human master larg languag model lack how address legal ethic issu aris use unstructur web crawl train languag model what learn field cognit linguist philosophi attempt measur intellig machin full inform avail http welmworkshop github io http welmworkshop github io livestream appear http welmworkshop github io livestream http welmworkshop github io livestream
GiuPaolo,MachineLearning,1617648036.0,[R] Call for Papers: Evolutionary Reinforcement Learning workshop @ GECCO 2021,time pass fast onli nmbr week go deadlin nmbrst evolutionari reinforc learn workshop gecco nmbr premier confer evolutionari comput year held virtual lill franc juli nmbr nmbr nmbr in recent year reinforc learn rl receiv lot attent thank perform abil address complex task at time evolutionari algorithm ea proven competit standard rl algorithm certain problem simpler scalabl recent advanc ea led develop algorithm like novelti search qualiti divers capabl effici address complex explor problem find wealth differ polici all result develop spark strong renew interest popul base comput approach nevertheless even ea perform well hard explor problem still suffer low sampl effici thi limit less present rl method notabl sampl reus contrari struggl hard explor set the complementari characterist rl algorithm ea push research explor new approach merg two order har respect strength avoid shortcom the goal workshop foster collabor share perspect spread best practic within grow commun intersect rl ea the topic heart workshop includ evolutionari reinforc learn evolut strategi popul base method polici search neuroevolut hard explor spars reward problem decept reward novelti divers search method diverg search sampl effici direct polici search intrins motiv curios build design behaviour character meta learn hierarch learn evolutionari automl open end learn autor invit submit new origin work new perspect recent publish work topic top submiss select oral present present alongsid keynot speaker jeff clune ex team leader uberai lab current research team leader openai import date submiss deadlin april nmbr nmbr notif april nmbr nmbr camera readi may nmbr nmbr you find info workshop websit http site googl com view evorl
Hydra1721,MachineLearning,1620342579.0,"Has There Been Any Follow Up Research Papers for the Anti-FRS AI Called ""Fawkes"" ""[Discussion]""",last year research paper publish describ ai could alter imagin certain manner prevent fr correctli identifi individu face without chang appear photo viewer http www theverg com nmbr nmbr nmbr nmbr facial recognit block ai selfi cloak fawk http www theverg com nmbr nmbr nmbr nmbr facial recognit block ai selfi cloak fawk it state time fawk veri comput expens therefor unabl perform modif real time sinc public i read research paper deriv origin work ha develop field research sinc anyon manag develop network run real time
Krisztian_Endre_,MachineLearning,1620639066.0,I am looking for a Final Year Project Idea which can be done in Android [Project],hello i second year informat univers student i look final year project idea i decid work android favorit technolog the problem i find perfect topic purpos i want someth basic applic also necessari conduct research
ottawalanguages,MachineLearning,1620432416.0,[D] Reinforcement Learning with R software,reinforc learn seem becom popular topic day doe anyon know peopl work reinforc learn problem use r doe anyon link tutori show reinforc learn game theori materi done use r softwar thank
JosiahWGibbs,MachineLearning,1619932666.0,"[D] How do you try out architecture changes, etc. when a model takes days to train?",i current train model take extrem long time converg the accuracti good excel i tri introduc modif architectur tune hyperparamet etc sinc model take long train coupl day close week hard get immedi feedback wether chang i make mean anyth keep thing worsen i notic mani sota model also take extrem long time train probabl issu mani peopl use deal how research typic deal problem do recomend i first thought extract subset dataset train hope result would extrapol whole thing seem result extrapol well sometim idea seem work well subset introduc chang full dataset revers also happen usual wors
DeMorrr,MachineLearning,1619215359.0,[P] TorchPQ: Efficient Nearest Neighbor Search and Clustering on GPUs,hi everyon i happi introduc open sourc project i work torchpq http github com demoriarti torchpq python librari approxim nearest neighbor search gpu it effici implement ivfpq http hal inria fr inria nmbrvnmbr document algorithm well variant e g ivfpq r the project written mostli python use pytorch librari custom cuda kernel acceler cluster search index torchpq allow search ten thousand queri million vector within second in set high recal rate priorit torchpq outperform implement algorithm faiss http github com facebookresearch faiss for benchmark result see bottom part readm page i also spent lot time optim k mean cluster algorithm gpu result ultra fast memori effici i recommend give tri even interest nearest neighbor search the project still earli stage could bug perform issu feel free creat issu encount contribut welcom
kaia_1527,MachineLearning,1617626377.0,[P] Basic Floor Plan Image Recognition,hi everyon first time poster thi one easi model given imag recogn whether imag floor plan typic residenti properti other boolean need anyth els should quick train one want check whether gener accept model thank
putinwhat,MachineLearning,1618758422.0,[D] MLOps Stack,i research differ librari tool avail use experi reproduc i recent implement open sourc tool like mlflow track model storag well dvc data version pipelin gener i curiou know tool tri other work
born_in_cyberspace,MachineLearning,1618471311.0,[R][D] On the Impossibility of Supersized Machines,found excel satir typic argument artifici gener intellig garfinkel et al nmbr on imposs supers machin http arxiv org ab nmbr abstract in recent year number promin comput scientist along academ field philosophi physic lent credenc notion machin may one day becom larg human mani argu machin could even come exceed human size signific margin howev least seven distinct argument preclud outcom we show implaus machin ever exceed human size fact imposs
divergentdata,MachineLearning,1620228956.0,[D] Leveraging Dropout for Uncertainty Quantification / Adversary Rejection,hey i use uncertainti quantif lot work product model risk mitig i made write underli idea http www rossidata com dropouttensorflowuncertaintyerrormnist background put demo notebook http github com nicholasarossi uq_method blob master notebook nmbr_neural_network_uncertainty_quantification_with_dropout ipynb would love feedback ml engin compani thank
Caffeinated-Scholar,MachineLearning,1617713834.0,[R] Facebook AI: An Empirical Study of Training Self-Supervised Visual Transformers,
bendee983,MachineLearning,1617629350.0,[R] Data poisoning circumvents certified adversarial training methods,a paper accept cvpr introduc new data poison method undermin random smooth train techniqu make machin learn model adversari attack call poison against certifi defens pacd method gener poison data optim target robust techniqu the result dataset reduc averag certifi radiu acr distanc within train machin learn model remain robust adversari perturb the techniqu test ga macer smoothadv three popular random smooth techniqu thi grey box attack the attack need knowledg target ml model architectur train method use but need access model weight pacd data gener one random smooth techniqu also transfer method though optim state the main takeaway paper data secur underr aspect adversari attack while mani defens techniqu focus make model weight robust adversari perturb need effort detect adversari perturb train data we also need measur certifi proven train data protect machin learn develop deploy pipelin prevent compromis train data read coverag paper interview lead author http bdtechtalk com nmbr nmbr nmbr machin learn data poison nmbr http bdtechtalk com nmbr nmbr nmbr machin learn data poison nmbr full paper http arxiv org ab nmbr http arxiv org ab nmbr implement http github com akshaymehranmbr poison _certifi _defens http github com akshaymehranmbr poisoning_certified_defens
Kal217,MachineLearning,1617403979.0,[P] Intuitive StarGAN Implemented in Tensorflow 2.3,late lot work involv stargan i want creat easi read implement architectur function freeli use importantli explain go stargan http arxiv org ab nmbr http arxiv org ab nmbr class translat model use singl gener translat freeli number class it advanc gan although outdat share import idea my implement document aim familiar machin learn pleas let know feedback might first time share project http github com kalnmbr stargan tutori tensorflow nmbr http github com kalnmbr stargan tutori tensorflow nmbr
TheCockatoo,MachineLearning,1618916138.0,[D] Arguments for supervised approach when an unsupervised one already exists?,assum nich topic receiv littl attent term machin deep learn paper there one unsupervis deep learn i like propos supervis approach i argu presenc unsupervis one doesn work without label trump anyth supervis
thunder_jaxx,MachineLearning,1616434209.0,[2103.06326] S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning,
pcaversaccio,MachineLearning,1617645967.0,[R] Facebook AI: Self-supervised learning for fast and scalable time series hyper-parameter tuning,
mcbal31,MachineLearning,1620119944.0,[P] Deep Implicit Attention: A Mean-Field Theory Perspective on Attention Mechanisms,in project model attent term collect respons statist mechan system we consid vector gener ise like spin system treat incom data appli magnet field output attent modul spin expect valu order rephras attent inner loop fix point optim we introduc slow explicit attent modul implement adapt thouless anderson palmer mean field theori fast neural one parametr call onsag self correct term the latter modul look lot like transform modul by approxim constrain mean field equat show simplifi updat step appear mirror vanilla transform architectur explain origin feed forward layer import residu connect blog http mcbal github io post deep implicit attent mean field theori perspect attent mechan code http github com mcbal deep implicit attent tl dr a project model attent collect respons statist mechan system we use deep equilibrium model solv set self consist equat provid mean field theori perspect transform the gist post combin physic mean field interpret deq transform introduc deep equilibrium model http arxiv org ab nmbr bunch paper boltzmann machin nmbr comment welcom
juliensalinas,MachineLearning,1616595392.0,[D] Production-Ready Machine Learning NLP API with FastAPI and spaCy,hey fastapi nice addit python ecosystem in opinion make api creation easier less error prone it also come great perform make perfectli suit machin learn api the nlpcloud io http nlpcloud io utm_sourc reddit utm_campaign lnmbranmbr aaaf nmbreb bcbc nmbracnmbr api develop use fastapi i thought would interest write concret articl set nlp api fastapi serv spaci model ner http juliensalina com en machin learn nlp api product fastapi nlpcloud http juliensalina com en machin learn nlp api product fastapi nlpcloud i love feedback guy are also fastapi user did notic caveat i awar or think better tool machin learn api thank
yusuf-bengio,MachineLearning,1616429243.0,[D] J√ºrgen Schmidhuber - But what has he published recently (Ep. 2),becaus mani peopl request last time j√ºrgen schmidhub work truli revolutionari idea algorithm back earli nmbr among thing propos artifici curios ac framework earli prototyp known gener adversari network gan in nmbr togeth student hochreit propos infam lstm architectur still consid de facto standard rnn architectur today but sinc sporad publish interest paper when compar high statu gener fund machin learn group led famou research research output rel low so question publish recent
CvikliHaMar,MachineLearning,1618568912.0,[D] Pushforward vs Pullback algorithms,hello guy for long time i skip pushforward i read http juliadiff org chainrulescor jl dev http juliadiff org chainrulescor jl dev clear descript the term frule rrule i tri googl internet i get use pushforward gradient comput whi use pullback faster what downsid use pushforward comput gradient anyon know
flippy98026,MachineLearning,1616699703.0,[N] Common Application Framework (CAF) for Synthetic Data Generation by Rendered.ai at GTC21,caf support container simul applic tool need produc analyz integr synthet data comput vision project thi includ tool scenario gener comput manag collabor analysi data manag gui api interfac chain abl agent factori standard custom scene modifi the framework caf host render ai nmbrrd parti simul synthet data engin nir wmir thermal rada sar satellit eo xray sensor nathan kundtz render ai http render ai gtcnmbr synthet data http preview redd bnbcnmbrhvdnmbrpnmbr png width nmbr format png auto webp nmbrenmbrccdnmbrenmbrfnmbraaanmbrcdnmbrenmbranmbraanmbrdbcabnmbr
mgalarny,MachineLearning,1619030679.0,[P] Attention Nets and More with RLlib‚Äôs Trajectory View API,hey everyon i want share two new featur stabl rllib http doc ray io en master rllib html support attent network custom model trajectori view api rllib http doc ray io en master rllib html popular reinforc learn librari part open sourc ray project http github com ray project ray there blog post http medium com distribut comput ray attent net rllib trajectori view api dnmbranmbrenmbr code snippet work i want share motiv import well motiv the goal rl algorithm train neural network action choic becom optim respect reward signal also provid environ we often refer neural network function polici œÄ action œÄ observ eq nmbr in common case eq nmbr observ current frame seen agent often see rllib user tri model enough for exampl in frame stack model see last n observ account fact singl time frame captur entir state environ think ball seen screenshot game know whether fli left right http preview redd pnmbrkrnmbrhuknkunmbr png width nmbr format png auto webp nmbrenmbrcnmbrbfnmbranmbrfnmbrddcnmbrenmbr action œÄ observ nmbr nmbr eq nmbr in recurr neural network rnn model see last observ also track hidden state memori vector previous produc model alter time action memori œÄ observ memori nmbr eq nmbr furthermor attent net e g transform model model see last observ also last n track memori vector action memori œÄ observ memori n eq nmbr rllib new trajectori view api make complex polici model possibl fast build function show enabl effici attent net support rllib http medium com distribut comput ray attent net rllib trajectori view api dnmbranmbrenmbr let know thought question
mediaml,MachineLearning,1619099948.0,[D] What are good places to advertise PhD and post-doc positions in ML?,i princip investig european research group focus appli machin learn i interest experi good place advertis phd post doc posit specif phd student go look machin learn phd post doc posit faculti found good venu advertis phd post doc posit in experi worth invest money ad portal like findaphd com http findaphd com advertis group webpag social media promot way go i would particular like reach femal candid applic underrepres group ai adequ qualif ani insight advertis reach group also welcom edit some comment seem misconstru i look exclus hire femal candid thi cours case i want increas pool femal applic peopl underrepres group increas probabl find excel candid group thi partial i believ build divers research group lead interest healthier lab life partial i strongli believ research concern gender bia http curt rice com nmbr nmbr nmbr where evid littl scienc bia gender equal affirm action http www gse harvard edu news uk nmbr nmbr case affirm action
Andy_Reds,MachineLearning,1619795835.0,[2104.14421] What Are Bayesian Neural Network Posteriors Really Like?,
OnlyProggingForFun,MachineLearning,1618588775.0,"[News] Create 3D Models from Images! AI and Game Development, Design... GANverse3D & NVIDIA Omniverse",omnivers nvidia nmbr http www nvidia com en us omnivers http www nvidia com en us omnivers zhang et al nmbr imag gan meet differenti render for invers graphic and interpret nmbrd neural render http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf ganversenmbrd offici nvidia video http youtu nmbrpqnrnuiblu http youtu nmbrpqnrnuiblu nvidia s ganvers nmbrd blog articl http blog nvidia com blog nmbr nmbr nmbr gan research knight rider ai omnivers http blog nvidia com blog nmbr nmbr nmbr gan research knight rider ai omnivers watch video demo http youtu dvjwrbznmbrhnw http youtu dvjwrbznmbrhnw
davidbun,MachineLearning,1620139610.0,[N] Access Google Objectron (~1.92 TBs) in less than 5 seconds with Activeloop Hub,http redd ynmbrsnmbrunmbrxnmbr gif hi r machinelearn my team activeloop http activeloop ai utm_sourc social utm_medium reddit utm_campaign objectron partner googl make googl objectron avail nmbr second per dataset categori googl objectron one googl popular dataset contain short object centric video clip pose annot nmbr annot video nmbrm annot imag all need get start instal hub open sourc packag http github com activeloopai hub convert comput vision dataset cloud nativ numpi like array enabl nifti featur like stream pytorch tensorflow dataset version control collabor etc pip instal hub and load data bike categori import hub bike hub dataset googl bike in nmbr second dataset avail work e g filter appli transform etc the whole dataset nmbr tb metadata would take nmbr second access thank hub visual googl objectron comput vision dataset web app app activeloop ai http app activeloop ai dataset popular tag googl nmbrfshoe utm_sourc social utm_medium reddit utm_campaign objectron more detail use objectron hub avail releas blogpost http www activeloop ai blog nmbr nmbr nmbr access googl objectron data less nmbr second utm_sourc social utm_medium reddit utm_campaign objectron pleas make sure use latest updat hub http redd enmbrxanmbrxnmbr gif we work get dataset platform improv github com activeloopai hub http github com activeloopai hub tool let us know feedback like deliv maximum valu commun thank davitbun
Tea_Pearce,MachineLearning,1618352493.0,[R][P] Counter-Strike from Pixels with Behavioural Cloning,http reddit com link mqdnmbrho video lnmbronmbrnnmbrtnmbr player a deep neural network play csgo deathmatch pixel it train dataset nmbr hour nmbr million frame human play use behaviour clone arxiv paper http arxiv org ab nmbr http arxiv org ab nmbr gameplay exampl http youtu pnmbrvwknmbrumvm http youtu pnmbrvwknmbrumvm counter strike deatmatch larg scale behaviour clone tim pearc twitter http twitter com tea _pearc http twitter com tea_pearc jun zhu tsinghua unviers univers cambridg
windbreaker14,MachineLearning,1616513372.0,[D] Disappointed with the reviews in ICML21.,i submit paper icmlnmbr i receiv review nmbr day ago i suppos receiv nmbr review review nmbr nmbr nmbr nmbr howev i receiv nmbr review review nmbr nmbr two miss even though i sent messag contact e mail icmlnmbrchair gmail com mailto icmlnmbrchair gmail com i receiv respons also qualiti nmbr review poor the review weakli reject paper reason paper well organ three sentenc there critic issu i alreadi submit iclrnmbr paper prais well written well organ to sum i expect receiv nmbr review two miss one poor therefor i quit disappoint
proof_required,MachineLearning,1616753332.0,[D] How Facebook got addicted to spreading misinformation,behind paywal with new machin learn model come onlin daili compani creat new system track impact maxim user engag the process still today team train new machin learn model fblearner whether chang rank order post better catch content violat facebook commun standard rule allow platform then test new model small subset facebook user measur chang engag metric number like comment share say krishna gade serv engin manag news feed nmbr nmbr if model reduc engag much discard otherwis deploy continu monitor on twitter gade explain engin would get notif everi day metric like comment then deciph caus problem whether model need retrain but approach soon caus issu the model maxim engag also favor controversi misinform extrem put simpli peopl like outrag stuff sometim inflam exist polit tension the devast exampl date case myanmar viral fake news hate speech rohingya muslim minor escal countri religi conflict full blown genocid facebook admit nmbr year downplay role done enough help prevent platform use foment divis incit offlin violenc while facebook may oblivi consequ begin studi nmbr in intern present year review wall street journal compani research monica lee found facebook host larg number extremist group also promot user nmbr extremist group join due recommend tool present said predominantli thank model behind group you should join discov featur http www technologyreview com nmbr nmbr nmbr nmbr facebook respons ai misinform
LSTMeow,MachineLearning,1620131082.0,[N] ClearML release: v1.0 (open source MLOPs solution),hi r ml it almost two year sinc i first post open sourc solut thank amaz github star bump btw guy rock today seem like nmbr person year work tinker long night i pleas announc clearml hit version nmbr follow quickli releas clearml nmbr nmbr ad last remain featur felt nmbr need name multi model support well improv batch oper it long sometim bumpi path get us version nmbr there good time mi step everi journey differ help along way one nicest slack commun could ever wish thi feel truli like mileston a birthday i hope help us celebr more detail nmbr releas http clear ml horrayvnmbr http clear ml horrayvnmbr our commun roadmap http clear ml roadmapnmbr http clear ml roadmapnmbr formal changelog http github com allegroai clearml releas tag nmbr nmbr http github com allegroai clearml releas tag nmbr nmbr special episod show featur tiger http youtu rnmbrbmmdzfyanmbr http youtu rnmbrbmmdzfyanmbr celebratori meme http twitter com clearmlapp statu nmbr http twitter com clearmlapp statu nmbr ps i still owe commun call comparison matrix like glanc thi hard thing especi sinc mlop tool ecosystem constantli grow chang i happi say form comparison week i edit post arriv
hardmaru,MachineLearning,1618215799.0,"[R] A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes",
RaivoK,MachineLearning,1616590712.0,Fair Model Comparison [R],have publish need advic i compar accuraci differ video classif model train one train environ train trick i would like make comparison fair possibl there differ model nmbr each model use certain number input frame some might use nmbr nmbr nmbr nmbr each model use certain spatial size some nmbrxnmbr other nmbrxnmbr now i complet sure standard experi do i train model exact choic made paper i use spatial size frame number model a review might say forc model use nmbrxnmbr nmbr input frame fair valu model design on hand i train everi model valu use paper might get advantag use way comput i would like use spatial size number frame compar fast vs accur will review critic i like
ElCobo,MachineLearning,1618694910.0,[P] Wiggle-GAN: Stereoscopic camera simulation using generative adversarial neural networks,hello everyon i want post grad thesi i tri simul use stereoscop camera util monocular imag input the main goal give new altern someon want creat wigglegram http www reddit com r wigglegram way could achiev effect limit for exampl could use normal camera take mani pictur scene move effect would mimic stop motion wigglegram on hand could use array camera expens could use stereoscop camera nmbr nmbr lens kind camera analog take time effect that reason took approach use neural network limit in project i use wgan improv consist regular lnmbr loss compar output real imag see result adjust valu github http github com rocobonmbr wiggl gan code also see i train multipl multipl solut an autoencod ae one net the wiggl gan solut two net fight the wiggl gan solut extract metric see wiggl gan cr the input wiggl gan imag want move depth map direct left right output new imag move depth map estim could iter multipl time if want tri i made googl colab http colab research googl com drive nmbrnnmbrhjnmbrgevmnmbrymloenmbrcnmbrjklsnmbrf_tqn r usp share download checkpoint the limit net train imag nmbrxnmbr pixel except last one colab nmbrxnmbr the code automat chang scale imag size need chang manual sometim gener wiggl expect may due depth map estim if happen could download depth map imag folder imag input test name number _d png edit softwar could chang upload name place if want tri problem feel free ask anyth lot love
TuSharma,MachineLearning,1616862277.0,[R] Suggestions welcome: Code smell detection using deep learning,recent paper code smell detect deep direct learn transfer learn accept jss http www sciencedirect com scienc articl ab pii snmbr you may find preprint http tusharma preprint jssnmbr_code smell detect use deep learning_preprint pdf the key contribut paper nmbr detect smell without explicit featur engg e g metric esp impl smell nmbr autoencod work best among option cnn rnn nmbr transfer learn work context github reposiotori http github com tushartushar deeplearningsmel autoencod implement articl medium http tusharma medium com autoencod sourc code analysi use case nmbrdanmbrbnmbr provid implement detail would like provid opinion suggest feedback work
chasep255,MachineLearning,1617966989.0,[D] Loss function for audio auto encoder.,tri build auto encod raw audio data time domain i back never got good result i tri use mean squar error loss output realli captur mute version low frequenc signal i also tri comput mean squar error fft output much better now i tri combin wgan gp sort loss function i approach last week imag i combin wgan vggnmbr perceptu loss thi produc realli sharp imag howev i sort pretrain model raw audio i suppos i could make one so i tri combin fft loss wgan i kick train seen result yet howev i worri fft loss prevent model learn higher frequenc signal sinc larger penalti guess someth sound realist say nmbr degre phase doe anyon know better loss function i could tri sound data right fft loss defin fft _loss tf reduc _mean tf squar tf ab tf signal stft g nmbr nmbr tf signal stft r nmbr nmbr
Jump2Fly,MachineLearning,1618672265.0,[P][Code Release] A neural network implementation to detect whether a given video clip is in-game or not using transfer learning (can be applied to all sorts of games),
wasabi_toast,MachineLearning,1616635709.0,[Discussion] PlaidML and Intel's Iris Xe GPU support...?,thi probabl wish think sinc plaidml http github com plaidml plaidml part intel ai project upcom releas discret integr iri xe unit soon abl use chip gpu machin learn ye i know new iri xe unit power compar nvidia amd offer look like end cryptomin craze gpu shortag come soon i would realli like abl test dl code someth work sort gpu would help tremend
__Julia,MachineLearning,1616598885.0,"[D] Research in the Global South: Academic conference should build bridges, not barriers",hello in last month i seen academ commun twitter r machinelearn strive promot divers defend research http www wire com stori second ai research say fire googl question compani approach silenc controversi ethic ai howev i stand awe think commun gate keep research group commun the commun organ intern academ confer ask high fee base nation life standard research global south high rel life standard countri it hard forg path without includ it hard student professor learn share need pay tax includ hard see peopl defend group commun ignor anoth group it hard see intern academ confer place ban sever nation http twitter com andrewyng statu nmbr lang eu today order student global south make good univers us canada eu phd program student need least paper top tier confer obvious doabl peopl there initi one http www datascienceafrica org dsanmbraddi i think commun better if messag sound like rant mayb i think stumbl upon tweet a student africa wish start career research best self learn submit workshop get accept now onlin confer ask pay nmbr month hous rent present work zoom call whi gatekeep research http twitter com hadyelsahar statu nmbr http twitter com hadyelsahar statu nmbr if review paper confer organ confer make differ defend democrat scienc we better better lower bar live part world
KingHultan,MachineLearning,1617799367.0,[D] Metric for computational efficiency?,i tri find metric measur amount predict power model relat complex model similar fuel effici car i metric penalti loss flop the object minim penalti model find predict effici model configur quit use scenario comput power sever limit like phone autonom vehicl i tri find similar metric literatur avail do know metric measur comput effici model
dummy-gummy,MachineLearning,1619449303.0,"[P] Pytorch reimplementation of Encode-Attend-Navigate, a RL-based TSP solver",http github com astariul encod attend navig pytorch http github com astariul encod attend navig pytorch i recent implement encod attend navig http github com micheldeudon encod attend navig tsp solver base rl the offici repo use tensorflow nmbr x i decid implement pytorch i want share get opinion you train model use free gpu googl colab colab notebook provid readm
CireNeikual,MachineLearning,1619882590.0,"[P][R] AOgmaNeo ""Imagination"" after reinforcement learning",
sensetime,MachineLearning,1619065013.0,[R] Carbon Emissions and Large Neural Network Training (Google Brain and Berkeley paper with Jeff Dean as the last author),
nicolas-gervais,MachineLearning,1620053920.0,"[D] Half of my team knows Tensorflow, the other half PyTorch. How can we decide on which to use?",sadli titl say we know use need start collabor togeth all i find onlin pytorch often use research probabl even true anymor sinc everyon say thing peopl say
SmittyMcSmitherson,MachineLearning,1617948856.0,[D] MLCommons & inference benchmarking,whi mlcommon mlperf constantli ad new result is better resourc benchmark result variou inferenc asic
mistermysterioyster,MachineLearning,1616923147.0,[D] Paper Reading Group #015 - DERAIL: Diagnostic Environments for Reward And Imitation Learning. (Link to full slides in comments!),
PetarVelickovic,MachineLearning,1619684755.0,"[R] Geometric Deep Learning: Grids, Groups, Graphs, Geodesics and Gauges (""proto-book"" + blog + talk)",hi everyon i proud share first version project geometr unif deep learn kept us busi throughout covid time start februari nmbr we releas nmbr page proto book geometr deep learn michael bronstein joan bruna taco cohen we current releas arxiv preprint companion blog post http geometricdeeplearn com http geometricdeeplearn com through len symmetri invari group theori attempt distil need build neural architectur need all usual suspect cnn gnn transform lstm cover also includ recent excit develop spheric cnn so nmbr transform gaug equivari mesh cnn henc believ work use way navig increasingli challeng landscap deep learn architectur we hope find worthwhil perspect i also recent gave virtual talk fau erlangen nuremberg birthplac felix klein erlangen program one key guid principl i attempt distil key concept text within nmbr hour slot http www youtub com watch v nmbrcxhvqknmbralq http www youtub com watch v nmbrcxhvqknmbralq more goodi blog talk come soon if attend iclr nmbr keep eye michael keynot talk our work much work progress welcom feedback
prestodigitarium,MachineLearning,1617931758.0,"[P] Gourdian Free Dataset Download: EPA Air Quality System Daily CO, NO2, O3, SO2 Concentrations since 1980",howdi we ad anoth free dataset download project gourdian time epa air qualiti system daili level follow pollut measur station throughout us go back nmbr carbon monoxid co http gourdian net g eric epa_aq co_daily_summari nitrogen dioxid nonmbr http gourdian net g eric epa_aq nonmbr_daily_summari ozon onmbr http gourdian net g eric epa_aq ozone_daily_summari sulfur dioxid sonmbr http gourdian net g eric epa_aq sonmbr_daily_summari thi dataset updat twice per year whi care thing well pretti nasti pollut frequent affect human health especi long exposur period perhap concentr affect build home exampl they also use proxi variou type human activ carbon monoxid deadli high concentr bind hemoglobin make one blood carri much oxygen creat via combust fossil fuel nitrogen dioxid one result road traffic fossil fuel combust one precursor harm pollut ozon particul play role format acid rain becom nitric acid it also gener correl exposur byproduct road traffic mani link respiratori ill system inflamm lead whole host health issu ozon power oxid make caus damag respiratori tissu it also attack variou polym like rubber eventu caus crack it form primarili photochem reaction nitrogen oxid like nonmbr volatil organ compound voc high concentr limit urban area howev travel hundr mile downwind sourc final sulfur dioxid form larg combust fossil fuel high level sulfur well volcan activ it precursor acid rain becom sulfur acid sulfur dioxid known least mildli toxic hazard high concentr long term exposur low concentr also problemat the amount sulfur fossil fuel vari wide type automot gasolin much less bunker fuel commonli use contain ship exampl if like download part filter part care part via lat long filter button map select area year via slider as download size note download button upper right chang when got part want click download get csv a bit goal tri build filter option click button csv arriv hard drive download alway singl csv bundl weird directori structur format csv index filter column type lat long date time moment download part want open licens dataset free download no signup requir download open dataset search within across dataset feedback welcom if dataset like see ad let us know
weifz,MachineLearning,1620356445.0,[D]A question about causal discovery and causal inference,hi i know causal consist causal discoveri causal infer i wonder exist order two compon e g konw causal structur causal discoveri causal infer
Electronic-Lie4077,MachineLearning,1617117959.0,[P] OpenAI CLIP: Connecting Text and Images Gradio web demo,http reddit com link mgiimg video qstepjlnmbronmbrqnmbr player web demo open ai clip visual classif tri http gradio app hub aknmbr clip http gradio app hub aknmbr clip
TartarQ,MachineLearning,1620576418.0,[Discussion] Defining optimal false-positives and false-negatives balance with a cost function,roc _curv http preview redd nmbrmnmbreenmbrybnmbrynmbr png width nmbr format png auto webp nmbraanmbrfnmbrenmbrenmbrenmbraenmbrcnmbra http preview redd sheqqonmbrzbnmbrynmbr png width nmbr format png auto webp enmbranmbrbnmbrdnmbrbnmbrdbnmbranmbrcnmbreanmbr http preview redd qifabnmbrrzbnmbrynmbr png width nmbr format png auto webp nmbrcnmbraenmbrfnmbrfnmbranmbracnmbrdnmbrdefnmbrenmbrdnmbrdenmbr
prakhar21,MachineLearning,1620325388.0,[D] graph2vec: Learning Distributed Representations of Graphs | ML with Graphs (Paper Walkthrough),recent work represent learn graph structur data predominantli focu learn distribut represent graph substructur node subgraph graphnmbrvec propos techniqu emb entir graph high dimens vector space it inspir docnmbrvec learn approach graph root subgraph paper walkthrough http youtu hnmbr_omwnlo
False-Grape7566,MachineLearning,1620578000.0,[P] Keytotext Convert Keywords to Large texts,hello present keytotext keytotext nlp model convert keyword sentenc larger text it built use tnmbr model keytotext pypi instal demand infer api it also featur ui built use streamlit gpu enabl colab notebook easi usag pleas check github http github com gagannmbr keytotext http github com gagannmbr keytotext pleas star like work
CC_sciguy,MachineLearning,1618532149.0,[D] Anyone have experience running pytorch with AMD GPUs,in march pytorch mainstream rocm support mean amd gpu could viabl dl workflow i seen compel benchmark amd minmbr gpu noth end end test real deep learn workflow doe anyon experi run pytorch amd gpu are speed realli better top line nvidia gpu and importantli support good nvidia point sw side still matur
Philipp,MachineLearning,1618835247.0,[P] [D] Using GPT-3 to write short stories,hop interest i creat ongo seri http aiwrotethi substack com short stori substack co written wih gpt nmbr ai here video http www youtub com watch v nmbrfwknmbrknmbrasr show approach move stori certain direct would also love discuss topic ai fiction write i utterli fascin use gtp nmbr creativ tool
PresentCompanyExcl,MachineLearning,1618111444.0,[mocov3] An Empirical Study of Training Self-Supervised Visual Transformers,
setzRFD,MachineLearning,1617646105.0,[Discussion] What metaheuristics are interesting as an exercise to expand my knowledge of AI/ML?,i interest metaheurist search specif interwoven neural network interest result i work particl swarm genet algorithm train neural network i want tri other sinc fun exercis i look ant coloni bee coloni optim metaheurist seem work problem reduc graph travers are metaheurist think suit optim error function
Ziinxx,MachineLearning,1618173390.0,[P] Using StyleGAN2-Ada and Pixel2Style2Pixel to Become a Professional Artist,
xdtolm,MachineLearning,1617563498.0,[P] Nvidia A100 and AMD MI100 benchmarks - join VkFFT panel on Nvidia GTC 2021,hello i creator vkfft http github com dtolm vkfft vulkan cuda hip fast fourier transform librari i would like invit gtc nmbr http gtcnmbr event nvidia com panel vkfft happen april nmbrth nmbr pm cest higher educ research categori it focus implement optim creat cross platform code scale raspberri pi nmbr hpc gpu like nvidia anmbr the session also compar vulkan cuda hip comput platform nvidia anmbr amd minmbr gpu in post i would like give sneak peek part talk regard vkfft cufft rocfft perform comparison singl precis nmbrd batch fft test system nmbr nmbr represent arbitrari multipl nmbr nmbr nmbr nmbr nmbr nmbr the bandwidth calcul total memori transfer nmbrx system size divid time taken higher better nvidia anmbr result http preview redd jooknmbryvtfnmbrrnmbr png width nmbr format png auto webp nmbreadnmbrcnmbraenmbrenmbrfcnmbrcnmbrenmbrecnmbrenmbrb amd minmbr result http preview redd nmbrokfnmbrjevfnmbrrnmbr png width nmbr format png auto webp enmbrcanmbrbnmbrabdnmbrdnmbranmbrfnmbrcnmbrcnmbrdnmbrbdnmbrfab the talk also cover doubl precis multidimension test analysi i would realli appreci check
lfolle,MachineLearning,1620324878.0,[R] Deep learning methods allow fully automated segmentation of metacarpal bones to quantify volumetric bone mineral density,check latest research appli deep learn base segment network field rheumatolog http www natur com articl snmbr nmbr nmbr nmbr open access
seagullonthetop,MachineLearning,1619320683.0,Machine learning for a theoretical physicist [D],hi my background theoret high energi physic cosmolog i comfort mathematica use matlab python past though larg scale project i interest learn machin learn way suit someon background experi ha anyon trod similar path what use resourc book onlin cours alreadi done project exampl prefer someon physic i run get hand practic experi ml thank
chimp73,MachineLearning,1620077927.0,[D] An RL agent based on a large NN that one-shot learns in single SGD updates. Recall and planning through generalization from one-shot learned predictions and policy updates,yesterday http www reddit com r machinelearn comment nnmbrtsnmbrl d_how_far_can_we_get_with_oneshot_learn i explor consequ scale hypothesi true particular upscal give us one shot learn singl sdg updat well super human level infer predict gener abil today i think concret implement approach could look like idea cheap goe the model i come simpli fulli connect wide vae step perform one infer produc two gaussian sampl two predict base sampl the first sampl use predict futur second sampl use predict predict base first sampl as consequ model would one shot learn thought sensori experi occur let x _t n x t tensor contain t time step say nmbr second sampl nmbr hz n s p nmbr featur s length sensor vector p number motor neuron p muscl contract nmbr nmbr e sigmoid one extra dimens experienc reward r let first predict x _t vae concat x _ nmbr x _ nmbr second predict x _t correspond second sampl vae produc way then minim loss sgd x_t x _t nmbr x _t x _t nmbr kld z kld z p _t p _t Œ± r_t nmbr p _t p _t Œ± r _t nmbr Œª p _t _nmbr kld kl regular gaussian sampl Œ± scale constant reward strong absolut reward nmbr p _t _nmbr sparsiti prior polici encourag competit action the two rl loss simpli punish reinforc action coincid reward though slight tempor delay would like help the second loss act imagin polici imagin reward i unsur thought actual becom goal direct way i extrem surpris actual work fun think
Superb-Drawer5214,MachineLearning,1618760402.0,[D]What universities are considered top10 and top20 for ML/CV/NLP?,it seem topnmbr berkeley mit stanford cmu i sure univers consid top nmbr top nmbr ml cv nlp whenev person mention appli top nmbr school ml school refer
grid_world,MachineLearning,1617303683.0,[D] Quantization in Deep Learning,for deep learn model compress standard step appear prune cluster quantiz i experi implement first two step detail now i interest learn quantiz techniqu appli deep learn compress can point nice resourc research paper blog tutori video etc start point thank
m1900kang2,MachineLearning,1617071083.0,[R] Predicting Multiple Sclerosis from Gait Dynamics Using an Instrumented Treadmill ‚Äì A Machine Learning Approach,thi paper research univers illinoi urbana champaign look ml abl spot gait problem individu multipl sclerosi nmbr min present video http crossmind ai video predict multipl sclerosi gait dynam use instrument treadmil machin learn approach nmbranmbrebnmbrenmbrfabnmbr paper link http ieeexplor ieee org document nmbr abstract multipl sclerosi ms one common neurolog condit worldwid whose preval greatest among peopl nmbr nmbr year age while clinic present ms highli heterogen mobil limit one frequent symptom the aim studi examin ms disabl relat chang spatiotempor kinet gait featur normal evalu effect gait data base machin learn ml framework ms predict gmlnmbrm method in studi gait data self pace walk instrument treadmil nmbr person ms nmbr age weight height gender match healthi older adult hoa obtain we explor two normal strategi name size n standard bodi size base normal regress n regress base normal use scale factor deriv regress gait featur multipl subject demograph minim depend deriv gait featur subject demograph propos gmlnmbrm ml base methodolog classifi individu stride older person ms pwm healthi control gener across differ walk task subject gait normal result we observ regress n improv accuraci identifi patholog gait use ml compar size n when gener comfort walk walk talk gradient boost machin achiev optim subject classif accuraci auc nmbr nmbr respect subject gener multilay perceptron result best accuraci auc nmbr nmbr respect regress n normal data conclus the integr gait data ml predict ms may provid viabl patient centric approach aid clinician diseas monitor relaps treatment thi work first attempt employ demonstr potenti ml domain signific the result studi futur implic way regress normal gait featur may clinic use design ml base diseas predict strategi monitor diseas progress pwm butterfli diagram center pressur trajectori subject walk http preview redd nmbrvqlbvnmbrxsnmbrqnmbr png width nmbr format png auto webp nmbreanmbraanmbrbcfnmbrbenmbrbnmbrcnmbrfcaenmbr author rachneet kaur zizhang chen robert motl manuel enriqu hernandez richard sower univers illinoi urbana champaign
fripperML,MachineLearning,1617772778.0,[D] Is it always recommended to scale features to be predicted the same way as the training data was scaled?,i know ask and question might seem somewhat silli let start briefli standard approach the gener advic i alway seen decid scale data gener recommend fit _transform scaler train process appli scaler data predict thi make lot sens allow model predict one sampl whatev number sampl i question but i feel sometim best approach let give exampl let suppos deal model predict probabl default person use econom featur like annual incom amount debt etc let suppos preprocess make scale data let suppos train model data nmbr still use model product in set like kind drift worsen perform one could retrain model use recent data but intuit least partial one could reduc problem scale featur instanc predict use inform year cours i think kind econom featur affect inflat exampl annual incom nmbrk nmbr compar annual incom say nmbrk present year scale move ruler better scale fix ruler thi approach could use whenev featur mean chang time what think do think make sens of cours one limit easi implement way i think use model make batch predict big enough chunk scale featur accord distribut chunk meaning
jnbrrn,MachineLearning,1616769447.0,[R] Baking Neural Radiance Fields for Real-Time View Synthesis,real time photorealist neural render browser http nerf live http nerf live live demo http nerf live demo http nerf live demo paper pdf http nerf live bake _neural _radianc _field _for _real _time _view _synthesi pdf http nerf live baking_neural_radiance_fields_for_real_time_view_synthesi pdf explain video http www youtub com watch v nmbrjkrynmbrnnmbryonmbr http www youtub com watch v nmbrjkrynmbrnnmbryonmbr
hardmaru,MachineLearning,1616737639.0,[R] Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields,
SanjivGautamOfficial,MachineLearning,1619603499.0,[P] MLOverflow - A Webapp for ML/DL,hello ml ai enthusiast i creat small minimalist design webapp machin learn feed paper event webapp liter feed event paper section here link http mloverflow com http mloverflow com i current ad content peopl engag would delight let check featur webapp could spare moment feed share medium articl anyth find interest internet relat ml ai may linkedin post ml dl even reddit link project relat ai ml you made impress detect app upload youtub how share websit ani medium blog wrote read paper share link event share link event relat ml ai paper discuss research paper peopl comment differ blog video link use user come comment section we comment section feed paper would easier peopl post relat ml dl post there nmbr type comment audio video text explain audio video text contain link websit audio video blog post respect the link actual video audio explain clarifi write thing comment section need help link motiv what point creat site alreadi r machinelearn http www reddit com r machinelearn subreddit medium articl share cours googl search i believ make navig thing easier central place ml dl relat post would make conveni peopl interest ml dl consolid understand miscellan i realli great develop i think might help enthusiast i one note there option upload audio video gif imag i see point but need futur i would happi add well p s there suggest report section so bug featur think i need resolv add kindli tell you log go http mloverflow com report http mloverflow com report write thank read till cheer
mikegartrell,MachineLearning,1617917905.0,[N] Call for papers: KDD 2021 Workshop on Bayesian Causal Inference for Real-World Interactive Systems,http bcirwisnmbr github io http bcirwisnmbr github io august nmbr nmbr nmbr final workshop date tbd submiss deadlin may nmbr nmbr anywher earth format nmbr page extend abstract refer appendic acm proceed templat submiss websit http cmtnmbr research microsoft com bcirwisnmbr http cmtnmbr research microsoft com bcirwisnmbr increasingli use machin learn build interact system learn past action reward obtain theori suggest sever possibl approach contextu bandit reinforc learn calculu plain old bayesian decis theori what theoret appropri practic approach causal infer interact system we particularli interest case studi appli machin learn method interact system use bayesian likelihood base method discuss choic made term practic theoret argument we also welcom submiss follow area offlin evalu recommend interact system comparison bayesian polici heurist approach offlin metric probabilist approach appli contextu bandit reinforc learn approach probabilist approach increment attribut non bayesian approach trade off bayesian likelihood approach bayesian method product environ organ nichola chopin ensa mike gartrel criteo ai lab dawen liang netflix alberto lumbrera criteo ai lab david rohd criteo ai lab yixin wang uc berkeley
TrainYourMonkeyBrain,MachineLearning,1616507632.0,[D] Polyline prediction literature,i encount multipl occas i need predict line curv often repres polylin nmbrd nmbrd imag so far i alway obtain postprocess standard cnn predict like segment like i wonder exist research cnn base model directli predict polylin i unabl find i imagin dedic loss function base somehow minim area predict ground truth curv would work best i run issu difficult determin point defin line segment aka mani point one predict place best doe anyon literatur experi
pinter69,MachineLearning,1619361089.0,[R] Introduction to Photogrammetry and Points2Surf (ECCV 2020) - Link to free zoom lecture by the author in comments,
CarlJohnson2222,MachineLearning,1618958279.0,"[D] How long does it take to publish a research paper? How long is the the time from the moment you think of an idea, to the moment you submit the research paper to a journal (not including the time it takes for the journal to approve your paper)?",as question state know research long take publish paper what normal amount time abl conduct research fulli finish write paper submit
p_ranav,MachineLearning,1616342193.0,[P] Monocular Depth Estimation - I ran a number of fairly well-known pre-trained models and looked at the average,
DaredevilMeetsL,MachineLearning,1617157406.0,[D] What would you advice to make the most of a virtual conference?,i present attend confer intern symposium biomed imag venu dedic medic biolog imag analysi next month virtual it huge confer technic program http emb papercept net confer confer isbinmbr program isbinmbr_programataglanceweb html like cvpr neurip etc miccai much larger medic imag focu venu quit nich as phd student confer could quit use forg profession contact find potenti collabor what advic suggest would make experi virtual confer ideal i would like opportun network build connect ani advic suggest would appreci thank a common advic look confer program beforehand select relev work but limit i know much work mere titl abstract anoth minor inconveni time zone event cet make confer program nmbr am nmbr am
jj4646,MachineLearning,1618637941.0,[D] Is there such a theorem in machine learning?,is offici theorem statist machin learn state machin learn algorithm work gener well test data must similar train data i know common sens i search internet see offici refer principl is formal codifi somewher is referenc literatur pac theori turn provid basi machin learn algorithm
ZenDragon,MachineLearning,1617152883.0,[Discussion] What do you think would happen if a GPT model was continuously fine-tuned on its own I/O?,edit the ai simpli talk it talk human respons parti use train in batch pair togeth symbol indic say thi would quit comput expens obvious suppos i got hardwar lot time patienc suppos i daili convers system input output everi interact immedi fed back train and set learn rate higher normal strong fit would actual good case sinc natur convers singl person would take long time gener appreci volum text i think mayb also introspect period train gener side convers pretend still human particip we could even add simpl judgement pass weight fine tune ai output adjust depend human respond worth tri complet stupid idea
Ok_Reality2341,MachineLearning,1617487648.0,[D] How large can you go with CNN input images?,how larg reason go cnn regard input imag i train week worth acceleromet signal data nmbr data point per second convert spectrogram so higher resolut spectrogram better is someth like nmbrxnmbr feasibl i tri nmbrxnmbr imag enough resolut pick detail full week ani paper relat use cnn larg imag also plu
ubcengineer123,MachineLearning,1618605741.0,[R] Graphs for training loss per epoch in publications,hello i research write paper use ml cnn architectur semant segment medic imag i hope creat figur look someth like thi graph http www researchg net profil mohammad pashaei nmbr public nmbr figur fignmbr as nmbr nmbr averag loss per epoch train valid step ppm nmbr nmbr train imag patch epoch goe steadi state valu nmbr nmbr epoch ha anyon encount should i lower batch per epoch that accur epoch consist full train dataset few small detail i use weight binari cross entropi account posit neg label imbal default adam optim can anyon suggest possibl solut happen it bad thing per se model work i abl get nice look figur i reach steadi state quickli thank
zawerf,MachineLearning,1617278796.0,[D] Cheating Detection (from a recent a Google Code Jam competition),problem statement found http codingcompetit withgoogl com codejam round nmbra nmbrdnmbr rough summari nmbr player nmbr question player skill level s_i question difficulti q_j s_i uniform nmbr nmbr q_j uniform nmbr nmbr a player skill s_i answer question difficulti q_j correctli probabl sigmoid s_i q_j except one cheater answer correctli probabl nmbr sigmoid s_i q_j nmbr you result player answer question identifi cheater to pass need find cheater nmbr time possibl much better sinc code competit expect come simpl heurist see analysi tab intend solut but i curiou stat ml peopl would approach instead
allasamhita,MachineLearning,1617799679.0,[P] Accelerate Your Machine Learning and Data Workflows to Production using Flyte!,imagin pain behind orchestr ml workflow you take care maintain model artifact cach result facilit backtrack error sourc share result team member container job ensur scalabl time thi cheap a lot happen backend ensur ml workflow run seamlessli if part promin compani much vital ensur fool proof ml servic span multipl team here flyte could solut flyte make easi creat concurr scalabl maintain workflow machin learn data process heard right it ml data process flyte use product lyft spotifi freenom other at lyft flyte serv product model train data process four year becom de facto platform team like price locat eta map autonom in fact flyte manag nmbr nmbr uniqu workflow lyft total nmbr nmbr nmbr execut everi month nmbr million task nmbr million contain you check flyte http github com flyteorg flyte http github com flyteorg flyte websit http flyte org
the_travelo_,MachineLearning,1617795448.0,[D] what's the best approach to document a machine learning project?,at compani struggl correctli document project we use confluenc govern found proper rythm document everyth involv develop project what tool process code anyth use solv problem
cereal_final,MachineLearning,1620446819.0,[P] How to get better performance with styleGAN2-ada for cartoons,i tri gener pokemon stylegannmbr ada i get best result http imgur com hnmbrunmbrnvh i would say nmbr look like legit pokemon nmbr kinda trash like imag i link i tri train longer i believ model collaps http imgur com nmbrzivjnmbr how i improv result the dataset nmbrk imag pokemon headshot like http imgur com bxzunmbrvu
JFHermes,MachineLearning,1618835916.0,[D]Ethics in famous Machine Learning papers.,hi i ask write ethic review stat class univers most paper would think alreadi done i know lot great research happen ai i thought i would ask advic i need singl paper it uneth even gray would better i someth talk so yeah throw case anyon know one top head thank time
LosinCash,MachineLearning,1617995159.0,[D] Looking for some clarification on Big Sleep variables.,hi hope may abl produc insight variabl insid big sleep hope u whiskey moment respond i instal run big sleep nvidia jetson xavier python jupyt notebook use nmbrgb ram plenti left abus when drill variabl coupl stump i like know i experi specif seed gradient accumul torch_determinist class_temperatur thank help resourc point toward
timscarfe,MachineLearning,1617499307.0,"[D] Christian Szegedy - Formal Reasoning, Program Synthesis [Video Show]",http youtu ehnggyfonmbrm http youtu ehnggyfonmbrm dr christian szegedi googl research deep learn heavyweight he invent adversari exampl one first object detect algorithm inceptionnet architectur co invent batchnorm he think bet comput softwar nmbr would right bet ai but think program comput way sinc nmbr huge stagnat ever sinc mathemat process take fuzzi thought formalis but could autom could creat system act like super human mathematician talk natur languag thi christian call autoformalis christian think autom mani thing mathemat first step toward softwar synthesi build human level agi mathemat abil litmu test gener reason abil christian fascin take transform touch a promis path toward autoform gener artifici intellig szegedi http link springer com chapter nmbr nmbr nmbr nmbr nmbr nmbr _nmbr http link springer com chapter nmbr nmbr nmbr nmbr nmbr nmbr_nmbr learn reason larg theori without imit bansal szegedi http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf mathemat reason via self supervis skip tree train rabe szegedi http openreview net pdf id ymqanynmbrcmey http openreview net pdf id ymqanynmbrcmey lime learn induct bia for primit of mathemat reason wu szegedi http arxiv org ab nmbrvnmbr http arxiv org ab nmbrvnmbr deep learn for symbol mathemat lampl http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf it not what machin can learn it what we can teach yehuda http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf investig limit transform simpl arithmet task nogueira http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf provabl bound learn some deep represent arora http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf neural net learn program neural net fast weight schmidhub http peopl idsia ch juergen fast weight programm nmbr transform html http peopl idsia ch juergen fast weight programm nmbr transform html how batch normal help optim ilya http gradientsci org batchnorm http gradientsci org batchnorm how train your resnet nmbr batch norm http myrtl ai learn train resnet nmbr batch norm http myrtl ai learn train resnet nmbr batch norm train resnet nmbr accuraci cifar nmbr nmbr second singl gpu kuhn http efficientdl com train resnet effici nmbr batch norm reduc intern covari shift http efficientdl com train resnet effici nmbr batch norm reduc intern covari shift
Mjjjokes,MachineLearning,1617939562.0,[R] CPU algorithm trains deep neural nets up to 15 times faster than top GPU trainers,link http techxplor com news nmbr nmbr rice intel optim ai commod html fbclid iwarnmbruvvwnmbrfohdmlijxsinmbravownmbrjnwtykdiucfnmbrtmucnmbrdwwdahnmbrirttmabyj the whole industri fixat one kind improv faster matrix multipl shrivastava said everyon look special hardwar architectur push matrix multipl peopl even talk special hardwar softwar stack specif kind deep learn instead take expens algorithm throw whole world system optim i say let revisit algorithm from articl
pcaversaccio,MachineLearning,1618587670.0,[R] GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds,
meldiwin,MachineLearning,1617392472.0,"[N] ""DeepDream"" Questions for Alexander Mordvintsev, a research scientist at Google",hello for mayb famiilar deepdream comput vision http en wikipedia org wiki computer_vis program creat alexand mordvintsev ieee soft robot podcast go podcast question send http doc googl com form e nmbrfaipqlsdthtdlnmbrbkfbrrpoanmbrsczwfddqnmbrhijwqgtnmbrslsughnmbrndanmbrlna viewform vc nmbr c nmbr w nmbr flr nmbr gxid nmbr http doc googl com form e nmbrfaipqlsdthtdlnmbrbkfbrrpoanmbrsczwfddqnmbrhijwqgtnmbrslsughnmbrndanmbrlna viewform vc nmbr c nmbr w nmbr flr nmbr gxid nmbr http preview redd kqdkznmbraoctqnmbr png width nmbr format png auto webp enmbrbnmbrbnmbrbnmbrenmbraabnmbrcnmbrbnmbrbcnmbrfcnmbrenmbrc
SieunPark,MachineLearning,1617422929.0,[R] How to download the DIV8K dataset for Super-Resolution?,divnmbrk http peopl ee ethz ch timoft public gu iccvw nmbrb pdf dataset use super resolut thi use nmbr aim challeng nmbr ntire challeng the link challeng http competit codalab org competit nmbr learn _the _detail evalu http competit codalab org competit nmbr learn_the_detail evalu but unfortun i find link download dataset anywher internet how i download divnmbrk dataset thank
OShackathon,MachineLearning,1618620959.0,[P] Darknet on AMD Hardware,http github com alexeyab darknet compar master os hackathon master http github com alexeyab darknet compar master os hackathon master
iarai-weather4cast,MachineLearning,1617294382.0,[N] Join our new IARAI Multi-sensor Weather Forecast Competition!,join new multi sensor weather forecast competit studi multi channel weather movi predict weather product variou earth region appli transfer learn new earth region goal the goal competit short term predict select weather product three region core challeng appli transfer learn predict weather product three addit region transfer learn challeng follow recent success trafficnmbrcast competit neurip nmbr nmbr challeng similarli present weather forecast video frame predict task the competit goal predict next nmbr imag nmbr hour nmbr minut interv weather movi the imag contain four channel encod follow weather product temperatur access surfac top cloud earth convect rainfal rate probabl occurr tropopaus fold cloud mask base meteorolog satellit data obtain collabor aemet nwc saf each pixel imag repres area nmbr km x nmbr km region contain nmbr x nmbr pixel the region span vari landscap includ mountain desert island sea other the challeng offer real world benchmark shot transfer learn allow test multi sensor data fusion join us learn data websit weathernmbrcast ai http weathernmbrcast ai prize the winner core competit transfer learn competit award follow prize nmbrst place voucher cash prize worth nmbr nmbr particip team nmbrnd place voucher cash prize worth nmbr nmbr particip team nmbrrd place voucher cash prize worth nmbr nmbr particip team deadlin competit start april nmbr nmbr submiss deadlin may nmbr nmbr nmbr nmbr aoe held dataset avail june nmbr nmbr abstract submiss held dataset predict june nmbr nmbr nmbr nmbr aoe announc winner june nmbr nmbr
StrasJam,MachineLearning,1617867075.0,[D] Facebook's use of Softmax in multi-label classification,i read paper http arxiv org pdf nmbr pdf put group research facebook found use softmax ce loss function train led improv result sigmoid bce dure train chang one hot label vector nmbr divid number label given imag e g nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr howev mention could use infer stage requir threshold select correct label clear would theoret need set base upon expect number label imag inform avail infer ha anyon els read paper idea could work
jj4646,MachineLearning,1619296637.0,[D] relationship between svm and neural networks,is correct svm project data higher dimens look pattern project back lower dimens make final decis wherea neural network directli project data lower dimens make decis
zy415,MachineLearning,1619705753.0,[D] IJCAI 2021 Paper Acceptance Result,ijcai nmbr paper accept result releas creat discuss thread year result
huseinzol05,MachineLearning,1618732918.0,"[P] Malaya-Speech, Speech-Toolkit library for Malay language, powered by Deep Learning Tensorflow",featur age detect detect age speech use finetun speaker vector speaker diariz diariz speaker use pretrain speaker vector emot detect detect emot speech use finetun speaker vector gender detect detect gender speech use finetun speaker vector languag detect detect hyperloc languag speech use finetun speaker vector multispeak separ multispeak separ use fastsep nmbrk wav nois reduct reduc multilevel nois use stft unet speaker chang detect chang speaker use finetun speaker vector speaker overlap detect overlap speaker use finetun speaker vector speaker vector calcul similar speaker use pretrain speaker vector speech enhanc enhanc voic activ use waveform unet speech text end end speech text malay mix malay singlish use rnn transduc super resolut super resolut nmbrx waveform text speech text speech malay singlish use tacotronnmbr fastspeechnmbr vocod convert mel waveform use melgan multiband melgan univers melgan vocod voic activ detect detect voic activ use finetun speaker vector voic convers mani one one mani mani mani zero shot voic convers hybrid nmbr bit quantiz provid hybrid nmbr bit quantiz model reduc infer time nmbrx model size nmbrx pretrain model wave unet multi scale neural network end end audio sourc separ http arxiv org ab nmbr wave resnet unet ad resnet style wave unet paper produc wave resnext unet ad resnext style wave unet paper produc deep speaker an end end neural speaker embed system http arxiv org pdf nmbr pdf speakernet nmbrd depth wise separ convolut network text independ speaker recognit verif http arxiv org ab nmbr vggvox larg scale speaker identif dataset http arxiv org pdf nmbr pdf ghostvlad utter level aggreg for speaker recognit in the wild http arxiv org ab nmbr conform convolut augment transform speech recognit http arxiv org ab nmbr alconform a lite conform paper produc jasper an end end convolut neural acoust model http arxiv org ab nmbr tacotronnmbr natur tt synthesi condit wavenet mel spectrogram predict http arxiv org ab nmbr fastspeechnmbr fast high qualiti end end text speech http arxiv org ab nmbr melgan gener adversari network condit waveform synthesi http arxiv org ab nmbr multi band melgan faster waveform gener high qualiti text speech http arxiv org ab nmbr srgan modifi version srgan nmbrd convolut photo realist singl imag super resolut use gener adversari network http arxiv org ab nmbr speech enhanc unet http github com haoxiangsnr wave u net speech enhanc speech enhanc resnet unet ad resnet style speech enhanc unet paper produc speech enhanc resnext unet ad resnext style speech enhanc unet paper produc univers melgan univers melgan a robust neural vocod high fidel waveform gener multipl domain http arxiv org ab nmbr fastvc faster accur voic convers use transform paper produc fastsep faster accur speech separ use transform paper produc wavnmbrvec nmbr a framework self supervis learn speech represent http arxiv org ab nmbr check latest document http malaya speech readthedoc io check github repositori http github com huseinzolnmbr malaya speech
PaganPasta,MachineLearning,1616313712.0,[D] ICML pre-lim reviews are out.,pre liminari also interpret final depend review review icml come today creat discuss thread caus i alreadi see one
marksteve4,MachineLearning,1617752955.0,[D] state of art for Speaker Diarization?,i tri resemblyz http github com resembl ai resemblyz method yet alway either cut much voic includ much other it also requir clip talk qualiti clip heavili impact perform
malia912,MachineLearning,1620140015.0,YOLOV5 with a second stage classifier [D],d hello everyon thi question regard yolovnmbr in detect py modul i saw second stage classifi set fals problem statement i want classifi imag secondari classifi in first stage yolovnmbr draw bound box around imag dog basic localis dog imag help secondari classifi want classifi dog respect breed result bound box around dog name breed ha anyon tri approach thank time
ztzyz615,MachineLearning,1619087386.0,[D] Any statistical theory for mixture density network?,i want ask whether paper work relat statist theori mixtur densiti network http public aston ac uk id eprint nmbr nmbr ncrg _nmbr _nmbr pdf http public aston ac uk id eprint nmbr nmbr ncrg_nmbr_nmbr pdf like converg rate estim error bound i lot search fail find mani thank
PaganPasta,MachineLearning,1618989276.0,[D] Adding under review/submitted papers on Resum√©?,recent i skim resum potenti candid research role came across plenti add submit review cvpr icml etc public list is common practic it becom annoy paper arxiv candid wish present also share most time paper underwhelm lack rigour mani front i see poor effort ad reput confer name resum√© or perhap i miss util inform
say_wot_again,MachineLearning,1618230205.0,[R] What Will it Take to Fix Benchmarking in Natural Language Understanding?,
hnipun,MachineLearning,1617549237.0,[P][D] Dynamic Hyper-parameters,hyper paramet control learn process model they set train start either intuit hyper paramet search they either stay static chang base pre determin schedul we introduc dynam hyper paramet manual adjust train base model train stat github http github com lab ml labml http github com lab ml labml app http app labml ai http app labml ai what hyper paramet hyper paramet paramet control learn process model learn rate batch size weight decay the model might learn hyper paramet set correctli set hyper paramet key part deep learn research research find base intuit run hyper paramet search in hyper paramet search model train repeatedli differ hyper paramet find best set hyper paramet hyper paramet search becom costli number hyper paramet increas model train time increas some hyper paramet chang train base pre determin schedul for exampl could slowli decreas learn rate could decreas coeffici auxiliari loss model learn find schedul nearli imposs hyper paramet search usual determin base intuit research whi hard determin hyper paramet set hyper paramet requir quit bit experi kind model size train well dataset for instanc consid fine tune pre train languag model classifi tweet you get pre train languag model backbon attach layer two classif head first freez paramet backbon train head certain number updat unfreez paramet train paramet the number step keep backbon frozen gener set nmbr epoch thi hyper paramet and common practic freez nmbr epoch might small larg depend size model well dataset size someon work similar model dataset good intuit hyper paramet if new tri train model get feel introduc dynam hyper paramet dynam hyper paramet hyper paramet research adjust model train thi allow research activ control model train instead let model train pre determin set hyper paramet dynam hyper paramet help train model faster better singl train session also let research play around hyper paramet singl train run gather insight sometim research save model checkpoint restart train chang hyper paramet valu thi similar effect dynam hyper paramet quit cumbersom how work you need creat dynam hyper paramet regist along configur labml import experi labml config import floatdynamichyperparam lr floatdynamichyperparam nmbre nmbr range_ nmbr nmbr experi config learning_r lr then call dynam hyper paramet get current valu for exampl def train batch optim set_lr lr optim step the call lr return current learn rate set labml ai http labml ai app http github com lab ml app thi http github com lab ml labml raw master guid dynamic_hp png screenshot mobil web interfac chang dynam hyper paramet in demo http app labml ai run nmbreffnmbranmbrenmbrebnmbrbnmbrdbnmbrenmbrf hyper_param demo adjust learn rate clip rang number train epoch per sampl speed train ppo agent http nn labml ai rl ppo experi html atari breakout a standard learn rate decay static hyper paramet valu would taken lot train updat get score nmbr exampl use case freez pre train layer when fine tune languag model train backbon frozen rate improv loss drop chang hyper paramet affect layer frozen thi better faster go common practic keep backbon frozen nmbr epoch model dataset learn rate warm decay the learn rate manual increas initi train updat you could decid long warm base loss curv similarli decay learn rate loss valu stabil thi allow use higher learn rate initi speed train increas sequenc length recurr model train faster bptt length shorter but need higher bptt length improv accuraci therefor common practic start shorter bptt length increas later again decid beforehand hard chang dynam lot easier adjust regular paramet you start lower weight decay lower dropout probabl initi especi sure represent capac model you increas regular paramet later valid loss stop improv higher varianc adjust reinforc learn hyper paramet reinforc learn tend hyper paramet most need chang train discount factor entropi bonu coeffici learn rate etc pre determin almost imposs without observ train run train run go mani hour day even simpl game environ chang train base agent perform stat lot easier what next updat hyper paramet schedul our current implement allow user updat hyper paramet valu thi take much user time for instanc let say base current loss curv user figur want drop learn rate nmbre nmbr nmbre nmbr next nmbr nmbr updat with current implement would make sever manual chang we want let user set updat hyper paramet schedul user manual interven necessari rewind often train dynam hyper paramet feel like experi sort like small hyper paramet search model train but thing go wrong want reset to enabl work simpl rewind undo option user could restart checkpoint coupl tap screen
init__27,MachineLearning,1620470429.0,[P] Video/Discussion on Building an Aircooled rig to accommodate 3x GPUs,video url http www youtub com watch v snmbr lmnmbrmzjnnmbr http www youtub com watch v snmbr lmnmbrmzjnnmbr nmbr hi everyon thi project start tri find guid effect air cool nmbr nmbr gpu dl box i find detail discuss pick correct part lot iter i abl build one i decid publish video discuss part reason behind select anyon could use templat build rig pc part list http pcpartpick com list gfgtfnmbr http www youtub com redirect event video_descript redir_token quffluhqanmbrnylpnduvnmzhldjvnmbrmldnsuunmbrnuonmbrmvrsqxxbqnmbrjtcnmbrttqnmbrozunmbrenfnpawfdvwnmbrzvfzgrnmbrpnmbraktdehdxbnmbrjpvnmbrotzedpntanmbrsnbnvxzkbuknmbrqjlsatlcotzemwrnmbruzhwdnmbrdhmkfsbmtiluzxcenmbrbvllyrgvcwuytmfvkytbzqvhoylfnxnmbrpozwnbttzdenunmbruq q http nmbra nmbrf nmbrfpcpartpick com nmbrflist nmbrfgfgtfnmbr note show correct gpu i msi game x trio nmbr msi ventu nmbrx anmbr other resourc apart i would highli encourag refer solid writeup u emilwalln http www emilwalln com p ml rig http www emilwalln com p ml rig well legendari tim detter blog http timdettm com http timdettm com happi answer qs tia
phenomenonical,MachineLearning,1620462828.0,[D] Tech stack and resources for a ML project,what would best tech stack resourc would i need potenti ml product assum input data alreadi store azur could possibl store intern server cloud provid end product would web app show predict map the web app would ideal regist user would collect light data user info activ machin learn model would collect new data retrain make new predict annual model mainten would done compani unless good idea the client municip administr budget small would provid url host we eu user data collect would need gdpr compliant background i solo ing data scientist msc data scienc actual ml work experi i seen preced tri get ml run larg nmbr nmbr person firm i came good idea weav ml tradit servic firm provid i need figur actual thing i done proof concept toy data gave promis result could end end product done within azur is cheaper option sinc ml model would need updat annual my compani difficulti fund innov tie directli client project i essenti budget i get client buy what team member would make sens bring should i outsourc part extern compani i handl model build i idea happen i make api broadcast predict there compani lawyer overse countri gdpr complianc sure much free time also i current work close develop ish person involv creat web app sure much technic knowledg whenev i press detail seem clue exampl never heard azur i mention he said someth use github web app
Daddy_Long_Legs,MachineLearning,1619199043.0,[D] Hyperparameter tuning with a budget constraint on total number of model parameters,is possibl hyperparamet framework i convolut network hypterparamet kernel size number layer number channel would like search paramet place limit total number paramet present model due i deploy i found paper http arxiv org pdf nmbr pdf could find code implement strategi ha anyon implement someth like alreadi facebook ax allow someth similar linear combin paramet tough sinc number paramet conv layer superlinear n nmbr k seem like common problem curiou well
MacaronFraise,MachineLearning,1619255019.0,[D] Improve KNN calculation time,hey guy i current work machin learn project use knn i perform issu at moment knn load flask server host heroku whenev i want make predict i send flask server paramet predict the problem i encount take much time make singl predict nmbr second for project i actual need make nmbr predict one go so i post order ask solut is way optim knn handl nmbr predict quickli or i host knn anoth host servic comput power adapt machin learn like azur all quit new thank lot help updat after test i realiz i use nmbrmb ram avail heroku i know normal figur i code optim use much memori
dptzippy,MachineLearning,1619208491.0,[D] What are some projects/tutorials that I could use to get started with ML?,hello everybodi i tri learn ml i improv i find project tutori explain exactli go i look free prefer written form tutori help other start ml side question i tri find way creat program model fed text file add vocabulari use gener text i find someth i sure i want see anybodi knew project framework tutori i new python ml i program sever year i might need dumb specif stuff i probabl understand broader concept thank
pircherth,MachineLearning,1619201704.0,[R] The structure dilemma in biological and artificial neural networks,the role intern structur inform process network artifici biolog base model structur chang learn we show structur lead edg weight structur problem exclus http www natur com articl snmbr nmbr nmbr nmbr
RchGrav,MachineLearning,1618790215.0,[D] I made a script that does all the work to deploy GPT-NEO on Windows 10. (Please Test),envis purpos window nmbr gpt neo local demo averag joe http gist github com rchgrav nmbrbbnmbranmbranmbrenmbrcenmbreanmbr http gist github com rchgrav nmbrbbnmbranmbranmbrenmbrcenmbreanmbr so deploy minicondanmbr configur base environ download run one gpt neo model either cpu cuda capabl devic gpu w cuda instal i chose minicondanmbr concept behind allow someon run gpt neo local experiment foundat base environ if work pleas report back detail thi privat gist moment i may put github page peopl say would benefit anyon window system struggl get work system go i start journey actual work machin learn hand i deploy script year it field some technic note the script instal use choco command model apt linux chocol org http chocol org bootstrap minicondanmbr use echo gener support script request elev reload path environ variabl one step process run script final script also creat exampl python file execut text gener text also condit main script run tri redeploy everyth drop gpt neo demo there note bottom gist help anyon look run gpu use larger transform model minimum recommend spec ton core nmbrgb fast storag nvme ssd suggest nmbrgb hdd space smaller model nmbrx bigger model nmbrx to run gpu i know i geforc rtx nmbr work sure need instal cuda nvidia much i know side note person i hope get gpt neo work jetson nano board even swap i think go realli tight fit sound like gon na cost nmbr i wan na pretend michael knight convers car p pleas share feedback thi may help other look quick easi bootstrap way play gpt text gener it mess anaconda sinc minicondanmbr run environ far i surmis i see mess anyth system
TheCockatoo,MachineLearning,1618909454.0,[D] How to do stratified train/test split for semantic segmentation?,in word ensur similar class distribut train test set sampl arbitrarili pixel class a b other pixel class b a
techsucker,MachineLearning,1618502126.0,"[R] Brown University Researchers Introduce DeepONet, A Model Based On Deep Neural Network, To Approximate Both Linear and Nonlinear Operators (Paper and Github link included)",research brown univers built deeponet novel neural network base model effici learn linear nonlinear oper thi novel model inspir earlier studi led research fudan univers a continu function abrupt chang valu more precis small chang continu function output assur restrict suffici small chang input mani studi show artifici neural network ann highli effici approxim continu function howev mani studi yet focus abil approxim nonlinear oper inspir paper publish chen chen fudan univers discuss function approxim use singl layer neuron research decid explor possibl build neural network could approxim linear nonlinear oper summari http www marktechpost com nmbr nmbr nmbr brown univers research introduc deeponet model base deep neural network approxim linear nonlinear oper http www marktechpost com nmbr nmbr nmbr brown univers research introduc deeponet model base deep neural network approxim linear nonlinear oper paper http www natur com articl snmbr nmbr nmbr nmbr http www natur com articl snmbr nmbr nmbr nmbr github http github com lululxvi deeponet http github com lululxvi deeponet
maroxtn,MachineLearning,1617669407.0,[D] Is there better options than beam search in translation ?,are better sampl strategi beam search use big compani translat googl translat when i train transform translat i get lot repeat ngram use beam search longer sentenc
crack_pop_rocks,MachineLearning,1620581059.0,Any suggestions for deep learning textbooks that have a neuroscience perspective? [Discussion],i wonder anybodi expert suggest textbook address deep learn neurosci perspect there sever good public subject i difficulti find someth comprehens i studi ml nmbr month pretti steadi progress start get neural network my background neurobiolog cognit neurosci fundament principl behind dlnn model architectur behavior alreadi familiar deep learn much statist orient neurosci given natur model eas access quantit data i actual surpris littl biolog system discuss referenc especi given much know variou mechan modul learn synapt integr dendrit tree http sci hub se nmbr neu nmbr function signific passiv activ dendrit properti synapt integr identifi nonspik interneuron crayfish http journal physiolog org doi full nmbr jn nmbr also phd read look jellyfish they primordi neural net compos ganglia anatom seem similar deep learn model architectur abstract jellyfish nerv net provid insight origin nervou system taxonom posit evolutionari age impli jellyfish resembl earliest neuron bear activ swim anim here develop first neuron network model nerv net jellyfish specif focu moon jelli aurelia aurita control energi effici swim motion the propos singl neuron model disentangl contribut differ current spike the network model identifi factor ensur non patholog activ suggest optim transmiss signal after model jellyfish muscl system bell hydrodynam environ explor swim elicit neural activ we find differ delay nerv net activ lead well control differ direct movement our model bridg scale singl neuron behavior allow comprehens understand jellyfish neural control locomot http elifesci org articl nmbr http elifesci org articl nmbr
bachier,MachineLearning,1617909974.0,"[D] CVPR 2021 paper ""The Affective Growth of Computer Vision""",http authent sice indiana edu public su _crandal affectivegrowthcv cvprnmbr pdf http authent sice indiana edu public su_crandal affectivegrowthcv cvprnmbr pdf author norman makoto su david j crandal abstract the success deep learn led intens growth interest comput vision along concern potenti impact societi yet know littl chang affect peopl research practic comput vision commun spend much effort tri replic abil human littl time consid impact work in paper report studi ask comput vision research practition write stori emot salient event happen our analysi nmbr respons found tremend affect emot strain comput vision commun while mani describ excit success found strikingli frequent feel isol cynic apathi exasper state field thi especi true among peopl share unbridl enthusiasm norm standard comput vision research see part incrowd our find suggest feel close tie kind research profession practic expect comput vision we argu commun signific statur need work toward inclus cultur make transpar address real emot toil member
uhtiloah,MachineLearning,1617282793.0,AutoLoss-Zero: Searching Loss Functions from Scratch for Generic Tasks,
cloudone,MachineLearning,1618589798.0,[R] Efficient Large-Scale Language Model Training on GPU Clusters,
ilia10000,MachineLearning,1617749313.0,"[D] Is ""data"" plural in modern machine learning literature?",as titl suggest i tri figur whether modern machin learn literatur consid data plural noun e g the data spars singular mass noun e g the data spars my phd supervisor argu plural form correct i feel like sound quit right least cs ml context hit ear googl search suggest plural form histor consid correct one gener usag data sever time higher usag data appar scientif literatur usag equal doe anyon statist comment topic specif contemporari machin learn literatur
givdwiel,MachineLearning,1616408714.0,[P] pyRDF2Vec 0.2.0 is out!,pyrdfnmbrvec nmbr nmbr thi releas pack mani new featur optim hood an entir overview new found changelog http github com ibcnservic pyrdfnmbrvec releas tag nmbr nmbr http github com ibcnservic pyrdfnmbrvec releas tag nmbr nmbr an overview major updat nmbr what rdfnmbrvec rdfnmbrvec techniqu gener embed node entiti knowledg graph often repres rdf format henc name the techniqu unsupervis therefor task agnost you gener embed node use multipl downstream task a concret exampl graph contain inform chemic compound exampl snippet data compound rdf dnmbr cytogen_sc rdf datatyp xsd boolean true cytogen_sc hasatom rdf resourc dnmbr _nmbr mouse_lymph rdf datatyp xsd boolean fals mouse_lymph amestestposit rdf datatyp xsd boolean fals amestestposit hasatom rdf resourc dnmbr _nmbr hasbond rdf resourc bondnmbr hasbond rdf resourc bondnmbr hasbond rdf resourc bondnmbr hasatom rdf resourc dnmbr _nmbr hasbond rdf resourc bondnmbr hasatom rdf resourc dnmbr _nmbr hasatom rdf resourc dnmbr _nmbr hasbond rdf resourc bondnmbr cytogen_ca rdf datatyp xsd boolean fals cytogen_ca compound which turn numer represent rdfnmbrvec http preview redd xdqhknmbrzevnmbrpnmbr png width nmbr format png auto webp nmbrenmbrdnmbranmbrdcnmbranmbrdnmbrcbnmbrddebnmbr nmbr rudimentari liter support in addit node embed pyrdfnmbrvec extract numer inform neighbourhood around node user specifi path predic follow obtain numer inform http preview redd wnmbrueuoevnmbrkonmbr png width nmbr format png auto webp cdnmbrfcnmbrcnmbrednmbrenmbrenmbreenmbrbanmbradnmbraenmbr nmbr onlin learn origin entir model train underli knowledg graph chang thi longer case pyrdfnmbrvec nmbr nmbr featur onlin learn updat embed model dynam http preview redd nmbrwasofiynmbrkonmbr png width nmbr format png auto webp nmbrdnmbranmbrenmbranmbrdfnmbrbnmbrfnmbranmbrenmbrfbnmbranmbrebnmbrfnmbrcnmbrd nmbr revers walk the origin walk algorithm extract children start certain root recurs in pyrdfnmbrvec nmbr nmbr parent extract well thi enabl better interact underli window use wordnmbrvec http preview redd rijlnmbrpdznmbrkonmbr png width nmbr format png auto webp nmbrcnmbrdnmbrbnmbrbfednmbrbnmbrfnmbrecnmbrfnmbrdeenmbrc nmbr blaze fast walk mani optim made hood speed walk extract optim includ multiprocess cach asynchron oper etc speedup order magnitud easili achiev http preview redd nmbrthhykcnmbrkonmbr png width nmbr format png auto webp nmbrecdnmbrdnmbrfnmbrcnmbrfaenmbrenmbrfbnmbrfnmbrbnmbr extra a blog post publish shortli moreov notic pyrdfnmbrvec increasingli use within differ studi great see we compil overview http pyrdfnmbrvec readthedoc io en latest post paper html http pyrdfnmbrvec readthedoc io en latest post paper html
hyunwoongko,MachineLearning,1616353077.0,[P]Summarizers: Easy to use controllable summarization package,http preview redd nmbrtlzfppwhfonmbr png width nmbr format png auto webp dabbnmbranmbrcnmbrenmbrfnmbrbafnmbrecfnmbrdnmbrf hello i studi natur languag process i made packag weekend i write post share i think might abl use well the packag name summar name suggest easi tool summar text howev summar support varieti control summar option like imag well varieti domain gener articl summari paper summari patent summari for inform pleas visit http github com hyunwoongko summar http github com hyunwoongko summar
davidbun,MachineLearning,1617030776.0,"[N] do well in a CVPR/Kaggle Plant Pathology Challenge, win $500",tl dr top nmbr team use packag activeloopai hub cvpr plant patholog kaggl challeng win nmbr hey r machinelearn my team i creat hub github com activeloopai hub http github com activeloopai hub the packag make unstructur dataset size access machin scale help seamlessli stream data pytorch tf local as part ongo effort support machin learn commun support team well year cvpr fgvcnmbr challeng start plant patholog challeng http site googl com view fgvcnmbr competit plantpathologychallengenmbr authus nmbr team place top nmbr challeng kaggl leaderboard use packag solut receiv nmbr for addit inform see wiki http github com activeloopai hub wiki hub plant patholog nmbr challeng let know here short notebook http github com mynameisvinn hub tutori blob master push nmbrplant nmbrpatholog nmbrdataset nmbrto nmbrhub ipynb use hub cvpr dataset featur hub might find relev challeng creat larg dataset huge nmbr nmbr x nmbr nmbr size array store local hub storag cloud collabor team dataset version control dataset api filter dataset get sampl need creat data pipelin transform data easili access visual slice dataset without download entir dataset directli plug hub dataset tensorflow pytorch start train transfer dataset across differ locat easili good luck davidbun
user01052018,MachineLearning,1616920279.0,[D] Pointer sentinel mixture model - Why is $P_{ptr}$ is $V$ dimensional?,i check paper http arxiv org ab nmbr http arxiv org ab nmbr in research paper said model capabl predict rare less frequent word also unseen word now i notic p _ ptr size v that mean way encod inform unseen word v size vector i wonder possibl unseen word when train consid v size vocabulari appear softmax vocabulari to clear suppos rnn vocabulari contain nmbr word reddit user unk now suppos i nmbr unseen word text like quora stackoverflow lichess wikipedia how would nmbr size vocabulari handl
ykilcher,MachineLearning,1616435112.0,[D] Paper Explained - Perceiver: General Perception with Iterative Attention (Full Video Analysis),http youtu p _xeshtnpzg http youtu p_xeshtnpzg inspir fact biolog creatur attend multipl modal time deepmind releas new perceiv model base transform architectur perceiv make assumpt modal input data also solv long stand quadrat bottleneck problem thi achiev latent low dimension transform input data fed multipl time via cross attent the perceiv weight also share across layer make similar rnn perceiv achiev competit perform imagenet state art modal make architectur adjust input data outlin nmbr nmbr intro overview nmbr nmbr built in assumpt comput vision model nmbr nmbr the quadrat bottleneck transform nmbr nmbr cross attent transform nmbr nmbr the perceiv model architectur learn queri nmbr nmbr posit encod via fourier featur nmbr nmbr experiment result attent map nmbr nmbr comment conclus paper http arxiv org ab nmbr http arxiv org ab nmbr
AerysSk,MachineLearning,1620222682.0,[D] A small dataset with high resolution?,hello everyon i test augment strategi current i use cifar small nmbrxnmbr visual result is dataset small size like nmbr imag smaller high resolut nmbrxnmbr mayb i use pytorch if code load i greatli appreci
MrAcurite,MachineLearning,1619615551.0,[D] Recommendations for increasing training stability with extremely small batches?,howdi folk i current situat batch size basic exceed nmbr if i cluster i abl much better i i thi i think lead stabil issu phenomena model take input homogen given step model simpli tri optim toward give appropri output gener rather condit what i tri should i bump beta adam optim hold onto gradient multipl batch appli ani idea
yashchandak,MachineLearning,1619781819.0,[R] Universal Off-Policy Evaluation,hi everyon i happi share first step toward univers polici estim uno one provid polici estim high confid bound paramet return distribut http arxiv org ab nmbr http arxiv org ab nmbr joint work scott niekum bruno silva erik learn miller emma brunskil phil thoma we use uno estim simultan bound mean varianc quantil median inter quantil rang cvar entir cumul distribut return polici counterfactu set we also discuss uno applic variou set includ fulli observ partial observ e unobserv confound markovian non markovian stationari smoothli non stationari discret distribut shift uno use mani critic applic requir think metric beyond expect return for exampl medic set tail sensit risk measur like valu risk cvar essenti avoid catastroph outcom onlin recommend metric like median inter quantil essenti tackl high nois data collect human machin interact metric like varianc entropi essenti quantifi uncertainti system outcom we believ bare scratch surfac direct welcom feedback
SeasonedLeo,MachineLearning,1617925125.0,Multi classification issue [R],hello all i work multi classif problem three class i use light gbm model my fnmbrscore test data set pretti good three class nmbr howev tri classifi use model new set model misclassif is huge i abl understand possibl happen ani pointer idea all dat featur thank help
dokluch,MachineLearning,1620367447.0,[D] Deploying ML model for inference on user devices,hi i would like creat simpl app coupl pre train ml model would run varieti user devic window maco machin nvidia amd even gpu are guidelin infrastructur i current look tflite i sure right way thank
cdossman,MachineLearning,1618397655.0,[D] Understanding Hinton‚Äôs Capsule Networks Series,whi capsul neural network architectur import intuit behind dive technic detail part i intuit http pechyonkin capsul nmbr part ii how capsul work http pechyonkin capsul nmbr part iii dynam rout between capsul http pechyonkin capsul nmbr part iv capsnet architectur http pechyonkin capsul nmbr
SrData,MachineLearning,1619252993.0,[D] Recovering images from bottlenecks or training dataset.,i wonder possibl gener imag use train cnn possibl gener imag input bottleneck do know paper post i could check i investig http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf imag compress spars code vs bottleneck autoencod although similar my point investig understand level privaci imag bottleneck produc imag store go beyond level privaci imag use train model
runcep,MachineLearning,1617622899.0,[D] Are there attempts at a large German-language LM?,i awar smaller attempt huggingfac german gpt nmbr model also zamia model i wonder univers research group project want build proper german languag lm size gpt nmbr xl model i especi interest learn train set made i saw the pile interest build open sourc model differ languag could find anyth german one ani hint appreci
AhmedAl93,MachineLearning,1617316167.0,[D][R] Solutions for handwritten text generation,hello the aim post discuss possibl solut synthet handwritten text gener specif constraint context current work data scientist french compani i encount issu deal handwritten text recognit mainli amount avail data simpli enough nmbrk imag handwritten text the first idea came mind gener larg artifici handwritten text dataset assembl singl handwritten charact check charsnmbrk dataset i made script take string input assembl charact imag provid imag contain handwritten text thi strategi gave realli promis result i train text recognit model call deep text recognit benchmark artifici dataset nmbrk imag finetun real dataset got nmbr accuraci howev even result good improv mainli gener handwritten text similar real one possibl i think use gan model problem need i lack first place big amount data do idea solv dilemma also i thought dilemma seen phd thesi propos i plan discuss manag share view would great
VeterinarianTight102,MachineLearning,1618891530.0,[P] Awesome Semantic Search,edit thank current support a repositori paper tool project librari dataset conf relat multimod semant search task current mainli text base stuff http github com agrovernmbr awesom semant search i believ plethora content relat topic less consolid one place
techsucker,MachineLearning,1618244638.0,[R] Researchers At The University of Tokyo Present A Frequency-Based Inpainting Method To Generate Missing Image Portions,research univers tokyo introduc frequenc base inpaint method use frequenc spatial inform gener miss imag portion imag inpaint comput vision cv techniqu fill miss pixel imag it allow remov unwant object photo recreat miss region occlud imag inpaint popularli use predict miss imag data howev difficult synthes miss pixel realist coher summari http www marktechpost com nmbr nmbr nmbr research univers tokyo present frequenc base inpaint method gener miss imag portion http www marktechpost com nmbr nmbr nmbr research univers tokyo present frequenc base inpaint method gener miss imag portion paper http www spiedigitallibrari org journal journal electron imag volum nmbr issu nmbr nmbr imag inpaint use frequenc domain prior nmbr nmbr jei nmbr nmbr full sso nmbr
andyljones,MachineLearning,1617866914.0,[R] Scaling Scaling Laws with Board Games,studi sequenc small problem let extrapol behaviour order magnitud larger problem paper http arxiv org ab nmbr tweet thread http twitter com andy_l_jon statu nmbr here work board game friendliest domain possibl scale behaviour but potenti show mani place if resourc constrain research i think realli promis avenu look keen hear thought
elbogotazo,MachineLearning,1617384423.0,Discovering column mappings [R],i challeng work work tri figur approach we intern system store transact data tabular form we receiv daili file data domain transact metadata column name standardis data field alway exact e g the amount field may nmbr digit behind comma system expect nmbr digit system call amount might call quantitynmbr incom file etc there multipl amount date free text categor field relationship field note sourc data come extern parti i control format incom file we manual map transform defin incom file volum differ format sourc ever increas im look way take input file train model predict column like correspond column target file i look thing use nlp spaci train model recognis pattern column data e g numer period comma like correspond amount i also look model data extract rdf represent use open sourc tool call karma see i train model network graph but realli struggl see implement regex would get us part way i realli tri see scalabl way implement is anyon awar formal name type problem tri test approach implement i could build upon
Mundane_Definition_8,MachineLearning,1619678595.0,"[D] I'm kaggler and hate waiting result, what makes you feel good?",hi guy usual programm i enjoy watch result immedi but ml although i want creat model i hate wait result i know i realli like ai my viewpoint make limit programm grow where happi point creat and what model train
marksteve4,MachineLearning,1617819843.0,[D] Does anyone use huggingface hosted interface?,i tri bunch mani disabl default but much use am i miss sth thought sourc hf make money
DietMediocre8993,MachineLearning,1617816736.0,[D] ML Engineer with Data Engineer,hello fellow enthusiast i upcom interview data engin role one round data scientist problem solv i sure focu prep even kind question i expect suggest it seem focu would around product de scientist work collabor togeth think
Yuqing7,MachineLearning,1617162546.0,[N] Microsoft & Princeton‚Äôs Text-Game Agents Achieve High Scores in Complete Absence of Semantics,a research team princeton univers microsoft research discov autonom languag understand agent capabl achiev high score even complet absenc languag semant indic current rl agent text base game might suffici leverag semant structur game text here quick read microsoft princeton surpris discoveri text game agent achiev high score complet absenc semant http syncedreview com nmbr nmbr nmbr microsoft princeton surpris discoveri text game agent achiev high score complet absenc semant an earli version paper read act blindfold the need semant text game agent featur neurip nmbr workshop http wordplay workshop github io modern wordplay when languag meet game the updat paper avail arxiv http arxiv org pdf nmbr pdf
tars9999,MachineLearning,1617288820.0,Mixture of experts - tradeoffs vs traditional single nets [D],i person surpris branch nn seemingli call mixtur of expert popular sucess techniqu eg imagenet entri appear recent stori is research compar train time model size evalu time nmbr dens net mixtur expert e g would pan tri imagenet eg nmbr branch nmbr categori nmbr vs nmbr also research tradeoff branch heirach moe like nmbr caterogi nmbrxnmbrxnmbr perhap particular problem optimum branch depth happen certain size optimum number branch nmbr i guess singl net work better i expect featur cooper attempt moe model common trunk share branch
jostmey,MachineLearning,1616375436.0,[R] Dynamic Kernel Matching for Non-conforming Data: A Case Study of T-cell Receptor Datasets,preprint http arxiv org ab nmbr http arxiv org ab nmbr abstract most statist classifi design find pattern data number fit row column like spreadsheet mani kind data conform structur to uncov pattern non conform data describ approach modifi establish statist classifi handl non conform data call dynam kernel match dkm as exampl non conform data consid dataset t cell receptor tcr sequenc label diseas antigen ii dataset sequenc tcr repertoir label patient cytomegaloviru cmv serostatu anticip dataset contain signatur diagnos diseas we success fit statist classifi augment dkm dataset report perform holdout data use standard metric metric allow indetermin diagnos final identifi pattern use statist classifi gener predict show pattern agre observ experiment studi
Yuqing7,MachineLearning,1617987945.0,"[N] TUM, Google, Nvidia & LMU M√ºnchen's CodeTrans Pretrained Models Crack Source Code Tasks With SOTA Performance",a research team technic univers munich googl nvidia lmu m√ºnchen propos codetran encod decod transform model achiev state art perform six task softwar engin domain includ code document gener sourc code summar code comment gener etc here quick read tum googl nvidia lmu m√ºnchen codetran pretrain model crack sourc code task with sota perform http syncedreview com nmbr nmbr nmbr tum googl nvidia lmu munchen codetran pretrain model crack sourc code task sota perform the codetran code avail project github http github com agemagician codetran the paper codetran toward crack languag silicon code through self supervis deep learn high perform comput arxiv http arxiv org ftp arxiv paper nmbr nmbr pdf
OnlyProggingForFun,MachineLearning,1619005027.0,[D] Will Transformers Replace CNNs in Computer Vision?,i recent wrote articl will transform replac cnn comput vision http pub towardsai net transform replac cnn comput vision nmbranmbr show transform appli text also imag type input i cover paper call swin transform http arxiv org pdf nmbr pdf give way appli transform architectur comput vision i know mani other quit promis like the perceiv http arxiv org ab nmbr question do think transform better suit comput vision convolut neural network are viabl comput time result compar cnn optim properti imag especi classif
m_nemo_syne,MachineLearning,1617723592.0,[R] Timers and Such: A Practical Benchmark for Spoken Language Understanding with Numbers,timer such new speech dataset timer alarm unit convers math use test speech model train offlin voic assist paper http arxiv org ab nmbr http co nmbritxnmbrkkvyo amp nmbr code speechbrain http github com speechbrain speechbrain tree develop recip timer http github com speechbrain speechbrain tree develop recip timer pre train model hug face http huggingfac co speechbrain slu timer direct librispeech asr http huggingfac co speechbrain slu timer direct librispeech asr
jj4646,MachineLearning,1618972573.0,[D] Complexity of Time Series Models: ARIMA vs. LSTM,nmbr when come time seri analysi i tri understand make newer model lstm capabl captur complex pattern data compar older modei arima in statist learn theori someth call vc dimens algorithm http en wikipedia org wiki vapnik enmbr nmbr nmbrchervonenkis_dimens vc dimens appar describ relart level complex machin learn algorithm captur doe concept vc dimens carri model time seri analysi is possibl show lstm higher vc dimens compar arima style model supposedli neural network base time seri model develop modeol like arima unabl provid reliabl estim bigger complex dataset mathemat speak allow lstm captur variat complex dataset compar arima nmbr late i seen mani peopl start suggest convolout neural network cnn also use purpos time seri forecast just gener question instanc would better use cnn time seri forecast compar lstm thank
AirZealousideal1342,MachineLearning,1618671696.0,[D]What is this in ontonotes dataset?,i found ontonot mani punctuat preced slash e g is error if fix verionnmbr http preview redd brnmbrpnmbrtngnmbrrtnmbr png width nmbr format png auto webp nmbrenmbrenmbrcbnmbrbenmbrbfnmbrenmbrabnmbrdfnmbrcnmbrbenmbrccnmbrdnmbr but normal http preview redd atckggnmbrvrvtnmbr png width nmbr format png auto webp anmbrednmbrdnmbrdnmbrenmbrbenmbrdbnmbrdnmbrdnmbrcnmbrdnmbr
Stingeymingey,MachineLearning,1617265463.0,[D] What's out there in terms of Video comprehension/understanding?,hi i wonder peopl could point paper project work video subsequ frame understand not object detect use previou frame context guid futur predict thank
cloudone,MachineLearning,1616563801.0,[N] Pieter Abbeel launched a new podcast,first guest andrej karpathi http www therobotbrain ai
BodybuildingPhD,MachineLearning,1616747965.0,[D] Does the NN really learns probability distribution?,i current tri understand neural net learn probabl distribut at first glanc seem imposs sinc basic neural net determinist non linear function as vae encod vae take x input result main paramet distribut mostli mean covari gaussian distribut thi seem plausibl ad random variabl epsilion n nmbr i construct normal distribut but decod though mani literatur assum decod form probabl distribut p x z yet unlik encod part random structur vae decod moreov mani decod vae assum normal distribut could sure is anyth i miss
Koyset,MachineLearning,1617640968.0,"[Discussion] ""Developers should take philosophy classes to make ethical AI""",hello commun i still third semest cs student alreadi rather confus workshop student job telecommun firm it start two consult undergrad social scienc code they provid us within day ai ethic guidelin develop implement work i ask make guidelin like de bia code make inclus algorithm function code sinc first job said i take addit philosophi class hidden bia how implement ethic guidelin code doe everi compani guidelin sorri i uncomfort ask question sinc i understand overal workshop hope provid real life exampl job
the21st,MachineLearning,1619516433.0,[P] I missed writing native SQL queries inside jupyter so I built a Python+SQL interop feature in our notebook tool,hi i simon engin deepnot previous i work ml team lead e commerc compani i recent built new featur deepnot i want brag littl bit i proud it nativ sql cell python interop check exampl project http deepnot com project rna explor duplic xlarwicernqqnmbridnmbrvnmbrrynmbra nmbrfnotebook ipynb full doc featur http doc deepnot com featur sql cell thi possibl thank stand shoulder open sourc giant panda jinjasql i huge appreci make truli happi i appreci feedback thought innov love see around notebook futur
New-Sound8660,MachineLearning,1616886907.0,[R] Teaching a machine to paint like a painter comparing photos and associated paintings,hello everybodi i approach ml i need guidanc here idea i set photo set human made paint base photo tri replic faith possibl photo can i give algorithm two set imag ask learn creat paint style painter ho realiz dataset start new photo ani suggest book articl cours blog i follow learn would greatli appreci thank much
vladiliescu,MachineLearning,1616591206.0,[D] [P] How do you use tools like AutoML?,hi girl guy i wonder use tool like automl day day life like anyth hnmbro googl automl auto sklearn ask sinc person i find automl use train initi baselin you know manag get dataset clean enough use itch see time need use someth lightgbm it alway lightgbm though alway anyway apart initi phase i realli use tool i work azur flavor http doc microsoft com en us azur machin learn concept autom ml least revers engin model take whatev i adapt whatev i take kinda like picasso http quoteinvestig com nmbr nmbr nmbr artist steal i imagin i written short ish blog post creat model base azur automl train one you find http vladiliescu net revers engin autom ml it focus time seri underli principl appli regress classif model hope like and i appreci feedback may i realli curiou use tool think approach
otso_ai,MachineLearning,1618355393.0,[P] otso Annotator - A cloud-based Text Annotator built for Machine Learning Engineers and Data Scientists working in teams.,otso launch annot built need mani sub check a cloud base text annot built machin learn engin data scientist we work otso annot two year it began intern tool use manag annot data label machin learn project as tool interfac develop began provid select enterpris custom we receiv much signific posit feedback client decid launch annot standalon product otso annot provid three key benefit user experi prioritis eas use understand the project manag featur let alloc manag annot task final cloud first tool longer need annot use cli get start make much easier tool team use whi focu user experi team text annot best done team environ ideal machin learn engin data scientist set run project subject matter expert provid annot we built otso annot differ user type mind enabl seamless project setup project admin easi keyboard enabl annot experi annot with public launch grant user team sign april extend trial period nmbr day to check head otso ai annot http otso ai annot no credit card requir
artificial_intelect,MachineLearning,1616734142.0,[P] NAS repos,when look git repo implement mnasnet efficientnet ever seem implement network found neural architectur search doe anyon know git repo implement proxim polici optim find efficientnet similar na algorithm repo
tanelai,MachineLearning,1618087578.0,[P] Using PyTorch + NumPy? A bug that plagues thousands of open-source ML projects.,use numpi random number gener multi process data load pytorch caus ident augment unless specif set seed use worker _init _fn option dataload i bug silent regress model accuraci how mani other bug done damag curiou i download hundr thousand repositori github import pytorch analys sourc code i kept project defin custom dataset use numpi random number gener multi process data load less straightforward analys use abstract syntax tree out nmbr repositori plagu problem it insid pytorch offici tutori openai code nvidia project even karpathi admit fall prey for exampl follow imag show duplic random crop augment get blindli follow offici pytorch tutori custom dataset http preview redd pccynmbrwskpesnmbr png width nmbr format png auto webp fnmbrdnmbradnmbrcbacnmbrcnmbranmbrdnmbrfanmbrddnmbr you read detail http tanelp github io post bug plagu thousand open sourc ml project
PT_Lightning,MachineLearning,1619457247.0,[N] Lightning Transformers - Train HuggingFace Transformers at scale with PyTorch Lightning,lightn transform http github com pytorchlightn lightn transform user want train evalu predict use huggingfac model dataset pytorch lightn full customiz code use lightningmodul trainer hydra config composit quick easi experiment no boilerpl code requir easili swap model optim schedul without touch code check blog post train transform scale pytorch lightn http pytorch lightn medium com train transform scale pytorch lightn enmbrcbnmbrfnmbrdbnmbr inform document http lightn transform readthedoc io http redd ufmoebjbwjvnmbr gif
Mephistothelessa,MachineLearning,1616657297.0,[D] What is the best way to publish an image dataset?,hello peopl as small team look around dataset need project find one so decid properli creat one publish peopl use futur we want properli publish dataset mean want use kaggl mayb dedic websit might work want look profession mayb github page may use what suggest what think best way publish dataset open suggest curiou guy think all input appreci cheer
artificial_intelect,MachineLearning,1616542211.0,[D] PipeMare paper discussion,mayb pipemar paper rant a back i read paper mitig effect asynchron pipelin train call pipemar http proceed mlsi org paper nmbr hash nmbrcnmbrccnmbraenmbrenmbrbnmbranmbrf abstract html their method seem novel super help i ignor paper then i notic accept confer mlsysnmbr so i guess worth put thought onlin pipemar propos two method mitig asynchron pipelin nn train issu nmbr type asynchron pipelin nn train mitig pipelin backpropag petrowski et al nmbr petrowski et al nmbr even cite paper just pipedream cite petrowski et al nmbr mean note pipelin backpropag nmbr issu inconsist weight delay gradient pipedream use weight stash elimin inconsist weight still delay gradient pipemar elimin overhead weight stash discrep correct realli deal delay gradient except use lr warmup the two method pipemar propos tnmbr learn rate reschedul type learn rate warm warm period base pipelin delay tnmbr discrep correct type backward weight predict reconcil weight use forward backward pass while tnmbr deal weight inconsist mitig gradient delay issu nmbr if tnmbr type learn rate warm paper show baselin run regular learn rate warm my guess regular learn rate warm would well new convolut method tnmbr issu nmbr in tabl nmbr pipemar paper show tnmbr work well tnmbr tnmbr whi use tnmbr it seem help overhead pipedream weight stash elimin weight inconsist tnmbr mitig weight inconsist elimin in nmbr chen et al http arxiv org ab nmbr propos method call spectrain in work show weight inconsist big issu elimin use weight stash useless if weight inconsist big issu shown spectrain paper use tnmbr especi sinc tabl nmbr show useless tnmbr novel evid simpl lr warm well tnmbr look like useless the method neither novel use how review mlsi see i mean paper interest the pipelin execut model interest the analysi interest mitig method ie paper contribut increment best how get person i think spectrain paper http arxiv org ab nmbr similar topic better mitig method analysi good much better paper publish conf note i author spectrain paper if anyon attend mlsysnmbr could question author point brought post my request question ask nice like i said analysi delay optim still realli interest explor world fine grain pipelin train ie actual explor non mainstream execut model even pipelin backpropag exist sinc nmbr realli use modern nn edit in paper figur nmbr figur nmbr show pipelin depth artifici increas larg tnmbr becom use point pipelin train hard time achiev accuraci sgd point mayb even use pipelin train
memgamemotron,MachineLearning,1619183370.0,[D] data science and ML bootcamp check!,anyon complet data scienc boot camp meti flatiron brain station gener assembl other i look see legit help land job data scienc complet boot camp they advertis nmbr hire rate top tech compani curiou anyon contribut thought
TopIndependent5791,MachineLearning,1618733779.0,[D] Which AWS tools/services are necessary to learn for Machine Learning Engineer?,what aw tool i need learn order qualifi industri i person involv machin learn colleg person project i feel i lack entri level industri knowledg what would right resourc aw
mgl96,MachineLearning,1617264240.0,[N] Trankit v1.0.0 - An open-source Transformer-based Multilingual NLP Toolkit for 56 languages is out.,hi everyon we releas version vnmbr nmbr transform base multilingu nlp toolkit name trankit outperform popular sota stanford nlp stanza mani task nmbr differ languag the new version vnmbr nmbr offer a trainabl transform base pipelin fundament nlp task nmbr languag nmbr new pretrain transform base pipelin nmbr languag the new pipelin train xlm roberta larg boost perform significantli nmbr treebank univers depend vnmbr corpu for english trankit significantli better stanza sentenc segment nmbr depend pars nmbr ua nmbr la for arab toolkit substanti improv sentenc segment perform nmbr chines observ nmbr nmbr improv ua la depend pars perform languag also significantli improv the detail comparison trankit stanza udpip spaci languag found http trankit readthedoc io en latest perform html univers depend vnmbr nmbr auto mode multilingu pipelin in auto mode languag input automat detect enabl multilingu pipelin process input without specifi languag check turn auto mode http trankit readthedoc io en latest news html auto mode multilingu pipelin command line interfac avail use thi help user familiar python program languag use trankit easili check command line tutori page http trankit readthedoc io en latest commandlin html trankit written python easili instal via pip our code pretrain model publicli avail http github com nlp uoregon trankit http github com nlp uoregon trankit we also creat document page demo websit trankit document page http trankit readthedoc io en latest index html http trankit readthedoc io en latest index html demo websit http nlp uoregon edu trankit http nlp uoregon edu trankit technic detail trankit found paper http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf thank time read post hope enjoy trankit
RyanAI100,MachineLearning,1620584248.0,[D] Pooled Contextualised Embeddings for NER | Research Papers Summary 017,
hardmaru,MachineLearning,1620197291.0,[R] MLP-Mixer: An all-MLP Architecture for Vision,
orenog,MachineLearning,1619488275.0,[D] Node Collapse with StyleGAN2 - ada,hey reddit i problem i train stylegannmbr ada nmbr hearthston card result amaz start look until got point gener nmbr card nmbr spell nmbr nmbr minion similar artwork i tri augment pipelin option got result it node collaps nmbr tick got less less variat went i want ask way deal node collaps and way deal node collaps specif stylegannmbr ada the dataset seem like lot variat nmbr card look similar part differ type card card uniqu artwork somehow gener artwork look nmbr tick i realli want work advic direct toward solut super help i even know caus thank edit appar mode collaps node collaps
Farconion,MachineLearning,1620326515.0,[D] Any value in negative / null results?,i middl complet small independ research project ml professor colleg ideal project aim reimplement replic result previou paper coupl year ago decent number citat nmbr extend upon work simpl worthwhil way howev reimplement code realli old pytorch compat hardwar run basic experi i fail replic even basic result i plan run experi confirm i get hope obvious number reason chang pytorch error implement i feel confid still etc tri write publish someth say techniqu x work i replic feel worthwhil correct doe anyon tip best way util null result like i hope use project part grad school app current state i sure best way frame even i
robust_melon,MachineLearning,1619475121.0,[D] ethical considerations with launching a website with vehicle accident density forecasts,i work project predict distribut accid citi local short term forecast horizon nmbr hour i wish creat public page dashboard updat hourli forecast assum i great model predict accid hot spot geograph like occur next hour ethic ramif forecast made public should i assum someon ill intent use inform crimin intent e g infer emerg respons resourc like edit bold emphasi
downtownslim,MachineLearning,1618939161.0,[R] The Power of Scale for Parameter-Efficient Prompt Tuning,
RyanAI100,MachineLearning,1619377883.0,[D] BERTweet (SOTA) for Named Entity Recognition in Social Media | Research Papers Summary 015,
biotechdood,MachineLearning,1617993459.0,[D] Looking for an interesting paper in the field of biotech and AI,hi i present chosen paper day look revolutionari scientif discoveri contain ai domain bio biotech pharma bioprocess engin etc i would realli thank could help ideal complic laymen come bio area i would appreci someth supposedli revolutionari alphafold nmbr thank advanc kind regard i would also appreci paper recommend field comput vision microscopi
hotpot_ai,MachineLearning,1617654345.0,[D] Overview on SOTA methods for deep learning model compression,intro thi post cover model infer optim compress breadth hope depth march nmbr thi includ engin topic like model quantiz binar research orient topic like knowledg distil well well known hack each year larger larger model abl find method extract signal nois machin learn in particular languag model get larger everi day these model comput expens runtim memori costli serv custom slow larg function edg environ like phone research practition come mani method optim neural network run faster less memori usag in post i go cover state art method if know anoth method think includ i happi add thi slight pytorch bia haha i familiar url http rachitsingh com deep learn model compress http rachitsingh com deep learn model compress
federico-bianchi,MachineLearning,1620243697.0,[N] Coveo SIGIR Data Challenge for Ecommerce,for interest coveo http www coveo com organ sigir data challeng use appli deep learn ml skill one biggest ecommerc dataset ever releas includ fine grain shop behavior search queri click unclick item product meta data catalog great chanc get creativ write research paper challeng websit http sigir ecom github io data task html repositori http github com coveooss sigir ecom data challeng import date registr end june nmbrst nmbr final leaderboard june nmbrth nmbr sigir ecom full day workshop juli nmbrth nmbr
Chriscbe,MachineLearning,1617135089.0,[R] Please point me in the right direction: decision trees or possibly something better,ml practition i scientist studi purifi recombin protein i gener profici python i look way fortifi decsion make purif protein creat e coli cell cultur what part ml would best learn order improv plan decis make decion tree like format i seen literatur issu i like start point i understand exampl part sci kit learn might address issu etc thank help
amaigmbh,MachineLearning,1620394984.0,"[N] i.am.ai Newsletter - Updated AI Conference Calendar, Crowdsourced Speech Recognition, Dinos and more",hello http www youtub com watch v eaemskzqgag share latest edit http www ai en blog newslett nmbr utm_campaign newslett nmbr post r machinelearn utm_medium social utm_sourc reddit ai newslett hope interest annoy self promot read whole thing feel free subscrib http ai newslett utm_campaign newslett nmbr post r machinelearn utm_medium social utm_sourc reddit feedback welcom what import iclr nmbr confer the landmark deep learn confer iclr http iclr cc take place may nmbrrd may nmbrth for second time gather held complet virtual research around world gather poster session keynot workshop out nmbr paper nmbr accept confer the offici outstand paper award award nmbr paper except qualiti lead confer you find full list http iclr conf medium com announc iclr nmbr outstand paper award nmbraenmbrab meanwhil topbot made select iclr confer paper breakthrough potenti these includ visual transform vit detr deberta perform paper previous introduc newslett read breakthrough paper topbot com http www topbot com iclr nmbr research paper more come iclr mark begin annual confer summer with global health situat improv slowli confer move virtual meet find updat version ai confer calendar import ai confer http www ai en blog ai confer nmbr utm_campaign newslett nmbr post r machinelearn utm_medium social utm_sourc reddit http preview redd ynmbrrbhnmbrecpxnmbr png width nmbr format png auto webp dnmbrbcnmbrcbnmbrenmbrabccnmbrbdnmbranmbrdnmbrfnmbr thing we found worth share contribut the crowdsourc project common voic aim creat free databas speech recognit nmbr languag sinc nmbr mozilla ask volunt record sampl sentenc review record other they recent saw usd nmbr million invest nvidia continu look particip contribut switch languag top right http commonvoic mozilla org en a person recommend amai http linkedin com compani amai gmbh ceo j√ºrgen stumpp http www linkedin com juergen stumpp the book real world ai a practic guid respons machin learn provid execut quick thorough overview step necessari success ai project moreov help soon univers graduat prepar work field in book http www goodread com book show nmbr real world ai alyssa rochwerg director product blue shield appen cto wilson pang share practic experi present approach claim nmbrx higher success rate ai project compar industri averag learn real world ai a practic guid respons machin learn author interview http www forb com site tomtaulli nmbr nmbr nmbr real world ai great guid manag paper dino in paper emerg properti self supervis vision transform arxiv http arxiv org ab nmbr research inria facebook ai sorbonn univers introduc dino short self di stillat label method segment imag self supervis manner mean without label requir upfront read dino accompani paw venturebeat com http venturebeat com nmbr nmbr nmbr facebook detail self supervis ai segment imag video facebook ai blog ai facebook com http ai facebook com blog dino paw comput vision self supervis transform nmbrx effici train one man paper discuss group yannic kilcher walk viewer paper detail nmbr minut youtub com http www youtub com watch v hnmbrijnmbrfnmbrcpik these self attent map select head gener use dino video hors bmx rider puppi fish boat facebook ai http reddit com link nnmbryspn video xghumnmbrcpxnmbr player market microsoft acquir nuanc april massachusett compani focuss ai driven speech recognit at usd nmbr billion merger mark second highest acquisit microsoft histori linkedin acquir nmbr billion nmbr nuanc commun behind speech recognit capabl appl voic assist siri more axio com http www axio com microsoft readi deal frenzi bbcnmbranmbr fdnmbrb nmbranmbr nmbrdnmbr cfnmbrdnmbranmbr html regul the european commiss releas artifici intellig act nmbr page http digit strategi ec europa eu en librari propos regul lay harmonis rule artifici intellig artifici intellig propos regul ai more propos legisl hurdl ahead politico eu http www politico eu articl nmbr key battl europ ai law artifici intellig act outsid eu chines regul begun enforc data local local compani from data store china certain applic facial recognit biometricupd com http www biometricupd com nmbr china push standard face biometr plenti tongu cheek after xkcd http xkcd com nmbr post nmbr type scientif paper natasha jaqu http twitter com natashajaqu max kleiman weiner http twitter com maxhkw two phd mit put togeth nmbr type machin learn paper http twitter com natashajaqu statu nmbr xkcd edit natasha jaqu http preview redd nmbrmownmbrenmbrcpxnmbr jpg width nmbr format pjpg auto webp nmbrbnmbracefnmbranmbrbanmbrbnmbrebaefnmbranmbr brief nmbr graph you need see understand ai nmbr in last issu share stanford nmbr ai index report http hai stanford edu research ai index nmbr from eliza strickland take nmbr visual highlight import develop scroll ieee org http spectrum ieee org tech talk artifici intellig machin learn state ai nmbr graph educ one best educ resourc ai andrew ng deep learn special coursera the cours receiv nmbr updat all program exercis tensorflow nmbr syllabu includ transform network find updat cours coursera org http www coursera org special deep learn event may nmbr onlin nmbr nmbr cet how ai turn exist busi model upsid down join onlin interact hear astonish input disrupt ai busi model harvard post doc johann merantix lab organ ki garag fro institut entrepreneurship innov research stuttgart univers partner german digit hub initi regist http www bwstiftung de de veranstaltungen ai turn exist busi model upsid
czhu12,MachineLearning,1617908894.0,[P] A torchvision transforms visualizer,the torchvis transform librari use almost cv project document bit hard visual i threw app togeth http pytorch transform builder chriszhu teammat also found use i figur i share commun it built streamlit host googl cloud run i found nice way deploy kind thing see http pytorch transform builder chriszhu let know use anyon els i happi spend weekend make better help http preview redd nneznmbrsvnmbrzzrnmbr png width nmbr format png auto webp fcnmbrenmbranmbrffnmbrenmbrbnmbrbnmbrfnmbrafnmbrdnmbreenmbrfnmbr http preview redd gnmbrcktqvnmbrzzrnmbr png width nmbr format png auto webp nmbrafnmbrcnmbrfcnmbrfnmbrcnmbrcnmbranmbrabnmbrbbnmbrenmbr
Combination-Fun,MachineLearning,1617887342.0,[R] Video explaining Normalization Free Nets paper,here video explain idea nf net paper titl high perform larg scale imag recognit without normal hope use enjoy http youtu azkfgjrbrnmbro http youtu azkfgjrbrnmbro
jary93,MachineLearning,1620411298.0,Structured Ensembles: an Approach to Reduce the Memory Footprint of Ensemble Methods,
ashubham,MachineLearning,1617060191.0,[P] Prediction Trees in Pure Javascript,i recent learnt compact predict tree thought would great use case web browser henc built librari http github com ashubham cpt http github com ashubham cpt feedback welcom
PeupleDeLaMer,MachineLearning,1618982723.0,[R] Looking for Paper Recommendations for characterising model performance/ Assurance,hello i rel new ml research i read literatur help user characteris perform model order understand point input space consid reliabl point some exampl includ algorithm assur http paperswithcod com paper algorithm assur activ approach adversari attack http openai com blog adversari exampl research exactli i right track i found huge amount work relat i figur i ask
techsucker,MachineLearning,1617380494.0,[N] Introducing PyTorch Profiler ‚Äì The New And Improved Performance Debugging Profiler For PyTorch,the analysi refin larg scale deep learn model perform constant challeng increas import model size owe lack avail resourc pytorch user hard time overcom problem there common gpu hardwar level debug tool pytorch specif background oper avail user merg multi tool appli minim correl inform manual make sens data retriev miss inform the pytorch profil came rescu open sourc tool precis effici troubleshoot perform investig larg scale deep learn model summari http www marktechpost com nmbr nmbr nmbr introduc pytorch profil new improv perform debug profil pytorch http www marktechpost com nmbr nmbr nmbr introduc pytorch profil new improv perform debug profil pytorch sourc http pytorch org blog introduc pytorch profil new improv perform tool
hyunwoongko,MachineLearning,1617286558.0,"[P] Asian language BART models (English, Chinese, Japanese, Korean and ECJK mixed)",http preview redd wznspjnmbrklkqnmbr png width nmbr format png auto webp anmbracnmbrafnmbrdnmbrabnmbrfnmbrfnmbrdnmbrbfnmbranmbrenmbr hello i hyunwoongko studi natur languag process in mani asian languag chines korean japanes pre train sequenc sequenc model necessari current lack so i made chines japanes korean english bart model prune embed layer facebook mbart model the mbart model multilingu languag model nmbr languag howev need one languag e g japanes mbart vocab token embed unnecessari take space therefor i organ necessari token languag model use monolingu set pleas check follow link detail usag http github com hyunwoongko asian bart http github com hyunwoongko asian bart
kongxianxingren,MachineLearning,1620585692.0,[D] Are Centroidal Voronoi tessellation and Voronoi tessellation unsupervised learning in machine learning?,the centroid voronoi tessel cvt special type voronoi tessel gener point voronoi cell also centroid center mass it view optim partit correspond optim distribut gener the voronoi tessel partit plane region close given set object the follow simpl pictur centroid voronoi tessel i found wiki http en wikipedia org wiki centroidal_voronoi_tessel http preview redd ircxpnmbrxrnmbrynmbr png width nmbr format png auto webp nmbrafnmbrbnmbrdnmbrfnmbrenmbrcnmbrbaaanmbrenmbrfnmbranmbrdnmbr for like k mean algorithm conclud cluster method unsupervis learn am i right the reason i ask i see anybodi relat cvt machin learn algorithm
Uncommented_python,MachineLearning,1616368763.0,[D] An example of machine learning bias on popular. Is this specific case a problem? Thoughts?,
mrathi12,MachineLearning,1618417597.0,[D] Addressing Gender Bias in Neural Machine Translation,hey everyon i made video discuss fix bia neural machin translat http youtu pnmbrfjlmfnmbrfw http youtu pnmbrfjlmfnmbrfw everi often get viral tweet come assign gender gender neutral languag like hungarian googl translat default stereotyp translat thi video look evalu gender bia use dataset winomt http www aclweb org antholog pnmbr nmbr pdf http www aclweb org antholog pnmbr nmbr pdf discuss current solut googl translat add intellectu debt final i believ practic approach debias larg languag model domain adapt http arxiv org ab nmbr http arxiv org ab nmbr person i think curat larg dataset scale need impract much practic fine tune small curat dataset http link springer com articl nmbr snmbr nmbr nmbr nmbr http link springer com articl nmbr snmbr nmbr nmbr nmbr would interest hear thought think practic approach debias twitter thread discuss http twitter com mukulrathi _ statu nmbr nmbr http twitter com mukulrathi_ statu nmbr nmbr transcript http mukulrathi co uk googl translat bias http mukulrathi co uk googl translat bias
CrypticParagon,MachineLearning,1617351673.0,[D] When does stratified k-fold cross-validation provide worse performance than standard k-fold?,i use sklearn train random forest model default paramet the dataset nmbrk data point nmbr featur binari classif nmbr nmbr all nmbr featur simpl likelihood label nmbr given specif valu categor featur i use built cross valid nmbr fold the thing i chang standard vs stratifi stratifi perform slightli wors whi would
jj4646,MachineLearning,1619239890.0,"[D] Relationship Between Kernels, Neural Networks and Gaussian Process",at initi artifici neural network ann equival gaussian process infinit width limit thu connect kernel method can someon pleas provid intuit exampl sort connect neural network gaussian process kernel thank sourc http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf
Seankala,MachineLearning,1620131965.0,[D] Do you guys take out time to study math?,for month i take time everyday studi math i nmbrth semest msc degre undergrad background stem i alway feel like i lack strong mathemat foundat also i read paper lot mathemat formul sometim i get intuit understand equat mean often take hour even day googl i curiou whether anyon els goe way brush studi math stuff sometim feel futil i tri tell otherwis
jj4646,MachineLearning,1619239577.0,[D] Automatic Feature Engineering during Deep Learning,i often heard one reason deep learn method prefer machin learn method algorithm like deep neural network requir analyst spend much time select variabl model e featur engin featur select featur extract appar deep neural network abl intellig background consid creat mani differ combin featur conduc model problem natur i curiou claim intuit i understand hidden layer weight activ function neural network make new combin featur pass forward ultim use make predict new data beyond i sure think refer paper document either theoret empir deep neural network abl larg take care task featur engin compar tradit algorithm like regress model decis tree random forest have experi done mani irrelev featur ad dataset deep neural network abl ignor
NotThatGuy97,MachineLearning,1617633514.0,[D][P] Feedforward Noise Cancelling Project. Looking for some advice before i dive into details.,hi i beginn ml finish one minor project yet use simpl neural network now i head toward new project complex search good approach sinc i much experi i want introduc project hope idea which approach make sens nn rnn rl altern approach the main goal project find paramet amplitud a _i phase p _i fix frequenc nmbrhz nmbrhz sinusoid signal gener the gener signal ad main signal order cancel nois consist n x nmbrhz frequenc basic nois channel problem solv feedforward algorithm the input measur durat nmbr nmbr second main signal if fourier transform fft perform amplitud nmbrhz harmon nmbrhz nmbrhz nmbrhz clearli observ fft with correct a _i p _i amplitud frequenc suppress frequenc compens addit introduc signal creat signal gener the goal find perfect a _i p _i frequenc the first measur shown fft _amplitud frequenc uniqu minimum found gradient toward minimum observ simplifi fft _amplitud a _i nmbr p _i nmbr the loop optim would look like nmbr measur main signal fft nmbr input n x nmbr array fftamptitud _nmbr fftamptitud _n nmbr optim algorithm nn rnn rl nmbr output n x nmbr array a _nmbr p _nmbr a _nmbr p _nmbr a _n p _n nmbr signal process nmbr measur main signal ad signal the loss function could look like loss sum fftamptitud _i tri minim loss function sinc fft _amplitud a _i nmbr p _i nmbr train simul creat order pre train algorithm i hope i made situat clear one problem the output array paramet loss function calcul measur point nmbr see i would treat output layer order get backpropag work right pleas add advic furthermor algorithm alway wait measur is issu i want use kera what think are nn rnn rl capabl solv task which would best approach what problem see do know compar project paper pleas share
timscarfe,MachineLearning,1618582221.0,[D] Francois Chollet interview on ML Street Talk,in today show join francoi chollet he extrem interest view intellig generalis abstract inform convers ratio he wrote measur intellig end nmbr huge impact think he think nn model continu problem well smooth learnabl manifold mani type nmbr problem involv reason plan suitabl nn he think mani problem type nmbr type nmbr enmesh togeth he think futur ai must includ program synthesi allow us generalis broadli exampl search could guid neural network search space interpol extent video http youtu jnmbrp _thjjnoo http youtu jnmbrp_thjjnoo pod http anchor fm machinelearningstreettalk episod nmbr francoi chollet intellig generalis evnmbrinmbr http anchor fm machinelearningstreettalk episod nmbr francoi chollet intellig generalis evnmbrinmbr
anon-burner-5981,MachineLearning,1620412872.0,[D] Parting Gifts for Lab Director and Ph.D. Student,i spent last two year work amaz lab next year i leav they tremend impact i like abl give someth show appreci what would good gift mentor ph d student
Square365,MachineLearning,1617649803.0,[D] Good video dataset labeling services? (Frame By Frame),hello sort new ml i tri make dataset train imag recognit yolovnmbr week im use darklabel aproxim nmbrk frame nmbr video label im plan label anoth nmbr i would like know good servic label rate i seen amazon mturk box imag video topic i got estim someon will nmbrvideo nmbr i would like get opinion
AristocraticOctopus,MachineLearning,1619491330.0,[N] Toyota subsidiary to acquire Lyft's self-driving division,after zoox sale amazon uber layoff ai research look grim self drive commerci i doubt mani sub terribl surpris given difficulti problem still sad see anoth one bite dust person i fan comma ai technic approach human polici clone i still think dozen high qualiti research paper away superhuman drive agent interest see peopl valu divis lyft receiv total approxim nmbr million cash transact nmbr million paid upfront subject certain close adjust nmbr million payment five year period the transact also expect remov nmbr million annual non gaap oper expens net basi primarili reduc r d spend acceler lyft path adjust ebitda profit
Symbiot10000,MachineLearning,1618176734.0,[D] Practical benefits of unlocking vGPU functionality in NVIDIA cards for ML?,over weekend lot attent http news ycombin com item id nmbr given http old reddit com r hardwar comment mnordnmbr unlock_vgpu_functionality_for_consumer_grade_gpu new softwar method http github com dualcod vgpu_unlock unlock vgpu function consum nvidia card what mean anyth smaller ml outfit could divid gpu resourc across vm subdivid gpu across differ ml task
Competitive-Rub-1958,MachineLearning,1618587934.0,[D] Can some other organization/company replicate GPT-3 for their own use?,gpt nmbr creat much new innov per se overfit model huge amount data larg number paramet probabl base predecessor architectur less so easi compani like googl faang compani replic gpt nmbr size nlp model use but million dollar question inde easi much advantag openai prevent googl launch new model bigger better offer consum cheaper openai ms
lukeiy,MachineLearning,1617422679.0,[P] A TF implementation of AdamW with a One-Cycle policy,http preview redd nmbrwucnmbrrluvqnmbr png width nmbr format png auto webp nmbrbnmbrcnmbrbcnmbrfbnmbrenmbrfdnmbreacnmbrcnmbrenmbrccnmbr http github com lukebolli onecycleadamw http github com lukebolli onecycleadamw when articl fast ai http fast ai origin post recept mix i recent implement though model sped train remain stabl higher learn rate i ad small exampl compar regular adam adamw let know issu cheer
proximauri,MachineLearning,1616976163.0,[D] Face recognition: classification vs distances between embeddings,hi i new face recognit method i notic one popular approach use pre train model new dataset measur distanc two embed i understand howev prefer use pre train network without top layer fine tune new fulli connect layer top model honestli i even understand train model first approach could someon clarifi pleas
alexandrea_pierrick,MachineLearning,1617958906.0,[D] Unsupervised document similarity state of the art,i set n document length rang nmbr nmbr charact i want calcul similar score nmbr nmbr pair document higher number indic higher similar assum deploy supervis model infeas due resourc constraint necessarili data scienc relat gather label expens infrastructur approv supervis model whatev reason etc approach i consid nmbr tf idf nmbr smooth invers frequenc sif embed develop usif p sif http openreview net pdf id syknmbrvnmbrxx http openreview net pdf id syknmbrvnmbrxx http www aclweb org antholog wnmbr nmbr http www aclweb org antholog wnmbr nmbr http arxiv org ab nmbr http arxiv org ab nmbr nmbr bert bert like embed e g http arxiv org ab nmbr http arxiv org ab nmbr nmbr hierarch optim transport document represent hott http paper nip cc paper nmbr hash nmbrbnmbranmbranmbrbafnmbrenmbrenmbrcnmbrenmbranmbrbnmbr abstract html http paper nip cc paper nmbr hash nmbrbnmbranmbranmbrbafnmbrenmbrenmbrcnmbrenmbranmbrbnmbr abstract html question is unsupervis techniqu shown peer review set achiev higher accuraci fnmbr similar long text say nmbr charact hott background the hott paper benchmark variou approach k nn classifi show hott perform best dramat better tf idf hott nmbr vs tf idf nmbr normal error note hott algorithm unsupervis dataset paper label otherwis benchmark would possibl the sif paper mostli deal st dataset long text p sif benchmark reuter dataset use svm supervis approach interestingli hott paper find sif perform well k nn approach nmbr normal error in mani case bert requir pre train max averag pool perform pool bert layer appear wors glove embed http arxiv org ab nmbr http arxiv org ab nmbr page nmbr i also abl find unsupervis benchmark docnmbrvec univers sentenc encod use there addit question calcul similar embed obtain e g http www aclweb org antholog nnmbr nmbr pdf http www aclweb org antholog nnmbr nmbr pdf scope question unless affect comparison unsupervis benchmark e g k nn approach use variou distanc metric may affect accuraci if benchmark hott repres method exist perform substanti better tempt make conclus tf idf still strong approach sinc simpl implement understand certainli simpler hott if case i think remark conclus given deep learn develop last nmbr nmbr year edit ad pool bert layer
noodlepotato,MachineLearning,1619701885.0,[D]Anyone reading Probabilistic Machine Learning: An Introduction? (Murphy's new textbook),alreadi post r learnmachinelearn answer how far is addit differ edit like notat wise i heard first edit pretti inconsist notat i ask i plan buy nmbr machin learn probabilist perspect physic book check tabl content new one i might consid buy physic book edit instead just want know other think read
Guest_Basic,MachineLearning,1617344944.0,[D] AUC vs F-measure for binary classification for unbalanced target variable,i work build binari classif predict model my target variabl extrem unbalanc nmbrk nmbr nmbrmillion nmbr as i understand auc good metric evalu model f measur might better altern question nmbr assumpt correct the model i built decent auc nmbr realli low f measur nmbr thi make think i actual built realli bad model howev exist publish literatur claim auc nmbr none report f measur question nmbr if goal build better model current exist i take victori lap right
amourav,MachineLearning,1619529111.0,[D] Distributed data platform / framework,what thought aw sagemak horovod distribut data train what method choic
moajjem04,MachineLearning,1618508700.0,[D] Best Literature Review Practices,my supervisor assign new topic research typic project i mostli handl experi part thi time i thought i literatur review well i know huge defici part i want know best practic do ts beyond search googl scholar keyword tl dr help senpai provid knowledg
SlickBlueML,MachineLearning,1619025945.0,[P] Multilingual translation like Google Translate with PyTorch (+explanation),i recent put togeth tutori multilingu translat i think code alon might use peopl it includ demo play around get run support chines japanes english right bat with small amount train work surprisingli well i colab need worri setup use if use non pro version colab though make sure chang model repo googl mtnmbr base googl mtnmbr small els get memori error cuda github code http github com ejmejm multilingu nmt mtnmbr blob main nmt _full _version ipynb http github com ejmejm multilingu nmt mtnmbr blob main nmt_full_vers ipynb colab code http colab research googl com drive nmbregscodnmbrsjwd _yofwbnmbrkmjoedzgunmbrlp usp share http colab research googl com drive nmbregscodnmbrsjwd_yofwbnmbrkmjoedzgunmbrlp usp share there also video seri goe anyon interest http www youtub com watch v huzqnmbrkklxnmbrq list pl _nmbrvdnmbrkwq _obgmwnmbrgnmbrhmolndynmbrnhvnmbr index nmbr nmbr http www youtub com watch v huzqnmbrkklxnmbrq list pl_nmbrvdnmbrkwq_obgmwnmbrgnmbrhmolndynmbrnhvnmbr index nmbr nmbr
wecmiw,MachineLearning,1618074938.0,[D] How do you share your models/ demos with others?,hi i phd student work deep learn i often show demo model i current simpli share result present use notebook i want show explicit experi spot is anoth way i could see done lot especi industri talk mani stakehold i awar gradio i wonder way ani insight appreci
hubert0527,MachineLearning,1617996004.0,[R] InfinityGAN: Towards Infinite-Resolution Image Synthesis,synthes infinit resolut imag finit resolut input a nmbr nmbr imag compos nmbr patch independ synthes infinitygan spatial fusion two style the gener train nmbr nmbr patch e g mark top left sampl nmbr nmbr real imag note train infer resolut perform singl gtx titan x gpu http preview redd nmbrdrmgnmbreznmbrsnmbr png width nmbr format png auto webp nmbrdnmbranmbraanmbrcnmbrenmbrenmbranmbrenmbrcnmbrbnmbrenmbrb tl dr we propos infinitygan toward new problem synthes infinit resolut imag the model train imag limit resolut gener arbitrari resolut test we demonstr sever applic train gener spatial style fusion imag outpaint imag inbetween project page http hubertnmbr github io infinitygan http hubertnmbr github io infinitygan paper http arxiv org ab nmbr http arxiv org ab nmbr we releas code soon http github com hubertnmbr infinitygan http github com hubertnmbr infinitygan
SensitiveAnteater420,MachineLearning,1616960506.0,[D] Would it be possible to make a model that predicts where a picture is taken?,i love osint geoloc i python dev wonder i extend boundari the titl self explain is possibl make model predict pictur taken exist dataset
InsightFinder,MachineLearning,1617028825.0,[News] Women in computer science leadership talk on 4/9,event alert women tech leadership discuss exec bank america dell insightfind on april nmbr nmbr nmbr am est insightfind cto founder helen gu particip women tech leadership panel host nc state women comput scienc wic organ professor gu teach nc state also faculti leader wic she join industri leader liz holland vice presid dell technolog betsi bradi manag director bank america moder nc state professor wic faculti leader dr lina battestilli these leader agre share stori includ limit earli career decis watersh career moment would advis young student profession today all welcom attend to join regist websit form http insightfind com event googl form http doc googl com form e nmbrfaipqlsenmbrhyyvpgljvqiwoblsnmbrifmcztdgrynrznmbryotnmbrmnnmbrcnnmbrwrnmbrg viewform
asivokon,MachineLearning,1617719141.0,[N] Grammarly releases a grammatical error correction (GEC) dataset for the Ukrainian language,thi dataset contain nmbr nmbr sentenc annot grammat error fluenci correct the licens cc by nmbr thi blog post provid context http www grammarli com blog engin announc ua gec http www grammarli com blog engin announc ua gec the data code github http github com grammarli ua gec http github com grammarli ua gec paper draft http arxiv org ab nmbr http arxiv org ab nmbr i one author happi answer question
shreyansh26,MachineLearning,1620580380.0,[P] BERT - Annotated Paper + Paper Summary,everyon interest nlp even dl ml matter definit heard bert famili model bert roberta distilbert mani mani thi paper bert pre train deep bidirect transform languag understand first introduc complet chang way ai practition solv look nlp problem day as part paper note seri i gone paper creat inform summari paper thi time goe bit longer previou paper summari done the paper contain mani tini interest nugget i includ check link happi read paper summari bert pre train deep bidirect transform languag understand http shreyanshnmbr github io post nmbr nmbr nmbr_pretraining_deep_bidirectional_transformers_bert annot paper http github com shreyanshnmbr annot ml paper blob main bert pdf http github com shreyanshnmbr annot ml paper blob main bert pdf
techsucker,MachineLearning,1618972153.0,[R] Researchers Introduce a Convolutional Neural Network (CNN)-Based Model that Automates the Distinction Between Natural Images and Computer-Generated Images (CGI),with increas perform accuraci comput softwar system realist appear comput gener imag cgi deepfak often lead assum authent imag research changsha univers scienc technolog hunan univers hunan china recent develop imag sourc pipelin forens method base convolut neural network cnn autom distinct natur imag cgi the work announc intern journal autonom adapt commun system describ cnn base model fine tune use databas nmbr imag summari http www marktechpost com nmbr nmbr nmbr research introduc convolut neural network cnn base model autom distinct natur imag comput gener imag cgi http www marktechpost com nmbr nmbr nmbr research introduc convolut neural network cnn base model autom distinct natur imag comput gener imag cgi paper http www indersci com offer php id nmbr
Yuqing7,MachineLearning,1617064776.0,[N] DeepMind & Alberta U Introduce Novel Search Algorithm: Policy-Guided Heuristic Search with Guarantees,a research team deepmind alberta univers propos polici guid heurist search ph novel search algorithm use heurist function polici offer guarante search loss relat qualiti heurist polici here quick read deepmind alberta u introduc novel search algorithm polici guid heurist search guarante http syncedreview com nmbr nmbr nmbr deepmind alberta u introduc novel search algorithm polici guid heurist search guarante the paper polici guid heurist search guarante arxiv http arxiv org pdf nmbr pdf
vwxyzjn,MachineLearning,1619399521.0,[P] Open Reinforcement Learning Benchmark 0.5.0,
ilikepancakez,MachineLearning,1619018686.0,On the Relationships Between the Grammatical Genders of Inanimate Nouns and Their Co-Occurring Adjectives and Verbs [R],
Xxyjoel,MachineLearning,1617007872.0,ML + Infrastructure [P],hey all i data scienc machin learn space major career recent spent time meddl around infrastructur could naiveti though complex ineffici bundl cloud tool bother i built tool help manag cost it still requir polici finagl self servic yet howev i love all candid feedback tool bluearch io http bluearch io apolog sub rule share work scari i pretti excit project
thermokopf,MachineLearning,1617657632.0,[D] Can the same convolutional network be used on different image sizes?,convolut network perform convolut imag array pixel basic decreas size imag input typic feedforward network how gener handl differ imag size for exampl i train network bunch nmbrxnmbr imag will i abl use network make predict nmbrxnmbr imag size
flaviojuvenal,MachineLearning,1619445763.0,[P] Entity Embed: fuzzy and scalable Entity Resolution using Approximate Nearest Neighbors,http github com vintasoftwar entiti emb http github com vintasoftwar entiti emb entiti emb base special case autoblock model describ amazon http www amazon scienc public autoblock hand block framework entiti match it allow transform entiti like compani product etc vector support scalabl record linkag entiti resolut use approxim nearest neighbor use entiti emb train deep learn model transform record vector n dimension embed space thank contrast loss vector organ keep similar record close dissimilar record far apart embed space embed record enabl scalabl ann search http ann benchmark com index html mean find thousand candid duplic pair record per second per cpu thi first deep learn project launch hope use pleas feel free reach feedback
hardmaru,MachineLearning,1617347384.0,[R] On the role of planning in model-based deep reinforcement learning,
,MachineLearning,1619991678.0,"[D] What is the reason behind the recent explosion in NLP-based research, jobs, and tools?",i notic nlp quit renaiss moment past nmbr year to kinda came nowher i sure expert saw come anyway i see much nlp research publish well everi compani seek peopl nlp knowledg whi what caus led explos nlp past nmbr nmbr year
mhj,MachineLearning,1619270649.0,"[P] Implementations of Apriori, Eclat and FP-Growth in Go",
ObjectiveDue9905,MachineLearning,1617205094.0,[D] How important is controls theory in machine learning?,hi i wonder import control theori machin learn seem go hand hand applic i current comput engin major student taken mostli cs cours come machin learn control theori cours ece electr comput engin depart i interest take seem applic i could see use hardwar softwar futur
samk2104,MachineLearning,1617093257.0,[D] Not all independent variables available for same time period..how to handle such situations for ML models?,i nmbr nmbr independ variabl inform avail last nmbr year includ depend variabl for nmbr nmbr variabl inform avail last nmbr month featur recent launch the simplest way would build model nmbr month variabl avail number data point enough is way i incorpor new featur model e use nmbr month data nmbr nmbr featur i still build model use nmbr year data
NotAHomeworkQuestion,MachineLearning,1616962377.0,"[D] Instead of taking an approach like Invariant Risk Minimization, why is it not enough to control for environmental factors (confounders) by including them as regressors?",i start dive fascin topic pleas excus ignor i realli enjoy read irm paper left wonder accomplish someth similar includ environment variabl regressor peopl causal infer for exampl mnist color applic could final layer model take top layer usual plain vanilla cnn well indic color imag we thu control color confound imag cnn part model architectur account everyth as worri shenanigan futur data point effect color revers thu creat predict futur data point ignor color effect predict thi i think would give similar result gray imag shown give excel perform what i miss
rom1504,MachineLearning,1616491364.0,[P] fromconfig: A library to instantiate any Python object from configuration files.,fromconfig http github com criteo fromconfig act gener command line interfac configur file absolut chang code fromconfig http preview redd xnmbrlnmbrlzwqonmbr png width nmbr format png auto webp cnmbrdnmbrfenmbrdnmbrfnmbrbanmbrcnmbrdnmbr it particularli well suit machin learn see exampl http github com criteo fromconfig machin learn launch train job remot cluster requir custom command line argument need propag call stack e g set paramet particular layer the usual way write custom command reduc set argument combin assembl creat differ object with fromconfig command line becom gener specif kept config file as result preserv code backward depend issu allow full reproduc save config file job artifact it also make easier merg differ set argument dynam way refer interpol
TheOverGrad,MachineLearning,1619902564.0,Memory-Efficient Semi-Supervised Continual Learning (IJCNN2021 oral),
cowgod2007,MachineLearning,1617853595.0,[D] Sourcing medical data?,hey for ml project one sourc buy obtain medic label data train data e g label radiolog imag data thank
JST99,MachineLearning,1619188054.0,[D] How to properly version control ML models amid rapid experimentation?,come softwar engin background i use git version control file along config json includ model train hyperparamet a trainer class would read specifi configur file train model save best one highest valid score thi pipelin work begin i iter slow pace recent howev i increasingli realiz save checkpoint file obsolet non trivial chang made model architectur sinc last experi by checkpoint i realli refer torch load some_state_dict question framework agnost i could cours check experi conduct git checkout repositori specif point time howev part believ incred common thing ml engin must eleg solut so far research brought sacr http sacr readthedoc io en latest index html i got post http www reddit com r machinelearn comment nmbrnpgnmbrd how_to_keep_track_of_experi keepsak http keepsak ai dvc http dvc org appear tangenti sinc question pertain model data thank advanc share insight
charles96322,MachineLearning,1618968095.0,[D] How Valuable Would Cutting Your ML Models Computation Time (at Inference) By 30-50% Be?,hello everyon i current work person project i tri optim deep learn algorithm respect hardwar deploy far i pretti decent result the idea hardwar handl comput better you build simul show util block neural network arrang model keep capac improv comput time significantli e g see paper http arxiv org pdf nmbr pdf eventu goal would select piec hardwar model deploy optim model click button i wonder solut like would made busi sens i love know use case so deploy machin learn model edg devic nmbr what kind applic deploy iot devic latenc typic problem nmbr how much time spend optim model comput time nmbr how valuabl would cut comput time nmbr nmbr infer i wonder applic e g robot medic nmbr nmbr would becom valuabl i love speak someon work field
ijovab,MachineLearning,1620598087.0,[D] What are some promising areas in privacy-preserving learning in medical data?,so eu new propos gener problem relat usag medic data topic seem becom fairli import i read feder learn continu learn differenti privaci recent what think promis area simplifi guarante safeti medic imag data train ani paper suggest also appreci
binaryfor,MachineLearning,1618678509.0,[P] Flashlight - A C++ standalone library for machine learning. Open-sourced by Facebook.,
kamil-rafalko,MachineLearning,1618305825.0,[Project] Better neurobiological research with AI,how instanc segment star shape cell call astrocyt nmbrd alreadi known comput vision techniqu thi task may seem simpl first turn unexpectedli tricki i share detail process find solut problem blog post http blog softwaremil com better neurobiolog research ai dnmbreacafnmbr http blog softwaremil com better neurobiolog research ai dnmbreacafnmbr i hope would interest ani comment welcom
proximauri,MachineLearning,1617183404.0,"[D] Is uploading dataset to personal Google Drive and use it in Google Colab against ""No distribution agreement""?",hi i machin learn databas i accept agreement in agreement state distribut data third parti prohibit my question upload dataset person gdrive load googl colab i want share anyon
dh27182,MachineLearning,1619591958.0,[D] Open source projects for interpretability,are good open sourc project model interpret i catch sever distil pub http distil pub articl recent author show impress visual unfortun seem open sourc wonder anyon use built project visual inspect model
ykilcher,MachineLearning,1619540955.0,[P] We gave GPT-3 random ingredients and cooked the recipe it came up with (Video),http youtu hiocn _nmbrqtvu http youtu hiocn_nmbrqtvu we went store bought set complet random ingredi openai gpt nmbr come recip cook ate our rule nmbr all vegan nmbr follow recip close possibl nmbr we must finish plate the recip nmbr boil potato carrot nmbr in meantim prepar vegan minc meat use pre cook soy meat nmbr then fri vegan butter add garlic mushroom stir nmbr minut nmbr add soy cream stir cook three minut nmbr add pickl tomato bean stir simmer five minut nmbr cut bread small squar fri vegan butter golden brown nmbr cut lime cube squeez juic bean mixtur nmbr add soy sauc parsley salt pepper cumin cilantro dri fig stir add kale nmbr pour bean mix blender nmbr bake nmbr minut oven nmbrc nmbr cut sweet potato cube add pot remain butter add red bean mixtur nmbr cut bell pepper cube add pot nmbr add vegan minc meat cook oven nmbrc nmbr minut nmbr add avocado nmbr add chickpea nmbr add chocol nmbr serv bread mustard pommegrenad top video outlin nmbr nmbr the plan nmbr nmbr ingredi nmbr nmbr what gpt nmbr nmbr nmbr let cook nmbr nmbr the tast test gpt nmbr wikipedia http en wikipedia org wiki gpt nmbr http en wikipedia org wiki gpt nmbr gpt nmbr paper http arxiv org ab nmbr http arxiv org ab nmbr
Stargor14,MachineLearning,1616875179.0,[D] Efficient ways of quantitatively classifying price movements for algorithmic trading using machine learning,hi everyon i current high school student i recent experi algorithm cryptocurr trade i start gener condit strategi howev prove rel ineffici simpl i tri move onto machin learn approach i use xgboost python i tri figur effici way classifi short term price movement case depend variabl i tri predict model i tri use chang next nmbr nmbr candl work well i realli look specif answer tbh i curiou everyon thought applic predict short term price movement random forest if think post bit vagu feel free ask away ani answer appreci
RenYang_ETHZ,MachineLearning,1619719239.0,"[N] NTIRE 2021 Challenge on Quality Enhancement of Compressed Video: Dataset, Methods and Codes",we organ ntire nmbr challeng video enhanc conjunct cvpr nmbr we propos larg scale divers video databas challeng the propos method challeng advanc state art enhanc compress video the homepag includ databas open sourc code keep updat benchmark http github com renyang home ntirenmbr _venh http github com renyang home ntirenmbr_venh the dataset method report http arxiv org ab nmbr http arxiv org ab nmbr http arxiv org ab nmbr http arxiv org ab nmbr we hope databas benchmark benefit futur research direct the ntire workshop held first day june nmbr cvpr nmbr welcom attend workshop
bin_wang_osl,MachineLearning,1617079701.0,[N] Live IEEE-NASPI Contest calls for ML experts' participation!,can machin learn better solv power system problem it expert here live contest co host ieee naspi apr nmbr jun nmbr nmbr see detail http www naspi org node nmbr http www naspi org node nmbr you welcom regist solv import real world problem root power energi system if need someon power system background form team worri way find one http doc googl com spreadsheet nmbrzanmbrqdlknmbr nmbroiczh nmbrianmbrzmzuirdndnmbriqnmbrxkpnjokvha edit gid nmbr http doc googl com spreadsheet nmbrzanmbrqdlknmbr nmbroiczh nmbrianmbrzmzuirdndnmbriqnmbrxkpnjokvha edit gid nmbr
AirZealousideal1342,MachineLearning,1618023079.0,[D] Why we must use weight demodulation in stylegan2,whi scale specif style control use architectur figur c must use architectur figur the paper say in practic style modul may amplifi certain featur map order magnitud for style mix work must explicitli counteract amplif per sampl basi otherwis subsequ layer would abl oper data meaning way but i understand and i undertand weight demodul solv problem http preview redd ynmbrljnsdmfnmbrsnmbr png width nmbr format png auto webp nmbrenmbrcnmbrcnmbrcnmbrfanmbranmbranmbrecenmbrfbnmbrdnmbranmbrc
Cosack,MachineLearning,1617493961.0,[Project] Estimating fine-tuning cost,with model size grow larger larger mention time retrain prohibit individu fine tune more reason while cours tune intens would depend task size avail data would go estim cost tune fix amount data say i look fine tune gpt neo open sourc gpt nmbr nmbrb paramet nmbrk short input nmbrm token how could i estim cost
ByteHubAi,MachineLearning,1617650022.0,[P] ByteHub: simple timeseries data preparation in Python,hi everyon share project i work help make time seri data easier store access transform build machin learn model it python base featur store avail open sourc librari http github com bytehub ai bytehub low cost cloud host servic http bytehub ai for bit background i written http medium com bytehub ai make featur store simpl nmbraenmbrdnmbrdcacnmbr built in summari want help data scientist save time build machin learn model someth simpl use e compat jupyt notebook complex infrastructur setup manag i appreci feedback anyon interest check
gospodin_dan,MachineLearning,1619896827.0,[N] Fresh paper: Detecting objects in images by describing them with keywords üî•,
jeongdoowon,MachineLearning,1616305744.0,[D]What is the hardest part in computer vision project at company?,hello i work comput vision engin medic ai compani though time spent find best thesi i use dataset tri see good accuraci if accuraci good enough time i spent got fruitless thi toughest part work routin what comput vision engin think hardest part project
evanatyourservice,MachineLearning,1618239686.0,[2102.11600] ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks,
ilikepancakez,MachineLearning,1620598303.0,Open Catalyst 2020 (OC20) Dataset and Community Challenges [R],
dev_bes,MachineLearning,1618317666.0,[R][P]MobileStyleGAN: A Lightweight Convolutional Neural Network for High-Fidelity Image Synthesis,in recent year use gener adversari network gan becom popular gener imag model while style base gan architectur yield state art result high fidel imag synthesi comput highli complex in work focu perform optim style base gener model we analyz comput hard part stylegannmbr propos chang gener network make possibl deploy style base gener network edg devic we introduc mobilestylegan architectur xnmbr fewer paramet xnmbr less comput complex stylegannmbr provid compar qualiti the main goal work democrat ai to start work modern ai base high fidel face gener need two python command pip instal random_fac python random_fac demo paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com be dev mobilestylegan pytorch http github com be dev mobilestylegan pytorch python librari http github com be dev random _face http github com be dev random_fac youtub video http www youtub com playlist list plstkhmdpwbtwsvq _nmbralmpbf _mblmknmbrui http www youtub com playlist list plstkhmdpwbtwsvq_nmbralmpbf_mblmknmbrui
bci-hacker,MachineLearning,1617472841.0,[D] Trustworthy Machine Learning talk | ideas and potential research,hey i recent gave talk http www youtub com watch v nmbrcqnmbreutcurc virginia tech trustworthi machin learn discuss research idea model interpret influenc function gradient base attribut structur learn would love check provid feedback possibl still ug apolog rigor academ talk tryin best improv haha would love sub cuz love make video research d
grid_world,MachineLearning,1618074601.0,[R] Finding important neural network connections,most research work relat neural network prune revolv around iter prune ever gener idea prune p connect per iter round either local global structur vs unstructur a common criterion absolut magnitud weight base prune han et al frankl et al sinc iter prune techniqu number round larg say prune nmbr nmbr is prune techniqu overcom shortcom it kind like tri identifi import connect entir train process iter process skip
levi97zzz,MachineLearning,1618010691.0,[D] how useful is OS knowledge in AI/ML?,question titl i choos sever class next semest one class os how use os knowledg i want get ai ml futur
peaked-too-early,MachineLearning,1619992949.0,"[D] With ICLR starting, how do you make the most of an online conference?",befor end time person confer would product least could make acquaint later lead ph d internship job offer collabor could natur learn other convey research casual convers poster hall the fact block entir schedul confer week obvious help us focu confer luxuri anymor i tri wing onlin ml ml adjac confer littl success do tip resourc make suboptim situat
abpan8,MachineLearning,1618930656.0,[P] Open data about logistics,could suggest dataset good site take data scrape forecast cost transport good truck us
medwatt,MachineLearning,1617829959.0,[D] Explain Energy Based Models,i electr engin student basic practic understand neural network work i understand basic idea multi layer perceptron mlp convolut layer etc i even implement binari neural network use kera as electr engin student i taken hardcor machin learn cours even optim theori probabl yet work way curriculum univers i attend most knowledg field self interest i recent saw project involv build hardwar acceler machin learn task the project requir background energi base model unsurprisingli i never heard i came across paper onlin even found yann lecunn video lectur topic needless say i abl understand much i moment unfamiliar lot idea field so i would like someon could give explan energi base model interest differ probabilist model train applic suitabl etc mayb make easier revisit paper understand second read
Egan_Fan,MachineLearning,1617299603.0,[D] Statistical Significance in Deep RL Papers: What is going on?,i icml review i read author respons i primarili rl research mani paper i review use deep network rl i reject nmbr nmbr paper empir result reli nmbr nmbr trial author perform sort hypothesi test statist analysi would help littl data one author respons said someth like well everyon els thing comput cost high it excus wrong either point whi seen accept in field e g medic journal manuscript nmbr nmbr data point statist analysi would immedi reject right author respond said well afford larger studi one would see legitim excus howev none review paper rais concern whi i one concern whi paper like get accept top confer even win best paper award am i miss someth deep problem field case i stick firmli reject paper thank advanc thought repli discuss
fripperML,MachineLearning,1616972625.0,"[D] What‚Äôs the simplest, most lightweight but complete and 100% open source MLOps toolkit?",i know ask mani time mani differ way and ton blog post articl video cours address compar hundr tool librari framework and part problem i face mani option i feel like buridan ass die starvat know although i want write much i need speak littl situat order put question context our team our team small we four peopl could qualifi beginn data scientist one us profil littl bit engin data engin could suitabl anyway much experi neither python project machin learn what passion love ml for coupl year function sa plan chang python landscap much vivid excit in last year made two project python without use good practic everi step made hand prone error model neither monitor even deploy use make batch predict project properli structur document pain so know need chang becom unmanag we expect size team grow fast let say coupl year expect nmbr nmbr peopl work us organ know import machin learn econom issu obstacl our project for moment made classic machin learn i mean deep learn we use panda scikit learn xgboost etc and batch mode but expect chang less year need train imag classifi need train use deep learn convolut network integr applic code java fast real time other chang expect need distribut comput need manag huge databas simpli fit panda datafram these import challeng face our compani we work big compani also impos restrict us mainli we budget spend mlop solut everyth open free we hire data scientist data engin moment there tool use team use part mlop stack although best class regard last item short list set restrict follow we cloudera express instal it basic cheaper cloudera option come tool machin learn manag it give us hdf impala spark set node run python script we control m orchestr workflow manag tool we datastag etl tool we use svn code version system ye git we deploy project use simplifi self made version docker it littl bit awkward i think push littl bit could convinc organ let us use docker but docker reachabl kubernet capabl we jenkin ci we visual studio code profession licens toolset with premis i two differ oppos concern even fear fear use enough tool good practic arriv coupl year state manag code project model fear use mani tool impos burden small team bear it clear need mlop much i know i review thing i read i hope help choos right tool python program it look like program use visual studio we use remot interpret run thing cloudera node although program local integr code svn repositori do need tool standard code like pylint flakenmbr mypi black would recommend ci deploy we use jenkin for deploy code docker brainer minimum standard i tend think i read i like sure good argument do need tool project scaffold i read pyscaffold cookiecutt best point view kedro i think stick kedro templat offer much function i like think project set pipelin run what think kedro document would recommend separ document gener document project use sphinx anoth similar tool i tend prefer second option first one like tend gener obsolet doc but i know burden second big gener doc suffic typic ml project project registri is tool could use project registri like simpl web app could navig project read doc think like i know if registri svn repo project folder data explor prepar i think matplotlib seaborn panda suffic thing go big use pyspark scala even plain sql impala howev i know dask exist newer tool like koala vaex what think for creat data transform pipelin use kedro although lot tool look interest like dagster when enter deep learn realm keep use tool should use anoth framework like tfx i prefer caus learn one framework hard two wors if solut valid project better or tfx valid classic ml deep learn test i think unit test much burden us but i come great expect librari think well suit ml project would recommend import part mlop stack by way kedro great expect plugin could benefit featur store is realli need especi consid team size experi if i read feast snorkel data version is realli need especi consid team size experi if i read dvc experi i think import piec although i wonder realli need tool could use standard report artifact follow tri but risk goe unmanag high kedro journal i know suffic also kedro mlflow plugin could benefit use mlflow experi tool i also read guild seem realli lightweigh easi i know much train i develop librari nest cross valid within function optim hyperparamet model pipelin gener report train assess qualiti model it build mainli top skopt i pip instal http github com jaimearboleda nestedcvtrain http github com jaimearboleda nestedcvtrain so might use trane workflow least project along typic model like xgboost lightgbm scikit learn but need framework like tensorflow kera see model registri i think import piec although i know even could build standard databas if mlflow seem matur option model serv i sure includ previou point anyway i read streamlint fastapi would recommend is apach kafka need real time predict visual with i mean share organ basic web app customiz plot explain predict thing like i read panel abil transform jupyt notebook simpl web app it might interest model monitor is good free tool monitor model detect loss accuraci data drift thing like or better gener script monitor run period bigdata as i said plan use mainli spark need i know lot info mayb i overcompl i use nmbr i think i or mayb i idea ani help greatli appreci thank advanc edit i add coupl thing first one spread among two comment i work spanish public administr so lot data use explor thi also rigid budget thing i explain thi also explain cloud option us data protect legal even polit reason forbid us data outsid scope it piti i think aw anoth provid help part stack cover as alreadi use datastag ibm provid told us soon unifi cloud pak for data might soon cloud pak for data licens i mix feel product think might benefit us opposit
jj4646,MachineLearning,1619315323.0,[D] how accurate were the statistical models you developed on real-world data?,when come real world data accur statist model develop were model abl consist accur make predict e g supervis binari classif anyon abl develop model high accuraci high sensit high specif
Yuqing7,MachineLearning,1618849550.0,[N] DeepMind 'Podracer' TPU-Based RL Frameworks Deliver Exceptional Performance at Low Cost,a research team deepmind introduc anakin sebulba two architectur demonstr reinforc learn platform base tpu effici deliv except perform scale low cost here quick read deepmind podrac tpu base rl framework deliv except perform low cost http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost the paper podrac architectur scalabl reinforc learn arxiv http arxiv org pdf nmbr pdf
xiikjuy,MachineLearning,1619173343.0,[D] Should I report the pretraining results?,hello i use transform base model pretrain unlabel larg data finetun pretrain model label smaller dataset regular learn pipelin follow idea bert my question i report pretrain result like learn curv need describ pretra step optim etc for literatur use transform base model learn paradigm pretrain finetun seem paper report pretrain result result donwstream task shouldn first show pretrain model well pretrain matter much even model perform poorli pretrain phase somehow checkpoint work well downstream task problem thank edit report mean show regular ml dl confer paper
ilikepancakez,MachineLearning,1619293570.0,Team Polk‚Äôs Bryan Pellegrino Talks About His AI Research And How It Helped Formulate Strategies To Win $1.2 Million [P],http www cardplay com poker news nmbr team polk bryan pellegrino talk ai research help formul strategi win nmbr nmbr million realli interest use game theori had honor watch happen live a moment silenc human r poker player pleas
alexirpan,MachineLearning,1618168907.0,[D] Thoughts on industry research vs academia,hi i go grad school go straight indsutri instead i work ml nmbr year i thought interest look back turn the post http www alexirpan com nmbr nmbr nmbr grad school nmbryear html http www alexirpan com nmbr nmbr nmbr grad school nmbryear html i got feedback across ml career spectrum straight ml engin phd industri academia post phd tri address experi hope match realiti help consid similar decis
glassAlloy,MachineLearning,1617285861.0,[P] How to group every data point with HDBSCAN to some group to have no noise?,task i cluster product nmbr dimens ex price rate nmbr nmbr product tag clean toy food fruit i use hdbscan goal the goal user come site i show similar product view question how get data point part group goal nois code cluster hdbscan hdbscan min_cluster_s nmbr min_sampl nmbr fit data color_palett sn color_palett pair nmbr cluster_color color_palett x x nmbr els nmbr nmbr nmbr x cluster labels_ cluster_member_color sn desatur x p x p zip cluster_color cluster probabilities_ plt scatter project t nmbr linewidth nmbr c cluster_member_color alpha nmbr label cluster labels_ number cluster label ignor nois present n_clusters_ len set label nmbr nmbr label els nmbr print estim number cluster n_clusters_
cbsudux,MachineLearning,1616679371.0,[D] Cheapest GPU server options for deploying a side-project?,hey guy cheapest option deploy ml model aw gcp cost nmbr nmbr usd mo use tnmbr pnmbr instanc too much side project vast ai http vast ai independ gpu provid cost around nmbr nmbr usd per month still bit pricey nmbr are pay go option aw elast equival nmbr are cheap option nmbr nmbr usd mo
KirillTheMunchKing,MachineLearning,1620480849.0,[D] Solving computer vision without convolutions! MLP-Mixer explained.,mlp mixer an mlp architectur vision http casual_gan nmbr thi paper spiritu successor vision transform last year thi time around author come mlp multi layer perceptron model solv comput vision task thi time around self attent block use either instead two type mix layer propos the first interact featur insid patch second patch see detail http casual_gan nmbr model architectur overview http preview redd nanmbreawfwxnmbr png width nmbr format png auto webp fbnmbraenmbrfbnmbrbnmbrcnmbrenmbrbnmbrdbcnmbrbnmbrccnmbrbbdnmbrfnmbr nmbr minut paper explan http casual_gan nmbr arxiv http arxiv org pdf nmbr pdf
st-memory,MachineLearning,1616860882.0,[P] Generating Galaxies using StyleGAN2-ADA,thi http www youtub com watch v kxpenmbrouxnmbrjq video stylegannmbr ada http github com nvlab stylegannmbr ada train imag hubbl http esahubbl org imag archiv categori galaxi involv travel latent space differ truncat valu varieti imag increas exchang qualiti video progress the imag scrape manual clean fair either diagram defect the dataset nmbr nmbr imag network train improv fid note
roVinchi,MachineLearning,1620639086.0,[D] Will the talks of ICLR21 be publicly available?,known releas date i could find inform websit
Yuqing7,MachineLearning,1617322595.0,[N] Google Research's SOTA GNN 'Reasons' Interactions over Time to Boost Video Understanding,a research team googl research propos messag pass graph neural network explicitli model spatio tempor relat use either implicitli explicitli represent object gener previou structur model video understand here quick read googl research sota gnn reason interact time boost video understand http syncedreview com nmbr nmbr nmbr googl research sota gnn reason interact time boost video understand the paper unifi graph structur model video understand arxiv http arxiv org pdf nmbr pdf
sharvil,MachineLearning,1620146526.0,[P] ArxivDiff: view diffs of arXiv paper revisions,i built tool show diff two revis paper arxiv just take arxiv url replac arxiv org arxivdiff org e g http arxiv org ab nmbr becom http arxivdiff org ab nmbr edit first reddit award thank much fellow um net surfer
ottawalanguages,MachineLearning,1619997683.0,[D] correct application of autoencoders for classification,can autoencod perform data way princip compon analysi can perform dimension reduct data use autoencod use random forest reduc data or counterproduct
CauchySchwartzDaddy,MachineLearning,1619047967.0,[D] Is it just me or is it getting harder and harder to get access to cloud GPUs with regions being out of resources almost all the time,i nmbr vm set googl cloud basic everi region i get vnmbr yet multipl time day i cant access due region resourc mayb gcloud thing combin cutthroat gpu market i interest know anyon els problem
xela-sedinnaoi,MachineLearning,1618815073.0,"[P] [D] The benefits of training the simplest model you can think of and deploying it to production, as soon as you can.",i mani success approach with mind i put togeth exampl http www bodyworkml com post scikit learn meet product make agil approach develop machin learn system realiti demonstr take nmbr minut deploy scikit learn model use fastapi bodywork http github com bodywork ml bodywork core open sourc mlop tool i built how compar experi i interest get peopl thought background larg structur data
prestodigitarium,MachineLearning,1617376157.0,"[P] Gourdian Free Dataset Download: Daily weather of the world, back to 1929",hi have ever thought use train model histor weather data chunk world want deal grungi data wrangl massiv dataset get conveni format have ever curiou averag temperatur egypt nmbr well friend i made webpag let filter nmbr gig noaa global summari day weather dataset small fraction download part care csv http gourdian net g eric noaa_gsod global_summary_of_day tabl preview left geograph time filter download button right deliv singl clean csv easi import panda r databas whatev els like use work tabular data csv work everyth a bit goal tri build filter option click button csv arriv hard drive download alway singl csv bundl weird directori structur format csv index filter column type lat long date time moment download part want open licens dataset free download no signup requir download open dataset search within across dataset basic focu build someth simpl power fine grain queri someth like bigqueri easier get go thi super earli version web javascript download client never shown publicli client python librari tri figur make better love feedback especi break whatev reason what would make life easier pleas note work well mobil yet figur mani peopl would want brows download dataset two us prioriti but wrong pleas let us know
SQL_beginner,MachineLearning,1619323632.0,[D] Reservoir Computing/Echo State Networks vs RNN's and LSTM's,ha anyon ever heard reservoir comput echo state network http en wikipedia org wiki reservoir_comput doe anyon idea situat use compar model rnn lstm
marcovirgolin,MachineLearning,1619510512.0,[R] Model Learning with Personalized Interpretability Estimation,for high stake applic e g cancer treatment ai use lightli recklessli we need model trust achiev trust interpret key factor the field explain ai xai concern method explain behavior black box deep neural network method gener white box e model interpret think e g spars linear model small decis tree symbol express there good reason latter desir former see e g famou paper cynthia rudin http arxiv org ab nmbr we propos new proof concept work look whether xai interpret model gener person what follow essenti taken abstract in fact current algorithm synthesi potenti interpret model reli object regular term repres interpret coars e g model size design specif user yet interpret intrins subject we propos approach synthesi model tailor user enabl user steer model synthesi process accord prefer we use bi object evolutionari algorithm synthes model trade off accuraci user specif notion interpret the latter estim neural network train concurr evolut use feedback user collect use uncertainti base activ learn to maxim usabl user ask tell given two model time one less complex with experi two real world dataset involv nmbr particip find approach capabl learn estim interpret differ differ user moreov user tend prefer model found use propos approach model found use non person interpret indic preprint http arxiv org ab nmbr accept appear ec dm workshop gecco nmbr
Last-Programmer2181,MachineLearning,1617364678.0,"[R] Why can a single large SL model be broken down into smaller SL models, and have better accuracy?",for refer i use learn classifi system lc perform supervis learn dataset i larg synthet gener set data nmbr differ input predict action output after gener nearli million differ data point i train sl model achiev roughli nmbr classif accuraci i normal hyperparamet sweep accuraci vari anywher nmbr nmbr the data uniqu sens mani differ combin eleven input lead twenti seven differ possibl classif action i know number pretti specif i want give sens i deal the action could rang noth someth x someth y where someth x a mani possibl variant similar action someth y what i decid break one larger sl problem small chunk i broke singl larger problem four much manag model one lead next model a b c d ultim predict result larger singular model the first model would simpli decid noth someth i combin someth x y singl predict and achiev model predict accuraci nmbr and i kept make model specif ultim lead twenti seven differ possibl classif i one larger model each model accuraci nmbr refer each model would alway nmbr input i remov data point longer relev base previou model choic whi would one larger model tri everyth much lower classif accuraci multipl model thing classif accuraci nmbr
fedetask,MachineLearning,1616519398.0,[R] RL Papers using graph techniques on sampled trajectories,are paper construct graph state action reward collect someth i find idea intrigu i found much
downtownslim,MachineLearning,1617383464.0,[R] Scaling Local Self-Attention for Parameter Efficient Visual Backbones,
programmerChilli,MachineLearning,1619417306.0,[D] Huawei just announced that they trained a 200 billion transformer model on an entirely Chinese stack,my tweet http twitter com chhille statu nmbr they train nmbr billion paramet decod dens transform nmbrb token nmbr huawei ascend nmbr chip moreov done use mindspor huawei ml framework in contrast gpt nmbr nmbrb paramet model train nmbrb token on alreadi quit impress even though done nmbrb token biggest model yet china repres one biggest model yet world howev thing realli impress done chines stack huawei mindspor framework compil huawei ascend chip i known huawei work ai chip i unawar matur point could feasibl train model scale code http git openi org cn pcl platform intellig pangu aipha paper http co nmbrwqepoviyq amp nmbr
OnlyProggingForFun,MachineLearning,1618063607.0,[News] From Amputee to Cyborg with this AI-Powered Hand! ü¶æ[Nguyen & Drealan et al. (2021)],paper involv arm nmbr nguyen drealan et al nmbr a portabl self contain neuroprosthet hand deep learn base finger control http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf nmbr luu nguyen et al nmbr deep learn base approach decod motor intent peripher nerv signal http www researchg net public nmbr _deep _learn base _approach _for _decod _motor _intent _from _peripher _nerv _signal http www researchg net public nmbr_deep_learn based_approaches_for_decoding_motor_intent_from_peripheral_nerve_sign nmbr nguyen et al nmbr redund crossfir a techniqu achiev super resolut neurostimul design exploit transistor mismatch http ieeexplor ieee org document nmbr http ieeexplor ieee org document nmbr nmbr nguyen xu et al nmbr a bioelectr neural interfac toward intuit prosthet control ampute http www biorxiv org content nmbr nmbr nmbrvnmbr full http www biorxiv org content nmbr nmbr nmbrvnmbr full video demo http youtu wnbrcrzlbvw http youtu wnbrcrzlbvw
FormerYogurtcloset17,MachineLearning,1617233499.0,"[D] How can I augment an existing model with new training data, preferably on the edge?",how can i augment exist model new train data i built app i use mobilenet model tensorflow lite detect object live steam camera now i wish retrain model somehow augment new train data e new photo how i accomplish object edg e devic even remot server fast
satprepnow124,MachineLearning,1618955447.0,[P] Time Series Forecasting,hey i dataset polic complaint i want time seri forecast i got offic wage year promot year complaint file i want predict futur complaint base wage past complaint promot ani suggest method use sorri i never done time seri forecast i bit confus
pinter69,MachineLearning,1617552299.0,[R] Graph Convolutional Networks in Videos and 3D Point Clouds - Dr. Ali Thabet - Link to free zoom lecture by the author in comments,
WigglyHypersurface,MachineLearning,1618503893.0,[DISCUSSION] How do the different versions of the bootstrap work with deep neural networks?,i look deep learn method possibl way imput miss data lead question deep neural network interact variou version bootstrap in statist miss data context goal estim posterior predict distribut miss data condit observ data you fill miss data draw distribut lead version dataset observ data miss data vari you analysi time use simpl formula combin analys give nice clean pictur much uncertainti miss data reduc confid whatev hypothesi test ok deep net part in statist literatur miss data idea proper say want posterior distribut miss data reflect sourc uncertainti model use fill miss data your model fill miss data either need fulli bayesian approxim fulli bayesian model possibl the simplest way approxim proper posterior miss data world often use either parameter nonparametr bootstrap for parametr bootstrap nmbr train model say learn mu sigma linear regress nmbr sampl predict valu outcom variabl ie make new outcom variabl sampl learn mu sigma nmbr retrain model use sampl valu new depend variabl nmbr make whatev predict infer want second model if bunch time aproxim bayesian posterior nonparametr bootstrap resampl data replac train resampl data again repeat mani time get approxim posterior so question deep neural network nmbr what advantag disadvatag deep net use variat bay versu deep net use either version bootstrap are known expect bias either form bootstrap deep neural network nmbr will caus bia train network scratch multipl iter bootstrap would problem exampl resampl data carri weight previou bootstrap iter nmbr is good resourc chang fulli bayesian deep network chang sort choic make dropout batch normal activ etc
timscarfe,MachineLearning,1619855005.0,[D] Unadversarial Examples video with Hadi Salman (MIT lab),perform reliabl unseen shift data distribut difficult challeng modern vision system even slight corrupt transform imag enough slash accuraci state art classifi when adversari allow modifi input imag directli model manipul predict anyth even percept chang known adversari exampl the ideal definit adversari exampl human consist say two pictur machin disagre hadi salman ph d student mit ex uber microsoft research start think adversari robust could leverag beyond secur he realis phenomenon adversari exampl could actual turn upsid lead robust model instead break hadi actual util brittl neural network design unadversari exampl robust object object design specif robustli recogn neural network video http youtu _ehrichlgnmbrk http youtu _ehrichlgnmbrk pod http anchor fm machinelearningstreettalk episod nmbr unadversari exampl hadi salman mit enmbrknmbr in first nmbr min i give intro cover mit featur bug paper non robust featur etc adversari exampl are not bug they are featur http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf adversari robust prior learn represent http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf imag synthesi singl robust classifi http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf unadversari exampl design object robust vision http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf do adversari robust imagenet model transfer better http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf a convex relax barrier tight robust verif neural network http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf provabl robust deep learn via adversari train smooth classifi http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf denois smooth a provabl defens pretrain classifi http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf imagenet train cnn bias toward textur increas shape bia improv accuraci robust http arxiv org ab nmbr http arxiv org ab nmbr
pinter69,MachineLearning,1618759421.0,[R] Putting visual recognition in context - Link to free zoom lecture by the authors in comments,
ploomber-io,MachineLearning,1617292408.0,[D] Incremental builds for ML pipelines,hi everyon i like get perspect increment build when develop ml pipelin i often revisit process step e g updat sql python script sinc output outdat i rerun pipelin i skip unaffect task save time pipelin grow signific impact the common exampl make increment build must sinc allow modifi someth bring everyth date quickli a orchestr featur ploomber http github com ploomber ploomber i develop dvc drake r other dagster kedro prefect surprisingli user latter group seem miss mayb awar featur my guess peopl mostli work deep learn see much benefit make like tool fewer pre process step am i miss anyth how ensur task use recent data and importantli quickli get output date
thejuror8,MachineLearning,1616768727.0,[D] Class-incremental learning and Reviewer 2,disclaim i one author i connect author shape form follow iclr nmbr reject paper review access http openreview net forum id munmbrwnwwwwc while result present seem promis although i quit fresh cil i surpris read review two conclus in summari premis class increment learn appear weak in practic vision applic often label manual highli time consum major bottleneck get suffici mani accur label mani class as label arriv train retrain time space batch train issu exist batch train method comput power besid fact classic review nmbr move traction around paper present new cil method vision special confer quit signific especi recent suggest least degre relev which lead question consensu relev cil peopl share review opinion im practic
Haunting-Garbage-364,MachineLearning,1620036485.0,"[D] Companies that sell ""creative"" AI/ML products and services",hey everyon i write final thesi artifici intellig use creativ sector i lookout creativ sector compani use ai specif autom creation product servic for exampl compani http ironov artlebedev com http ironov artlebedev com is sell logo design ai i look compani someth similar find if idea compani know pleas let know i would realli appreci
hardmaru,MachineLearning,1617335153.0,[R] EfficientNetV2: Smaller Models and Faster Training,
downtownslim,MachineLearning,1618984939.0,[N] Cerebras launches new AI supercomputing processor with 2.6 trillion transistors,cerebra system http venturebeat com nmbr nmbr nmbr cerebra wafer size chip nmbr time faster gpu unveil new wafer scale engin nmbr processor record set nmbr trillion transistor nmbr nmbr ai optim core it built supercomput task second time sinc nmbr lo alto california base cerebra http cerebra net unveil chip basic entir wafer chipmak normal slice wafer nmbr inch diamet ingot silicon process chip factori onc process wafer slice hundr separ chip use electron hardwar but cerebra start seamicro founder andrew feldman take wafer make singl massiv chip each piec chip dub core interconnect sophist way core the interconnect design keep core function high speed transistor work togeth one full text http venturebeat com nmbr nmbr nmbr cerebra system launch new ai supercomput processor nmbr nmbr trillion transistor http venturebeat com nmbr nmbr nmbr cerebra system launch new ai supercomput processor nmbr nmbr trillion transistor
TheoreticallyBlank,MachineLearning,1619406224.0,[R] Fractional pooling layers in CNNs,have recent public survey relat improv replac standard pool layer fraction one
Yuqing7,MachineLearning,1618933498.0,"[R] Rice University, IBM & USC Study Pushes Quantum State Tomography Beyond Current Computation Capabilities",a research team rice univers ibm usc combin compress sens non convex optim acceler techniqu introduc new algorithm momentum inspir factor gradient descent mifgd push qst beyond current capabl here quick read rice univers ibm usc studi push quantum state tomographi beyond current comput capabl http syncedreview com nmbr nmbr nmbr rice univers ibm usc studi push quantum state tomographi beyond current comput capabl the paper fast quantum state reconstruct via acceler non convex program arxiv http arxiv org pdf nmbr pdf
FreddeFrallan,MachineLearning,1616355252.0,[P] [R] Pre-trained Multilingual-CLIP Encoders,http preview redd nnmbrvkznmbrceofonmbr png width nmbr format png auto webp bfnmbrbnmbrdnmbrbnmbrafnmbrenmbrdnmbrfdnmbrenmbrcnmbrdnmbrbnmbradnmbr we start creat set pre train text encod match openai clip http openai com blog clip imag encod see github page http github com freddefrallan multilingu clip tree main model nmbrcard m bert nmbrdistil nmbr inform list current avail model we current perform minor qualit evalu french russian spanish german green swedish the model seemingli yield reason result test languag see result http github com freddefrallan multilingu clip tree main model nmbrcard m bert nmbrdistil nmbr everi column softmax correspond imag given text the idea creat multilingu clip encod via teacher learn coupl machin translat creativ unlik write proper paper so thought might well share preliminari model directli we releas bigger multilingu model soon finish train hope guy find use enjoy
hhh312,MachineLearning,1619813787.0,[D] Optimizing the top of a network only,hey guy i use backbon bart model huggingfac transform librari fine tune addit head what i right i provid weight optim i hand weight head howev i suspect train _grad appli non head weight henc lot comput resourc wast is case how i enforc grade weight thank
jj4646,MachineLearning,1618864084.0,"[D] Has anyone ever heard of ""scissor plots"" being used in machine learning?",http imgur com dnmbrtnmbrgii i came across interest graph call scissor plot i never heard anyon els heard is well known plot it would interest know way roughli approxim n point perhap n point could use decid make sens use complex model simpl model
JollyEye3,MachineLearning,1620281484.0,[D] Anomaly detection in sequential data under budget constraint,i work problem i need detect anomali collect n sequenti exampl coupl requir nmbr in exampl multipl anomali e exampl may contain nmbr nmbr anomali howev goal detect atleast one anomali per exampl detect singl anomali good enough nmbr the number detect anomali allow b thi fix annot budget confirm detect anomali a human review review confirm anomali there train data avail problem thi constrain optim problem need maxim number exampl cover anomali detect per exampl atleast one ani thought constrain optim view problem is research paper around topic cost constrain anomali detect corpu sequenti data
dhekurbaba,MachineLearning,1620448897.0,[D] just accepted an offer upon graduation..... what do you do in-between?,phd realli mess work life balanc first job upon graduat join nmbr week mean mani day noth think email boss ask refer tool concept teach thing wonder norm play video game instead guy
Brahimce,MachineLearning,1618321567.0,[R][P] How to handle equality constraints in mutation of evolutionary algorithms?,i new evolutionari algorithm field i chromosom nmbr variabl real variabl sum variabl equal one i look mutat formula gener new chromosom respect equal constraint sum new chromosom alway equal one
LakeTurbulent5878,MachineLearning,1617513587.0,"[D] Having published at top ML conference, how to be nominated as a reviewer?",i use believ somebodi invit publish paper neurip icml iclr publish two first author paper confer i receiv invit review i actual quit enjoy review paper i would happi review i think i qualifi least advisor mainli work ml field idea nomin then i contact who right nomin review just review ac pc
ptoews,MachineLearning,1620036509.0,[D] CPU choice for machine learning server (Epyc vs. Threadripper),we plan build rig nmbr rtx nmbr nmbr gb ram the applic area comput vision preprocess like necessari i read dali might use sure yet we current look threadripp vs epyc are benchmark experi two line up compar imag preprocess task so far i read threadripp higher clock speed run hotter support less memori capac bandwidth wherea epyc opposit but translat border applic ml as side question import core count preprocess appar nmbr core per gpu recommend scale
statsIsImportant,MachineLearning,1618647712.0,[D] Looking for the extreme classification + Language modelling video,hi i look video icml nmbr workshop invit talk nmbr histor perspect extrem classif languag model toma mikolov talk http icml cc confer nmbr schedulemultitrack event nmbr collapsenmbr if somebodi point websit provid link would great
elTope,MachineLearning,1618161239.0,[D] Industry vs Learning process gap,mayb hole post rason anyon still i alway feel i tri learn machin learn stuff i obvious constantli amaz develop archiv ml industri research whenev i enrol cours search guid etc i wrap head around end interact product environ mani cours may explain model attach toy exampl come implement end end solut specif problem i still rather clueless mayb mayb best way learn i lack enough inform know better if neither case i would like know someon could provid differ aproach method resourc remov abstract if i bitch tell also thank attent
jhanytime,MachineLearning,1618156293.0,[D] Video - Why would you use graphs for machine learning data?,i phd student studi machin learn applic transport system autonom system think rl robot while sever gcn made easi video youtub i feel like video often miss forest tree especi sinc gcn nmbr algorithm develop nmbr video often cover broader histor context gnn develop differ variat allow model new type system thi first video seri i make graph graph neural network applic area potenti make big impact pleas let know think video learn anyth new http youtu munmbrinznmbrltlo
srcho,MachineLearning,1619696052.0,[R] Ethical consideration in AI(Machine learning) decision-making process,dear commun i desper need help as part master thesi universiteit van amsterdam i conduct studi ai machin learn ethic consider relationship decis make outcom qualiti i would like kindli ask help particip survey thi survey peopl who have experi in the decis make process with busi project if work experi ai machin learn deep learn would even better pleas fill survey support the survey link http uva franmbr qualtric com jfe form sv _nmbrbwwzrfretjmgsa thi survey take nmbr minut maximum to find relationship i need help suffici particip pleas fill survey contribut help finish academ work feel free distribut survey network i look forward hear answer
emilwallner,MachineLearning,1617697075.0,[P] How I built a ‚Ç¨25K Machine Learning Rig,link http www emilwalln com p ml rig http www emilwalln com p ml rig hey i made machin learn rig four nvidia rtx anmbr amd epyc nmbr nmbr core includ nmbr gb gpu memori nmbrgb ram part list http doc googl com spreadsheet nmbrvmtilzbglachkscbabcnmbrvovvwsi_nmbrynmbrbbawnmbrrnmbrrcnmbri edit usp share i made nmbr word guid peopl look build nvidia amper prosum workstat server includ differ budget tier where place home offic data center etc constraint consum gpu reason buy prosum enterpris gpu build workstat server key compon rig pick list retail build list let know question here build four rtx anmbr epyc nmbr http preview redd nmbrhnmbrfbtbnmbriirnmbr jpg width nmbr format pjpg auto webp nmbraanmbrcnmbrfnmbranmbrdnmbrdnmbranmbrcnmbraenmbrbcnmbr
lkhphuc,MachineLearning,1618873310.0,[R] ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning,zero infin glanc zero infin novel deep learn dl train technolog scale model train singl gpu massiv supercomput thousand gpu it power unpreced model size leverag full memori capac system concurr exploit heterogen memori gpu cpu non volatil memori express nvme short learn paper zero infin break gpu memori wall extrem scale deep learn http www microsoft com en us research public zero infin break gpu memori wall extrem scale deep learn the highlight zero infin includ offer system capabl train model nmbr trillion paramet nmbr nvidia vnmbr tensor core gpu nmbrx larger state art deliv excel train effici superlinear throughput scale novel data partit map exploit aggreg cpu nvme memori bandwidth cpu comput offer nmbr petaflop sustain throughput nmbr nvidia vnmbr gpu further mission deepspe team democrat larg model train allow data scientist singl gpu fine tune model larger open ai gpt nmbr nmbr billion paramet elimin barrier entri larg model train make simpler easier zero infin scale beyond trillion paramet without complex combin sever parallel techniqu without requir chang user code to best knowledg parallel technolog http www microsoft com en us research upload prod nmbr nmbr nmbrxnmbr_deepspeed_nologo nmbr mpnmbr from blog post http www microsoft com en us research blog zero infin deepspe unlock unpreced model scale deep learn train http www microsoft com en us research blog zero infin deepspe unlock unpreced model scale deep learn train massiv prop microsoft deepspe team work i thrill everi time i see new zero paper deepspe releas github
cedricdb,MachineLearning,1618850067.0,[R] [D] Label info in Adversarial Autoencoders,i question adversari autoencod paper makhzani et al nmbr http arxiv org ab nmbr http arxiv org ab nmbr let look figur nmbr concern architectur semi supervis adversari autoencod a softmax use obtain soft label input imag thi soft output encourag close categor sampl object upper gan the question happen soft label optim decod are suppos draw hard sampl take argmax in semi supervis set import later figur nmbr dimension reduct adversari autoencod architectur reus here softmax output use cluster head selector is soft hard selector the way i see make kind sens follow optim upper gan use soft label but optim decod use reconstruct error sampl but impli gradient reconstruct error flow softmax layer can someon clarifi thank
roma-glushko,MachineLearning,1618823116.0,[P] How I built my Deep Learning workstation,recent i built deep learn workstat share experi follow blogpost http www romaglushko com blog built ml workstat http www romaglushko com blog built ml workstat i tri cover aspect build machin learn pc theori choos pc part ml hardwar instal troubleshoot guid softwar cuda setup i hope go help
touchanimize,MachineLearning,1618075882.0,[P] Fine tuning Magenta ML model,hi i bit novic machin learn i undergrad work fine tune onset frame model googl http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf use code base http github com greenbech onset frame http github com greenbech onset frame i tri fine tune model jazz music differ classic music use train origin model i bit unsur go process i hope anyon could given insight thing i could i done follow thu far acquir dataset jazz music convert midi have train differ mix jazz music larger maestro dataset use train onset frame model i gotten fnmbr score mix i think increment train progress checkpoint mayb batch dataset mix do i need hyper paramet search i exactli sure move forward idea would much appreci thank guy time
omnipotent_i,MachineLearning,1620326101.0,[D] Paths to become a Productive Non-Academic Researcher,hello i much fortun work research role post bachelor start up we tri almost nmbr year get accept confer iclr neurip etc have alway unsuccess research interest unfortun i afford get academ due situat is part i could take go ahead path is fantasi get accept confer come non academ research lab top compani provid clear direct guidanc thank
meowklaski,MachineLearning,1618758483.0,[P] MyGrad: Drop-In Autodiff for NumPy,http github com rsokl mygrad http github com rsokl mygrad mygrad lightweight librari add automat differenti numpi depend numpi mygrad primari goal make automat differenti access easi use across python numpi ecosystem as strive behav feel exactli like numpi user need learn yet anoth array base math librari import mygrad mg import numpi np x mg tensor nmbr nmbr nmbr like numpi array support backprop f np sum x x tensor work numpi function f backward trigger automat differenti x grad store df dxnmbr df dxnmbr df dxnmbr array nmbr nmbr nmbr it work leverag numpi new ish protocol overrid function thu mygrad could eventu use bring autodiff cupi xarray spars array array base librari thi proven also use librari help folk learn auto diff machin learn i first creat support class i teach becom fulli fledg autodiff librari sinc
diffgram-anthony,MachineLearning,1618524641.0,[P] Diffgram - Open Annotation Platform,share http github com diffgram diffgram http github com diffgram diffgram thi someth i anthoni work last nmbr year close sourc recent grown small team what make diffgram differ we list benefit http github com diffgram diffgram benefit i pick one thing complet system you run nmbr minut http youtu ynmbrlenmbrqpxxenmbr docker and scale big tech co level multipl knmbr cluster http diffgram readm io doc open instal product over time goal continu defin abstract need smoothli work data anyway desir system thi goe far beyond ui custom specif speed approach implement realli complet one system would love feedback http preview redd acknmbrfznmbrvetnmbr png width nmbr format png auto webp bnmbranmbrcnmbrcnmbrfnmbrdnmbrenmbrdnmbrcnmbrdnmbranmbraa
JuanPRamirez,MachineLearning,1617358083.0,[D] What would you say are the biggest hurdles for people looking to get into ML?,hey so context i junior year undergrad current take first cours ml hope look get deeper academia either becom research professor field i origin plan post ask i better prepar come i feel like better gaug first ask common major hurdl whether academ industri life hurdl commonli show ani info highli appreci
tomkoker,MachineLearning,1616612505.0,"[P] Torchsort - Fast, differentiable sorting and ranking in PyTorch",introduc torchsort implement fast differenti sort rank blondel et al http arxiv org ab nmbr pytorch complet custom c cuda kernel fast perform pip instal torchsort http github com teddykok torchsort http github com teddykok torchsort differenti sort rank oper open door new loss function for exampl easili implement spearman rank coeffici use torchsort model learn output predict monoton relationship target import torch import torchsort def spearmanr pred target kw pred torchsort soft_rank pred kw target torchsort soft_rank target kw pred pred pred mean pred pred pred norm target target target mean target target target norm return pred target sum pred torch tensor nmbr nmbr nmbr nmbr nmbr requires_grad true target torch tensor nmbr nmbr nmbr nmbr nmbr spearman spearmanr pred target tensor nmbr torch autograd grad spearman pred tensor nmbre nmbr nmbre nmbr nmbre nmbr nmbre nmbr nmbre nmbr the algorithm o n log n run quit fast cpu gpu even larg batch size sequenc length thank custom isoton regress kernel i hope help tool ml commun
SentientHero,MachineLearning,1616998376.0,[Project] Resumeasy: Our first attempt to create a data product: An application to recommand relevant jobs and useful skills based on user profile.,
crubier,MachineLearning,1619634130.0,"[P] Labelflow, the open source image labeling and dataset cleaning platform.",hi announc labelflow http www labelflow net http www labelflow net open sourc imag label dataset clean platform we team nmbr peopl experi imag label dataset curat build qualiti dataset deep learn we frustrat amount script requir move data back forth tool lack control data especi data easili share so start build labelflow imag label tool bell whistl open sourc backend connect data stack easili let know think feel free request earli access get nmbr releas month
abhijithneilabraham,MachineLearning,1619615635.0,Question Answering on Covid-19 data [research],hi i upload first model huggingfac lonfgorm model question answer covid nmbr data you find sourc code http github com abhijithneilabraham covid qa give star like project also test huggingfac api link given readm http preview redd dmknmbrfnmbriazwvnmbr png width nmbr format png auto webp enmbradnmbrfanmbrbnmbrceffnmbrenmbrcnmbraadnmbrcnmbr
Ziinxx,MachineLearning,1618165769.0,[P] Trained StyleGAN2-ADA on Naruto picture and plugged it through Lucid Sonic Dreams.,
episodeyang,MachineLearning,1620097999.0,"Paper claims scale invariance, Yet implicitly uses data augmentation?",
KirillTheMunchKing,MachineLearning,1616775591.0,[D] Encoding in Style (Pixel2Style2Pixel - pSp) explained,have guy seen result psp encod i found paper extrem use research gan invers latent space project deep learn base imag edit if want know main idea paper encod style stylegan encod imag imag translat pixelnmbrstylenmbrpixel psp richardson et al head telegram channel http casual_gan i break main idea popular gan paper in case miss pixelnmbrstylenmbrpixel nowaday use mani imag edit app simpl yet effect idea work read http casual _gan nmbr http casual_gan nmbr
jj4646,MachineLearning,1619157754.0,[D] neural tangent kernel,ha anyon heard neural tangent kernel i origin thought activ function neural network look http en wikipedia org wiki neural_tangent_kernel neural tangent kernel ntk kernel describ evolut deep artifici neural network train gradient descent it allow ann studi use theoret tool kernel method can someon pleas help understand mean whi neural tangent kernel import thank http rajatvd github io ntk
Rishit-dagli,MachineLearning,1616898697.0,[P] Implementing Geoffery Hinton's latest idea paper,i glad today present attempt implement geofferi hinton latest idea paper repres part whole hierarchi neural network also ml way human brain http github com rishit dagli glom tensorflow http github com rishit dagli glom tensorflow consid give star like
opensourcecolumbus,MachineLearning,1619664415.0,"[Project] Framework to build AI powered search with just 7 lines of code. Supports semantic, text, image, audio & video search",befor open sourc project jina http github com jina ai jina one depend close sourc solut implement neural search with jina help build semant search engin text text search imag imag search text imag search audio audio search text audio search text video search be open sourc apach nmbr licens modifi host infrastructur complet control data how differ solr elasticsearch solr elasticsearch implement symbol search rule base base jina implement neural search base pre train deep learn model result better semant search new capabl cross modal e g text video multi modal e g text imag video imag video text search appreci feedback question
RoyalScores,MachineLearning,1619528216.0,[D] Is Object Detection a sub-optimal way to do triage and diagnosis in Medicine?,current microscopi object detect fastest feasibl method diagnosi parasitosi triag underdevelop countri basic model given hundr microscopi imag fece appli object detect order find least one possibl case infect the way impact problem bulk neg imag elimin model imag might contain egg parasit analyz biomed thi person review detect classifi accordingli recent come classif part scheme isnt import problem could solv approach similar anomali detect creat network classifi imag suspici infect neg imag are current research go specif problem triag ml problem novel it seem urgent solv issu who declar intend elimin ntd nmbr biggest obstacl achiv scalabl cheap diagnosi
hardmaru,MachineLearning,1616392175.0,[R] A rapid and efficient learning rule for biological neural circuits,
hardmaru,MachineLearning,1620018399.0,[R] DriveGAN: Towards a Controllable High-Quality Neural Simulation,
bendee983,MachineLearning,1617367196.0,[D] Machine learning business models in robotics,boston dynam latest robot stretch bore comparison compani previou robot it danc backflip trick spot handl atla could but might commerci success robot compani creat far success autonom mobil robot hing versatil robust one hand cost effici on versatil side follow rule machin learn the narrow domain robust ml model you robot mani trick fail often one trick robustli stretch fit descript perfectli it one thing move box predict environ flat ground warehous reli work safe robustli case and given bd long histori comput vision robot push limit versatil beyond competitor without compromis robust safeti on cost effici side sinc bd acquir hyundai better posit manufactur robot low cost ship enhanc prop make even versatil so stretch cool potenti turn bd profit compani meanwhil continu work push limit scienc research humanoid bipe robot it kinda like patent clerk job einstein held earli nmbr it help pay bill use idl time develop import scientif theori histori read full analysi bd new robot mean compani futur http bdtechtalk com nmbr nmbr nmbr boston dynam stretch robot http bdtechtalk com nmbr nmbr nmbr boston dynam stretch robot
GiuPaolo,MachineLearning,1618831031.0,[R] Sparse Reward Exploration via Novelty Search and Emitters,excit announc work deal spars reward environ novelti search emitt accept gecco nmbr public you find http arxiv org ab nmbr http arxiv org ab nmbr the code instead releas http gpaolo github io seren http gpaolo github io seren check question hesit ask abstract reward base optim algorithm requir explor find reward exploit maxim perform the need effici explor even signific spars reward set perform feedback given sparingli thu render unsuit guid search process in work introduc spars reward explor via novelti emitt seren algorithm capabl effici explor search space well optim reward found potenti dispar area contrari exist emitt base approach seren separ search space explor reward exploit two altern process the first process perform explor novelti search diverg search algorithm the second one exploit discov reward area emitt e local instanc popul base optim algorithm a meta schedul alloc global comput budget altern two process ensur discoveri effici exploit disjoint reward area seren return collect divers solut cover search space collect high perform solut distinct reward area we evalu seren variou spars reward environ show compar favor exist baselin
huggingface,MachineLearning,1617809911.0,[R] A prompt is worth a thousand data points: combining GPT3-style prompting and traditional fine-tuning,
MushiML,MachineLearning,1619776404.0,[D] Temperature term in SimCLR or MoCo papers.,hi i read interest articl simclr quit help http amit com nmbr nmbr illustr simclr http amit com nmbr nmbr illustr simclr what real purpos term temperatur loss function pleas anyon help understand intuit exampl also i found temperatur term moco paper mean i found follow comment blog post http towardsdatasci com contrast contrast loss function nmbrcnmbrcanmbrfnmbr http towardsdatasci com contrast contrast loss function nmbrcnmbrcanmbrfnmbr i think i realli understood mean chen et al found appropri temperatur paramet help model learn hard neg in addit show optim temperatur differ differ batch size number train epoch thank
OnlyProggingForFun,MachineLearning,1619878190.0,[R] Infinite Nature: Fly into an image and explore it like a bird!,
tdls_to,MachineLearning,1619374980.0,[D] Can you train a privacy-aware language model,pretrain languag model memor train data uncov probe model appropri prompt thi seriou privaci implic here paper discuss i would love hear http arxiv org ab nmbr http arxiv org ab nmbr
kk_ai,MachineLearning,1619004138.0,[D] Convenient libs to use for new research project at the intersection of GNN and RL.,if start new research project start point rough idea want potenti take nmbr year tool would pick there number librari domain gnn rl base tf kera pytorch jax to end bit overwhelm review make inform choic i homework i candid mind i intent share i want bia discuss toward particular direct in gener i mind learn new librari promis flexibl futur grow commun user pl advic thx
hardmaru,MachineLearning,1617242521.0,[R] Fast Adaptation with Linearized Neural Networks,
techsucker,MachineLearning,1619587796.0,"[R] Researchers at JAIST, the Japan Advanced Institute of Science and Technology, Have Proposed a Model that Allows Voices to Mimic and Control the Generated Speech‚Äôs Speaker Identity",voic convers vc method use modifi speaker ident without alter linguist content non linguist inform vital natur human human commun by chang non linguist inform ad emot speech vc make human machin commun sound natur thi allow peopl get inform speech thu social better human use sever languag commun often need machin translat speech speech convers prof akagi jaist explain convent monolingu vc model face challeng appli cross lingual vc clvc task for exampl chang speaker ident led undesir modif linguist inform summari http www marktechpost com nmbr nmbr nmbr research jaist japan advanc institut scienc technolog propos model allow voic mimic control gener speech speaker ident http www marktechpost com nmbr nmbr nmbr research jaist japan advanc institut scienc technolog propos model allow voic mimic control gener speech speaker ident paper http ieeexplor ieee org document nmbr http ieeexplor ieee org document nmbr
jj4646,MachineLearning,1619072335.0,"[D] is the ""curse of dimensionality"" still as relevant as it was 20 years ago?",i read good exampl explain layman term curs dimension these exampl first consid circl insid squar nmbr dimens exampl nmbr consid sphere insid cube nmbr dimens exampl nmbr thi illustr fact cube exampl nmbr lot emptier ratio volum sphere cube compar squar exampl nmbr as number dimens increas e g cube becom hypercub nmbr dimens mathemat shown ratio empti increas in analog sphere repres data cube repres space data belong these exampl show us higher dimens need exponenti data fill space thu higher dimens data becom spars sparsiti make harder fit machin learn algorithm i understand intuit i know mathemat explan behind sparsiti give machin learn algorithm hard time perhap sparsiti make matrix calcul harder calcul furthermor shown use chernhoff inequ higher dimens data probabilist like occupi extrem region space exacerb curs dimension all said modern machin learn exampl e g deep neural network abl overcom curs dimension some cnn convolut neural network deal pictur natur high dimension data thu like suffer curs dimension yet compani like googl microsoft constantli develop neural network abl success make predict pictur by look would appear curs dimension dead rather affect us much how modern neural network abl handl curs dimension i read techniqu call manifold learn abl extract import inform data reduc number dimens therebi mitig curs dimension just thought somewher within architectur hidden layer neural network form dimension reduct take place
Spotums,MachineLearning,1617791320.0,[D] Docos on ML like AlphaGo - The Movie,i realli enjoy watch alphago the movi youtub wonder similar documentari relat machin learn worth watch entertain infotain without dri
jfischer,MachineLearning,1617812523.0,[P] Datahut.ai: A directory of data science and data engineering projects,http datahut ai new free websit provid statist analysi popular data scienc data engin project my wife i creat site spend lot time research project best fit given use case client person side project we cover nmbr project scratch surfac we love feedback topic cover addit content like see thank
soulslicer0,MachineLearning,1618352118.0,[D] Bayesian Machine Learning for KITTI Depth Estimation,thi code predict depth rgb imag but instead produc depth alon produc multimod depth distribut pixel form categor distribut thi use weed uncertain nmbrd point downstream adapt depth sens task we solv task monocular stereo lidar upsampl base depth estim use architectur the core network architectur taken psm net neural rgbd i note bayesian machin learn realli explor detail research especi look multi view stereo sensor fusion writeup http github com soulslic probabilist depth blob main pic explan pdf http github com soulslic probabilist depth blob main pic explan pdf code http github com soulslic probabilist depth http github com soulslic probabilist depth
harish-2306,MachineLearning,1616831163.0,[P] Looking for a teammate in implementing a neat algorithm in Python with C++ as the backend.,hi i nmbr major field data scienc i plan creat python librari neat c backend faster alreadi exist neat librari thi first time write librari i well experienc python c dl i thought write wrapper swig we cloud dicuss chang technolog plan need i fun person work so interest join drop messag thank
Inevitable_Engineer5,MachineLearning,1617281572.0,[D] Genetic Algorithm: the chromosome representation for Sliding Puzzle Solver?,hello i want solv game slide puzzl solver via genet algorithm but i idea chromosom represent problem for exampl i encod movement via bit nmbr nmbr nmbr right nmbr left it ok recombin work chromosom represent movement allow do idea thank
ykilcher,MachineLearning,1620491472.0,[D] Paper Explained - Involution: Inverting the Inherence of Convolution for Visual Recognition (Full Video Analysis),http youtu phnmbrjzunnmbrmoy http youtu phnmbrjzunnmbrmoy convolut neural network cnn domin comput vision almost decad appli two fundament principl spatial agnostic channel specif comput involut aim invert principl present spatial specif comput also channel agnost the result involut oper rednet architectur compromis classic convolut newer local self attent architectur perform favor term comput accuraci tradeoff compar either outlin nmbr nmbr intro overview nmbr nmbr principl convolut nmbr nmbr toward spatial specif comput nmbr nmbr the involut oper nmbr nmbr comparison self attent nmbr nmbr experiment result nmbr nmbr comment conclus paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com linmbr involut http github com linmbr involut
emystats,MachineLearning,1616606233.0,"[P] Best way to calculate ""performance"" in a probability estimation task",thank advanc take time read long post i work task particip estim probabl seri bead extract one two hidden jar the bead extract one one replac the two jar http stack imgur com nmbrfonmbrhm png contain bead two color yellow black differ proport jar a contain nmbr yellow bead nmbr black bead jar b contain nmbr yellow bead nmbr black bead while jar hidden particip awar differ therefor estim probabl sequenc bead extract specif one two jar exampl after extract particip alway answer question what probabl sequenc extract jar a then first bead extract yellow like bead extract jar a second bead also yellow even like sequenc bead extract jar a the estim cours chang particip shown bead all particip shown sequenc the actual task at event nmbr particip ask question see bead thi estim plot http imgur com xlnmbrqxlk png nmbr in plot see red line estim one particip on x axi see extract number event number axi probabl estim in black see ideal observ estim correct probabl then particip shown sequenc bead alreadi extract in case nmbr yellow bead nmbr black bead http stack imgur com pnmbrztpm png that point event nmbr sequenc like come jar a after particip shown bead extract one one they happen black particip know beforehand cours that probabl estim slowli decreas final sequenc http stack imgur com nrbbmm png the problem i would like defin perform profil particip base respond task then i would like abl correl profil psychometr result averag respons survey about perform profil i would like good idea much particip far ideal observ i thought i could calcul distanc pair point axi sum probabl absolut distanc squar distanc would better i would also like retain sign similar task particip respons overestim underestim ideal observ estim use distanc i could easili correl perform person data question doe make sens i wonder better way perform type analysi is way i retain inform particip choic for exampl i thought i could fit one curv particip respons one curv ideal observ estim evalu differ paramet defin curv i sure go someon suggest i instead perform time seri k mean cluster http drkeithmcnulti com nmbr nmbr nmbr cluster time seri data r group particip respons i familiar analysi could idea but i perform cluster analysi could i see cluster perform respect person criteria for exampl peopl cluster a particularli high x criterium i also thought perform pca http www sthda com english articl nmbr princip compon method r practic guid nmbr pca princip compon analysi essenti see person criteria correl anoth analysi i familiar the question relat psychometr result perform by way http stack imgur com bvmsq png see imag particip if idea recommend onlin exampl tutori i would realli appreci r code one particip librari ggplotnmbr librari scale particip probabl estim particip structur list event c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr prob_est c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr class data frame row name c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr ideal observ probabl estim ideal_observ structur list event c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr prob c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr row name c na nmbrl class data frame plot ggplot data subset particip event nmbr ae x event prob_est col red geom_point cex nmbr geom_lin lwd nmbr lab x event number probabl scale_y_continu break pretty_break n nmbr limit c nmbr nmbr scale_x_continu break pretty_break n nmbr geom_lin data subset ideal_observ event nmbr ae x event prob col black lwd nmbr geom_point data subset ideal_observ event nmbr ae x event prob col black cex nmbr plot calcul discrep ideal perform differ sum particip nmbr ideal_observ nmbr differ nmbr nmbr sup creat nmbr nmbr nmbr reprex packag http reprex tidyvers org vnmbr nmbr sup
SQL_beginner,MachineLearning,1619536458.0,[D] Rules for Determining how much Data should he used in a Model,thi concept alway struggl statist data alway better suppos nmbr year data hospit visit you interest supervis classif you predictor age height weight blood type salari etc you interest predict hospit stay less nmbr day nmbr day thi easili solv use random forest my dilemma use nmbr year data might abl captur wide varieti pattern sinc interest predict futur inform mayb older data less relev might surpress current trend how deal problem
Rina-Panigrahy,MachineLearning,1619364646.0,"[R] Google-Workshop: Conceptual Understanding of Deep Learning, May 17. Join Us.",pleas join us virtual googl workshop conceptu understand deep learn http site googl com view conceptualdlworkshop home when may nmbrth nmbram nmbrpm pst where live youtub http www youtub com watch v gnmbrdgbwjiulq goal how brain mind perhap even artifici one work algorithm level while deep learn produc tremend technolog stride recent decad unsettl feel lack conceptu understand work extent work current form the goal workshop bring togeth theorist practition develop understand right algorithm view deep learn character class function learn come right learn architectur may provabl learn multipl function concept rememb time human theoret understand languag logic rl meta learn lifelong learn the speaker panelist includ ture award winner geoffrey hinton lesli valiant godel prize winner christo papadimitri full detail http site googl com corp view conceptualdlworkshop home panel discuss there also panel discuss fundament question is mathemat model mind we explor basic question is provabl algorithm captur essenti capabl mind how rememb complex phenomena how knowledg graph creat automat how learn new concept function action hierarchi time whi human decis seem interpret twitter conceptualdlworkshop http twitter com search q nmbrconceptualdlworkshop src recent_search_click pleas retweet http twitter com rinapi statu nmbr hope see rina panigrahi http theori stanford edu rinap http theori stanford edu rinap
wattnurt,MachineLearning,1620102631.0,"[D] Are there any ML algorithms that can learn a simple ""X+1"" problem?",i idea simplist problem statement suppos n binari input n binari output the simpl problem arbitrari input copi output set one output bit nmbr ani as exampl input nmbr correct output would nmbr now n cours larg enough exhaust learn input output set train an interest side effect problem also input usual sever correct output mani nmbr input are ml algorithm learn someth like i note i much interest heavili cater solut e g problem statement encod featur set model architectur gener learn power point view are algorithm learn extrem simpl rule
Yuqing7,MachineLearning,1617727057.0,"[N] IBM, UMich & ShanghaiTech Papers Focus on Statistical Inference and Gradient-Boosting",a team univers michigan mit ibm watson ai lab shanghaitech univers publish two paper individu fair ml model introduc scale free interpret statist principl approach assess individu fair method enforc individu fair gradient boost suitabl non smooth ml model here quick read improv ml fair ibm umich shanghaitech paper focu statist infer gradient boost http syncedreview com nmbr nmbr nmbr improv ml fair ibm umich shanghaitech paper focu statist infer gradient boost the paper statist infer individu fair http arxiv org pdf nmbr pdf individu fair gradient boost http arxiv org pdf nmbr pdf arxiv
ykilcher,MachineLearning,1618846736.0,[D] Paper Explained - NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (Full Video Analysis),http youtu crln cyfxtk http youtu crln cyfxtk view synthesi tricki problem especi given spars set imag input nerf emb entir scene weight feedforward neural network train backpropag differenti volum render procedur achiev state art view synthesi it includ direct depend abl captur fine structur detail well reflect effect transpar outlin nmbr nmbr intro overview nmbr nmbr view synthesi task descript nmbr nmbr the fundament differ classic deep learn nmbr nmbr nerf core concept nmbr nmbr train nerf spars view nmbr nmbr radianc field volum render nmbr nmbr result view depend nmbr nmbr posit encod nmbr nmbr hierarch volum sampl nmbr nmbr experiment result nmbr nmbr comment conclus paper http arxiv org ab nmbr http arxiv org ab nmbr websit code http www matthewtancik com nerf http www matthewtancik com nerf
jj4646,MachineLearning,1619155542.0,"[D] can someone please explain the ""representer theorem"" in simpler term?",http en wikipedia org wiki representer_theorem can someon pleas tri explain represent theorem simpler term whi consid import realm machin learn thank
ClaudeCoulombe,MachineLearning,1619512223.0,"[D] Who first advanced the ""manifold hypothesis"" to explain the stunning generalization capacity of deep learning?",the manifold hypothesi state natur data lie low dimension manifold kind local euclidian subspac within high dimension space data encod i alreadi found clayton nmbr algorithm manifold learn http cseweb ucsd edu lcayton resexam pdf written term deep learn invent hinton nmbr brahma wu she nmbr whi deep learn work a manifold disentangl perspect http diginol lib fsu edu islandora object fsu nmbr datastream pdf view mention manifold hypothesi fact without citat
niels_vg,MachineLearning,1617358952.0,Predict Company Sales - Design choices; how to store incoming sales/which model to choose? [P],hi folk i tri predict book stand comedian cafe there lot featur i use affect number sale e g day year weather averag sale last month day week averag sale specif day week etc the goal creat model abl predict number sale given day everi hour start nmbr day nmbr hour show stop one hour deadlin show we multipl predict variabl alway known chang avg _nmbr averag daili sale last nmbr day avg _nmbr averag daili sale last nmbr day vacat hot cold variabl indic whether vacat day longtermgrowth number day compani alreadi exist measur continu growth dayofyear the day year min nmbr max nmbr weekday each day week hot cold encod moday nmbr nmbr etc apart variabl one indic mayb import highli correl eventu sale tri predict thi combin two variabl currenthour the number hour start show min nmbr max nmbr current sale the number sale alreadi obtain my question is would best method store data way i suffici train predict model for currenthour currentsal i doubt follow two method nmbr i simpli use two column x data nmbr indic number hour deadlin nmbr indic number sale alreadi obtain howev provid us inform sale obtain nmbr i creat column hour deadlin nmbr column total name hr _nmbr hr _nmbr where valu hour would number sale yet obtain timestamp the downsid solut would nmbr nmbr column hold data good idea thi like drastic increas comput time conclud i follow two question nmbr what would best two method describ store sale yet obtain better idea two scenario i creat would glad hear furthermor nmbr type predict model would think result best perform current i see high perform linear regress lasso ridg i hardli believ would result best perform thank avanc
jacobgil,MachineLearning,1619376340.0,[Project] Recent Class Activation Map Methods for CNNs and Vision Transformers,http github com jacobgil pytorch grad cam http github com jacobgil pytorch grad cam cam base method famili pixel attribut method tri highlight part imag contribut model output these method assign weight spatial nmbrd activ network sum get nmbrd salienc map thi project includ pytorch implement pip instal sever class activ map method includ recent one grad cam http arxiv org ab nmbr http arxiv org ab nmbr grad cam http arxiv org ab nmbr http arxiv org ab nmbr xgrad cam http arxiv org ab nmbr http arxiv org ab nmbr ablat cam http ieeexplor ieee org abstract document nmbr http ieeexplor ieee org abstract document nmbr score cam http arxiv org ab nmbr http arxiv org ab nmbr and work vision transform test deit well cnn test torchvis model i hope use conveni start point develop compar new method
TheCollaboratory,MachineLearning,1619194117.0,[P] Introducing The Collaboratory: A place to explore and discover research based on your interests,keep track new research increasingli time consum task mani field fast pace interdisciplinari domain like ml even harder stay top requir research self curat varieti sourc bookmark newslett arxiv review etc topic relev the collaboratori webservic aim eas pain explor keep research relev our platform automat sourc recommend latest research relev interest base paper seed read list these recommend power larg languag model transform research descript semant embed b compar pre comput embed grow index nmbrm paper dataset our model ensur recommend highli relev index effort ensur time we inspir solv problem encount daili live check dozen sourc week stay top literatur differ field we think tool realli use peopl spin new topic peopl whose interest lie field peopl need keep stream research move quickli pleas take look site let us know think thecollaboratori ai http thecollaboratori ai the platform remain work progress want keep make better pleas let us know make better
kaia_1527,MachineLearning,1618075767.0,[D] Learning resources: multi-object localization,hey everyon i learn multi object local wonder whether anyon could recommend learn resourc end end exampl i went nmbr fast ai http fast ai lesson http www youtub com watch v nmbrfrkxr nmbrpbi object local use pascal dataset exampl date i hope train multi object detector singl class found exampl surprisingli spars
swifty540,MachineLearning,1619081651.0,[D] How repetitive are the Ambient Sounds?,as fan ambient sound featur appl homepod i wonder repetit found thread r homepod comment dpunmbrm _anyon _els _feel _like _the _ambient _sound _are http www reddit com r homepod comment dpunmbrm does_anyone_else_feel_like_the_ambient_sounds_ar i sure actual repetit describ thread wonder machin learn could use figur exactli repetit actual doe anyon insight tool detect repetit audio
mamrollahi,MachineLearning,1616864558.0,[D] Which similarity method has been used in WS353 dataset?,hello may i know similar method use wsnmbr dataset http alfonseca org eng research wordsimnmbr html
KirillTheMunchKing,MachineLearning,1619540579.0,"[D] Main ideas from ""EigenGAN Layer-Wise Eigen-Learning for GANs"" explained!",eigengan layer wise eigen learn gan http casual_gan nmbr the author propos novel gener architectur intrins learn interpret direct latent space unsupervis manner moreov direct control straightforward way strength coeffici directli influenc attribut gender smile pose etc gener imag sampl architectur overview http preview redd zdsnmbrxwsnmbrsqvnmbr png width nmbr format png auto webp nmbrfnmbrbanmbrenmbrenmbrcnmbrcenmbrbfbnmbrcnmbrdnmbrenmbrdnmbreefnmbranmbrf direct travers exampl http reddit com link mzsnmbrct video nmbrokqodsqvnmbr player check nmbr minut paper explan http casual_gan nmbr arxiv http arxiv org pdf nmbr pdf
Anomalix,MachineLearning,1619811263.0,[D] Any good enough DCGANs that work on low-end GPUs?,i want experi bit dcgan nmbrgb vram enough someth like stylegan i wonder anyth run lower end gpu good enough i want abl nmbrxnmbr possibl nmbrxnmbr i bet imposs low amount vram
blatant_variable,MachineLearning,1619388418.0,[R] Correcting Experience Replay for Multi-Agent Communication (ICLR 2021 Spotlight),hi i first author paper rl agent learn commun in gener quit challeng agent learn polici chang make multi agent environ highli non stationari our key insight orwellian one use present inform alter past messag improv futur learn thi involv relabel messag sampl replay buffer reflect current commun polici agent we find greatli enhanc agent abil learn substanti improv perform multi agent rl algorithm across rang experi paper http openreview net forum id xvxpuckcnpo http openreview net forum id xvxpuckcnpo video http www youtub com watch v piinq fgdci http www youtub com watch v piinq fgdci pleas ask question may happi answer
minimaxir,MachineLearning,1619970229.0,[P] Create Your Own AI-Generated Magic: The Gathering Cards (2-cell Colab Notebook),http colab research googl com drive nmbrvotnmbruzvltobgmduzmunmbrvwhinmbrx nmbre_a a coupl year ago i train gpt nmbr magic the gather card work extrem well howev overengin due limit around gpt nmbr time now much better ai text gener tool i train bespok tini gpt nmbr nmbrm paramet encod magic card data use aitextgen http github com minimaxir aitextgen schema capabl anecdot qualiti card gener much better rnn approach past the card follow color pie i abl make colab notebook surprisingli littl code unnest includ card decod the model small enough run local cpu download notebook let know question
forsakenMule,MachineLearning,1617823068.0,[D] Regularly retraining a churn prediction model,i tri build process aim predict custom churn and i hard time find good resourc tackl problem retrain model inde rel easi train model first time given i right data i struggl determin best strategi deal regular retrain inde let assum i train model wich perform well compani decid use deriv action custom flag potenti churner i face issu new data avail bias action taken due predict model product reinforc learn realli option feedback time count year concept drift due product chang competit pressur rather month ani idea link go tackl issu
nirmalya8,MachineLearning,1617254105.0,"""[D]"" Generating Medical Images using GANs",hey peopl medic dataset either less data dataset imbalanc to deal imbal i thought synthet gener medic imag class less exampl so i look paper gener medic imag help gener adversari network can i get recommend constraint nmbr dataset no constraint prefer freeli avail nmbr either code paper detail architectur loss function activ function etc thank you
6rubtub9,MachineLearning,1619011427.0,[D] Meaning of semantic in machine learning,hi thi may elementari question ask i read sever comput vision paper i come across phrase semant use featur semant strong featur deep semant featur i tri look mean semant machin deep learn domain find satisfi answer so anyon explain mean semant strong deep use thank you
seuqaj114,MachineLearning,1618486921.0,[P] Nimbo: Run jobs on AWS with a single command,hey everyon my friend i launch nimbo http nimbo sh dead simpl cli wrap aw cli allow run code aw run local github http github com nimbo sh nimbo http github com nimbo sh nimbo doc http doc nimbo sh http doc nimbo sh we decid build frustrat cumbersom use aw want abl run job aw easili run local at time want make use cheap spot instanc nimbo singl paramet all like current user experi for reason also provid mani use command make faster easier work aw easili check price log onto instanc sync data snmbr see use command http doc nimbo sh use command unlik similar servic sole client side mean code run ecnmbr instanc data store snmbr bucket server infrastructur orchestr happen nimbo packag we ton idea nimbo one command jupyt notebook ecnmbr add docker support person favorit provid imag preload larg dataset like imagenet download store simpli spin instanc dataset avail dataset we happi receiv feedback suggest
michaelaalcorn,MachineLearning,1620422300.0,"[R] DeepMind - Game Plan: What AI can do for Football, and What Football can do for AI",
khalilmeftah,MachineLearning,1616538667.0,[P] Generating CryptoPunks Images with GPT-2,gener cryptopunk gpt nmbr http preview redd nmbrkncstuonmbr png width nmbr format png auto webp bnmbrfcnmbrfnmbrccnmbrbnmbrcanmbrcnmbrcfanmbrfnmbrcnmbr
chimp73,MachineLearning,1619910179.0,"[D] How far can we get with one-shot learning, generalization and policy gradient?",openai research http arxiv org ab nmbr show mere scale simpl nn improv perform gener sampl effici notabl fine tune gpt nmbr converg one epoch http github com cabhijith gpt nmbr_doc blob master fine tune md thi rais question can larg nn sampl effici one shot learn singl sdg updat reach human level infer gener abil beyond assum capabl i wonder could actor model look like make use chiefli one could elimin larg time horizon use rnn transform instead continu one shot learn sensori transit within brief time window predict next second previou one further one could dedic output neuron drive actuat train polici gradient then long term near term recal would simpli gener one shot learn sensori transit similarli decis make would simpli gener one shot learn modul polici to make clear i mean one shot learn sdg recal gener let say dinner predict go pasta actual fish then sdg updat make one shot learn ate even due predict error when ask ate next day gener context yesterday context question know fish further one could use predict sampl addit predict target model one shot learn predict thought occur gener reward modul thought becom goal driven allow agent ignor predict object increas reward e g ponder via inner monologu instead listen one would also need feed predict sampl addit sensori input time step model access thought predict then consciou thought latent space sensori space thi match human mind thought beyond model data gener process sensori experi further consciou thought would occur brief time slice also match human consciou thought skip one thought almost discret manner conscious henc exist briefli forward pass http karpathi github io nmbr nmbr nmbr forward pass realiti interpret second afresh tie togeth via one shot learn contextu inform previou step by allow model learn imagin predict reward imit learn would simpl consequ gener name identifi agent self model natur emerg the mere self model one predict thought learn predict one predict seem suffici thought get strateg condit previou thought goal direct reli gener i e model may condit x one shot learn polici updat world knowledg know x work context y establish subgoal the model also know thought act predictor thu gener order achiev x gener thought model expect complet manner use get y the architectur detail may matter much ignor econom factor larg differ differ nn architectur far even though transform perform nmbrx better http arxiv org ab nmbr lstm fig nmbr left strong diverg e evid lstm abl achiev perform nmbrx resourc transform seem mostli trick get larg time horizon biolog implaus also necessari reli one shot learn tie togeth long term depend instead long time horizon gener would side step issu meticul backprop long term depend tempor unrol exhaust backprop valu inform throughout state space rl polici gradient extrem noisi human level higher gener abil might abl filter one shot learn noisi updat common sens learn world work though predict task model conclud learn experi pain pleasur plausibl relat certain caus world
hiDDenthings63,MachineLearning,1616820874.0,[D] How do I make a model which takes a bedroom image as input give an output of different design of bedroom related to input image?,i want make model project take interior design imag input provid output differ kind design relat input imag i know start i think would use cnn track make i find anyth relat googl
KirillTheMunchKing,MachineLearning,1618595253.0,[R] Spatially-Adaptive Pixelwise Networks for Fast Image Translation (ASAPNet) by Shaham et al. - Explained,spatial adapt pixelwis network fast imag translat http casual_gan nmbr the author propos –∞ novel architectur effici high resolut imag imag translat at core method pixel wise model spatial vari paramet predict convolut network low resolut version input reportedli nmbrx speedup achiev baselin method similar visual qualiti more detail http casual_gan nmbr asapnet http preview redd ablptrdnmbrpktnmbr png width nmbr format png auto webp nmbrfednmbrdnmbrfbaanmbrdnmbranmbrcnmbrecec if familiar paper check http casual_gan nmbr
bendee983,MachineLearning,1616616039.0,[D] Has anyone tried Newton's method for ML optimization?,is scenario newton method would better sgd adam etc if ye includ ml dl framework unless i mistaken
deep-yearning,MachineLearning,1618494268.0,[D] What really makes neural networks generalizable?,we usual employ regular techniqu dropout batch norm earli stop etc help prevent model overfit train set perform well valid set howev still usual help model perform better real data test data data consid distribut train valid set thi mean model generaliz thi clearli huge area research paper i read lead direct usabl advic project instead focus theoret discuss generaliz pleas correct i wrong point better paper so question what practic tip train develop get model actual perform well real test data distribut data obvious start train valid data match distribut expect test data great start alway predict guarante distribut test data
amirninja,MachineLearning,1617643791.0,[Discussion] Similarity between two datasets/matrices,hello i dataset creat anoth dataset use tow differ method method a method b i would like find close newli creat dataset origin dataset what metric would make sens case cosin similar euclidean distanc if i captur close differ singl number use frobeniu norm thi subredit http www reddit com r machinelearn comment rnmbrinmbr proper_method_for_calculating_similarity_between seem suggest mantel test howev i sure that right one ani thought help would appreci thank
thisisdhruvagarwal,MachineLearning,1620638455.0,Can we use PPO in a multi-action task? [D],can use ppo multi action task like nmbr output layer first one specifi whether move left right second one specifi whether shoot both layer nmbr output neuron softmax activ function so use ppo task if ye what actor loss
JEUNGHWAN,MachineLearning,1620611903.0,[P] AI Kant is willing to be ghostwriter only for you,hi there i dream someon write philosophi essay place i major philosophi so i came idea i train gpt nmbr the critiqu pure reason kant kant becom ghostwrit write kantian essay place student the project call teachabl nlp http forum ainetwork ai teachabl nlp kant will ghostwrit nmbr http forum ainetwork ai teachabl nlp kant will ghostwrit nmbr it program help fine tune natur languag process nlp model without complex code graphic process unit gpu so easili train get nlp model there use case want i appreci feedback thought thank demo http reddit com link nnmbrtnmbrud video ognnmbrpttjnmbrynmbr player
broutonlab,MachineLearning,1620219389.0,[D] Have you ever faced attacks on deep learning model in your projects?,adversari attack blog post http broutonlab com blog adversari attack deep learn model seriou threat dl model an attack intent creat malici input fool dl model get incorrect output thi lead seriou troubl e g bank applic user identif face citizen surveil system airport the question nmbr when develop deep learn model take account fact may come adversari attack product nmbr if method protect employ nmbr have ever tri attack dl model product
Yuqing7,MachineLearning,1619627967.0,[R] Google‚Äôs 1.3 MiB On-Device Model Brings High-Performance Disfluency Detection Down to Size,a research team googl research propos small fast devic disfluenc detect model base bert architectur the smallest model size nmbr mib repres size reduct two order magnitud infer latenc reduct factor eight compar state art bert base model here quick read googl nmbr mib on devic model bring high perform disfluenc detect down size http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper disfluenc detect unlabel data small bert model arxiv http arxiv org pdf nmbr pdf
vaseline555,MachineLearning,1619268301.0,[D] Has anybody implemented FedAvg? I have a question,hello i implement fedavg use pytorch even look github repositori i still confus test model my main question nmbr should i prepar test dataset client e client train test dataset or i use global ident test set client sinc finish fedavg client model weight detail descript i deal mnist dataset nmbr client each client one digit client nmbr digit nmbr client nmbr digit nmbr client nmbr digit nmbr simul non iid set after local train client send paramet central server server aggreg final distribut averag model client for test averag model perform i test use test dataset digit former case question test nmbr time use local split test set one digit calcul mean report final perform it confus if latter true client final abil encod unobserv data e g client nmbr nmbr digit sampl final avail encod anoth digit nmbr nmbr fedavg am i right thank advanc
martin1285,MachineLearning,1618585781.0,[D] Serializing and using KNN for Predictions,hello i work problem i would like use k nearest neighbor regressor make predict i work python i use joblib serial model pickl format i understand k nearest neighbor instanc base requir entir train set make predict when run model pipelin etl train model serial model make predict i abl make predict use pickl model my understand python train data serial along algorithm requir load entir train data make predict result size pickl object get larger train data increas is understand correct deploy perspect thi would first time deploy instanc base model thank advanc
wdanilo,MachineLearning,1618363356.0,"[News] [Project] Enso 2.0 is out! Visual programming language for Data Science. It lets you code in a visual way in Python, Java, R, and JavaScript. Written in Rust and running in WebGL.",hi i wojciech one founder enso enso award win interact program languag dual visual textual represent it tool span entir stack go high level visual commun nitti gritti backend servic singl languag enso also polyglot languag let import librari enso java javascript r python use function callback data type without wrapper the enso compil underli graalvm jit compil compil instruct set unifi memori model check demo video http www youtub com watch v fqvwmoojmqk nmbr ab _channel enso http www youtub com watch v fqvwmoojmqk nmbr ab_channel enso websit http enso org http enso org github enso open sourc http github com enso org enso http github com enso org enso graalvm websit enso compil base http www graalvm org http www graalvm org
hardmaru,MachineLearning,1616464018.0,[N] NeurIPS2021 will be using openreview.net to manage submissions,accord program chair neurip nmbr use openreview manag submiss year review process public as previou year submiss visibl assign program committe all intern discuss remain privat review process after notif deadlin accept opt reject paper made public togeth anonym review meta review so unlik iclr review process still privat review would releas afterward reject submiss default would reveal unless author opt http openreview net group id neurip cc nmbr confer
techsucker,MachineLearning,1619392197.0,"[R] Scientists From The Max Planck Florida Institute For Neuroscience (MPFI) Have Developed ‚ÄòGold Digger‚Äô, A Software Tool That Uses A Modified PIX2PIX Deep Learning Network",electron microscopi em method use high resolut imag biolog non biolog sampl it requir precis time consum step sampl prepar imag acquisit produc clariti detail requir visual small cell structur high resolut addit extract biolog inform em creat imag labori time intens task thi current em analysi softwar usual requir skill eye examin hundr pictur manual a team scientist max planck florida institut neurosci mpfi appli neural network creat novel analysi softwar gold digger aim streamlin part lengthi process diego jerez eleanor stuart two high school data scienc student http techxplor com news nmbr nmbr gold digger neural network nexu html start work project curios but later turn complex interdisciplinari project summari http www marktechpost com nmbr nmbr nmbr scientist max planck florida institut neurosci mpfi develop gold digger softwar tool use modifi pixnmbrpix deep learn network http www marktechpost com nmbr nmbr nmbr scientist max planck florida institut neurosci mpfi develop gold digger softwar tool use modifi pixnmbrpix deep learn network paper http www natur com articl snmbr nmbr nmbr nmbr http www natur com articl snmbr nmbr nmbr nmbr
moon-child-99,MachineLearning,1618115946.0,[P] How do I validate a subjective model?,i cluster model classifi best worst essenti trade featur provid sinc class subject i valid test case right answer
bendee983,MachineLearning,1616423246.0,[R] Adversarial training reduces safety of neural nets in robots,adversari train result drop pure accuraci dl model gener receiv accept tradeoff robust adversari attack but use robot accuraci degrad caus safeti risk accord research paper http bdtechtalk com nmbr nmbr nmbr adversari train robot learn ist austria mit tu wien key point adversari train design static imag classif task infer task independ other robot deal dynam environ infer done depend sequenc in robot matter often error happen also error take place e happen consecut cycl result robot crash classic adversari train metric measur number misclassif error in robot also import far predict error deviat correct label read coverag paper interview lead author http bdtechtalk com nmbr nmbr nmbr adversari train robot learn http bdtechtalk com nmbr nmbr nmbr adversari train robot learn read full paper http arxiv org ab nmbr http arxiv org ab nmbr
Rohit901,MachineLearning,1618904137.0,[D] When to use one-hot encoding of categorical variables?,hey i nmbr continu input variabl nmbr categor variabl nmbr level i use one hot dummi encod creat nmbr variabl input degrad model perform i plan use simpl multi layer neural network mayb add lstm layer classif task if help i nmbr nmbr data point i plan use creat dummi method panda encod categor variabl
Appaulingly,MachineLearning,1618063524.0,[P] A machine learning tool now exists to detect Photoshop face warping!,sheng yu wang et al http arxiv org ab nmbr develop ml tool identifi imag edit use adob photoshop face awar liquifi tool common tool utilis warp facial featur the ml algorithm outperform human identifi edit imag even determin edit taken place imag i highli recommend check work fascin i creat subreddit r fakewarpbot scrape imag r instagramr r kimkardashianp use tool analys imag face warp r instagramr subreddit redditor post imag purport edit differ way but lot time suggest edit subtl human determin fact edit taken place so i hope r fakewarpbot provid certain determin edit you also post imag r fakewarpbot analysi i would stress way machin earn tool final determin whether face warp occur all credit goe sheng yu wang et al http arxiv org ab nmbr edit spell
_rusht,MachineLearning,1619974802.0,"[P] Onepanel - open source, extensible deep learning platform, now includes an Ubuntu based deep learning desktop, hyperparameter tuning and a Python DSL for defining pipelines and workflows",
aselsiriwardena,MachineLearning,1618556255.0,[P] Simple UI for deep learning model,hi i look help project i work it simpl imag imag translat project i want creat ui model the project built use pytorch i look simpl ui demonstr like select imag left side show result imag right side ani suggest are broiler plate code
NahanTrogn,MachineLearning,1618195876.0,[Discussion] About pre-processing audio for Yamnet's input,hi commun ml thi first time i post question forum i read input yamnet http github com tensorflow model tree master research audioset yamnet input audio featur input audio featur as previou releas vggish yamnet train audio featur comput follow all audio resampl nmbr khz mono a spectrogram comput use magnitud short time fourier transform window size nmbr ms window hop nmbr ms period hann window a mel spectrogram comput map spectrogram nmbr mel bin cover rang nmbr nmbr hz a stabil log mel spectrogram comput appli log mel spectrum nmbr offset use avoid take logarithm zero these featur frame nmbr overlap exampl nmbr second exampl cover nmbr mel band nmbr frame nmbr ms so question frame length nmbr ms exampl cover nmbr mel band nmbr frame nmbr ms but nmbr ms i think nmbr ms length window stft nmbrm window hop thank advanc wish good day
ottawalanguages,MachineLearning,1619755336.0,[D] How sensitive are statistical models to the richness of information within the data?,i spent last hour think creat exampl illustr question http imgur com nmbrgunmbrpb my question indirectli relat exploratori data analyt featur select statist model suppos variabl let assum categor variabl exampl make histogram variabl appear extrem skew on first glanc would want includ heavili skew variabl input statist model e g nmbr variabl singl valu inform use could statist model but know heavili skew variabl contain use inform nmbr might realli help make futur predict sometim use context problem e g work biolog problem consult biologist might abl gain insight time tri use logic figur heavili skew variabl fact use model big complex data possibl i post exampl illustr problem http imgur com nmbrgunmbrpb i would curiou know dealt similar problem past thank
dgheere,MachineLearning,1619432105.0,[R] Survey on evaluation of algorithmically generated music. Can you tell the difference?,dear at utrecht univers i conduct scientif studi evalu algorithm gener music i test see whether peopl identifi whether piec music made comput johann sebastian bach specif it matter whether familiar style bach i would much appreci could take nmbr nmbr minut time fill survey it would greatli help write bachelor thesi your respons cours complet anonym treat confidenti thank time http survey uu nl jfe form sv_nmbruclrbbcuhubnmbr
Professional-Bag392,MachineLearning,1617261893.0,[D] Is there a way to evaluate model during training?,i work machin learn project i set ml pipelin variou stage project the pipelin goe like data extract data valid preprocess train model evalu now model evalu concern current happen train complet base evalu model approv reject now i want model evalu take place train point say nmbr train complet train stop model evalu base model approv resum train how scenario implement
johndoe709,MachineLearning,1616437000.0,[D] Gender Bias in Persian to English Google Translate,the third person pronoun mani languag neutral call epicen in translat text languag languag third person pronoun neutral english translat usual either determin gender pronoun gener assum use evid below see translat text persian english done googl translat gender bia persian english translat http preview redd nmbrxsnmbrqtlnmbrbmonmbr png width nmbr format png auto webp cnmbrcnmbranmbranmbrcnmbrfnmbrdenmbr i point googl translat lot better year ago and help write text i curiou solut avoid bia languag model and solut becaus model train text human produc thi post inspir follow post http www reddit com r europ comment mnmbruphb hungarian _ha _no _gender _pronoun _so _googl utm _sourc share utm _medium webnmbrx context nmbr http www reddit com r europ comment mnmbruphb hungarian_has_no_gendered_pronouns_so_googl utm_sourc share utm_medium webnmbrx context nmbr
Stanford_Online,MachineLearning,1619652145.0,[N] Free webinar - Hacking AI: Security & Privacy of Machine Learning Models,regist upcom webinar stanford professor dan boneh he discuss recent work intersect cybersecur machin learn emphasi adversari machin learn http learn stanford edu secur privaci machin learn model webinar html http learn stanford edu secur privaci machin learn model webinar html
papajan18,MachineLearning,1619619546.0,"[R] ""Understanding Human Intelligence through Human Limitations"" - A Great Article that Highlights How to Think of the Relationship Between the Study of Human and Machine Intelligence",http www sciencedirect com scienc articl pii snmbr some highlight articl human intellig aris optim three main constraint limit time lifespan limit comput must fit insid singl brain commun must abl transfer solut brain sustain humankind the space problem human intellig solv subset potenti problem want artifici intellig solv most machin face constraint human necessarili use solut there use case machin intellig one limit time bandwidth high latenc commun in case understand human optim around constraint provid valuabl insight
qudcjf7928,MachineLearning,1618165059.0,"[D] Has anyone looked at ""LSPE"" algorithm as portfolio rebalancing method?",http proceed mlr press vnmbr uzielnmbra uzielnmbra pdf http proceed mlr press vnmbr uzielnmbra uzielnmbra pdf thi long short term forecast portfolio select transact cost paper claim produc posit return even market time typic problem classic method portfolio rebalanc commiss fee oblivi model result quit realist ever sinc numer way found incorpor said commiss fee etc and i came across lspe paper problem idea talk i get long term portfolio get rebalanc everi day short term portfolio mod nmbr agent choos updat short term portfolio but i idea transit path part what transit path purpos serv dimens use
ykilcher,MachineLearning,1619899473.0,[D] Paper Explained - DINO: Emerging Properties in Self-Supervised Vision Transformers (Full Video Analysis),http youtu hnmbrijnmbrfnmbrcpik http youtu hnmbrijnmbrfnmbrcpik self supervis learn final frontier represent learn get use featur without label facebook ai new system dino combin advanc self supervis learn comput vision new vision transform vit architectur achiev impress result without label attent map directli interpret segment map obtain represent use imag retriev zero shot k nearest neighbor classifi knn outlin nmbr nmbr intro overview nmbr nmbr vision transform nmbr nmbr self supervis learn imag nmbr nmbr self distil nmbr nmbr build teacher student move averag nmbr nmbr dino pseudocod nmbr nmbr whi cross entropi loss nmbr nmbr experiment result nmbr nmbr my hypothesi work nmbr nmbr conclus comment paper http arxiv org ab nmbr http arxiv org ab nmbr blog http ai facebook com blog dino paw comput vision self supervis transform nmbrx effici train http ai facebook com blog dino paw comput vision self supervis transform nmbrx effici train code http github com facebookresearch dino http github com facebookresearch dino
Difficult_Parsnip876,MachineLearning,1620376445.0,[N] The Pastry A.I. That Learned to Fight Cancer,the pastri a i that learn fight cancer the new yorker http www newyork com tech annal technolog pastri ai learn fight cancer seem like bread shop countri adopt technolog well
MaJhole007,MachineLearning,1618824980.0,[D] BERT Finetuning/Domain Adaptation,usual bert finetun downstream task task adapt small dataset nmbr sampl requir i wonder much data need finetun specif domain like financ domain adapt and expect result model outperform origin bert downstream task financi domain thank advanc
dojoteef,MachineLearning,1619234019.0,[R] Wordcraft: a Human-AI Collaborative Editor for Story Writing,
thunder_jaxx,MachineLearning,1616698147.0,[R] Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification,abstract in standard markov decis process formal user specifi task write reward function howev mani scenario user unabl describ task word number readili provid exampl world would look like task solv motiv observ deriv control algorithm first principl aim visit state high probabl lead success outcom given exampl success outcom state prior work approach similar problem set two stage process first learn auxiliari reward function optim reward function use anoth reinforc learn algorithm in contrast deriv method base recurs classif eschew auxiliari reward function instead directli learn valu function transit success outcom our method therefor requir fewer hyperparamet tune line code debug we show method satisfi new data driven bellman equat exampl take place typic reward function term experi show approach outperform prior method learn explicit reward function arxiv url http arxiv org ab nmbr http arxiv org ab nmbr thi wonder direct rl i excit paper written direct
jikkii,MachineLearning,1618864223.0,"[N] HuggingFace releases accelerate: A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-precision",huggingfac releas new pytorch librari acceler http github com huggingfac acceler user want use multi gpu tpu without use abstract class control tweak easili with nmbr line code ad raw pytorch train loop script run local well distribut setup they releas accompani blog post detail api introduc acceler http huggingfac co blog acceler librari here exampl look like practic huggingfac acceler practic http preview redd menmbrgnmbrrtmwnmbrunmbr png width nmbr format png auto webp nmbrefdfnmbrbfacnmbrenmbrenmbrcnmbrdfnmbrfnmbrafnmbrenmbr the librari fulli open sourc avail pypi github learn check document http huggingfac co doc acceler
fabien-campagne,MachineLearning,1618632546.0,[P] Multi-modality Perceiver implementation for Pytorch,i fork phil wang repo implement perceiv pytorch fix two problem implement nmbr the figur preprint text indic cross attent block follow latent transform the text indic latent transform nmbr block train imagenet thi repo fair implement i seen kera jax make mistak use singl latent block latent transform made sever block nmbr the signatur forward method implement support train multi modal input multi modal want train video audio imag instanc input model the signatur support multi modal modal differ number dimens posit encod must appli modal independ thi possibl accept singl tensor input forward posit encod done forward method the repo also offer experiment contribut help text one input modal i implement fix two issu fork http github com facnmbr perceiv multi modal pytorch http github com facnmbr perceiv multi modal pytorch packag avail pypi pip instal perceiv multi modal pytorch http github com facnmbr perceiv multi modal pytorch
bayonetworking123,MachineLearning,1619155102.0,[P] Imputing values to training/testing data after model selection,i develop model multipli imput miss valu covari data experi i ran as expect i select model train train data base test set fit am i run risk leakag use model predict miss valu combin train test data thi somewhat differ scenario i typic experienc i tri predict miss valu current data without overfit rather predict data i see futur i could use bootstrap dataset cross valid instead test set avoid issu i sure issu first place
squidwardstrousers,MachineLearning,1616373467.0,[D] Why does computer vision get more attention than speech recognition?,i see lot tutori dataset gear toward comput vision speech recognit whi
MonitorIndividual341,MachineLearning,1618801306.0,Prospects of Machine Learning and AI [Discussion],just want opinion futur ml ai how major role play futur what job also someon start learn topic
jwestonhughes,MachineLearning,1616338331.0,[D] Explicitly modelling inter-operator variability in segmentation,i medic imag segment dataset exampl segment exactli one twelv differ segment order thousand segment i want understand segment differ systemat exampl one segment usual draw tighter segment usual cut piec segment often doe anyon know exist comput vision method look i could swear i saw public recent build model predict everi segment segment i find wonder i dream
dlisfyn,MachineLearning,1619647752.0,[D] Need advice on how to generate HD point clouds visuals for a presentation,hi all i show point cloud data part present i want seek idea render high definit point cloud visual till i take screenshot meshlab look good also someon awar gener rotat shape visual nmbr nmbr http www youtub com watch v nmbriulxjmqiinmbr thank
whyhateverything,MachineLearning,1617194894.0,[D] Good algorithm for clustering big data (sentences represented as embeddings)?,hi i lot sentenc nmbr repres embed sentenc transform i want cluster group number sentenc larger well all result googl point kmean i like sinc use cosin similar scalabl slow at time i interest find good algorithm help cluster amount embed without lose qualiti time friendli i also struggl use solut sinc also ask cluster number advanc i cannit determin obviou reason i must point i profession machin learn engin even though i understand use implement disadvantag advantag i rewrit optim i often see happen research world pro data scienc ml ai your help valuabl welcom take care i wish good health everyon
spiritualParkour,MachineLearning,1619002088.0,[P] Coral Dev board vs coral Dev board mini,hope right sub ask i went site i understand differ http coral ai product dev board mini http coral ai product dev board mini http coral ai product dev board http coral ai product dev board it great someon point thank
tdls_to,MachineLearning,1617115495.0,"[P] ML Product Challenge (free to participate, sponsored by a few startups)",hey peopl we host machin learn product challeng http ai scienc _m deep learn product challeng cohort nmbr utm_sourc rdt work small team bring team meet peer team solv interest busi problem use ml there project sponsor startup well opportun work project nmbr nmbr prize build web app automat detect bia risk ml model nmbr nmbr prize tbc build recommend system web app nmbr nmbr prize build api mine relationship busi use case technic concept nmbr prize whatev want build if question pleas ping join info session http www eventbrit ca e ml product challeng info session xai ticket nmbr aff newslett ps thi challeng free join everyon need submit propos invit particip templat propos instruct video seri provid
RyanAI100,MachineLearning,1619981364.0,[D] CrossWeigh: Training NER with Imperfect Annotations | Research Papers Summary 016,
mennasiam,MachineLearning,1616527200.0,Video Class Agnostic Segmentation Benchmark in Autonomous Driving [R],check work video class agnost segment autonom drive identifi unknown object jointli semant panopt segment paper http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf code http github com msiam video _class _agnost _segment http github com msiam video_class_agnostic_segment demo http www youtub com watch v cnmbrhmfhdtsnmbrm http www youtub com watch v cnmbrhmfhdtsnmbrm
Green_ninjas,MachineLearning,1620350367.0,[R] Easier machine learning conferences,i know neurip deadlin come easier peer review journal confer i student i think paper decent qualiti i sure standard neurip without faculti mentor
remymess,MachineLearning,1619896317.0,[N] Hybrid seminar platform,hey friend hope great we alain remi phd mathemat statist togeth friend build hybrid onlin physic platform sculpt academ seminar while realli miss physic seminar find onlin seminar amaz myriad reason time cost ecolog network we want perk stop we envis futur seminar consist hybrid mixtur person onlin audienc build platform around vision we aspir leverag modern technolog academia make life seminar organis easi possibl allow everi academ open door academ seminar coupl click talk public other requir registr need review organis offer place onlin seminar particip socialis event virtual cafeteria form dynam gather town provid way physic onlin seminar particip interact give everi commun everi institut equal chanc shine worldwid qualiti event matter if vision reson pleas look websit http agora stream http agora stream we wit exponenti increas traffic sinc releas research group univers societi oxford ucl stanford world publish content regular basi the platform evolut driven feedback feel free reach us question suggest would like meet inform chat http calendli com remi mess e coffe http calendli com remi mess e coffe special thank mani engag us last time post nmbr we love meet hear experi idea see soon alain remi nbnmbr at moment platform complet free want money barrier knowledg veri soon deploy premium account user would want enjoy luxuri featur e g abil host seminar nmbr particip simpli support us nbnmbr to miss hottest seminar moment hear new featur follow us twitter link http twitter com agorastream http twitter com agorastream http www linkedin com compani agorastream http www linkedin com compani agorastream nbnmbr as appet small select fun featur got onlin seminar particip socialis event dynam gather town integr applic form potenti futur speaker everi commun page abil clap end seminar smash space bar fulli work dev environ releas soon mobil app allow physic onlin audienc interact fulli work dev environ releas soon
apatus,MachineLearning,1617707302.0,Multi-Task learning for unbalanced classes [P],i current work project assign four class input so exampl target could nmbr nmbr nmbr nmbr the problem class differ amount nmbr nmbr data in first class nmbr nmbr nmbr nmbr the problem model alway decid favor repres class thi mean class nmbr alway guess number close nmbr i find solut problem i read littl bit oversampl realli hard get distribut right sinc everi item number class i realli sure approach problem doe anyon idea i could solv
danparker276,MachineLearning,1616348052.0,"[D] Should I build my own AI bot for sms with azure ml studio, or use a 3rd party that say they understand speech better",so first cost much issu part ip better but look build concierg type bot take respons nurtur lead live agent there product like vers offer solut alreadi send logic need api should build ourself good ai ml dev we nmbrmillion row data either way feed system i guess whatev nmbrrd parti languag process top azur cognit servic lui text process aw googl nlp probabl data process make differ nmbrrd parti would anyway some nmbrrd parti work top and limit text sm logic go make much differ they say year experi convers make better either way say need live train well bot know i realli wonder nmbrrd parti blackbox make much differ
bloodcarter,MachineLearning,1619885051.0,[D] Black Box Interpretations,hi folk i wrote overview interpret problem is method i cover think i would love advic http dasha ai en us blog black box interpret ml http dasha ai en us blog black box interpret ml
ottawalanguages,MachineLearning,1618956370.0,[D] Why do polynomials have a bad reputation for overfitting?,we must heard start learn statist model overfit data first exampl often given polynomi function e g see pictur http ardianumam wordpress com nmbr nmbr nmbr deriv polynomi regress regular avoid overfit we warn although higher degre polynomi fit train data quit well sure overfit gener poorli test data my question whi happen is mathemat justif higher degre polynomi function overfit data the closest explan i could find onlin someth call rung phenomenon http en wikipedia org wiki rung nmbrs_phenomenon suggest higher order polynomi tend oscil lot explain polynomi function known overfit data i understand whole field regular tri fix overfit problem e g penal prevent statist model hug data close use mathemat intuit polynomi known overfit data in gener function e g respons variabl tri predict use machin learn algorithm approxim use older method like fourier seri taylor seri newer method like neural network i believ theorem guarante taylor seri polynomi neural network arbitrarili approxim function perhap neural network promis smaller error simpler complex but anyon know polynomi said bad habit overfit extent neural network larg replac interest paper http www nber org system file working_pap wnmbr wnmbr pdf
jakedageek127,MachineLearning,1616442294.0,[P] Mars 2020 Images Sorted by Content Diversity,hi spun quick project weekend the main outreach site http mar nasa gov marsnmbr multimedia raw imag raw imag mar nmbr persever rover great sort chronolog order these mission natur take multipl pictur target galleri page get bit repetit i made new simpl webdev passion galleri site use demud algorithm unsupervis novelti detect priorit novel interest imag the result content dens content divers collect imag skim easili http jakehle com mnmbr content divers the how doe thi work button explain methodolog i past i tri updat result morn even sinc imag roll throughout day i also comment answer question becaus persever take mani imag object design calibr target sort chronolog galleri result mani page similar content to find differ object content galleri flip hundr page thousand imag the demud algorithm solv problem priorit set imag divers novel content it quickli identifi one everi item rank look if give demud massiv orchard return one everi fruit thi use quickli find interest thing larg dataset the demud algorithm also capabl explain thought item interest enough bring attent it implement check step nmbr extract featur imag resnet nmbr last fulli connect layer prior softmax nmbr find interest imag demud nmbr display top nmbr order priorit resourc demud github repositori http github com wkiri demud guid scientif discoveri explan use demud wagstaff et al aaai nmbr paper link http wkiri com research paper wagstaff demud nmbr pdf unusu chemcam target disocv automat curios first nineti sol gale crater mar wagstaff et al lpsc nmbr paper link http www hou usra edu meet lpscnmbr pdf nmbr pdf interpret discoveri larg imag data set wagstaff lee icml whi nmbr paper link http wkiri com research paper wagstaff interp nmbr pdf visual imag content explain novel imag discoveri lee wagstaff dmkd nmbr paper site http jakehle github io visual img disc
Alternative_Detail31,MachineLearning,1617110460.0,[D] How effective is explainable AI in getting rid of biases?,i go y combin compani recruit manpow sector came across compani http www hiresweet com http www hiresweet com accord land page advertis could streamlin recruit process use explain ai order get rid bias what would setup possibl look like are someth like assign influenc percentag paramet someth like blog post addit read materi effect bia reduct xai welcom
techsucker,MachineLearning,1617164953.0,[N] Researchers at MIT and Amazon Study Pervasive Label Errors in Test Sets that Destabilize Machine Learning Benchmarks,larg label data set crucial success supervis machin learn ml across sever domain imag classif sentiment analysi audio classif howev machin learn ml dataset perfectli label the process use develop dataset often involv automat label crowdsourc inher error prone techniqu prior work majorli focus nois train set ml dataset not mani studi concentr label error test set yet divers potenti consequ no studi look systemat error across cite ml test set benchmark test dataset use evalu ml model valid theoret find if label error occur extens could potenti undermin framework measur machin learn progress label error test set could mislead practition incorrect conclus model perform summari http www marktechpost com nmbr nmbr nmbr research mit amazon studi pervas label error test set destabil machin learn benchmark http www marktechpost com nmbr nmbr nmbr research mit amazon studi pervas label error test set destabil machin learn benchmark paper http labelerror com paper pdf demo http labelerror com
GrettaGrove,MachineLearning,1619573475.0,[R] Self-Tuning Deep Reinforcement Learning,http arxiv org ab nmbrvnmbr http arxiv org ab nmbrvnmbr
GabrieleValvano,MachineLearning,1618841919.0,[R] Interested in GAN and Attention? Take a look at Adversarial Attention Gates!,find adversari condit attent gate improv object segment last least tri new weakli annot dataset project page http vio github io multiscal adversari attent gate http co uwnmbrbxkynmbrqnmbr amp nmbr paper http arxiv org ab nmbr http co nmbrnglbxhpqnmbr amp nmbr code http github com gvalvano multiscal adversari attent gate http co sfnmbrxcgxqci amp nmbr dataset http vio github io multiscal adversari attent gate data http co nkavtnmbrugd amp nmbr http preview redd cagmlnmbrgqnmbrunmbr png width nmbr format png auto webp nmbranmbrdnmbrcnmbrfnmbradnmbrdnmbrdnmbrbdanmbranmbraanmbrbnmbr abstract larg fine grain imag segment dataset annot pixel level difficult obtain particularli medic imag annot also requir expert knowledg weakli supervis learn train model reli weaker form annot scribbl here learn segment use scribbl annot adversari game with unpair segment mask train multi scale gan gener realist segment mask multipl resolut use scribbl learn correct posit imag central model success novel attent gate mechan condit adversari signal act shape prior result better object local multipl scale subject adversari condit segmentor learn attent map semant suppress noisi activ outsid object reduc vanish gradient problem deeper layer segmentor we evalu model sever medic acdc lvsc chao non medic ppss dataset report perform level match achiev model train fulli annot segment mask we also demonstr extens varieti set semi supervis learn combin multipl scribbl sourc crowdsourc scenario multi task learn combin scribbl mask supervis we releas expert made scribbl annot acdc dataset code use experi http vio github io multiscal adversari attent gate http vio github io multiscal adversari attent gate
sk81k,MachineLearning,1620485171.0,How big of a deal are scale free networks? [D],i sure right subreddit post sinc network analysi come machin learn i thought might right place i recent read broido clauset scale free network rare paper i wonder much differ model degre distribut scale free vs non scale free actual matter is need non scale free algorithm
rarboot,MachineLearning,1617027809.0,[D] Andrew Ng's data-centric vs model-centric Machine Learning,regard http youtu nmbr azxmwhjo nmbr http youtu nmbr azxmwhjo nmbr timestamp choic mine i actual referenc video mlop http www reddit com r machinelearn comment mfcanmbrp d_whats_the_simplest_most_lightweight_but post deeper comment thread i felt deserv discuss my abridg analysi machin learn data scienc current model centric in project orient team without back product i would actual rephras experi centric sens workflow someth line problem specif sota literatur review data collect model estim mvp ng advoc data centric approach allevi problem underspecif issu shift focu often fruitless model fiddl actual deliv valu qualiti data it feel like actual mlop talk sens actual project pattern tool present given last point qa i felt andrew ng comment http youtu nmbr azxmwhjo nmbr matur mlop tool internet tutori vertic approach advocaci actual veil critisc current mlop landscap i underwhelm first given andrew ng mlop hot topic afterward realli bug bad data manag especi project orient scenario ani thought
hou_yz,MachineLearning,1620040910.0,[R] Visualizing Adapted Knowledge in Domain Transfer,http arxiv org ab nmbr http arxiv org ab nmbr thi paper first attempt visual model learn domain adapt specif found sourc target network make similar predict compens knowledg differ target imag forc translat complet unseen sourc style such result also indic reli model rather imag style transfer http preview redd hgnmbrnnmbrhmtnmbrwwnmbr png width nmbr format png auto webp nmbraeaebnmbrbnmbrfnmbraanmbrebnmbrfnmbrenmbrebnmbr
techsucker,MachineLearning,1619285060.0,"[N] MLCommons, AI Industry‚Äôs Performance Benchmark, Releases MLPerf‚Ñ¢ Inference v1.0 Results To Understand The Power Usage of Machine Learning (ML) Models",machin learn area incorpor almost everi industri call standard machin learn benchmark similar spec benchmark creat primarili cpu these benchmark would prove pivot compar rel machin learn solut avail marketplac mlcommon http mlcommon org en open engin consortium work direct creat machin learn benchmark train infer platform mlperf mlcommon usual list industri academ partnership aim advanc develop access latest ai machin learn dataset the benchmark creat discuss disclos time make peopl awar refin take place along way recent compani unveil platform infer vnmbr also releas nmbr result http mlcommon org en news mlperf infer vnmbr databas not compani also disclos new power measur techniqu platform would look provid addit metadata result full read http www marktechpost com nmbr nmbr nmbr mlcommon ai industri perform benchmark releas mlperf infer vnmbr nmbr result understand power usag machin learn ml model http www marktechpost com nmbr nmbr nmbr mlcommon ai industri perform benchmark releas mlperf infer vnmbr nmbr result understand power usag machin learn ml model
GiuPaolo,MachineLearning,1618052104.0,[R] Last CFP for the Evolutionary RL workshop at GECCO 2021.,onli nmbr day deadlin nmbrst evolutionari reinforc learn workshop gecco nmbr premier confer evolutionari comput year held virtual lill franc juli nmbr nmbr nmbr in recent year reinforc learn rl receiv lot attent thank perform abil address complex task at time evolutionari algorithm ea proven competit standard rl algorithm certain problem simpler scalabl recent advanc ea led develop algorithm like novelti search qualiti divers capabl effici address complex explor problem find wealth differ polici all result develop spark strong renew interest popul base comput approach nevertheless even ea perform well hard explor problem still suffer low sampl effici thi limit less present rl method notabl sampl reus contrari struggl hard explor set the complementari characterist rl algorithm ea push research explor new approach merg two order har respect strength avoid shortcom the goal workshop foster collabor share perspect spread best practic within grow commun intersect rl ea the topic heart workshop includ evolutionari reinforc learn evolut strategi popul base method polici search neuroevolut hard explor spars reward problem decept reward novelti divers search method diverg search sampl effici direct polici search intrins motiv curios build design behaviour character meta learn hierarch learn evolutionari automl open end learn autor invit submit new origin work new perspect recent publish work topic top submiss select oral present present alongsid keynot speaker jeff clune ex team leader uberai lab current research team leader openai import date submiss deadlin april nmbr nmbr notif april nmbr nmbr camera readi may nmbr nmbr you find info workshop websit http site googl com view evorl
CopperGenie,MachineLearning,1620269184.0,[D] What is the most human-like chatbot available to the public?,i necessarili talk comprehens bot discuss wise but bot appear consist human like respons
ykilcher,MachineLearning,1620314786.0,[D] Paper Explained - MLP-Mixer: An all-MLP Architecture for Vision (Full Video Analysis),http youtu nmbrknmbrznmbrrqjwik http youtu nmbrknmbrznmbrrqjwik convolut neural network domin comput vision nearli nmbr year might final come end first vision transform vit shown remark perform even simpl mlp base model reach competit accuraci long suffici data use pre train thi paper present mlp mixer use mlp particular weight share arrang achiev competit high throughput model rais interest question natur learn induct bias interact scale futur research outlin nmbr nmbr intro overview nmbr nmbr mlp mixer architectur nmbr nmbr experiment result nmbr nmbr effect scale nmbr nmbr learn weight visual nmbr nmbr comment conclus paper http arxiv org ab nmbr http arxiv org ab nmbr
vadimdotme,MachineLearning,1619763832.0,[R] Eindhoven Reinforcement Learning Seminar,hi r machinelearn we run biweekli onlin obviou reason seminar reinforc learn tu eindhoven http einreis tilda ws we discuss advanc topic like bayesian method curios multi agent rl think rl theori seminar http site googl com view rltheoryseminar practic bent for everi topic tri invit best expert guest speaker deepmind openai uber lyft uva inria yandex etc check record youtub http www youtub com channel ucnmbrwcvhgsstonmbrtbbfnmbrpjcsnmbrw feel free join us we event today nmbr nmbr cet distribut machin learn no registr requir click join http meet jit si eindhovenreinforcementlearningseminar
SQL_beginner,MachineLearning,1619534991.0,"[D] appeal of ""occam's razor"" in statistics and machine learning",peopl often refer occam razor statist simpler model prefer complex model provid model similar perform whi prefer simpler model doe varianc bia tradeoff
Advanced_Treat_7986,MachineLearning,1617701673.0,[Project] How I trained Spotify Podcast Speech Synthesis using Tacotron2,project in project speech synthesi voic train spotifi podcast text speech deep learn model tacotronnmbr paper googl implement nvidia thi medium articl contain train done step usabl data pipelin make scalabl appli ml project code paper project found metdium articl
hardmaru,MachineLearning,1617069336.0,[R] ViViT: A Video Vision Transformer,
shinysamurzl,MachineLearning,1616671416.0,[D] Human Error Function,is human error function thing so like model creat result human give score learn repeat how would go implement someth like
AdelSexy,MachineLearning,1617816916.0,[D] Data imbalance and noisy labels,i cv classif task nmbr class dataset imbalanc toward class nmbr i also know label noisi class nmbr nmbr mess nmbr case observ i got better result test set suppos clean i use default random sampler case weight random sampler sampl imag batch respect weight opposit class presenc dataset thi unexpect can noisi label sourc i also use mixup affect bad train noisi label
MaxRek,MachineLearning,1620342257.0,"[Project], [Discussion] Do you know any time series annotation platform?",last mani month i engag gener studi signal valu time seri built data electron document flow electron document interchang larg compani contractor indic signific drop indic compani i learn produc coupl type signal data one problem frequent fals posit to combat featur i want add markup and train classifi for mark purpos time seri data need near futur annot mechan work project requir function mani class label in plot label label index valu threshold larg number time seri abil maintain fill sever markup session edit mark valu abil work sub seri last n valu time seri tag data statist thi new area therefor i crossroad implement function look readi made solut tri implement project is exist someth cover requir
JosephLChu,MachineLearning,1619818568.0,[R] Work In Progress: A Drop In Replacement For Softmax With Uncertainty Calibrated Scores,so i work activ function could work drop replac softmax main origin intent appli principl maximum entropi prior would allow activ function output better calibr confid score probabl term uncertainti it use formula i came convert correl score nmbr nmbr probabl nmbr nmbr the idea certainti measur nmbr certain nmbr fulli unknown nmbr certainli way convert nmbr nmbr probabl set nmbr correl scale nmbr n probabl scale how relev neural net sens pre activ signal nmbr given node basic mean everyth cancel map maximum uncertainti anyway i want give away mani detail given unpublish after lot time effort theoriz experi mani variant formula i think i someth work when i train network new activ function output layer instanc mnist test notmnist result output seem much less overconfid equival network train softmax sigmoid howev accuraci mnist chang much in fact task new activ function get similar result softmax use output layer so i sure use actual there one place might affect perform though point i test larger sota model i tri use place softmax attent head transform network languag model the result seem promis i know scale work across task toy problem i abl run singl gpu what i like know experienc research whether project worth tri make paper publish while i think i may someth i sure bia want time effort spent wast anoth problem i find cours time i work project i accumul mani variant activ function determin one actual best task scale prove tricki for i concern i sever version work situat perform better reliabl so sens i famili activ function simpler eleg other how one deal kind uncertainti
cdancette,MachineLearning,1617104591.0,[P] multimodal: a library for VQA / vision and language research,hi everyon i current build librari vision languag research http github com cdancett multimod for focus visual question answer vqa dataset vqa vnmbr vnmbr vqa cp dataset provid pretrain visual featur bottom top attent evalu metric those featur dataset hassl implement start work vqa i figur would nice refer implement work i also implement model bottom model vqa exampl use librari i plan add vqa dataset gqa clevr model task like caption edit i ad clevr dataset let know think would like librari like pretrain model task dataset
UBIAI,MachineLearning,1618595730.0,[D] Tutorial on how to train entity relation extraction classifier with transformers & use cases,we recent publish articl http walidamam medium com train joint entiti relat extract classifi use bert transform spaci nmbrebnmbrdnmbrbnmbrc joint ner relat extract transform eager hear use case pleas checkout articl http walidamam medium com train joint entiti relat extract classifi use bert transform spaci nmbrebnmbrdnmbrbnmbrc share use case if question simpli dm i get back asap
hardmaru,MachineLearning,1617852612.0,[R] SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network,
bebbo203,MachineLearning,1616746707.0,[D] Random Network Distillation (RND) applied to robotic manipulators,is work applic network manipul it seem like algorithm appli robot anywher i search googl scholar variou search engin thank
louloucha,MachineLearning,1618846331.0,[D] Explanation System on Time-Series Data,as part final year research project i univers laboratori i work design agnost e black box explan system base data mine techniqu recommend system also right i focus sequenti data e sequenti purchas behavior user sequenti dynam etc now i evalu part sequenti pattern mine algorithm base numer target i search competitor i could compar afaik for purpos i ask guy know algorithm baselin work identifi explan pattern time seri data i found bunch paper link i slowli work i found bunch paper link i slowli work http link springer com chapter nmbr nmbrfnmbr nmbr nmbr nmbr nmbr _nmbr http link springer com chapter nmbr nmbrfnmbr nmbr nmbr nmbr nmbr_nmbr http ieeexplor ieee org document nmbr http ieeexplor ieee org document nmbr http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf http arxiv org ftp arxiv paper nmbr nmbr pdf http arxiv org ftp arxiv paper nmbr nmbr pdf ani help would appreci
Brahimce,MachineLearning,1618447831.0,[R][P] How to deal particle swarm optimization with equality constraints?,i face problem i want creat pso system particl consist nmbr variabl real variabl sum variabl equal one i gener initi popul i gener new popul initi popul particl gener popul equal one
Math_wizard369,MachineLearning,1620590419.0,[D] Annotated Research paper Walkthroughs using Jupyter Notebooks,hi i went the annot transform http nlp sea harvard edu nmbr nmbr nmbr attent html harvard nlp the post walk attent need paper line line also clone post googl colab read along run code i learn lot go notebook wonder anyon knew anymor type notebook i rememb websit i found back i abl find ani help would greatli appreci thank
Gletta,MachineLearning,1620281236.0,[N] Computer Vision News (with research and code!) - May 2021,dear have peek comput vision new may mani articl ai deep learn htmlnmbr version recommend http www rsipvis com computervisionnew nmbrmay pdf version http www rsipvis com comput vision news nmbr may pdf dilbert page nmbr free subscript page nmbr enjoy http preview redd nmbrinmbrlnmbrxayfxnmbr jpg width nmbr format pjpg auto webp fnmbrcnmbrbffnmbrdcfdnmbrfnmbrcfnmbrenmbranmbrcnmbrfnmbr
Yuqing7,MachineLearning,1619026057.0,[R] Pieter Abbeel Team Proposes Task-Agnostic RL Method to Auto-Tune Simulations to the Real World,a research team uc berkeley carnegi mellon univers propos task agnost reinforc learn method reduc task specif engin requir domain random visual dynam paramet here quick read pieter abbeel team propos task agnost rl method auto tune simul real world http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper auto tune sim real transfer arxiv http arxiv org pdf nmbr pdf
ennanco,MachineLearning,1617956035.0,"[N] Call for Papers: Special Issue ""Applied Machine Learning in NIR Technology""",host special issu appli scienc jcr nmbr submiss diffus highli appreci http www mdpi com journal applsci special _issu nir _technolog http www mdpi com journal applsci special_issu nir_technolog special issu inform sinc nmbr near infrar reflect nir scanner common companion laboratori thi technolog allow analysi electromagnet spectrum band close visibl spectrum as result larg amount inform analyz order make predict factor qualiti sampl thi advantag abl quickli analyz materi without destroy sampl made recent time kind equip move laboratori portabl devic case small credit card therefor numer applic develop umbrella technolog analysi sewer water determin food safeti diagnosi construct materi support medic vet diagnosi number applic near endless howev blossom applic usual goe along requir model identifi use inform captur spectra the relationship factor usual non linear complex necessari use machin learn techniqu obtain although usual perform analyt process current applic machin learn step forward term precis adjust result as nir machin learn multidisciplinari technolog mani field scienc industri could benefit use especi focu featur select band spectra contain inform requir solv problem applic machin learn need process adjust optim perform the aim special issu present latest advanc made field combin techniqu well show remain challeng futur area research that special issu solicit submiss limit follow area select featur band nir spectra special interest applic use nano scale nir scanner due limit oper rang studi differ preprocess techniqu comparison automat featur extract process pca lda evolutionari comput develop combin cloud comput fog comput edg comput process nir spectra differ industri process applic compar latest approach machin learn techniqu deep learn ensembl model work particular interest cover explain artifici intellig frame decis make use nir data machin learn keyword signal process near infrar machin learn artifici neural network support vector machin k nearest neighbour na√Øv bay random forest ensembl model evolutionari comput explain artifici intellig ensembl method deep learn featur extract princip compon analysi pca food secur materi analysi drug identif medic diagnosi vet diagnosi internet thing iot
ml_abler,MachineLearning,1620639883.0,[D] ML and Quantum Computing,hi reddit i entir sure right place ask i go i recent got opportun work quantum comput team the entir purpos team find applic quantum comput firm it sound like amaz opportun i lot reserv would love appreci insight i come cs engin background master ai ml full time posit moment data scientist work cluster model the quantum comput opportun avail due format new team lot vacanc moment although prospect quantum ai ml sound hella interest although nich quantum comput seem like extrem departur formal educ heavi emphasi physic thi make anxiou how viabl opportun career how job prospect domain someon background would help creat nich data scienc i admit shamelessli i like career pay big buck time keep interest enough would love opinion
MrAcurite,MachineLearning,1617202567.0,[D] Does anyone care about the quality of the prose in academic papers?,i read lot great literari work late i go back read academ paper notic downgrad qualiti languag employ and i guess make sens want commun technic inform lot room reason employ metaphor color languag but still seem like way make work better make legitim enjoy read instead linguist equival shove stale bread throat obvious often lot beauti found appreci clever new idea present appreci typic spite rather due actual qualiti write is someth anybodi els care
olegvol,MachineLearning,1617562096.0,[P] QSMM for building algorithmic neural nets,i work qsmm framework build algorithm neural net in principl produc qualiti adapt behavior requir excess comput resourc train oper suffer problem explain gener behavior the core method oper random select next state algorithm neural net accord probabl possibl state calcul basi cycl occur neural net current framework exampl demonstr possibl use case number shall increas futur one exampl util framework adapt pars token sequenc i hope peopl make use implement idea transform approach behind concept artifici intellig http qsmm org http qsmm org
vajra_,MachineLearning,1616699791.0,[D] Model Size calculation for sparse neural networks,in gener calcul model size spars neural network much weight nmbr non zero weight nmbr byte
deama15,MachineLearning,1616545017.0,[Project] Remastering old anime using machine learning,so i remast use ai algorithm old anim hajim ippo box anim finish the type remast i enhanc resolut clean artifact nois frame interpol i made subreddit i got info well faq sampl check http www reddit com r interpolateandenh screenshot comparison first one old second one new http doc googl com present nmbrbtnmbrpzizbdnmbrhovyxbnnmbrijlficmlqlnmbrbhqq_lnmbronnmbrpnmbrha edit usp share for i anim next seri old hunter x hunter at point i want tri live action content specif action stuff like martial art movi straight action interpol algorithm quit good enough well actual kinda least high end one good luck tri interpol anyth anyth rtx nmbr
machinemask,MachineLearning,1617699100.0,[D] Best system load monitoring tool?,hello i look tool monitor display inform cpu gpu usag time i envis someth like htop togeth interact dashboard filter data e g time user i like instal compani gpu server get better understand use we mostli use server train comput vision model i interest here featur i think would interest cpu usag block vs non block gpu util memori usag ram usag disk read write support multipl machin display save data dashboard filter display data e g user process time i found project similar thing permon http github com bminixhof permon gpu monitor http github com msalvari gpu_monitor nvtop http github com syllo nvtop weight bias http wandb ai site articl monitor improv gpu usag model train what think is good idea set system is softwar i miss ani experi suggest welcom
jhanytime,MachineLearning,1618156460.0,[D] Video - Introduction to graph neural networks (made easy!),i phd student studi machin learn applic transport system autonom system think rl robot while sever gcn made easi video youtub i feel like video often miss forest tree especi sinc gcn nmbr algorithm develop nmbr video often cover broader histor context gnn develop cover differ variat model allow model new type system thi second video seri i make graph graph neural network applic area potenti make big impact pleas let know think video learn anyth new http youtu ckanmbrfanmbrttinmbr
rish-16,MachineLearning,1620547959.0,[P] PyTorch Involution layer wrapper,hello everyon i current process learn implement paper scratch here implement newli introduc involut layer paper involut invert inher convolut visual recognit li et al present cvpr nmbr wrapper http github com rish nmbr involut _pytorch http github com rish nmbr involution_pytorch do forgiv implement error pr issu welcom note i releas tensorflow wrapper soon time permit if like would greatli appreci it motiv continu build easi use ml wrapper d thank
sim_inf,MachineLearning,1617905410.0,[D] Student Travel Grant for ACL/NAACL/EMNLP,is student travel grant award acl confer i mean acl naacl emnlp if one appli the confer commun typic receiv applic variou form i contact chair follow websit twitter account but i post hear nlp person know perhap first hand experi thank
ka-wei,MachineLearning,1618776983.0,[P] Cinemate - Movie Recommender System made with Tensorflow Rust,for last coupl month i work movi recommend system use tensorflow rust the model use collabor filter neural network recommend movi base movi input unlik model find internet model also take rate popular trade coeffici input if prefer popular movi coeffici set nmbr valu high averag rate coeffici set nmbr the optim number probabl two default valu nmbr a big goal websit fast recommend get recommend matter second due perform highli optim predict rust you visit websit http cinem http cinem
NoAnalyst4,MachineLearning,1620067314.0,[D] Does the ICML acceptance rate curtailment impact 2021 submissions?,are new icml accept rule appli year paper next year submiss thi first ever submiss icml i worri chanc chang announc http www reddit com r machinelearn comment nnmbrqw _icml _confer _we _plan _to _reduc _the _number _of http www reddit com r machinelearn comment nnmbrqw d_icml_conference_we_plan_to_reduce_the_number_of i bias seem realli unfair chang polici middl decis process
Yuqing7,MachineLearning,1619109567.0,[R] Are Multilingual Language Models Fragile? IBM Adversarial Attack Strategies Cut MBERT QA Performance by 85%,an ibm research team propos four multilingu adversari attack strategi attack seven languag zero shot set larg multilingu pretrain languag model e g mbert reduc averag perform nmbr percent here quick read are multilingu languag model fragil ibm adversari attack strategi cut mbert qa perform nmbr http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper are multilingu bert model robust a case studi adversari attack multilingu question answer arxiv http arxiv org pdf nmbr pdf
hardmaru,MachineLearning,1617623139.0,[R] Towards General Purpose Vision Systems,
Superb-Drawer5214,MachineLearning,1617340770.0,[D] How important is the prestige of undergraduate school in getting into top ML PhD programs?,i look cv resum phd student cmu berkeley stanford univers washington mit got bachelor degre berkeley stanford mit cmu harvard princeton iit there student graduat famou ivi leagu school univers washington peke tsinghua i could view cv resum upload cv i consid attend umd three student graduat umd phd school
byronbae,MachineLearning,1616680571.0,[P] Sound pollution mapping from GeoJSON,i undertak data scienc project within job subject unfamiliar there alreadi big problem extrem data scarciti asid i wonder anyon could help start point to put simpli possibl i geojson file contain sound measur specif coordin throughout citi i would like build model tri predict noisiest point eventu goal would includ type relat data real time traffic etc etc for i found seem closest problem http omdena com heatmap machin learn it go concept actual appli technolog etc idea type data outcom similar goal i play around data bit alreadi notebook leaflet arcqgi bit issu wrap head around entir workflow project could work sinc i want go map raw data point map key point identifi analysi point ani insight would greatli appreci
Ekkolo,MachineLearning,1620631488.0,[D] NER for Resume Parsing,hello i need resum pars french resum i use prodigi prodi gy http prodi gy annot dataset make model my question better annot full resum annot line line posit text full document inform mayb spaci care thank
Acrobatic-Egg-,MachineLearning,1619433901.0,[D] The Journey Of Problem-Solving Using Analytics,in nmbr year work analyt domain fortun nmbr client across geographi one thing i realiz peopl may solv busi problem use analyt journey lost somewher at risk sound clich enjoy journey destin so attempt creat problem solv journey i experienc learn fail the framework problem solv use analyt nmbr step process on go nmbr break busi problem analyt problem let start anoth clich if i hour solv problem i spend nmbr minut think problem nmbr minut think solut thi lot analyst consult fail as soon busi problem fall ear straightaway get solut ing without even bare attempt understand problem hand to tackl i team follow call cs fs framework extra mark come better name the cs fs framework stand current state futur state framework in cs fs framework first step identifi current state client current problem follow next step identifi desir futur state want solut provid insight behavior driven insight final outcom driven behavior the final import step cs fs framework identifi gap prevent client move current state desir futur state thi becom analyt problem thu input next step nmbr find analyt solut analyt problem now busi problem convert analyt problem let look data shall a big no we start form hypothes around problem without be bias by the data i stress point enough the process form hypothes independ data avail the correct method form possibl hypothes look avail data elimin hypothes data after hypothes form start look data usual analyt solut follow understand data eda test hypothes ml problem requir yada yada yada thi part analyst good for exampl problem revolv around custom churn step go ahead classif model let remind output step analyt solut classif model custom churn problem most time peopl solv problem would technic gift understand confus matrix output classif model output auc roc curv they want talk languag understand thi take final road journey problem solv final step nmbr convert analyt solut busi solut an analyt solut comput busi solut human and less deal human want understand mani week worth effort produc you may creat effici accur ml model world ever seen final stakehold unabl interpret mean whole exercis useless thi use stori board experi actual tell stori would start current state problem step taken reach desir futur state thi visual skill dashboard creation insight gener creation deck come pictur again creat dashboard report keep mind tell stori lay beauti color chart power bi tableau dashboard each chart number report action orient part larger stori onli someon understand stori like go purchas anoth book onli make journey beauti meaning fellow passeng stakehold travel with said i reach destin i hope i total open critic suggest improv i make journey look forward input commun
SimlaBurcu,MachineLearning,1619032775.0,[P] ColTraIn Hybrid Block Floating-Point (HBFP) Training Emulator,we excit announc releas coltrain hbfp train emul http github com parsa epfl hbfpemul hbfp http paper nip cc paper nmbr file nmbranmbraeddfcnmbrcnmbrdnmbrenmbrbnmbrcccnmbrabnmbrbcnmbr paper pdf offer accuraci nmbr bit float point numer silicon densiti nmbr bit fix point wide varieti model resnet wideresnet densenet alexnet lstm bert we forese hbfp lay foundat accur train algorithm run acceler order magnitud denser arithmet convent novel float point base platform the coltrain emul repositori includ sever exampl dnn model includ cnn lstm bert hbfp refer fpnmbr baselin check coltrain emul http github com parsa epfl hbfpemul http github com parsa epfl hbfpemul visit websit http parsa epfl ch coltrain http parsa epfl ch coltrain inform
hardmaru,MachineLearning,1618498632.0,[R] Meta-Learning Bidirectional Update Rules. A new type of generalized neural net where neurons and synapses maintain multiple states. They show that backprop in classical neural nets can be seen as a special case of a two-state net where one state is used for activations and another for gradients.,
Svito-zar,MachineLearning,1617024327.0,[D] Is anyone using Automatic Bug Fixing Tools for Python?,mani us make bug some often i one after fix bug sever month screw mani experi i wonder ml find bug quick search topic result mani paper even tool http analyticsindiamag com nmbr python bug fix tool essenti develop http analyticsindiamag com nmbr python bug fix tool essenti develop and i wonder anyon use tool are actual work can fix copi past error
mrgemy95,MachineLearning,1620443257.0,[D] JAX vs Pytorch gpu performance.,doe anyon know benchmark compar jax api pytorch speed gpu i awar comparison http dzone com articl acceler automat differenti jax http dzone com articl acceler automat differenti jax compar desn lay i look someth benchmark complic architectur
projekt_treadstone,MachineLearning,1619738644.0,[D] Prototypical network in the medical domain,is exist project work implement prototyp network base meta learn medic imag as medic imag heavier load comput imagenet i would like know handl larg pixel medic data as i resiz larg medic imag per standard prototyp architectur larg drop accuraci with larg resiz valu fit gpu train
hardmaru,MachineLearning,1616865606.0,[R] Out of Distribution Generalization in Machine Learning (Martin Arjovsky's PhD Thesis),
PebbleWrestler9000,MachineLearning,1617831182.0,[D] Issues with using LSTM networks to classify raw EMG signal data,i unsur correct subreddit post i current issu ml undergradu research project i hope potenti get guidanc my current task take emg signal data time domain electr signal data gather user classifi finger person engag moment thi multi class label classif problem nmbr total label possibl thi exampl emg signal look like plot python http preview redd ggednmbrotfgtrnmbr png width nmbr format png auto webp fafnmbrdnmbrfnmbrdnmbrdcbddnmbrddnmbrfnmbrenmbrcenmbrb as tell graph i normal amplitud rang rang nmbr nmbr ensur time seri equal length i append nmbr front end seri match length longest sequenc data set as result time seri approxim length nmbr nmbr total seri the distribut label approxim equal the result tensor shape nmbr nmbr nmbr nmbr row nmbr length sequenc nmbr valu store time step i current use follow kera model http preview redd frrnmbrcnbygtrnmbr png width nmbr format png auto webp anmbrenmbrfnmbrefeadenmbrbcnmbrabbnmbranmbrdcnmbrc i use lstm network length sequenc number neuron follow dropout follow dens layer anoth dropout layer final classif dens layer i use adam optim algorithm learn rate nmbre nmbr nmbre nmbr i also tweak lnmbr kernel regular valu default rang nmbre nmbr nmbre nmbr my issu i unusu terribl perform exampl http preview redd nmbresbnmbrphtrnmbr png width nmbr format png auto webp cfnmbrfnmbrcanmbrenmbrcnmbranmbrecaanmbranmbrfcnmbra the valid accuraci consist zero valid loss continu increas fit train accuraci plateau around valu nmbr i run model nmbr epoch valid accuraci nonetheless remain nmbr loss increas the train accuraci loss continu plateau even nmbr epoch i initi suspect overfit could issu deal dropout layer i believ case would anyon chat help figur go model simpli learn thank
hardmaru,MachineLearning,1617937116.0,[P] Neuralink's Monkey Mindpong,blog post http neuralink com blog their decod presum train machin learn take neural activ data monkey calibr enabl monkey play pong directli thought
Jack_Hackerman,MachineLearning,1618764770.0,[D] How to normalize and merge two different datasets with similar deltas for Keras?,hi i get enough attent stackoverflow ask i two dataset train model the first dataset valu within rang nmbr nmbr anoth one nmbr nmbr rang essenti dataset similar sens percentag data chang so nmbr data chang rownmbr valuenmbr nmbr rownmbr valuenmbr nmbr first dataset anoth dataset someth like rownmbr valuenmbr nmbr rownmbr valuenmbr nmbr raw valu rang target differ similar percentag chang nmbr how i normal make similar combin break network nmbr is possibl nmbr should i normal target should i normal data i feed predict function i tri predict stock someth data financi data need job make regress bond paramet updat i realiz i normal first second dataset separ use set mean set std lol i target what one target nmbr anoth target nmbr
Yuqing7,MachineLearning,1617896959.0,[N] ContinualAI Releases Avalanche: An End-to-End Library for Continual Learning,a research develop team continualai includ larg group research ku leuven byted ai lab univers california new york univers institut propos avalanch end end librari continu learn base pytorch here quick read continualai releas avalanch an end end librari continu learn http syncedreview com nmbr nmbr nmbr continualai releas avalanch end end librari continu learn the paper avalanch end end librari continu learn arxiv http arxiv org pdf nmbr pdf
thedeepreader,MachineLearning,1620224443.0,[D] (Paper Overview) MLP-Mixer: An all-MLP Architecture for Vision,video http youtu nmbrfhmzebnzro http youtu nmbrfhmzebnzro paper http arxiv org ab nmbr http arxiv org ab nmbr code will soon avail author http github com googl research vision _transform http github com googl research vision_transform abstract convolut neural network cnn go model comput vision recent attent base network vision transform also becom popular in paper show convolut attent suffici good perform neither necessari we present mlp mixer architectur base exclus multi layer perceptron mlp mlp mixer contain two type layer one mlp appli independ imag patch e mix per locat featur one mlp appli across patch e mix spatial inform when train larg dataset modern regular scheme mlp mixer attain competit score imag classif benchmark pre train infer cost compar state art model we hope result spark research beyond realm well establish cnn transform
niujin,MachineLearning,1620380538.0,[D] Predictive model for the shape of an entire histogram,i work project market research survey respond repli survey nmbr point scale nmbr dislik nmbr indiffer nmbr like the respons shown histogram i would like develop ml model predict shape histogram survey survey run wild i databas past survey countri industri etc it straightforward predict singl valu mean histogram train machin learn model predict entir histogram so far approach i consid train nmbr separ independ model train model mean one stdev assum normal bad assumpt i know histogram mani differ shape design custom machin learn architectur nmbr output when i train model predict mean histogram best perform come ensembl model random forest use auto ml azur ml ha anybodi tri someth similar i new market research data scienc sever year
michaelaalcorn,MachineLearning,1619522727.0,[R] baller2vec++: A Look-Ahead Multi-Entity Transformer For Modeling Coordinated Agents,
hardmaru,MachineLearning,1619579460.0,[R] Why AI is Harder Than We Think,
donkey_strom16001,MachineLearning,1619388491.0,[D] The Rants of an experienced engineer who glimpsed into AI Academia (Briefly),background i recent graduat master degre fortun unfortun glimps whole academ side ml i took thesi track degre immigr harder get good research lab without authorship coupl good paper or i delud i work full stack swe startup nmbr year come us master degre focus ml ai i everyth year from project manag build fulli polish s w product devop even dabbl ml i batchelor degre univers whose name even worth mention the univers master degre top nmbr ai space i know much ml curios drove univers come uni i focus learn ml ai one nmbr nmbr year i found advisor thesi topic thi fun start i amaz advisor entir peer review system way assess ml scienc tick thi rant begin rant nmbr acadmia follow gate institut narr let say ph d world top ai institut work best prof you way higher likelihood get good postdoc huge research lab vs someon poor countri ph d well known advisor publish well known paper i come develop nation i see mani time in countri academ get fund colleg us one reason colleg huge endow mani academ wealthi research sponsor brand name prestig carri massiv weight help get fund us academ circl thi prestig money percol student research work student top colleg get huge advantag circl top research keep set institut i noth top research top institut due natur citat way money flow base viciou cycl creat best institut keep get better rest get much notic rant nmbr peer review without code review ml ai shadi i comput scientist i appal i heard need code review research paper as comput scientist someon actual shit ton actual ml past year i find absolut garbag code review part system i say everi scientist read paper review code least one person paper code submiss at least ml ai space thi basic i get peopl call comput scientist want read fuck code if make grad student but collect scienc need the core problem lie fact peer review free there better solut we end creat git chang mani live academ research need someth similar rant nmbr my idea novel until i see someon els paper the volum scientif research grow exponenti inform creat faster digest we expect peopl know everyth amount overlap ai ml field requir way better search engin googl scholar the side effect larg volum research everi paper someth novel make harder filter fuck novel i mani experi i code someth came realiz someon els done someth symbol similar work seem like small variant that fuck head is i novel what fuck novel is stitch transform problem fanci embed tidi research paper novel is make transform bigger novel is new rl algorithm test nmbr seed fanci fuck prior esoter reason success novel is use parameter model get nmbr accuraci nmbr sampl test set novel is appli self supervis learn new dataset novel if i keep list question novelti i probabl write novel ask fuck novel rant nmbr citat base optim promot self growth over collect growth whatev peopl may say collabor academia intrins promot right incent structur harbor collabor let explain when write paper posit name matter if ph d student first author paper great if nth author not great appar touchi thing academ and lot ego clash around number order name i distinctli rememb attend seminar lab approach student research project idea the first thing came phd student mouth posit authorship as engin work team past never someth i thought especi i work industri alway group person academia revers academia applaud celebr individu achiev all understand someth i like thi make phd stick lane the way citat research focu calibr hire abil complet ph d thesi metric peopl incentiv think instead think collabor make someth better conclus a ph d idealist sens pursuit hard idea i poetic way in situat like publish perish word paper get pass scienc without even see code run i extrem discourag go rout all rant diss scientist i commun need better way address problem p s never expect mani peopl express opinion rant u take serious as mani peopl state i outsid tini experi give full pictur i realiz post come someth tri dichotom academia industri i tri i want highlight problem i saw one person blame these issu opinion byproduct econom creat system thank gold stranger
RSchaeffer,MachineLearning,1619728964.0,[R] Help understanding NeurIPS 2013 Dirichlet Process Mixture Model paper,hi i struggl understand certain part nmbr neurip paper onlin learn nonparametr mixtur model via sequenti variat approxim http proceed neurip cc paper nmbr hash nmbrcnmbrfnmbrenmbrenmbrcbnmbrddnmbrfnmbrdnmbrecf abstract html http proceed neurip cc paper nmbr hash nmbrcnmbrfnmbrenmbrenmbrcbnmbrddnmbrfnmbrdnmbrecf abstract html if anyon subreddit familiar bayesian nonparametr five minut i would realli appreci answer question i post math stackexchang http math stackexchang com question nmbr onlin stochast variat infer dirichlet process mixtur model http math stackexchang com question nmbr onlin stochast variat infer dirichlet process mixtur model base paper review review nmbr question i think author intend add answer supplement supplement start thi document provid proof theorem present paper never actual got around ad proof answer i email sole author i yet hear back
answersareallyouneed,MachineLearning,1617655429.0,[D] Questions on mathematical maturity for PhD/R&D ML,my current job mostli involv implement paper adapt model fit need compani math realli issu understand implement paper so far i believ i lack mathemat matur competit posit go back phd i work research past i specif interest domain adapt synthet data gener a question nmbr is common peopl come work gener understand concept slowli build matur a lot mentor math physic major later came machin learn perhap idea take bit skew nmbr i nmbr year i want appli start phd i plan work full time year what effect way use time what i studi first a colleagu recommend i go real analysi it also seem like good portion subreddit gone bishop the element statist learn least tldr i interest field would like mediocr mid level profession ani advic
ML_WAYR_bot,MachineLearning,1618171211.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 110,thi place share machin learn research paper journal articl read week if relat research mean elabor give us insight otherwis could interest paper read pleas tri provid insight understand pleas post thing present wiki prefer link arxiv page pdf easili access pdf summari page way around pertin link previou week nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr week nmbr http www reddit com nmbrqyjiq week nmbr http www reddit com nmbrxwnmbr week nmbr http www reddit com nmbrildf week nmbr http www reddit com nmbrsnmbrknmbru week nmbr http www reddit com nmbrtnnmbrax week nmbr http reddit com nmbrsnmbrelnmbr week nmbr http reddit com bfsxnmbrz week nmbr http reddit com dnmbrvnonmbr week nmbr http reddit com fnmbrfnmbriq week nmbr http reddit com hltnmbro week nmbr http reddit com knmbrywb week nmbr http www reddit com nmbrsnmbrxqm week nmbr http www reddit com nmbracbnmbrt week nmbr http www reddit com nmbrjwde week nmbr http www reddit com nmbrabnmbri week nmbr http www reddit com nmbrwvjfk week nmbr http reddit com anmbropot week nmbr http reddit com blnmbrov week nmbr http reddit com denmbrhnmbr week nmbr http reddit com fnmbrfsnmbrz week nmbr http reddit com hunmbrzqnmbr week nmbr http reddit com khnmbrnx week nmbr http www reddit com nmbrtnmbrmqm week nmbr http www reddit com nmbrcwfbnmbr week nmbr http www reddit com nmbr week nmbr http www reddit com nmbrd week nmbr http www reddit com nmbrexnmbr week nmbr http reddit com anmbryaro week nmbr http reddit com bqlbnmbrv week nmbr http reddit com dkoxnmbr week nmbr http reddit com ffinmbrb week nmbr http reddit com iaznmbr week nmbr http reddit com kpsxtc week nmbr http www reddit com nmbrubnmbrkw week nmbr http www reddit com nmbrfcnmbrmh week nmbr http www reddit com nmbrhhhb week nmbr http www reddit com nmbrjsnmbr week nmbr http reddit com nmbraluh week nmbr http reddit com adnmbrssz week nmbr http reddit com bwnmbrjmnmbr week nmbr http reddit com drnmbrnca week nmbr http reddit com fnnmbrrnmbr week nmbr http reddit com ijjcep week nmbr http reddit com kzevku week nmbr http www reddit com nmbrxomfnmbr week nmbr http www reddit com nmbrhynmbrur week nmbr http www reddit com nmbrteiz week nmbr http www reddit com nmbrbnmbravnmbr week nmbr http reddit com nmbrtnnez week nmbr http reddit com ainmbrgi week nmbr http reddit com cnmbritkk week nmbr http reddit com dxshkg week nmbr http reddit com fvknmbrjnmbr week nmbr http reddit com isnmbrhjnmbr week nmbr http reddit com lnmbrlvg week nmbr http www reddit com nmbrzcyvk week nmbr http www reddit com nmbrkdnmbrvd week nmbr http www reddit com nmbrdnmbrnbnmbr week nmbr http www reddit com nmbrenmbrfxnmbr week nmbr http reddit com nmbrxnmbroj week nmbr http reddit com apnmbrctk week nmbr http reddit com cdnmbrgko week nmbr http reddit com enmbrnmyk week nmbr http reddit com gnmbreavg week nmbr http reddit com jnmbrxrnmbr week nmbr http reddit com ljxnmbrn week nmbr http www reddit com nmbrtnmbrmo week nmbr http www reddit com nmbrobnmbrdx week nmbr http www reddit com nmbrgngwc week nmbr http www reddit com nmbrhccnmbrc week nmbr http reddit com nmbrjmh week nmbr http reddit com aucinmbrc week nmbr http reddit com cjnmbrkyc week nmbr http reddit com ebnmbrlxk week nmbr http reddit com gcxnmbruf week nmbr http reddit com jnmbrcbf week nmbr http reddit com luqbxl week nmbr http www reddit com nmbrheol week nmbr http www reddit com nmbrrnmbryd week nmbr http www reddit com nmbrjgdva week nmbr http www reddit com nmbrkgcqr week nmbr http reddit com nmbrupnmbrg week nmbr http reddit com azjoht week nmbr http reddit com cpnmbrjex week nmbr http reddit com ehbfst week nmbr http reddit com glmnmbrsv week nmbr http reddit com jhzznmbrv week nmbr http reddit com mnmbrunmbrz week nmbr http www reddit com nmbrkvsu week nmbr http www reddit com nmbrttnmbrcz week nmbr http www reddit com nmbrmnmbrlnmbrv week nmbr http www reddit com nmbrnayri week nmbr http reddit com nmbrnnmbrrt week nmbr http reddit com bnmbrrnmbri week nmbr http reddit com cvdenmbra week nmbr http reddit com entcxi week nmbr http reddit com gunmbrtnmbrd week nmbr http reddit com jqjgonmbr week nmbr http reddit com mfnmbrmnmbru week nmbr http www reddit com nmbrsnmbroa week nmbr http www reddit com nmbrwhnmbrwb week nmbr http www reddit com nmbrpnmbrhanmbr week nmbr http www reddit com nmbrqelnmbrp week nmbr http reddit com nmbrcfnmbr week nmbr http reddit com bakewnmbr week nmbr http reddit com dnmbrgnmbrknmbr week nmbr http reddit com euctyw week nmbr http reddit com hddfnmbrj week nmbr http reddit com jznmbrevt most upvot paper two week ago u rtrxnmbr how machin learn team share reus featur http www tecton ai blog machin learn team share reus featur u justdi effici explor chemic space dock deep learn http chemrxiv org articl preprint efficient_exploration_of_chemical_space_with_docking_and_deep learn nmbr u kirillthemunchk styleclip text driven manipul stylegan imageri sota stylegan imag edit http casual_gan nmbr besid rule fun
Farconion,MachineLearning,1620063831.0,[D] Effectively summarizing projects & research on a resume?,anyon tip effect summar ml project research resum i find sinc project research usual pretti nich tri convey uphil battl peopl read resum go idea talk enough space cover appropri background knowledg i get part job appli sinc i bank get ml posit colleg good chunk work ml relat i like make background approach unfamiliar field subfield relat work
mistermysterioyster,MachineLearning,1619897023.0,"[D] Paper Reading Group #018 - MP3: A Unified Model to Map, Perceive, Predict and Plan. (Link to full slides in comments!)",
hallavar,MachineLearning,1617297476.0,[Discussion] Any metric for evaluating non-image synthetic data ?,hello evalu gener data obtain ae gan etc alway tricki question for imag paper read use incept score evolut fid howev metric base well gener imag classifi pretrain network summari need detail but i gener data imag relat like text sequenc graph how i evalu gener model a good metric evalu plausibl synthet data ie realism gener given train distribut also divers ensur train distribut well understood model i know evalu first criterium realism idea evalu second if anyon ever work someth like glad talk work thank advanc
vijish_madhavan,MachineLearning,1618161739.0,"[P] SkinDeep, Remove Tattoos using Deep Learning. GitHub Link in comments.",
SolitaryPenman,MachineLearning,1619269805.0,[D] Looking for datasets for video time-series segmentation/labeling,i look video dataset time seri segment note i not look dataset semant segment video label time step one k categori an exampl video would person perform differ action one action singl video unfortun dataset i could find singl action perform video eg weizmann human action dataset thu singl label per video it would great someon could point video dataset time step differ label
hardmaru,MachineLearning,1617245208.0,[R] Going deeper with Image Transformers,
rarboot,MachineLearning,1618235282.0,[N] Microsoft buys AI speech tech company Nuance for $19.7 billion,from the verg http www theverg com nmbr nmbr nmbr nmbr microsoft buy nuanc ai speech tech i may wrong afaik sinc microsoft made huge acquisit compani arguabl heavili convolut intern ecosystem it feel like ms data acquisit process product portfolio imo cannib ani thought
mikegartrell,MachineLearning,1617282048.0,[N] Upcoming talks for Laplace‚Äôs Demon: A Seminar Series about Bayesian Machine Learning at Scale,we two upcom talk april ongo onlin seminar seri bayesian machin learn scale the intend audienc includ machin learn practition statistician academia industri upcom talk zoom registr link thi come wednesday nmbr april mont carlo integr repuls point process r√©mi bardenet http criteo zoom us webinar regist wn_i_vilnmbryttpafshnmbrdo_hdyg mont carlo integr workhors bayesian infer mean squar error mont carlo estim decreas slowli typic nmbr n n number integrand evalu thi becom bottleneck bayesian applic evalu integrand take ten second like life scienc evalu likelihood often requir solv larg system differenti equat i present two approach faster mont carlo rate use interact particl system first i show result random matrix theori lead stochast version gaussian quadratur dimens mean squar error decreas nmbr n nmbr nmbr thi quadratur base determinant point process argu kernel machin point process second i show take error rate assum integrand smooth in particular i give tight error bound integrand belong arbitrari reproduc kernel hilbert space use mixtur determinant point process tailor space thi mixtur reminisc volum sampl random experiment design use linear regress joint work ayoub belhadji pierr chainai adrien hardi nmbr april automat backward filter forward guid markov process graphic model frank van der meulen http criteo zoom us webinar regist wn_nmbrszkmhlfqhklnmbrkpalfmnmbrgq i discuss structur way effici infer probabilist graphic model build block consist markovian stochast process the start point gener model forward descript probabilist dynam the inform provid observ backpropag model transform gener forward model condit model guid data it approxim actual condit model known likelihood ratio two the backward filter forward chang measur suitabl incorpor probabilist program context formul set transform rule the guid gener model combin differ approach effici sampl latent state paramet condit observ applic set includ markov chain discret state space interact particl system state space model branch diffus gamma process past talk found http ailab criteo com laplac demon bayesian machin learn scale
strngelet,MachineLearning,1616679026.0,[P] boost T5 models speed up to 5x & reduce the model size by 3x using fastT5.,i want share new librari i work i open sourc here quick link github repositori http github com kinmbran fasttnmbr pypi project http pypi org project fasttnmbr fasttnmbr logo http preview redd knonmbrbmnmbrsenmbrpnmbr png width nmbr format png auto webp nmbrfenmbrbnmbrfanmbrfnmbrbanmbranmbrbnmbr titl suggest increas infer speed pretrain tnmbr model also decreas model size singl line code the librari instal pip instal fasttnmbr thi code snippet repositori readm give concis overview fasttnmbr usag http preview redd glranmbrhevenmbrpnmbr png width nmbr format png auto webp eanmbrbnmbrcbnmbrfcnmbrenmbrabnmbrcnmbranmbrfnmbrenmbrdacnmbrbnmbr the fasttnmbr librari export tnmbr model onnx past_key_valu quantiz run onnxruntim the export onnx model support gener method huggingfac transform inferenc inform project refer repositori http github com kinmbran fasttnmbr reduc tnmbr model size nmbrx increas infer speed nmbrx
MudlarkJack,MachineLearning,1617972696.0,[Discussion] is it possible to cross train a pre-existing model with a higher resolution data set than was used to train the original network?,use case should indic titl gan question for exampl i previous train network say nmbrxnmbr imag i want cross train complet new data set contain nmbrxnmbr imag benefit normal time save cross train can work smaller resolut origin data set somehow preclud
sideonion,MachineLearning,1619650542.0,[P] Are there non-profits who work on ML for social cause (fairness etc.) where I can work for a project and contribute?,geographi bar okay volunt geograph locat i want volunt work part time non profit work research ml thing like fair account i good tech background i abl find place i contribut possibl research social caus pleas recommend allen ai look full time peopl i move usa
regalalgorithm,MachineLearning,1620420803.0,[D] Invitation to help address AI misrepresentation and misconceptions,tldr i run site debunk misconcept ai news pl posit respons hope bring could use help fine as i post nmbr year i run thing call skynet today http www skynettoday com name meant iron news mission put ai new in perspect word debunk inaccur portray ai research media also put articl put thing perspect as mani peopl research feel annoy hype misconcept ai i wonder might want join effort we basic coupl grad student spare time put new articl due busi much help write lot work if interest pleas consid take look contribut survey http www skynettoday com contribut messag thank some exampl articl put includ deepmind alphafold nmbr an impress advanc with hyperbol coverag http www skynettoday com brief alphafoldnmbr the state deepfak nmbr http www skynettoday com overview state deepfak nmbr gpt nmbr an ai breakthrough come your job http www skynettoday com brief gptnmbr ibm microsoft amazon halt sale facial recognit polic call regul http www skynettoday com brief face recog polic boston dynam robot impress far termin http www skynettoday com brief boston dynam tldr i run site debunk mispercept ai pl join http www skynettoday com contribut wan na help
git-commit-bt7274,MachineLearning,1617721034.0,[P] Corgi: Rust neural network/dynamic automatic differentiation library I have been working on,hello i work rust automat differenti crate call corgi it level crate i thought would worth share github http github com patricksongzi corgi http github com patricksongzi corgi crate http crate io crate corgi http crate io crate corgi edit fix exampl edit nmbr ad support custom layer model exampl http github com patricksongzi corgi blob main exampl custom rs http github com patricksongzi corgi blob main exampl custom rs exampl dynam comput graph let arr nmbr let b arr nmbr let mut c arr nmbr _ nmbr nmbr c c b c nmbr nmbr c c c backward none assert_eq c arr nmbr assert_eq c gradient arr nmbr assert_eq b gradient arr nmbr assert_eq gradient arr nmbr fulli connect neural network http github com patricksongzi corgi blob main src dens rs http github com patricksongzi corgi blob main src dens rs custom oper need work readm the project still need lot work includ improv ergonom arr macro implement fulli connect layer effici improv use bla
WavyShapes,MachineLearning,1616431656.0,[P] Backprop: a library to easily finetune and use state-of-the-art models,hi everybodi i like share backprop http github com backprop ai backprop python librari i co author last month our goal make finetun use model easi possibl even without extens ml experi we current got support text imag base task wrapper around model like googl tnmbr openai clip facebook bart among other onc got train data import model task finetun singl line code we also got featur make deploy product easi full transpar deploy paid platform develop mean necessari use librari if decid check doc http backprop readthedoc io en latest got exampl notebook repo exampl http github com backprop ai backprop tree main exampl folder we happi progress made still earli day realli appreci thought feedback get make backprop featur easier use futur
ad1tyawagh,MachineLearning,1619612972.0,[Discussion] Why doesn't Google's Live Captioning feature generate punctuation marks?,post sinc someth relat nlp i understand data clean peopl usual remov punctuat might punctuat but consid punctuat hold semant mean i understand remov gener practic can someon shed light
ilikepancakez,MachineLearning,1616419675.0,[R] Combinatorial optimization and reasoning with graph neural networks,
Red-Portal,MachineLearning,1616337731.0,[D] How many of you explicitly ask the reviewer to raise their score?,hi given icml review period i would like ask experi explicitli ask review rais score i saw peopl got posit result i curiou effect neg gener in i thing might somewhat rude score total review is polit phrase ask thing also mani write someth privat feedback metareview box even outright unjust conduct review
bendee983,MachineLearning,1618507723.0,[D] Microsoft's ML acquisition strategy,thi week microsoft announc nmbr billion acquisit nuanc compani use deep learn transcrib clinic appoint stuff what interest deal evolut microsoft relat nuanc http bdtechtalk com nmbr nmbr nmbr microsoft nuanc acquisit go cloud provid partner owner thi success strategi microsoft mayb amazon posit implement step nmbr microsoft start invest ml compani give azur credit lure ml platform thi allow microsoft help compani develop also learn possibl replic product worth multipl small invest oppos one larg acquisit smart move mani compani tri new thing ml dl success with small invest microsoft cast wider net make sure good posit make next move step nmbr microsoft enter partnership compani success product thi allow microsoft integr ml product enterpris solut e g nuanc dragon dl integr microsoft cloud healthcar solut sinc compani build ml tool top azur stack integr much easier compani step nmbr acquir realli success compani nuanc great reach ai healthcar sector thi allow microsoft gain exclus access compani data talent technolog client with acquisit nuanc microsoft total address market healthcar reach nmbrb and integr ml technolog enterpris tool nuanc one exampl microsoft ml acquisit strategi the compani similar path openai http bdtechtalk com nmbr nmbr nmbr microsoft openai gpt nmbr licens carri similar strategi self drive car industri http bdtechtalk com nmbr nmbr nmbr microsoft self drive car strategi
pinter69,MachineLearning,1616346925.0,[R] Compositional Zero-Shot Learning - Dr. Massimiliano Mancini (CVPR 2021) - Link to free zoom lecture by the author in comments,
Jemsdaan,MachineLearning,1617052129.0,[D] RTX 3080 cuda 10.0,hi guy uni project i need replic project use tensorflow gpu nmbr cuda nmbr the gpu i dispos rtx nmbr now understand rtx nmbr support cuda nmbr cuda nmbr in order use cuda nmbr tensorflow need updat nmbr nmbr break alot code so quesiton i dead water to seem like solut either train model cpu terribl perfom upgrad code compat tensorflow nmbr nmbr scope project i sure correct place ask someon suggest get run gpu pleas let know
TheInsaneApp,MachineLearning,1619861540.0,[D] Types of Machine Learning Papers,
SPAMinaCanCan,MachineLearning,1618438536.0,[D] What are you thoughts on how the amount of classes can affect model accuracy,thi hope basic question i struggl find good paper explain amount differ class affect differ model for exampl say build semant segment classifi jpg imag contain soft drink can your object find can contain within imag is better construct train data use gener soft drink class or better construct train data use differ colour soft drink can seper class e red orang green etc i wonder class name convent affect overal accuraci classifi everi what thought also want comment extend thing car cloth etc
AuspiciousApple,MachineLearning,1620578926.0,[D] What's the SOTA/best practice for finetuning pre-trained CNNs on smaller datasets (~10k images)? Any principled approaches? Any papers comparing different schedules?,there basic two way approach transfer learn a treat pretrain weight particularli effici weight initialis method train model like normal focuss hyperparam especi data augment b use special protocol finetun for b francoi chollet recommend freez lower convolut layer train ad head option second step also finetun part lower convolut layer low learn rate http kera io guid transfer _learn introduct http kera io guid transfer_learn introduct http blog kera io build power imag classif model use littl data html http blog kera io build power imag classif model use littl data html i also rememb read idea like appli lnmbr penalti magnitud weight deviat pre train weight are special schedul worth is research i also happi suggest finetun
hyunwoongko,MachineLearning,1617857667.0,[P] Try to talk with GPT3 (GPT-Neo),http preview redd nmbrnphdngxrvrnmbr png width nmbr format png auto webp nmbrenmbrdfnmbrddcnmbrcnmbranmbrdnmbrdnmbracnmbrbaeb the gpt neo model releas eleutherai gpt neo http github com eleutherai gpt neo repositori sid black stella biderman leo gao phil wang connor leahi it gptnmbr like causal languag model train pile http pile eleuth ai dataset today i deploy prompt base convers option use gpt neo openchat you tri convers gpt neo use line code check http github com hyunwoongko openchat http github com hyunwoongko openchat want detail inform thank
fromnighttilldawn,MachineLearning,1617599998.0,[D] How do you improve your model after obtaining the test error?,i basic question train neural network ml model i see address literatur consid follow scenario you chop data train valid test someth like nmbr nmbr nmbr ratio you train perform valid feel pretti confid model perform well then run model test set obtain high error someth fall expect yike of cours stage would anyth improv model tri anyth effect use test set train set my question whether exist best correct practic improv model obtain test error i know literatur lot hyperparamet tune obtain test set i wish follow footstep if techniqu allow prevent scenario happen thank advanc
hobogalaxy,MachineLearning,1620042624.0,"[P] General and feature-rich PyTorch/Hydra template for rapid and scalable ML research/experimentation, with a list of best practices",hi i look way make research effici scalabl after iter coupl differ framework structur i converg follow templat http github com ashlev lightn hydra templat http github com ashlev lightn hydra templat to get feel might use take look your superpow http github com ashlev lightn hydra templat superpow section readm it base pytorch lightn hydra plugin i develop research team i also meant start point anyon would like learn technolog stack i find combin simpl use power time i believ conveni small team research reproduc paper gener project need maintain mani curat configur experi how i find use allow us painlessli scale small experi hiperparamet search multi gpu slurm comput cluster framework like optuna ax the hyperparamet optim requir minim setup need declar config hyperparamet rang hydra take care whole iter job logic possibl use experi track framework like neptun wandb mlflow csv file easi configur manag command line superpow need argpars thank hydra advanc train debug featur pytorch lightn e g gradient accumual deepspe integr etc encapsul dataset lightn datamodul give us conveni way understand reus dataset across project i feel like ml peopl use tool simpli realiz advantag especi hydra seem like use addit deep learn project i focus structur readm way i hope give quick overview hope help spread word framework broad commun it incorpor best practic http github com ashlev lightn hydra templat best practic trick i gather last coupl month play around my typic workflow follow nmbr i write lightningdatamodul i found intuit way encapsul dataset lightningdatamodul simpl abstract provid method data download split transform expos dataload would love see research tri concept even project use pytorch lightn read lightningdatamodul make immediet see dataset prepar seem like data scienc project throw around data logic across differ part pipelin make hard understand go you see exampl datamodul http github com ashlev lightn hydra templat blob main src datamodul mnist_datamodul py nmbr i write lightningmodul thi basic encapsul pytorch model code nmbr i add new experi config specifi path lightningdatamodul lightningmodul now train launch experi tracker attach like csv logger tensorboard python run py http run py experi simple_mnist logger tensorboard btw structur partli base data scienc cooki cutter project templat if hear i recommend check i found great sourc use concept project organ http drivendata github io cookiecutt data scienc http drivendata github io cookiecutt data scienc i love hear thought let know see limit room improv
seuadr,MachineLearning,1617201468.0,Machine Learning and HVAC [D],hi i work hvac control deploy fault detect platform the product current rule base find mani thing great determin long term perform drift i start data scienc boot camp learn machin learn eye toward appli build hvac system like use dataset predict thing rang gener expect energi use near futur period time like next hour perform drift sensor equip like heat coil perform meet expect current condit think abl seem area discuss openli internet googl fu weak sure start for instanc i collect larg dataset equip year pretti confid gain use insight autom process feed execut model kind interv consid execut short time interv like say nmbr min write kind comput power would need current vm nmbr core nmbrgb would expect poni get job done know big open question look guidanc start see might awar exist commun could help thank advanc time assist jare
ai_painter,MachineLearning,1619460955.0,[D] Lambda GPU Cloud launches world's first RTX A6000 instances,lambda launch rtx anmbr gpu cloud instanc http lambdalab com blog introduc nvidia rtx anmbr gpu instanc lambda cloud nvidia rtx anmbr instanc nmbrx faster nvidia rtx nmbr instanc rtx anmbr nmbr gib vram per gpu disclaim i engin lambda
Yuqing7,MachineLearning,1619192608.0,"[R] Facebook AI, McGill U & Mila Promote 'Translationese' to Boost NMT System Faithfulness",a research team mcgill univers mila quebec ai institut facebook ai propos novel metric perturb function detect quantifi compar trade off robust faith nmt system corpu level particular exampl here quick read facebook ai mcgill u mila promot translationes boost nmt system faith http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper sometim we want translationes arxiv http arxiv org pdf nmbr pdf
jeromeharper,MachineLearning,1618965208.0,[D] Cov-19 binary classification dataset.,hi guy i look binari classif covid nmbr dataset predict label posit neg label could whether one infect so far i found dataset kaggl but consist medic imag xray scan chest i look imag data featur i found one kaggl featur age gender hypertens etc label posit neg pleas help thank advanc cheer
JasonTodd550,MachineLearning,1619729450.0,[R] I‚Äôm building the interface for our product. I‚Äôd love some feedback and insights.,hey folk i frontend develop design work build interfac product platform ml model host sandbox ran api current mvp run interfac user use we look commun ml focus tri get industri target user particip research nmbr nmbr valid where better look sub dedic the link test http app useberri com mknmbrywphn i also super happi get one one feedback if interest send thought directli even interview partner dm
tstanislawek,MachineLearning,1617815710.0,[P] Curated List of Document Understanding (DU) Papers & Resources.,hi everybodi in last year i spent lot time work autom busi process big compani see rise interest du topic especi key inform extract field therefor i creat list http github com tstanislawek awesom document understand http github com tstanislawek awesom document understand resourc make easier track paper relev topic
Yogi_DMT,MachineLearning,1618847448.0,[P] StoRM: Mutation-based hyperparameter tuner,for struggl find decent hyperparamet tuner nn tune exampl i design tuner attempt remedi lot issu associ type paramet space nest categor condit etc there runnabl script exampl folder demonstr storm perform compar random tune pleas feel free post feedback let know use http github com ben arnao storm http github com ben arnao storm
gabegabe6,MachineLearning,1618579597.0,[D] What tools can you recommend for GPU resource alocation?,the problem given there team gpu server nmbr gpu what best way signal use gpu long e g i think simpl tool say nmbr day later need nmbr gpu alloc time of cours everyon team could see i plan creat simpl cli tool first want get feedback use purpos i realli want use excel sheet
CauchySchwartzDaddy,MachineLearning,1619584963.0,[D] Are there light(-er) installs of pytorch for model deployment that aren't nearly a whole gb of space and just support loading a model and forward pass?,i deploy model docker flask i find kind tediou i instal nmbr mb pytorch i need load model forward pass consid contain deploy method pretti light term space allot i realli afford huge instal
Equivalent-Choice-75,MachineLearning,1619383564.0,[D] Academia to Industry. How to deal with Research FOMO?,i master student top nmbr us univers i spend almost work hour ml research i go industri day fomo miss cut edg research due natur job product face rather pure research i sure mani phd student would face how deal do still read latest paper post join or suggest
CaptainMcThorn,MachineLearning,1617880707.0,[R] Hollow-tree Super: a directional and scalable approach for feature importance in boosted tree models,
numpee,MachineLearning,1617769571.0,[Discussion] Suggestions for well-written papers,i recent encount post regard qualiti prose http www reddit com r machinelearn comment mhnmbrvrt d_does_anyone_care_about_the_quality_of_the_pros utm_sourc share utm_medium webnmbrx context nmbr academ paper it seem like peopl gener differ view consid well written for exampl prefer clear concis languag without color languag and vice versa so question can suggest paper consid well written would nice gave quick explan prefer write style well
Headz0r,MachineLearning,1617960110.0,[D] Objective of openAIs Microscope,regard microscop applic openai http microscop openai com model contrastive_nmbrx image_block_nmbr_nmbr_add_nmbr_nmbr nmbr question one see two set imag gener featur visual one channel optim object result repeat pattern neuron optim object show spatial prefer what optim techniqu refer how gener imag differ respect class
binaryfor,MachineLearning,1617468530.0,[P] Deep Daze - A simple command line tool for text to image generation using OpenAI's CLIP and Siren,
1846bdksy,MachineLearning,1617602310.0,[D] Top 4 CS PhD AI+Healthcare Research Topic Worries,i grate accept top nmbr cs phd program mit stanford cmu berkeley year my research interest list ai healthcar phd applic faculti school assum i pursu area howev i recent start hesit make ai healthcar specif comput vision healthcar phd research topic the main reason i worri post phd career outcom topic like i realli like opportun work googl brain fair potenti even quant trade compani futur on hand i think ai healthcar promis field may potenti also startup relat i curiou think ai healthcar phd thesi topic thi assum i still make fundament advanc ai e g publish cvpr iccv eccv slightli lower frequenc pure ai student due addit paper healthcar relat journal do think hinder career possibl or i overthink thank much by way altern would tri pursu pure ai research without applic healthcar
ProbablyCloseEnough,MachineLearning,1616960156.0,[R] Slurm Interface Prototype Evaluation Survey (2 minutes),if use slurm schedul comput job share comput resourc pleas evalu propos interfac complet survey follow link http peersurvey cc gatech edu nmbrbnmbrenmbrcnmbrbenmbranmbrdnmbrafbfanmbr http peersurvey cc gatech edu nmbrbnmbrenmbrcnmbrbenmbranmbrdnmbrafbfanmbr thi continu investig previou post http www reddit com r machinelearn comment lfnnmbrdnmbr r_slurm_interface_survey_nmbr_minut utm_sourc share utm_medium webnmbrx context nmbr i coursework human comput interact cours thank particip
mrwafflezzz,MachineLearning,1619708471.0,[R] Question regarding sampling negative examples for supervised learning,i ask question sub rather difficult question bear let say i match predictor thi predictor use nmbr set featur one set content c one set user u it match user content both u c repres vector spatial meaning term distanc user u distanc content c let say i posit match u c label nmbr ani combin posit match ambigu mean would make sens approach semi supervis manner assum combin u c i sampl inher neg exampl label nmbr could fact nmbr nmbr could i give sampl combin u c label look similar vector u vector user consum content c the idea user similar user consum content c likelihood consum content c becom higher ani feedback welcom
fiddlerlabs,MachineLearning,1616372511.0,[R] A Practical Guide To Adversarial Robustness,while adversari machin learn still young field less nmbr year old explos paper work around attack model find vulner turn verit arm race defend attack here brief summari field http blog fiddler ai nmbr nmbr practic guid adversari robust http blog fiddler ai nmbr nmbr practic guid adversari robust
windy-city-wizard,MachineLearning,1618899153.0,[R] Two questions: computing class weights and large confusion matrix?,nmbr what algorithm comput class weight address imbalanc dataset multi class classif nmbr class nmbr what way make larg confus matrix nmbrxnmbr easier see initi obviou class get lot fals posit bad my guess i address class lot harder extract meaning insight larg confus matrix http preview redd nmbrgaobryqsnmbrunmbr png width nmbr format png auto webp enmbrfadnmbrdnmbraenmbrfnmbrbnmbrfnmbrccnmbrdnmbrenmbr
minimaxir,MachineLearning,1619798940.0,[P] Easily Transform Portraits of People into AI Aberrations Using StyleCLIP,so i lot experi use styleclip http github com orpatashnik styleclip creat fun imag i written blog post reproduc input _fun_ experi involv mark zuckerberg releas streamlin colab notebook get run http minimaxir com nmbr nmbr styleclip colab notebook http colab research googl com drive nmbrejnmbratvtnenmbrnnmbrinmbrullvrstanmbrjnmbrhdnubi usp share tl dr styleclip essenti photoshop driven text good bad chao entail
zecharias99,MachineLearning,1617968121.0,[P] Chai: Open source framework for deploying chat AIs,chai open sourc platform allow develop deploy chat ai check websit http chai ml doc http chai ml doc includ support huggingfac bot use chai _pi http pypi org project chaipi speak ai line code http preview redd ucabdgnmbrqvnmbrsnmbr png width nmbr format png auto webp bnmbrenmbrdenmbrbaanmbrenmbrfnmbrfanmbrenmbrfnmbrd http preview redd gkxnmbrtesnmbrwnmbrsnmbr png width nmbr format png auto webp nmbrcaaanmbrdnmbrbnmbrcnmbrdnmbrbnmbracnmbr check tri deploy facebook blenderbot http huggingfac co facebook blenderbot_smal nmbrm chai chat mobil app
RandomForests92,MachineLearning,1616527472.0,[P] I just published first version of my metrics library for ML projects,i hope well i releas new open sourc librari onemetr it use evalu comput vision project i hope becom default benchmark librari ml relat project i would grate could take look potenti suggest metric outsid comput vision might use http github com skalskip onemetr http github com skalskip onemetr one metric librari rule them all
bionet271,MachineLearning,1618480565.0,"[P] I implemented DeepMind's ""Perceiver"" in PyTorch",so deepmind publish paper http arxiv org pdf nmbr pdf i find sourc code my implement complet faith posit encod exampl paper also everi detail pretti close i thought i share case anyon want use help make better let know i miss anyth i still much learn http github com louislva deepmind perceiv http github com louislva deepmind perceiv
mroc_lak,MachineLearning,1616578491.0,[D] What tools do you use for testing your computer vision systems?,hi i interest best practic develop comput vision applic product are tool would recommend test system requir base test unit test integr test etc or write infra hous
faridrashidi,MachineLearning,1619327497.0,[P] Collection of Kaggle Past Solutions (to learn ideas and techniques),i collect nmbr nmbr almost avail solut idea code share top perform past kaggl competit thi list get updat soon new competit finish it allow search kaggl past competit solut idea nmbr http github com faridrashidi kaggl solut http github com faridrashidi kaggl solut nmbr http farid one kaggl solut http farid one kaggl solut
bert4QA,MachineLearning,1616667982.0,[R] Hurdles to Progress in Long-form Question Answering,
CKL-IT,MachineLearning,1620223941.0,"[N] 200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support - John Snow Labs NLU 3.0.0",nmbr state art medic model ner entiti resolut relat extract assert spark nmbr python nmbr support nlu nmbr releas much we incred excit announc releas nlu nmbr nmbr make john snow lab medic healthcar model avail nmbr line code nlu these model accur domain highli scalabl spark cluster in addit spark nmbr x spark nmbr x support togeth pythonnmbr thi enabl amaz spark nlpnmbr nmbr http nlp johnsnowlab com doc en release_not nmbr spark nlp healthcar nmbr nmbr http nlp johnsnowlab com doc en licensed_release_not nmbr releas new featur over nmbr new model healthcar domain nmbr new class model assert sentenc chunk resolv relat extractor medic ner model de identif model spark nmbr x nmbr x support python nmbr support new output level relat nmbr line instal nlu run wget http raw githubusercont com johnsnowlab nlu master script colab_setup sh o bash variou new emr databrick version support http github com johnsnowlab spark nlp releas tag nmbr nmbr gpu mode nmbr speedup enabl gpu mode author mode licens featur new document nlu healthcar exampl http nlu johnsnowlab com doc en examples_hc usag exampl nluload instrunct author environ use licens featur http nlu johnsnowlab com doc en examples_hc author access licens featur instal healthcar depend new notebook medic name entiti extract ner notebook http github com johnsnowlab nlu blob master exampl colab healthcar medical_named_entity_recognit overview_medical_entity_recogn ipynb relat extract notebook http github com johnsnowlab nlu blob master exampl colab healthcar relation_extract overview_rel ipynb entiti resolut overview notebook http github com johnsnowlab nlu blob master exampl colab healthcar entity_resolut entity_resolvers_overview ipynb assert overview notebook http github com johnsnowlab nlu blob master exampl colab healthcar assert assertion_overview ipynb de identif overview notebook http github com johnsnowlab nlu blob master exampl colab healthcar de_identif deidentification_model_overview ipynb graph nlu tutori http github com johnsnowlab nlu blob nmbrrcnmbr exampl webinars_conferences_etc graph_ai_summit healthcare_graph_nlu_covid_tigergraph ipynb assertiondlmodel languag nlu load refer spark nlp model refer english assert http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_en html assertion_dl http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_en html english assert biobert http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_biobert_en html assertion_dl_biobert http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_biobert_en html english assert healthcar http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_healthcare_en html assertion_dl_healthcar http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_healthcare_en html english assert larg http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_large_en html assertion_dl_larg http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_large_en html new word embed languag nlu load refer spark nlp model refer english emb glove clinic http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_en html embeddings_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_en html english emb glove biovec http nlp johnsnowlab com nmbr nmbr nmbr embeddings_biovec_en html embeddings_biovec http nlp johnsnowlab com nmbr nmbr nmbr embeddings_biovec_en html english emb glove healthcar http nlp johnsnowlab com nmbr nmbr nmbr embeddings_healthcare_en html embeddings_healthcar http nlp johnsnowlab com nmbr nmbr nmbr embeddings_healthcare_en html english emb glove healthcare_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_healthcare_nmbrd_en html embeddings_healthcare_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_healthcare_nmbrd_en html english en emb glove icdoem embeddings_icdoem english en emb glove icdoem_nmbrng embeddings_icdoem_nmbrng sentenc entiti resolv languag nlu load refer spark nlp model refer english embed_sent biobert mli sbiobert_base_cased_mli english resolv sbiobertresolve_cpt english resolv cpt sbiobertresolve_cpt english resolv cpt augment sbiobertresolve_cpt_aug english resolv cpt procedures_aug sbiobertresolve_cpt_procedures_aug english resolv hcc augment sbiobertresolve_hcc_aug english resolv icdnmbrcm http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_en html sbiobertresolve_icdnmbrcm http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_en html english resolv icdnmbrcm augment http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_augmented_en html sbiobertresolve_icdnmbrcm_aug http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_augmented_en html english resolv icdnmbrcm augmented_bil http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_augmented_billable_hcc_en html sbiobertresolve_icdnmbrcm_augmented_billable_hcc http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_augmented_billable_hcc_en html english resolv icdnmbrpc http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrpcs_en html sbiobertresolve_icdnmbrpc http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrpcs_en html english resolv icdo http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdo_en html sbiobertresolve_icdo http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdo_en html english resolv rxcui http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_rxcui_en html sbiobertresolve_rxcui http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_rxcui_en html english resolv rxnorm http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_rxnorm_en html sbiobertresolve_rxnorm http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_rxnorm_en html english resolv snome http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_en html sbiobertresolve_snomed_auxconcept http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_en html english resolv snome aux_concept http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_en html sbiobertresolve_snomed_auxconcept http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_en html english resolv snome aux_concepts_int http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_int_en html sbiobertresolve_snomed_auxconcepts_int http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_int_en html english resolv snome find http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_findings_en html sbiobertresolve_snomed_find http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_findings_en html english resolv snome findings_int http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_findings_int_en html sbiobertresolve_snomed_findings_int http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_findings_int_en html relationextractionmodel languag nlu load refer spark nlp model refer english relat posolog posology_r english relat http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_direction_biobert_en html redl_bodypart_direction_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_direction_biobert_en html english relat bodypart direct http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_direction_biobert_en html redl_bodypart_direction_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_direction_biobert_en html english relat bodypart problem http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_problem_biobert_en html redl_bodypart_problem_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_problem_biobert_en html english relat bodypart procedur http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_procedure_test_biobert_en html redl_bodypart_procedure_test_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_procedure_test_biobert_en html english relat chemprot http nlp johnsnowlab com nmbr nmbr nmbr redl_chemprot_biobert_en html redl_chemprot_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_chemprot_biobert_en html english relat clinic http nlp johnsnowlab com nmbr nmbr nmbr redl_clinical_biobert_en html redl_clinical_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_clinical_biobert_en html english relat date http nlp johnsnowlab com nmbr nmbr nmbr redl_date_clinical_biobert_en html redl_date_clinical_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_date_clinical_biobert_en html english relat drug_drug_interact http nlp johnsnowlab com nmbr nmbr nmbr redl_drug_drug_interaction_biobert_en html redl_drug_drug_interaction_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_drug_drug_interaction_biobert_en html english relat humen_phenotype_gen http nlp johnsnowlab com nmbr nmbr nmbr redl_human_phenotype_gene_biobert_en html redl_human_phenotype_gene_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_human_phenotype_gene_biobert_en html english relat temporal_ev http nlp johnsnowlab com nmbr nmbr nmbr redl_temporal_events_biobert_en html redl_temporal_events_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_temporal_events_biobert_en html nerdlmodel languag nlu load refer spark nlp model refer english med_ner ade clinic http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_clinical_en html ner_ade_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_clinical_en html english med_ner ade clinical_bert http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_clinicalbert_en html ner_ade_clinicalbert http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_clinicalbert_en html english med_ner ade ade_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_healthcare_en html ner_ade_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_healthcare_en html english med_ner anatomi http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_en html ner_anatomi http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_en html english med_ner anatomi biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_biobert_en html ner_anatomy_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_biobert_en html english med_ner anatomi coars http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_en html ner_anatomy_coars http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_en html english med_ner anatomi coarse_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_biobert_en html ner_anatomy_coarse_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_biobert_en html english med_ner aspect_senti http nlp johnsnowlab com nmbr nmbr nmbr ner_aspect_based_sentiment_en html ner_aspect_based_senti http nlp johnsnowlab com nmbr nmbr nmbr ner_aspect_based_sentiment_en html english med_ner bacterial_speci http nlp johnsnowlab com nmbr nmbr nmbr ner_bacterial_species_en html ner_bacterial_speci http nlp johnsnowlab com nmbr nmbr nmbr ner_bacterial_species_en html english med_ner bionlp http nlp johnsnowlab com nmbr nmbr nmbr ner_bionlp_en html ner_bionlp http nlp johnsnowlab com nmbr nmbr nmbr ner_bionlp_en html english med_ner bionlp biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_bionlp_biobert_en html ner_bionlp_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_bionlp_biobert_en html english med_ner cancer http nlp johnsnowlab com nmbr nmbr nmbr ner_cancer_genetics_en html ner_cancer_genet http nlp johnsnowlab com nmbr nmbr nmbr ner_cancer_genetics_en html english med_ner cellular http nlp johnsnowlab com nmbr nmbr nmbr ner_cellular_en html ner_cellular http nlp johnsnowlab com nmbr nmbr nmbr ner_cellular_en html english med_ner cellular biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_cellular_biobert_en html ner_cellular_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_cellular_biobert_en html english med_ner chemic http nlp johnsnowlab com nmbr nmbr nmbr ner_chemicals_en html ner_chem http nlp johnsnowlab com nmbr nmbr nmbr ner_chemicals_en html english med_ner chemprot http nlp johnsnowlab com nmbr nmbr nmbr ner_chemprot_biobert_en html ner_chemprot_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_chemprot_biobert_en html english med_ner chemprot clinic http nlp johnsnowlab com nmbr nmbr nmbr ner_chemprot_clinical_en html ner_chemprot_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_chemprot_clinical_en html english med_ner clinic http nlp johnsnowlab com nmbr nmbr nmbr ner_clinical_en html ner_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_clinical_en html english med_ner clinic biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_clinical_biobert_en html ner_clinical_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_clinical_biobert_en html english med_ner clinic noncontrib ner_clinical_noncontrib english med_ner diseas http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_en html ner_diseas http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_en html english med_ner diseas biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_biobert_en html ner_diseases_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_biobert_en html english med_ner diseas larg http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_large_en html ner_diseases_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_large_en html english med_ner drug http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_en html ner_drug http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_en html english med_ner drugsgreedi http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_greedy_en html ner_drugs_greedi http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_greedy_en html english med_ner drug larg http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_large_en html ner_drugs_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_large_en html english med_ner events_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_events_biobert_en html ner_events_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_events_biobert_en html english med_ner events_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_events_clinical_en html ner_events_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_events_clinical_en html english med_ner events_healthcr http nlp johnsnowlab com nmbr nmbr nmbr ner_events_healthcare_en html ner_events_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_events_healthcare_en html english med_ner financial_contract http nlp johnsnowlab com nmbr nmbr nmbr ner_financial_contract_en html ner_financial_contract http nlp johnsnowlab com nmbr nmbr nmbr ner_financial_contract_en html english med_ner healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_healthcare_d html ner_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_healthcare_d html english med_ner human_phenotyp gene_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_gene_biobert_en html ner_human_phenotype_gene_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_gene_biobert_en html english med_ner human_phenotyp gene_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_gene_clinical_en html ner_human_phenotype_gene_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_gene_clinical_en html english med_ner human_phenotyp go_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_go_biobert_en html ner_human_phenotype_go_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_go_biobert_en html english med_ner human_phenotyp go_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_go_clinical_en html ner_human_phenotype_go_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_go_clinical_en html english med_ner jsl http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_en html ner_jsl http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_en html english med_ner jsl biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_biobert_en html ner_jsl_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_biobert_en html english med_ner jsl enrich http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_enriched_en html ner_jsl_enrich http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_enriched_en html english med_ner jsl enriched_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_enriched_biobert_en html ner_jsl_enriched_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_enriched_biobert_en html english med_ner measur http nlp johnsnowlab com nmbr nmbr nmbr ner_measurements_clinical_en html ner_measurements_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_measurements_clinical_en html english med_ner medment http nlp johnsnowlab com nmbr nmbr nmbr ner_medmentions_coarse_en html ner_medmentions_coars http nlp johnsnowlab com nmbr nmbr nmbr ner_medmentions_coarse_en html english med_ner posolog http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_en html ner_posolog http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_en html english med_ner posolog biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_biobert_en html ner_posology_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_biobert_en html english med_ner posolog greedi http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_greedy_en html ner_posology_greedi http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_greedy_en html english med_ner posolog healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_healthcare_en html ner_posology_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_healthcare_en html english med_ner posolog larg http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_large_en html ner_posology_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_large_en html english med_ner posolog large_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_large_biobert_en html ner_posology_large_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_large_biobert_en html english med_ner posolog small http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_small_en html ner_posology_smal http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_small_en html english med_ner radiolog http nlp johnsnowlab com nmbr nmbr nmbr ner_radiology_en html ner_radiolog http nlp johnsnowlab com nmbr nmbr nmbr ner_radiology_en html english med_ner radiolog wip_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_radiology_wip_clinical_en html ner_radiology_wip_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_radiology_wip_clinical_en html english med_ner risk_factor http nlp johnsnowlab com nmbr nmbr nmbr ner_risk_factors_en html ner_risk_factor http nlp johnsnowlab com nmbr nmbr nmbr ner_risk_factors_en html english med_ner risk_factor biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_risk_factors_biobert_en html ner_risk_factors_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_risk_factors_biobert_en html english med_ner inmbrbnmbr nerdl_inmbrbnmbr english med_ner tumour http nlp johnsnowlab com nmbr nmbr nmbr nerdl_tumour_demo_en html nerdl_tumour_demo http nlp johnsnowlab com nmbr nmbr nmbr nerdl_tumour_demo_en html english med_ner jsl wip clinic jsl_ner_wip_clin english med_ner jsl wip clinic greedi http nlp johnsnowlab com nmbr nmbr nmbr jsl_ner_wip_clinical_en html jsl_ner_wip_greedy_clin http nlp johnsnowlab com nmbr nmbr nmbr jsl_ner_wip_clinical_en html english med_ner jsl wip clinic modifi http nlp johnsnowlab com nmbr nmbr nmbr jsl_ner_wip_modifier_clinical_en html jsl_ner_wip_modifier_clin http nlp johnsnowlab com nmbr nmbr nmbr jsl_ner_wip_modifier_clinical_en html english med_ner jsl wip clinic rd http nlp johnsnowlab com nmbr nmbr nmbr jsl_rd_ner_wip_greedy_clinical_en html jsl_rd_ner_wip_greedy_clin http nlp johnsnowlab com nmbr nmbr nmbr jsl_rd_ner_wip_greedy_clinical_en html de identif model languag nlu load refer spark nlp model refer english med_ner deid augment http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_augmented_en html ner_deid_aug http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_augmented_en html english med_ner deid biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_biobert_en html ner_deid_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_biobert_en html english med_ner deid enrich http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_enriched_en html ner_deid_enrich http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_enriched_en html english med_ner deid enriched_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_enriched_biobert_en html ner_deid_enriched_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_enriched_biobert_en html english med_ner deid larg http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_large_en html ner_deid_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_large_en html english med_ner deid sd http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_sd_en html ner_deid_sd http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_sd_en html english med_ner deid sd_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_sd_large_en html ner_deid_sd_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_sd_large_en html english med_ner deid nerdl_deid english med_ner deid synthet ner_deid_synthet english med_ner deid dl http nlp johnsnowlab com nmbr nmbr nmbr ner_deidentify_dl_en html ner_deidentify_dl http nlp johnsnowlab com nmbr nmbr nmbr ner_deidentify_dl_en html english en de_identifi http nlp johnsnowlab com nmbr nmbr nmbr deidentify_rb_en html deidentify_rb http nlp johnsnowlab com nmbr nmbr nmbr deidentify_rb_en html english de_identifi rule deid_rul english de_identifi clinic http nlp johnsnowlab com nmbr nmbr nmbr deidentify_enriched_clinical_en html deidentify_enriched_clin http nlp johnsnowlab com nmbr nmbr nmbr deidentify_enriched_clinical_en html english de_identifi larg http nlp johnsnowlab com nmbr nmbr nmbr deidentify_large_en html deidentify_larg http nlp johnsnowlab com nmbr nmbr nmbr deidentify_large_en html english de_identifi rb http nlp johnsnowlab com nmbr nmbr nmbr deidentify_rb_en html deidentify_rb http nlp johnsnowlab com nmbr nmbr nmbr deidentify_rb_en html english de_identifi rb_no_regex deidentify_rb_no_regex chunk resolv languag nlu load refer spark nlp model refer english resolve_chunk athena_condit http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_athena_conditions_healthcare_en html chunkresolve_athena_conditions_healthcar http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_athena_conditions_healthcare_en html english resolve_chunk cpt_clinic http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_cpt_clinical_en html chunkresolve_cpt_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_cpt_clinical_en html english resolve_chunk icdnmbrcm clinic http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_clinical_en html chunkresolve_icdnmbrcm_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_clinical_en html english resolve_chunk icdnmbrcm diseases_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_diseases_clinical_en html chunkresolve_icdnmbrcm_diseases_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_diseases_clinical_en html english resolve_chunk icdnmbrcm hcc_clinic chunkresolve_icdnmbrcm_hcc_clin english resolve_chunk icdnmbrcm hcc_healthcar chunkresolve_icdnmbrcm_hcc_healthcar english resolve_chunk icdnmbrcm injuri http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_injuries_clinical_en html chunkresolve_icdnmbrcm_injuries_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_injuries_clinical_en html english resolve_chunk icdnmbrcm musculoskelet http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_musculoskeletal_clinical_en html chunkresolve_icdnmbrcm_musculoskeletal_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_musculoskeletal_clinical_en html english resolve_chunk icdnmbrcm neoplasm http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_neoplasms_clinical_en html chunkresolve_icdnmbrcm_neoplasms_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_neoplasms_clinical_en html english resolve_chunk icdnmbrcm poison http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_poison_ext_clinical_en html chunkresolve_icdnmbrcm_poison_ext_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_poison_ext_clinical_en html english resolve_chunk icdnmbrcm pueril http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_puerile_clinical_en html chunkresolve_icdnmbrcm_puerile_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_puerile_clinical_en html english resolve_chunk icdnmbrpc clinic chunkresolve_icdnmbrpcs_clin english resolve_chunk icdo clinic http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrpcs_clinical_en html chunkresolve_icdo_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrpcs_clinical_en html english resolve_chunk loinc http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_loinc_clinical_en html chunkresolve_loinc_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_loinc_clinical_en html english resolve_chunk rxnorm cd http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_cd_clinical_en html chunkresolve_rxnorm_cd_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_cd_clinical_en html english resolve_chunk rxnorm chunkresolve_rxnorm_in_clin english resolve_chunk rxnorm in_healthcar chunkresolve_rxnorm_in_healthcar english resolve_chunk rxnorm sbd http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_sbd_clinical_en html chunkresolve_rxnorm_sbd_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_sbd_clinical_en html english resolve_chunk rxnorm scd http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_scd_clinical_en html chunkresolve_rxnorm_scd_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_scd_clinical_en html english resolve_chunk rxnorm scdc chunkresolve_rxnorm_scdc_clin english resolve_chunk rxnorm scdc_healthcar chunkresolve_rxnorm_scdc_healthcar english resolve_chunk rxnorm xsmall clinic http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_xsmall_clinical_en html chunkresolve_rxnorm_xsmall_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_xsmall_clinical_en html english resolve_chunk snome find http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_snomed_findings_clinical_en html chunkresolve_snomed_findings_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_snomed_findings_clinical_en html new classifi languag nlu load refer spark nlp model refer english classifi icdnmbr clinic classifier_icdnmbrcm_hcc_clin english classifi icdnmbr healthcar classifier_icdnmbrcm_hcc_healthcar english classifi ade biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_biobert_en html classifierdl_ade_biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_biobert_en html english classifi ade clinic http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_clinicalbert_en html classifierdl_ade_clinicalbert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_clinicalbert_en html english classifi ade convers http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_conversational_biobert_en html classifierdl_ade_conversational_biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_conversational_biobert_en html english classifi gender biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_gender_biobert_en html classifierdl_gender_biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_gender_biobert_en html english classifi gender sbert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_gender_sbert_en html classifierdl_gender_sbert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_gender_sbert_en html english classifi pico classifierdl_pico_biobert german medic model nlu load refer spark nlp model refer emb wnmbrv_cc_nmbrd emb wnmbrv wnmbrv_cc_nmbrd resolve_chunk chunkresolve_icdnmbrgm resolve_chunk icdnmbrgm chunkresolve_icdnmbrgm resolve_chunk icdnmbrgm nmbr chunkresolve_icdnmbrgm_nmbr med_ner legal ner_leg med_ner ner_healthcar med_ner healthcar ner_healthcar med_ner healthcare_slim ner_healthcare_slim med_ner traffic ner_traff spanish medic model nlu load refer spark nlp model refer emb scielo nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html embeddings_scielo_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html emb scielo nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html embeddings_scielo_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html emb scielo nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html embeddings_scielo_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html emb scielowiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html embeddings_scielowiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html emb scielowiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html embeddings_scielowiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html emb scielowiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html embeddings_scielowiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html emb sciwiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html embeddings_sciwiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html emb sciwiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html embeddings_sciwiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html emb sciwiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html embeddings_sciwiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html med_ner http nlp johnsnowlab com nmbr nmbr nmbr ner_diag_proc_ html ner_diag_proc http nlp johnsnowlab com nmbr nmbr nmbr ner_diag_proc_ html med_ner neoplasm http nlp johnsnowlab com nmbr nmbr nmbr ner_neoplasms_ html ner_neoplasm http nlp johnsnowlab com nmbr nmbr nmbr ner_neoplasms_ html med_ner diag_proc http nlp johnsnowlab com nmbr nmbr nmbr ner_diag_proc_ html ner_diag_proc http nlp johnsnowlab com nmbr nmbr nmbr ner_diag_proc_ html gpu mode you enabl nlu gpu mode set gpu true load model i e nlu load train sentiment gpu true if must resart kernel alreadi load nlu pipelin withouth gpu mode output level relat thi new output level use relat extractor give nmbr row per relat extract bug fix fix bug caus load nlu model offlin mode work occas nmbr line instal nlu wget http raw githubusercont com johnsnowlab nlu master script colab_setup sh o bash instal via pip pip instal nlu pyspark nmbr nmbr addit nlu ressourc nlu websit http nlu johnsnowlab com all nlu tutori notebook http nlu johnsnowlab com doc en notebook nlu video blogpost nlu http nlp johnsnowlab com learn python nlu librari nlu github http github com johnsnowlab nlu suggest question contact us slack http join slack com spark nlp shared_invit zt lutctnmbrgm kuuazcyfkhugynmbr_nmbramkxqa
sci-genie,MachineLearning,1619920075.0,[D] The Topics I Would Choose From If I Ever Did A Ph.D. in AI/ML Within the Next 2 Years. What would be Yours?,
cathie_burry,MachineLearning,1617639889.0,Why are correct AI medical diagnoses seemingly so hard to achieve? [D],there lot peopl work lot project invest lot realli smart peopl tri solv problem the studi i read fit problem peopl work run lot regulatori issu but end day seem like would less complic deal aspect medicin thing peopl built ai like alphazero the roadblock i hear add impass i see i go ai clinic
windy-city-wizard,MachineLearning,1619974865.0,[D] [R] Evaluation set for large number of imbalanced classes?,i work classif problem upward nmbr class i hundr observ class the top nmbr common class ten thousand observ bottom nmbr dozen observ my evalu set current nmbr observ class cap arbitrarili nmbr seem like sensibl setup my metric interest top nmbr accuraci is better way evalu model
shreyansh26,MachineLearning,1619962439.0,[P] GPT-1 - Annotated Paper + Paper Summary,gpt nmbr recent gpt nmbr creat lot hype launch howev start improv languag understand gener pre train paper introduc idea gpt nmbr as part paper note seri i gone paper creat brief yet inform summari paper it take take minut understand gpt nmbr well check link happi read paper summari improv languag understand gener pre train http shreyanshnmbr github io post nmbr nmbr nmbr_language_understanding_generative_pretrain annot paper http github com shreyanshnmbr annot ml paper blob main gptnmbr pdf http github com shreyanshnmbr annot ml paper blob main gptnmbr pdf
hwbs20,MachineLearning,1619257344.0,An RTX 3070 for protoyping [D],is rtx nmbr inmbr processor nmbr gb ram enough prototyp deep learn model my area work gener model use case nmbr check model code actual run mayb run tini dataset make sure thing correct onc done i put cluster scale experi nmbr mayb reproduc model demand much comput even case check code work push cluster nmbr to train basic gan vae etc understand main thing get result fast wait like hour or i wait go rtx nmbr similar spec the main problem nmbr bit budget avail august one avail right way budget wherea i want someth week thank advanc
thunder_jaxx,MachineLearning,1619812725.0,[D] Unpopular Opinion: Conferences Should Mandate a Limitations Section For Any Paper Introducing some New Model / Method / Variant,the titl say i mean specif limit section research convey solid limit new method propos i feel inform crucial dissemin good scienc age ai ml limit problem depend help ground claim research paper the review process help make section better whi reason nmbr if explicitli state go look insid paper may found mani time hidden footnot conclud remark requir cognit load read process state reduc cognit load think stuff cover part good scienc nmbr make us stick good scienc paper becom sourc benchmark porn nmbr keep clickbaiti titl check ai ml research brought advert model clickbaiti titl i clickbaiti titl mani time titl actual realli good spot http arxiv org ab nmbr but least fair scienc limit ensur boundari scienc salesmanship i awar put lot load research seldom peopl like but healthi cozi make us care learn research sell research what thought
Signal-Ad-8598,MachineLearning,1620398804.0,[D] How is tfjs-node performance in comparison with Python version?,hi i come across post show tfj node faster python tensorflow multi thread howev post nmbr year ago is still true whi tfj node popular should i train model node js i familiar js syntax python
__Julia,MachineLearning,1616942750.0,[D] Is it valuable to have a patent in our industry?,hello i work research engin r d i heard polar opinion work patent small circl i would like hear opinion peopl industri is valuabl patent someon resum how compar paper ml confer the gener public percept patent differ realiti in mani case harder write paper make top tier confer write patent howev show author abl think box enhanc exist product design system solut anoth argument i heard gate keep scienc seen blocker other well what opinion commun
Yuqing7,MachineLearning,1619541221.0,"[R] Microsoft & Peking U Researchers Identify 'Knowledge Neurons' in Pretrained Transformers, Enabling Fact Editing",a research team microsoft research peke univers peep pretrain transform investig factual knowledg store propos method identifi knowledg neuron util explicitli updat eras fact here quick read microsoft peke u research identifi knowledg neuron pretrain transform enabl fact edit http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper knowledg neuron pretrain transform arxiv http arxiv org pdf nmbr pdf
dojoteef,MachineLearning,1617280471.0,[N] John Carmack solves AGI!,after short year solitari research ai legendari programm john carmack recent unveil agi name rick creat combin flexibl gan express power predict minim i knew penchant physic build machin result qualiti facial express smooth motion uncanni it help record video nmbrk nmbrfp check http www youtub com watch v bxqlsrlakknmbr
rockwilly,MachineLearning,1619313536.0,[Project] - I made a fun little political leaning predictor for Reddit comments for my dissertation project,
NeedMoreTime4Things,MachineLearning,1617309596.0,[D] Keeping up with research - Poll,hi after talk peopl i realiz us differ way keep current develop ml as i tri dive new field phd i like know manag stay top research thank advanc view poll http www reddit com poll minmbrhrm
KirillTheMunchKing,MachineLearning,1620229627.0,[D] StyleGAN2 Distillation for Feed-forward Image Manipulation. How to gender swap Harry-Potter and edit other images explained!,stylegannmbr distil feed forward imag manipul http casual_gan nmbr in paper octob nmbr author propos pipelin discov semant edit direct stylegan unsupervis way gather pair synthet dataset use direct use train light imagenmbrimag model perform one specif edit add smile chang hair color etc new imag singl forward pass if familiar paper check nmbr minut summari http casual_gan nmbr sampl model http preview redd nmbrcohkadiobxnmbr png width nmbr format png auto webp nmbranmbrfnmbrcnmbrenmbranmbrbnmbrdnmbrccnmbrcnmbrabccnmbrabaaanmbrad arxiv http arxiv org ab nmbr paper explanain nmbr minut http casual_gan nmbr
KirillTheMunchKing,MachineLearning,1619016127.0,[R] Training Generative Adversarial Networks with Limited Data,train gener adversari network limit data http casual_gan nmbr the author propos –∞ novel method train stylegan small dataset thousand imag without overfit they achiev high visual qualiti gener imag introduc set adapt discrimin augment stabil train limit data more detail http casual_gan nmbr stylegan ada http preview redd nmbrtunmbrtenmbrgjunmbr png width nmbr format png auto webp nmbrdfnmbrdenmbrenmbrfnmbrbbnmbrdnmbrccnmbrfnmbrbnmbra in case familiar paper read http casual_gan nmbr
ancientmooner,MachineLearning,1618412945.0,[P] Code and pretrained models for Swin Transformer are released (SOTA models on COCO and ADE20K),imag classif pretrain model http github com microsoft swin transform http github com microsoft swin transform object detect coco http github com swintransform swin transform object detect http github com swintransform swin transform object detect semant segment adenmbrk http github com swintransform swin transform semant segment http github com swintransform swin transform semant segment
Exotic-Photograph-37,MachineLearning,1617994173.0,[P] Low Computation GAN? (Noobie to GAN),hello i research studi gan content we want find differ way manipul someon face map action e danc sing it seem like deepfak librari use requir lot comput time are librari low comput time we think someth like wombo ai http wombo ai take long though i know super power server connect we use wombo ai http wombo ai directli would privaci issu would requir commun third parti doe anyon tip librari could use thank
brainggear,MachineLearning,1617276285.0,[R] On the Origin of Species of Self-Supervised Learning,
Realistic_Sea_3634,MachineLearning,1620485299.0,"[D] Why has machine learning become such a toxic field, know-it-all field?",i work mani scientist mani differ field background none come close obnoxi pompos outright unpalat know vibe machin learn commun and i sure case small rotten bunch smear whole field thi behaviour rife nmbr place cesspit known twitter reddit somewhat industri it much less rampant compar academia experi clear googl brain deepmind fair academia here i observ think domin field littl involv sme often i see machin learn group group swarm problem throw ml data call problem solv veri littl sme involv importantli follow the except gener far dl encourag habit learn basic i encount often especi appar dl peopl jump straight e g cv nlp bother learn anyth foundat i seen spoken numer peopl publish cv paper prestigi confer even know colour space use even pixel sure fuck small squar imag you may claim need know delusion talk absolut there limit comput cnn transform after need foundat know improv no real work goe vast major paper dl problem thi cite mani past howev i must articul i also understand mani contribut factor inde problem it often slight architectur chang increment improv real thought gone paper what sometim result i seen numer time varieti set includ team phd good engin less product research msc experi belt the whole point phd come ml team use r d alway case much expect insol arrog fair ethic crowd thi crowd current oper simpli serv cancer tumour ml world there alway point problem never real solut they act like gatekeep god gift world it bring massiv toxic virtual ml commun prohibit free speech commun without fear repercuss the crowd could overhaul leader vitriol yobo claim academ for appli field littl focu applic often excus put forward field like math applic straight away firstli ml like math like straight engin especi dl it primarili appli thu much focus applic your slight architectur chang nmbr improv imagenet pythagoreon theorem wait happen it lazi want get phd sure phd actual want make real contribut field stand behind field like physic stat often appli make real world impact applic to fair ml also nowher near much especi averag compani industri can fix world problem over state abil ml not sure delus pr combin cite lot other edit nmbr i know peopl focus definit pixel i reiter small squar model help use enough work applic great use but claim help model definit i understand i downvot thank discuss i want understand reddit ml commun view origin content post minu pixel editnmbr realis would better put comment i regard ethic crowd i see mani peopl comment requir clarifi posit i feel intent tri make mountain molehil often least onlin perspect want engag civil discours debat present instead want blame live echo chamber they act like saviour pretenti god work the purpos ethic fair tri chang thing ethic fair commun it perpetu live littl echo chamber tri cancel disagre utter toxic never mind fact mani popular research space preach toxic larg tech compani ceo unfair practic top univers compani etc first work place like googl deepmind microsoft attend univers like stanford cmu if realli want make differ plight poc tech work deepmind go work consult littl random african start empow fuck hypocrit whatev conveni easi simpli popular contest again i found vent i quit fervent howev often appar display self entitl superior grant simpli observ mostli onlin also somewhat person
rsree123,MachineLearning,1617678542.0,How to overcome Impostor Syndrome [D],even work appli ml close nmbr year i sometim i get feel i know anyth i would abl recal thing top mind quick look help i would even rememb detail fundament concept is case everyon abl retain everyth mind peopl look profil high expect ani tip overcom
aselsiriwardena,MachineLearning,1619173423.0,[P] Pytorch Load Balance and Scalability,i need idea execut test pytorch imag gener model load balanc scalabl are specif tool do i need execut parallel process
hardmaru,MachineLearning,1620428651.0,[R] Computer-Aided Design as Language,
__data_science__,MachineLearning,1616513807.0,[D] Advanced Takeaways from fast.ai book,i recent read fast ai deep learn book http www goodread com book show nmbr deep learn coder fastai pytorch want summaris mani advanc takeaway trick i got i go leav basic thing enough post focus i found new special book i also put insight deck http saveal ai share deck nmbr nmbr nmbrknmbruxpazkgnmbr save help rememb long term i would massiv recommend use space repetit app video explan http youtu adnmbrafdrcskq like anki save http saveal ai thing learn otherwis forget much import here takeaway neural network train fundament alway start ml project produc simpl baselin if binari classif could even simpl predict common class train dataset other baselin linear regress random forest boost etc then use baselin clean data look datapoint get incorrect check see actual classifi correctli data in gener also leverag baselin help debug model e g make neural network nmbr layer abl match perform linear regress baselin bug e g ad featur improv perform linear regress probabl also improv perform neural net unless bug hyperparamet optimis help bit especi learn rate gener default hyperparamet quit well close optimis hyperparamet one last thing tri rather first if know someth problem tri inject induct bia train process e g featur relat sequenti way incorpor train separ use rnn e g know output nmbr nmbr use sigmoid design final layer forc output network rang transfer learn alway use transfer learn find model pre train similar task fine tune model particular task e g see huggingfac http huggingfac co help nlp gradual unfreez discrimin learn rate work well fine tune transfer learn model gradual unfreez freez earlier layer train later layer gradual unfreez earlier layer one one discrimin learn rate differ learn rate per layer network usual earlier layer smaller learn rate later layer trick deal overfit best way deal overfit get data exhaust first start regularis method data augment realli power possibl text well imag imag data augment crop pad squish resiz imag text data augment negat word replac word simil perturb word embed nice github repo http github com qdata textattack mixup regularis creat new data averag togeth train datapoint backward train nlp train addit separ model fed text backward averag output two model get final predict other trick improv perform test time augment test time use averag predict mani augment version input predict rather predict true input nmbr cycl train increas reduc learn rate throughout train circular fashion usual make huge differ learn rate finder algorithm algorithm fast ai provid help automat discov roughli best learn rate never use one hot encod use embed instead even tabular data use adamw instead adam help littl bit lower precis train help pytorch lightn http github com pytorchlightn pytorch lightn simpl flag set for regress problem know output within rang good use sigmoid forc neural net output within rang i e make network output min _valu sigmoid output max _valu min _valu cluster featur help identifi one redund remov help perform label smooth use nmbr nmbr instead nmbr nmbr label target smoothen train don dichotomis data output continu better train network predict continu valu rather turn classif problem progress resiz train model smaller resolut imag first increas resolut gradual speed train lot strateg use bottleneck layer forc network form compact represent data differ point help tri use skip connect help smooth loss surfac pleas let know found help train trick use also know
Yuqing7,MachineLearning,1620061055.0,"[R] CMU, UT Austin & Facebook‚Äôs CNN Layer Width Optimization Strategies Achieve 320x Overhead Reduction",research carnegi mellon univers univers texa austin facebook ai propos novel paradigm optim width cnn layer the method compat across variou width optim algorithm network achiev nmbrx reduct width optim overhead without compromis top nmbr accuraci imagenet here quick read cmu ut austin facebook cnn layer width optim strategi achiev nmbrx overhead reduct http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper width transfer on in varianc width optim arxiv http arxiv org pdf nmbr pdf
dontreallyknowmuch,MachineLearning,1618540777.0,[R] GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds,here new work nvidia recent showcas gtc nmbr keynot it convert user creat minecraft block world view consist realist look world the method learn perform translat absenc pair minecraft real data use gan pretrain network gener pseudo ground truth tweet http twitter com arunmallya statu nmbr http twitter com arunmallya statu nmbr arxiv http arxiv org ab nmbr http arxiv org ab nmbr webpag http nvlab github io gancraft http nvlab github io gancraft sampl output http reddit com link mrunmbrh video inmbrarzkyfktnmbr player http reddit com link mrunmbrh video njqlnmbrgcnmbrgktnmbr player http reddit com link mrunmbrh video nmbrrqenmbrgenmbrgktnmbr player it even chang style output world http reddit com link mrunmbrh video srgnmbrqwnmbrgktnmbr player
mroc_lak,MachineLearning,1616427593.0,[D] How do you test your machine learning models for healthcare to gain confidence before embarking on a clinical trial?,hi i look ml applic healthcar interest understand compani prepar clinic trial which metric correl well clinic trial perform import pitfal avoid
timscarfe,MachineLearning,1616537282.0,[D] Meta-Gradients in Reinforcement Learning with Tomas Zahavy (DeepMind) and Robert Lange (Video),dr tom zahavi research scientist deepmind think reinforc learn gener learn framework today opinion could lead artifici gener intellig he think task could solv simpli maximis reward back nmbr tom undergradu deep learn revolut attend onlin lectur cnn automat discov represent thi epiphani tom he decid moment go becom ml research tom view abil recognis pattern discov structur import aspect intellig thi quest ever sinc he particularli focus use divers preserv metagradi discov structur in discuss dive deep meta gradient reinforc learn video http youtu hfazwgk _isnmbr http youtu hfazwgk_isnmbr pod http anchor fm machinelearningstreettalk episod nmbr meta gradient rl dr toma zahavi deepmind etbcrnmbr http anchor fm machinelearningstreettalk episod nmbr meta gradient rl dr toma zahavi deepmind etbcrnmbr
freshprinceofuk,MachineLearning,1619968135.0,[D] Best CPU real time pose estimation model available?,hi i look quit pose estim model cpu gpu nmbrd nmbrd i seen anyth impress kemtai kemtai com browser cpu real time can anyon suggest model may
Rat-a-ouchie,MachineLearning,1619213594.0,"[D] PhD Applied Maths - Machine Learning, supervisor selection should be one you get along with or something else is more important?",hey guy i phd appli mathemat love machin learn i want specialis machin learn base thesi amd i wonder anyon advic phd supervisor select i sure right place ask advic appreci in summari what look supervisor how find right research topic
jj4646,MachineLearning,1619155260.0,"[D] is this the equivalent of the ""what came first, the chicken or the egg"" in machine learning?",http en wikipedia org wiki probably_approximately_correct_learn i learn concept statist learn call probabl approxim correct pac although word seem complic technic i understand correctli essenc pac show target concept e g set possibl input point correspond certain output error machin learn algorithm probabilist bound certain rang i think intend show machin learn algorithm use make predict instead base predictor color sock neighbor wear nmbr pac framework develop nmbr yet prior mani statist model use make predict e g regress model onc pac develop research examin statist model use prior confirm model compat pac framework nmbr now question modern model when newer machin learn model develop e g lstm model develop long pac framework establish new algorithm test make sure compat pac framework nmbr can someon pleas confirm understand pac framework correct sourc http stat stackexchang com question nmbr pac learn theori mean http machinelearningmasteri com hypothesi machin learn a hypothesi context pac seem gener term machin learn algorithm hypothesi space space possibl algorithm e g linear regress model specif beta paramet individu hypothesi possibl linear regress model hypothesi space d distribut data concept class im still confus differ target concept concept class can someon pleas clarifi
__data_science__,MachineLearning,1617707256.0,[D] Training strategy given Double Descent phenomenon,how doubl descent http openai com blog deep doubl descent chang ideal train strategi befor i use follow broad train strategi nmbr make network big enough overfit train data nmbr then regularis reduc overfit but possibl doubl descent mean might correct anymor i wonder guy think
anianruoss,MachineLearning,1617294131.0,[R] Robustness Certification for Point Cloud Models,we present first robust certifi semant transform e g rotat shear nmbrd point cloud model object classif part segment task paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com eth sri nmbrdcertifi http github com eth sri nmbrdcertifi abstract the use deep nmbrd point cloud model safeti critic applic autonom drive dictat need certifi robust model semant transform thi technic challeng requir scalabl verifi tailor point cloud model handl wide rang semant nmbrd transform in work address challeng introduc nmbrdcertifi first verifi abl certifi robust point cloud model nmbrdcertifi base two key insight gener relax base first order taylor approxim applic differenti transform ii precis relax global featur pool complex pointwis activ e g relu sigmoid commonli employ point cloud model we demonstr effect nmbrdcertifi perform extens evalu wide rang nmbrd transform e g rotat twist classif part segment task for exampl certifi robust rotat nmbr nmbr point cloud max pool relax increas certif nmbr
adammathias,MachineLearning,1619016230.0,"[N] Aim 2.3.0 is out with system resource monitoring, ""reverse grouping"" and more",highlight comment system resourc monitor an option automat track gpu cpu memori i curiou much cover disk network revers group thi aim call option divid everyth one param typic seed it look like pick variabl ui experi clear set variabl default indivis via api line chart smooth thi self explanatori mayb somewhat automat default base number point scale standard error standard deviat new built aggreg mode addit min max support infinit valu nan full list releas issu featur request http github com aimhubio aim mileston nmbr close nmbr announc http medium com aimstack aim vnmbr nmbr nmbr system resourc usag revers group nmbrddnmbranmbrff gev
CanadianTuero,MachineLearning,1617011308.0,[P] Differentiable Optimizers with Perturbations in PyTorch,after read http www reddit com r machinelearn comment mcdox p_torchsort_fast_differentiable_sorting_and post day i learn use perturb creat differenti optim http arxiv org ab nmbr http arxiv org ab nmbr there offici implement http github com googl research googl research tree master perturb tensorflow sinc i primarili use pytorch tool someth i want play around research i reimplement use nativ pytorch figur i would share case other find use well http github com tuero perturb differenti pytorch http github com tuero perturb differenti pytorch
BotPoetsSociety,MachineLearning,1618053966.0,[P] AI Poetry,we creat poem combin ai model the poem gener gptnmbr model fine tune poetri we choos edit gener poetri we think fun read raw poetri come machin even obviou flaw photo http unsplash com voic text speech aw azur http reddit com link monmbrxrk video qfmfynmbrfbzbsnmbr player youtub channel http www youtub com channel uchydklnmbrlnmbrwnmbrvebsakswnmbrsdw http www youtub com channel uchydklnmbrlnmbrwnmbrvebsakswnmbrsdw twitter http twitter com botpoetssocieti http twitter com botpoetssocieti
JoshN1986,MachineLearning,1616957813.0,[P] scite: a smart citation index that displays the context of citations and classifies their intent using deep learning,
bendee983,MachineLearning,1617897743.0,[D] Waymo now has a machine learning PhD as its co-CEO,in nmbr googl hire john krafcik veteran automot industri lead self drive car effort later spun waymo last week krafcik step cede role dimitri dolgov comput scienc phd veteran ml research tekedra mawakana doctor law whi import at time krafcik join googl gener belief deep learn matur enough sdc reach product level sdc matter scale road test gather enough train data train dl model but becom evid current state dl readi tackl mani challeng open road mani gap need fill the legal infrastructur sdc also readi mani question remain unansw thi make sens put ml engin lawyer helm compani deep learn come long way push sdc forward bumpi road still lie ahead read full analysi http bdtechtalk com nmbr nmbr nmbr waymo ceo reshuffl self drive car industri http bdtechtalk com nmbr nmbr nmbr waymo ceo reshuffl self drive car industri
bryant1410,MachineLearning,1619129609.0,[N] Competition on classifying tweets as jokes + more,comput humor task tweet nmbr subtask binari classif intend humor non intend humor funni score humor mechan classif humor target classif http competit codalab org competit nmbr http competit codalab org competit nmbr it spanish i think big blocker speak the paper team describ system publish iberlef workshop sepln nmbr m√°laga spain virtual
VinayUPrabhu,MachineLearning,1617308083.0,[P] A small dataset of mis-parsed citations from Google scholar,tl dr googl scholar parser aggress index public sometim index high school cafeteria restaur menu paper the nice aspect lot agro journal global south meet fate well nmbr dataset http github com vinayprabhu reveng _of _the _pith _sigboviknmbr tree main data http github com vinayprabhu revenge_of_the_pith_sigboviknmbr tree main data nmbr awar rais paper author sigbovik humor style http github com vinayprabhu reveng _of _the _pith _sigboviknmbr blob main sigbovik _plant _nmbr _camera _readyish pdf http github com vinayprabhu revenge_of_the_pith_sigboviknmbr blob main sigbovik_plants_nmbr_camera_readyish pdf http preview redd vzunmbriqpdmqnmbr jpg width nmbr format pjpg auto webp nmbrabaenmbrenmbrdnmbrenmbr
Symbiot10000,MachineLearning,1616967325.0,"[D] Papers on intelligent agents for search (not voice, Alexa, etc.)",i look write someth intellig agent use search internet resourc regular platform e mobil desktop headless platform like alexa ai voic assist specif topic without user directli interact search engin for variou reason incred difficult googl drill paper subject the signal nois ratio beaten i think gpt nmbr style gener oracl infinit scope abstract great deal hide sourc ai project scrape replac googl perhap rather machin learn system task specif domain blastoma research compress specif audienc mind greater level discern judgement regard qualiti sourc averag search engin if anyon link two would point right direct i grate
jj4646,MachineLearning,1619580096.0,[D] do machine learning models handle multicollinearity better than traditional models (e.g. linear regression)?,when come older tradit model like linear regress ensur variabl multicollinear import multicollinear greatli harm predict abil model howev older tradit model meant use smaller dataset fewer row fewer colum compar modern big data intuit easier identifi correct multicollinear smaller dataset e g variabl transform remov variabl stepwis select etc in machin learn model big data multicollinear big problem e g model like randon forest known sustain strong perform presenc multicollinear if make random forest immun multicollinear are neural network deep neural network abk deal multicollinear if make neural network immun multicollinear thank
jj4646,MachineLearning,1619072556.0,"[D] Competetive ""Rule Based"" Machine Learning Models",http en wikipedia org wiki association_rule_learn ha anyon ever seen advanc associ rule model involv machin learn architectur what advanc machin learn model provid complet set rule interpret make predict doe someth like exist
kpang0,MachineLearning,1617823197.0,[P] Vald: a highly scalable distributed fast approximate nearest neighbour dense vector search engine.,hi i recent releas vnmbr vald cloud nativ distribut fast approxim nearest neighbour dens vector search engin run kubernet oss project apachenmbr licenc it alreadi run behind yahoo japan imag search recommend engin also run behind japanes nation digit librari digit archiv retriev engin by use machin learn convert unstructur data audio imag video user characterist etc vector use vald perform vector search vector possibl oper faster complex search engin vald still new project look lot feedback mani user pleas come visit site web http vald vdaa org http vald vdaa org github http github com vdaa vald http github com vdaa vald
SQL_beginner,MachineLearning,1620156717.0,"[D] ""Classifier Technology and the Illusion of Progress"" (2006, Hand)",http arxiv org ab math nmbr i found interest paper author argu complex algorithm e g deep neural network alway signific advantag simpler algorithm real world henc illus the author bring mani reason happen reason relat mathemat other relat experiment design note author bring point i sure true convers two class case although real data set exactli linear decis surfac common find centroid predictor variabl distribut class differ simpl linear surfac surprisingli well estim true decis surfac whi common find centroid predictor variabl distribut differ whi allow linear surfac estim true surfac well here thought i read paper thi paper publish nmbr deep learn revolut e g nmbr convolut neural network clearli outperform human imagenet competit is possibl result paper somewhat irrelev outdat research univers compani e g googl facebook microsoft probabl spent billion dollar sinc nmbr develop complex machin learn model use common sens mani model perform well enough research done futur i agre certain problem perhap simpler model e g linear regress decis tree perform well deep learn model sure mani problem real world requir complex model can argument made complex model requir use concept vc dimens http en wikipedia org wiki vapnik enmbr nmbr nmbrchervonenkis_dimens relat problem initi x perceptron problem could say big data data mani column mani row less like linearli sepper e harder shatter shatter classifi perfectli compar smaller dataset could say data point exist configur data point arrang make less probabl analyz use simpler model vc dimens simpler model lower vc dimens complex model doe fact alon somewhat justifi need develop complex model
l34df4rm3r,MachineLearning,1618580410.0,[D] Graph Convolution and GraphSAGE: why don't people use these together?,in deep learn graph peopl graph convolut graph sage i seen combin two intuit combin transduct induct framework is drawback use dgl quit easi stack layer get output so question see use work involv graph neural network gcn variant
othotr,MachineLearning,1616740968.0,[R] Stanford HAI Spring Conference - Intelligence Augmentation: AI Empowering People to Solve Global Challenges,stanford institut human center ai host spring confer today interest convers ai best support human healthcar art educ address global challeng more detail event record avail hai confer site http hai stanford edu event intellig augment ai empow peopl solv global challeng here quick outlin video section welcom introduct http crossmind ai video stanford hai nmbr spring confer intellig augment ai empow peopl solv global challeng nmbrdnmbrabfnmbrcnmbrbnmbr timecod nmbr hai director fei fei li john etchemendi russ altman jame landay session i healthcar http crossmind ai video stanford hai nmbr spring confer intellig augment ai empow peopl solv global challeng nmbrdnmbrabfnmbrcnmbrbnmbr timecod nmbr immers technolog caregiv innov opportun ecosystem challeng deborah estrin cornel tech student lightn talk on complement extend human intellect principl direct eric horvitz microsoft mobil ai achiev healthi child develop worldwid denni wall stanford safer proactiv care ai suchi saria john hopkin univers session ii art http crossmind ai video stanford hai nmbr spring confer intellig augment ai empow peopl solv global challeng nmbrdnmbrabfnmbrcnmbrbnmbr timecod nmbr other intellig exotic ai ken goldberg uc berkeley student lightn talk art intellig exotic ai michel elam stanford the digit griot a reimagin archiv rashaad newsom stanford amplifi human artist through ai hilari hahn carol reiley deepmus ai session iii educ http crossmind ai video stanford hai nmbr spring confer intellig augment ai empow peopl solv global challeng nmbrdnmbrabfnmbrcnmbrbnmbr timecod nmbr escap autom legaci bad instruct daniel schwartz stanford student lightn talk ai super power teacher chri piech stanford push boundari educ technolog ami ogan carnegi mellon univers ai acceler workplac learn scale candac thill amazon http preview redd pnmbrqgnmbreutibpnmbr png width nmbr format png auto webp nmbrccnmbrddnmbrcnmbrcnmbrdanmbrdnmbrcanmbrfnmbrdnmbrcnmbr
dadasenior,MachineLearning,1619096232.0,"[Discussion] I own a 16"" macbook pro with max specs. But how can I make it fast for Keras?",i train convolut neural network huge dataset use tensorflow kera so far i notebook kaggl veri slow gpu acceler seem not work also mani user so i make expens pc build ml i wonder could i exploit expens macbook pro nmbr instead macbook pro nmbr nmbr nmbr ghz intel core inmbr nmbr core nmbr gb nmbr mhz ddrnmbr amd radeon pro nmbrm nmbr gb what best option plaidml i could exploit discret amd gpu macbook b use acceler tensorflow specif tailor mac avail http github com appl tensorflow_maco c i also egpu power amd radeon rx nmbrxt nmbrgb cuda compat someth like plaidml your call ani help experi appreci thank advanc
bert4QA,MachineLearning,1617439649.0,[R] FeTaQA: Free-form Table Question Answering,
EinsteiniumArmour,MachineLearning,1620342778.0,"[P] Last year, I built a multilingual text simplifier for my undergraduate thesis. This year, I made it work with multilingual BERT!",english simplif made mile http preview redd kympalubnmbrlxnmbr png width nmbr format png auto webp anmbrdnmbreaeanmbrcfnmbrffnmbrfenmbrbnmbranmbrcednmbrf mile http github com kvasir mile multilingu text simplifi inspir lsbert http arxiv org ab nmbr a bert base lexic simplif approach propos nmbr unlik lsbert mile use bert base multilingu uncas model well simpl languag agnost approach complex word identif cwi candid rank although test mile support least nmbr languag arab bulgarian catalan czech danish dutch english finnish french german hungarian indonesian italian norwegian polish portugues romanian russian spanish swedish turkish ukrainian pleas note result use languag specif resourc mile alway offer synonym substitut complex word although almost alway simpler origin select substitut may alter mean text pleas keep mind feel free use tailor mile languag choos the github repo mile found http github com kvasir mile
FirstTimeResearcher,MachineLearning,1620101406.0,[D] Petition to the Neurips 2021 conference to extend the deadline,origin tweet hi neuripsconf sincer request mani friend collabor importantli student affect covid pleas extend deadlin mani student i know work experi covid close famili member hospit a grow number neuripsconf paper submit indian research student i person know mani scrambl write paper experi situat pleas consid extend least week two i person know two student hospit current work hard submit paper time while talk indian collabor almost everi student similar situat an extra week two would help tremend thank much pl amplifi http twitter com rishiy statu nmbr
weifz,MachineLearning,1620391383.0,[D]Why is it impossible to do causal discovery from observational data?,hi there say as shall see problem statist imposs despit larg number paper topic http www stat cmu edu larri sml causat pdf http www stat cmu edu larri sml causat pdf sec nmbr could explain sinc i read lot paper causal discoveri observ data thank
SeaworthinessOk834,MachineLearning,1619396009.0,[D] Is Anaconda Worth the Trouble?,hi everyon i get readi work pytorch struggl whether i reinstal anaconda i issu past kind screw path old laptop i care i got new comput go along fine i uninstal month back i would realli like use seem definit guid avoid recur issu i hope mayb somebodi might resourc advic if make work must realli suck hur hur get platform thank advanc edit it strang reassur know i window user problem anaconda you given plenti consid thank respons feedback
thisisdhruvagarwal,MachineLearning,1618056732.0,Which Policy Gradient Method was used by Google's Deep Mind to teach AI to walk? [D],i saw http www youtub com watch v gnnmbrnrccnmbrtwq video youtub which polici gradient method use train ai walk wa ddpg dnmbrpg
mimeticaware,MachineLearning,1617515924.0,[D] Hashing techniques to compare large datasets?,are implement research paper hash fingerprint techniqu larg dataset greater nmbr gb i want implement librari gener hash fingerprint larg dataset easili compar i sure start exist implement research paper would realli help
Rishit-dagli,MachineLearning,1618399521.0,[P] Implementing Perceiver: General perception with Iterative Attention in TensorFlow,today i glad present implement perceiv gener percept iter attent model build top transform solv quadrat scale problem without make assumpt data like previou approach tensorflow thi mean use model imag audio video etc thi model also achiev state art task ps thi made readi use python packag get start easili the project http github com rishit dagli perceiv http github com rishit dagli perceiv
VinayUPrabhu,MachineLearning,1618166994.0,[P] On the extreme compressibility of Dall-E encoding tensors,brief abstract i saw bunch artsi folk experi interest downstream applic dall e encod thought i share observ as turn one could potenti use much lower effect vocab size nmbr instead nmbr without suffer much visual qualiti loss or word intrins dimension vocabulari space unearth tucker decomposit like tensor compress techniqu nmbr so use much lower dimension encod vector nmbr compress rather raw nmbr x nmbr xnmbr d vector post encod regress classif linear algebra twiddl pipelin ps notic nice space fill artifact gif travel upward nmbrd nmbrd colab http github com vinayprabhu colabarama blob master dall _e _low _d ipynb http github com vinayprabhu colabarama blob master dall_e_low_d ipynb http preview redd wnmbrdqnmbrinmbrlsnmbr png width nmbr format png auto webp nmbrbnmbrdnmbrcnmbrdnmbrcnmbrfnmbrbnmbrefnmbrdnmbranmbranmbrb the obligatori cat gif http redd khmdlenmbralsnmbr gif
sideonion,MachineLearning,1620432525.0,[D] What DL algorithm to use to track target when I know target coordinates first frame - single target only?,so i set imag i defin first frame hu target detect track subsequ frame most deep learn model pre train data i i imag i want detect one specif target i know human detect model exist i use i want detect particular human subsequ frame there may multipl human frame i want focu one i tri detect if method help pleas let know thank
TheCockatoo,MachineLearning,1616836263.0,[D] What's your experience with ML conference rebuttals / letters to area chairs?,have ever written area chair due review incompet review e g review obvious spent nmbr minut paper yet reject high confid comment reveal understand basic machin learn happen
stivi2000,MachineLearning,1617832590.0,[P] Language Independent Sentiment Analysis,we train sentiment model use english dataset but use german sentenc work surprisingli well see detail actual work http github com aok plu sentimentanalysi
WFHFAWAY,MachineLearning,1617552633.0,[D] Is A Failure Ever Worth Publishing?,so i formal research part ms i architectur idea find exampl literatur i went research process applic integr idea exhaust due time constraint the net result research integr approach exist backbon lower valid perform slightli appl appl basi if anyon tri mayb work i could find refer anyon tri are experi alway lead big improv never worth publish i feel like make progress know tri
SkyLordOmega,MachineLearning,1618722171.0,[D] Wav2Vec2 training for Hindi language,i part datasprint huggingfac wavnmbrvecnmbr fine tune task i train three dataset hindi languag nmbr commonvoic nmbr indic tt iitm nmbr iiith indic dataset while train model give good perform longer audio nmbr nmbr wer nmbr perform commonvoic bad wer nmbr commonvoic audio smaller length i attach imag exampl predict test set what could reason drastic degrad qualiti could i improv model resum train commonvoic dataset http preview redd nmbrwqzwchonmbrvtnmbr png width nmbr format png auto webp bnmbranmbraecnmbrfacnmbrdenmbrednmbrbnmbrafnmbrbnmbr
PaganPasta,MachineLearning,1620454345.0,[D] ICML 2021 Results,icml result due today gather around anxiou author fare relev content last week http www reddit com r machinelearn comment nnmbrqw d_icml_conference_we_plan_to_reduce_the_number_of good luck
Seankala,MachineLearning,1618462099.0,"[D] Regarding BERT-based models (BERT, RoBERTa, etc.) do we absolutely have to include the [CLS] and [SEP] special tokens in the input data?",the thought occur i process data if use cl token classif would obvious make sens includ use token includ
Gullible_Dance,MachineLearning,1619642170.0,[D] New paper shows that federated learning is broken?,titl see gradient imag batch recoveri via gradinvers http arxiv org ab nmbr http arxiv org ab nmbr the author recov individu train exampl accumul gradient what mean data privaci law
ravode,MachineLearning,1617294699.0,[D] Dask on App Engine or Cloud Run?,hello i wonder run dask app engin cloud run thing the use case etl job run sk learn model part argo workflow precis execut done unparallel respect node we like parallel sk learn stuff move dask the obviou approach argo knmbr base would integr dask knmbr cluster but coupl reason i wonder whether app engin cloud run might also viabl option in case skip horizont scale instead fire strong instanc parallel dask avail core instead
jj4646,MachineLearning,1620015148.0,[D] stochastic block model vs. standard community detection algorithms,ha anyon ever come across stochast block model http en wikipedia org wiki stochastic_block_model all seem like commun detect algorithm graph e network cluster doe anyon know circumst would make sens use stochast block model compar commun detect algorithm louvain cluster thank
xiikjuy,MachineLearning,1619972031.0,[D] How to visualize the features of encoder output of an encoder-decoder Transformer model?,hello i wonder visual encod output featur encod decod model like bart tnmbr for base bart model max posit nmbr model dimens nmbr featur dimens would nmbr nmbr nmbrk i experi use sne still reason choic featur dimens order ani suggest good practic thank
blazejd,MachineLearning,1617211645.0,[Discussion] How was this paper titled?,thi littl desper coupl week ago i stumbl upon interest paper i rememb titl lot search i find it explain use gradient could identifi easi difficult classifi exampl data afterward shown use nmbr exampl chosen properli achiev similar perform use whole dataset train there figur show imag two dimens someth like if anyon rememb base vagu descript titl i would realli appreci share http preview redd cnmbramgnmbrlaeeqnmbr png width nmbr format png auto webp nmbrbdcdnmbrfnmbrccnmbreenmbrecnmbrdnmbranmbrc
ccrbltscm,MachineLearning,1618792131.0,[P] Research paper graph for NeRF: foundational work & latest advancements - Link to the interactive graph and paper collection in comments,
meldiwin,MachineLearning,1619994622.0,"[N] Living Robots ""Computationally Designed Organisms""",
innerlee,MachineLearning,1617966854.0,"[N] MMOCR: A Toolbox for Text Detection, Recognition, and Understanding Based on PyTorch",we releas http github com open mmlab mmocr http github com open mmlab mmocr new member openmmlab http openmmlab com http openmmlab com thi first releas support text detect http redd hoyxnmbrffgnmbrsnmbr gif text detect psenet panet dbnet textsnak maskrcnn text recognit http redd ppnmbrtpyrjgnmbrsnmbr gif text recognit crnn sar robustscann segocr nrtr key inform extract http redd huzucxylgnmbrsnmbr gif key inform extract sdmg r longer post see http medium com openmmlab mmocr comprehens toolbox text detect recognit understand nmbrbefanmbrbnmbr http medium com openmmlab mmocr comprehens toolbox text detect recognit understand nmbrbefanmbrbnmbr
inigomlap,MachineLearning,1619161977.0,[D] What methodology do you use in data science projects?,data scientist project methodolog team use data scienc you check methodolog use poll articl http www sciencedirect com scienc articl ab pii snmbr http www sciencedirect com scienc articl ab pii snmbr view poll http www reddit com poll mwponm
vanstorm9,MachineLearning,1618251549.0,[D] How do you visualize and compare image distributions of datasets?,i situat i handl multipl imag dataset i want determin similar two imag dataset distribut thi help determin thing whether suitabl combin two dataset one debug valid accuraci high test low straight discov inform compar imag dataset would aid import decis the i done gener pixel intens histogram one multipl imag two dataset compar accordingli is anyth els i visual compar imag distribut among dataset is also metric i also visual calcul compar certain properti imag dataset
lsmith1988,MachineLearning,1618030770.0,Search engine used to seek details of videos/images [r],other caption paper project underway ml extract inform given video imag search exact locat may internet exclud revers imag search googl for instanc search color wheel frame video speech etc return locat i interest learn type technolog whether someth done alreadi
cgnorthcutt,MachineLearning,1617033396.0,[R] Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks,hi reddit we excit share latest research label error pervas nmbr commonli use benchmark test set use machin learn research we investig implic label error particular affect stabil ml model benchmark rank an exampl label error categori imag dataset the figur show given label cl guess altern human valid correct label also second label multi class data point a browser label error across nmbr dataset avail http labelerror com error text audio dataset also includ websit http preview redd nmbruhmppnmbrozpnmbr png width nmbr format png auto webp bcnmbrenmbrcnmbranmbrcnmbranmbrbdnmbranmbrfnmbrbnmbranmbrdcnmbrd demo http labelerror com http labelerror com blog post http lnmbr curtisnorthcutt com label error http lnmbr curtisnorthcutt com label error abstract we identifi label error test set nmbr commonli use comput vision natur languag audio dataset subsequ studi potenti label error affect benchmark result error test set numer widespread estim averag nmbr error across nmbr dataset exampl nmbr label error compris nmbr imagenet valid set put label error identifi use confid learn algorithm human valid via crowdsourc nmbr algorithm flag candid inde erron label tradit machin learn practition choos model deploy base test accuraci find advis caution propos judg model correctli label test set may use especi noisi real world dataset surprisingli find lower capac model may practic use higher capac model real world dataset high proport erron label data for exampl imagenet correct label resnet nmbr outperform resnet nmbr preval origin mislabel test exampl increas nmbr on cifar nmbr correct label vgg nmbr outperform vgg nmbr preval origin mislabel test exampl increas nmbr paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com cgnorthcutt cleanlab http github com cgnorthcutt cleanlab joint work anish athaly jona mueller
,MachineLearning,1616615314.0,[N] Hype GTC 2021,get glimps futur comput nvidia ceo jensen huang gtcnmbr keynot nmbr nmbr nmbr nmbr pdt save date http bit ly nmbrrlvfwz http bit ly nmbrrlvfwz i think across ai ml commun extrem import push boundari thi keynot free listen even need regist confer heard nvidia ceo jensen huang speak sincer impress thing i use ai ml data scienc inform tip tomorrow just thought i push mass today
CauchySchwartzDaddy,MachineLearning,1617076262.0,[D] Advice on getting grants/funding for a college ML research club to cover GPU costs,basic i help run ml club campu i want abl get sort fund cover gpu cost cloud one friend said googl give gpu i find info we realli need whole ton run whole oper i wonder good way go
blissfox-red,MachineLearning,1617171438.0,[D] Nvidia Data Science of the Day posts,subsequ bump post whose author disappear emb your sql queri into your python code let it rip gpu http forum develop nvidia com emb sql queri python code let rip gpu nmbr http www reddit com r machinelearn comment mnmbrbnmbr p _emb _your _sql _queri _into _your _python _code _and utm _sourc share utm _medium webnmbrx context nmbr http www reddit com r machinelearn comment mnmbrbnmbr p_embed_your_sql_query_into_your_python_code_and utm_sourc share utm_medium webnmbrx context nmbr with gpu k nearest neighbor algorithm cross finish line when other start block http forum develop nvidia com gpu k nearest neighbor algorithm cross finish line other start block nmbr http www reddit com r machinelearn comment mnmbrzvenmbr p _with _gpu _knearest _neighbor _algorithm _cross utm _sourc share utm _medium webnmbrx context nmbr http www reddit com r machinelearn comment mnmbrzvenmbr p_with_gpus_knearest_neighbor_algorithm_cross utm_sourc share utm_medium webnmbrx context nmbr i arriv part i far miss nvidia webpag might alreadi know data scienc day page propos post one day averag seem encapsul usual link blog post articl technic news data scienc not everi post might relev ml practition i believ least might so like miss want give look link http forum develop nvidia com c ai data scienc data scienc day nmbr none http forum develop nvidia com c ai data scienc data scienc day nmbr none
tranhp129,MachineLearning,1620591990.0,[D] Non Strongly-convex loss is strongly convex in expectation,i seen sever paper mention loss strongli convex strongli convex expect eg logit loss squar loss just take deriv loss i show loss strongli convex i understand expect strongli convex for exampl hessian squar loss would rank nmbr matrix outer product vector thu squar loss strongli convex but take expect make differ ani help appreci
gta141,MachineLearning,1620337216.0,[Research] DeepPlastic: A Novel Approach to Detecting Epipelagic Bound Plastic Using Deep Visual Models,the goal paper quantifi marin plastic use deep learn check paper http arxiv org ab nmbr http arxiv org ab nmbr predict use model http reddit com link nnmbrihmnmbr video dzdhwqfikkxnmbr player
RussellEsby,MachineLearning,1618479575.0,[P] Voice Conversion VAE-Cycle-GAN on Melspectrograms,hi i follow great work ehab a albadawi http ebadawi github io post speech _style _transfer http ebadawi github io post speech_style_transf the demonstr result incred and realli stand approach qualiti feasibl i work open sourc implement past month the link found http github com russellsb voic convers gan http github com russellsb voic convers gan but sinc struggl load mode collaps model output blurri spectrogram quit captur initi structur there architectur chang i make abl execut model for one i ad conv layer encod decod get right dimens in paper descript design residu block either i use convolut layer i tri mani modif experi better stabil train close replic paper i feel i replic much i current might anyon abl point may issu keen lean right direct
paulcjh,MachineLearning,1616435921.0,[P] Silero NLP streaming on serverless GPUs (~300ms latency),hey everyon a coupl week ago i put post deepspeech run serverless setup neuro http getneuro ai http getneuro ai i got silero run well i found model lot faster ds way accur see around nmbrm per request moment hope closer nmbrm soon pretti decent speed applic alreadi the code listen mic local machin stream silero model return convers result you find sourc http github com neuro ai dev npu _exampl tree main silero python http github com neuro ai dev npu_exampl tree main silero python of cours run serverless hammer theori hard want silero http github com snakersnmbr silero model http github com snakersnmbr silero model audio text convers model pretti heavi if q want see let know i think next i play around spade http github com nvlab spade http github com nvlab spade set bulki vision model cheer
idg101,MachineLearning,1619555928.0,[D] Unpopular Opinion: I hate the tensorboard Smoothing algorithm and always set the slider to 0.,look code smooth slider bar tensorboard implement exponenti move averag use major ml task i it seem someth much simpl like move averag filter would much better make slider window length
Drakshh,MachineLearning,1619710277.0,[Project] Model to evaluate audio clips similarly,post multipl subreddit got respons henc post sorri belong dear i rel new nlp ml current i work project i compar score two audio clip origin clip singl sentenc movi charact anim real second clip human tri mimic i come model determin similarli score human clip nmbr factor i consid use nmbr get text speech compar origin nmbr evalu similarli audio spectrogram spectral centroid zero cross rate nmbr identif emot speech use emot embed assum avail internet measur similarli probabl use cosin similarli i come factor can pleas help come new comparison factor suggest i approach problem better way thank anticip
cloud_weather,MachineLearning,1619254999.0,[D] StyleGAN2 + CLIP = StyleCLIP: You Describe & AI Photoshops Faces For You,
skeering,MachineLearning,1619970192.0,[R][D] Starting a Post-Doc and Looking for Advice on Research Area,so i start post doc within next nmbr nmbr month i look around opportun my supervisor advis post doc area phd instead branch two main field diversifi my phd xai i happi last nmbr year went go forward i look hot research area asid i person like find interest correct i wrong seem big question ai go forward nmbr how generalis better e g take learn mnist appli fashionmnist nmbr how make system immun adversari attack nmbr how get explan opaqu model e g medic radiolog nmbr how learn fewer exampl one shot learn semi supervis learn the ultim goal unsupervis learn work well real world i sure i miss anyth probabl i interest asid xai number nmbr would i correct assum four area import next gener ai technolog is area i miss lastli would agre number nmbr good area get second research interest next nmbr nmbr year thank great day
Jason_s0214,MachineLearning,1619216428.0,[R][D] Our new ICLR'21 work clarifies a misconception regarding distillation and label smoothing in a previous NeurIPS'19 study,is label smooth truli incompat knowledg distil an empir studi http arxiv org ab nmbr project page http zhiqiangshen com project ls _and _kd index html http zhiqiangshen com project ls_and_kd index html ani comment discuss welcom
Zethsc2,MachineLearning,1618571357.0,[R] mlf-core: a framework for deterministic machine learning,
aspcraft,MachineLearning,1620306117.0,Noise-reduction techniques and evaluation for timeseries data [Discussion],what common practic deal noisi data what common nois reduct techniqu non stationari time seri also sort formula compar differ method nois reduct for exampl one produc two differ timeseri origin noisi data way compar two new timeseri evalu better for exampl linear regress best line typic chosen minimis mean squar error is someth similar if anyon idea criterion could adapt formula minimis maximis get best noic reduc timeseri i interest hear thought gener idea
ottawalanguages,MachineLearning,1618866478.0,[D] Effective Ways of Choosing the Number of Layers/Neurons in a Neural Network,i read theoret background neural network e g univers approxim theorem seen sever author demonstr even simpl layer mani neuron neural network theoret approxim variabl interest e respons variabl decent level precis howev implic use simpl neural network order achiev good result would requir larg number neuron therefor deeper neural network develop year attempt provid good result layer fewer number neuron thi bring situat i never abl success fit neural network real world data i use i alway gotten realli bad result neural network tri sort combin number neuron number layer learn rate activ function drop regular etc thi seem hyperparamet grid search problem iron model like cart decis tree good result data supervis binari classif random forest produc even better data small mean contain around nmbr column nmbr nmbr row data doe anyon know routin written e g tensorflow kera assist problem decid number layer number neuron is ground rule decid mani layer mani neuron begin is someth around intellig point right direct mani neuron layer choos
Unreasonable_Energy,MachineLearning,1618961433.0,Do we already have the ML technology to make eye contact work better in video chat? [D],the problem in video chat make eye contact imag convers partner eye appear screen eye point camera thu appear partner make eye contact appear look offset direct relev xkcd http xkcd com nmbr a solut principl if multipl camera array edg screen say nmbr nmbr webcam around edg screen instead nmbr seem like possibl machin learn magic combin multipl camera feed come slightli differ vantag point singl feed virtual vantag point within convex hull physic camera point somewher middl screen then need abl automat locat imag convers partner eye within screen basic solv problem i understand set virtual vantag point one eye imag point voila make eye contact screen imag actual see screen imag appear make eye contact if would easi alreadi exist do machin learn technolog alreadi make realiti is somebodi alreadi the potenti hurdl immedi come mind nmbr learn virtual vantag point transform would hard mayb i pretti sure i alreadi seen impress demonstr vantag point shift would requir i certainli enough understand specialti know i though mayb hard nmbr take long appli vantag point transform real time induc unaccept lag ye process need happen real time happen local machin virtual vantag point feed costli transmit network standard video feed i imagin appli local could pretti fast alreadi seem superfici impress video transform appli real time face contour etc nmbr requir non standard hardwar setup sure like realli expens difficult one coupl extra webcam could doesn work mobil everyth nmbr nobodi care problem enough work i suspect surprisingli larg gain make video chat littl less uncanni mayb gain small worth effort i appreci thought feasibl scheme machin learn perspect
triplehelix_,MachineLearning,1618407205.0,[D] [R] AI/ML colorisation versus actual color photos from between 1909 and 1915,
mate_classic,MachineLearning,1617894376.0,[D] State of Deep Learning outside CV and NLP,comput vision natur languag process get limelight deep learn world right but someon work anoth field fell deep learn hype i often see problem direct equival cv nlp nevertheless peopl tri adopt success method field thi sometim lead result meaning research take time adapt method properli field often dataset much smaller sampl part group e g step time seri there enough paper one part time seri put train part test set i wrote blog post http krokotsch eu research nmbr nmbr nmbr one eye data scientist html one problem field predict mainten lead whole line research astray so question would state dl field cv nlp suffer blindli copi approach
vulnerablebeast,MachineLearning,1618978908.0,[P] Is it possible to use a loss function involving one input and multiple ground truths,instead optim say f x _groundtruth _i _predict _i can take averag ground truth say f x _groundtruth _i nmbr _predict _i _groundtruth _i _predict _i nmbr ha done thank
bert4QA,MachineLearning,1618589144.0,[R] Privacy-Adaptive BERT for Natural Language Understanding,
hardmaru,MachineLearning,1617713905.0,[R] MobileDets: Searching for Object Detection Architectures for Mobile Accelerators.,
mihirkarkare,MachineLearning,1617327641.0,[D] Churn prediction using ML,what would good way defin churn analys behavior custom use revolv credit if credit card compani want retain revolv credit custom would good strategi attack problem use ml in situat term churn littl difficult defin use revolv month two complet natur indic custom made mind stop use revolv credit
Caffeinated-Scholar,MachineLearning,1619202533.0,[R] FIERY: Future Instance Prediction in Bird's-Eye View from Surround Monocular Cameras,
sl2085,MachineLearning,1616794332.0,[D] What type of machine learning can be used to solve timetable optimisation problems?,i realli think tradit oper research relat techniqu linear program success techniqu peopl use solv timet optimis problem
Competitive-Net-5306,MachineLearning,1617836999.0,[P] About a ML agent for the game Slay the Spire that I've been making,hi i recent work make setup i would abl train test machin learn agent tcg roguelik game call slay spire i like share process current statu project i receiv feedback improv mayb help other face problem similar i went for project i solv follow problem nmbr establish connect game process least mimic someth similar nmbr find way design model capabl make differ type decis differ format input depend game state the model must abl handl differ task rang select card reward choos whether throw potion particular enemi would benefici nmbr find way properli reward model nmbr run much game possibl parallel given moment time the first problem prove lot easier i expect there alreadi mod call commun mod practic solv problem moment i discov it allow connect commun game process arbitrari extern python script stdin stdout i fiddl make work afterward i good go second problem bit tricki i quit happi i solv i divid game distinct situat requir distinct format input make distinct type decis then i made neural network everi singl one i shake feel might effici way i still noob the way i solv second problem made solv third problem bit difficult i train one singl net collect net togeth play game tri predict benefici play action situat would i howev abl solv follow process nmbr add one extra net collect net whose purpos predict much score ai would get end game base perfect snapshot current situat nmbr while agent play game creat snapshot set moment game record everi decis made snapshot nmbr when game assign label everi snapshot creat game score equal got game nmbr train snapshot net label nmbr label everi decis point snapshot _score snapshot _score nmbr train net label the fourth problem tricki enjoy one solv as know data usual better machin learn my data gener train agent actual play game i could make agent play game simultan i would get data to howev i abl launch run multipl game i abl achiev use virtual machin basic i would creat virtual machin worker node actual run game make game commun local python script would establish socket connect main machin actual run agent but one catch i enough comput resourc larg scale my solut googl comput engin cloud platform each instanc virtual machin connect internet almost perfect use howev put gpu instanc practic due cost without game run abysm slow due render issu i solv make small mod game appli bytepatch code disabl render call main loop it surprisingli easi due game written java howev i still run game cli requir window manag and i want autom process without open desktop worker node manual travers gui launch game the solut problem prove decept simpl just attach command gnome session properti start automat fire game then use ssh connect open new gnome session done cli bash script when thing requir reset i could close gnome session also done via cli start back that
cvpy,MachineLearning,1616342349.0,"[P] Face make up powerd by deep learning | change color of lips, eyes and eyeglasses",
StandardDull3128,MachineLearning,1617116497.0,[Discussion] Can I use CNNs to solve this problem?,what intuit experi expertis tell would i abl train cnn solv binari classif problem describ expect high accuraci let say nmbr the problem predict whether imag contain one type textur class nmbr contain sever textur clear border among class nmbr the data the data high resolut nmbr centimet pixel agricultur imageri obtain via remot sens drone imag so pictur depict differ crop weed road soil bush etc i would feed model squar imag nmbrxnmbrpx nmbrxnmbrpx exampl imag neg class nmbr po class nmbr http imgur com gnkbnca http imgur com gnkbnca
xiikjuy,MachineLearning,1618403267.0,[D] Is captioning a reasonable way towards explainable AI?,take video classif exampl someon may visual spatial tempor attent mask way explain ai focus see if i add video captain function top video classif model thu test video class predict associ sentenc and check sentenc gener sens ai mind make predict doe make sens relat publish work kind idea
mfilion,MachineLearning,1618933040.0,[Project] Continuous 3D Hand Pose Tracking using Machine Learning & Monado OpenXR,as part project back invest ai program manag ivado lab collabora develop multi stage neural network base solut accur locat track hand despit complex background nois occlus hand our system estim nmbrd nmbrd joint locat without depth inform collabora also current work integr monado xr codebas use box differ devic http www collabora com news blog blog nmbr nmbr nmbr continu nmbrd hand pose track use machin learn monado openxr http www collabora com news blog blog nmbr nmbr nmbr continu nmbrd hand pose track use machin learn monado openxr
bjourne-ml,MachineLearning,1617774303.0,[P] Music generation using tracker music in MOD format,link http modmusicgen com hi i work project gener music use neural network train tracker music mod format the tracker music convert simpl intern format make amend train convert midi sound like piano music tracker music i would much appreci time fill prefer survey also question project i tri answer thread
techsucker,MachineLearning,1617636798.0,[R] Researchers From the University of Toronto and LG AI Research Develop ‚ÄòExplainable‚Äô Artificial Intelligence (AI) Algorithm,a team research univers toronto lg ai research develop explain artifici intellig xai algorithm the algorithm help identifi elimin defect display screen the algorithm outperform compar approach industri benchmark develop ongo ai research collabor lg univers toronto accord research xai algorithm could appli field primarili requir detail machin learn make decis includ data interpret medic scan summari http www marktechpost com nmbr nmbr nmbr research univers toronto lg ai research develop explain artifici intellig ai algorithm http www marktechpost com nmbr nmbr nmbr research univers toronto lg ai research develop explain artifici intellig ai algorithm paper http arxiv org pdf nmbr pdf
koolaidman123,MachineLearning,1619518931.0,Visformer: The Vision-friendly Transformer,
yusuf-bengio,MachineLearning,1620636756.0,[D] Recent MLP-only architectures plagiarize J√ºrgen Schmidhuber,hi group first show simpl mlp architectur achiev state art perform comput vision benchmark given strong enough data augment nmbr nmbr moreov work pioneer use committe e techniqu popular term mixtur expert howev recent fuzz mlp architectur fundament contribut even worth singl sentenc he simpli cancel nmbr better digit recognit committe simpl neural net meier cire gambardella schmidhub nmbr pdf http peopl idsia ch juergen icdarnmbrb pdf nmbr handwritten digit recognit committe deepneur net gpu cire san meier gambardella schmidhub nmbr pdf http arxiv org pdf nmbr pdf
NeitherBandicoot,MachineLearning,1616955264.0,[D] Why some major papers in ML aren't peer-reviewed?,i littl bit outsid come life scienc field i notic major public field ml peer review strike unusu given field paper peer review good blog post i understand need publish asap research field move fast preprint exist reason could somebodi explain peer review appear priorit ml research i tri critic way work i puzzl confus i use see edit took exampl repres question comment suggest
upulbandara,MachineLearning,1619204466.0,[D] How to extend a text classification ML model to work with more than one language?,we use product ml text classif we train model use custom english text corpu current model work accept level accuraci purpos now want extend handl french languag well we plan investig follow two approach nmbr we french languag corpu therefor would like train new model handl french text nmbr use model train english corpu but use third parti languag translat servic googl translat translat french text english input ml model so i would like know thought regard two approach
MediocreMinimum,MachineLearning,1617017494.0,[D] What will the major ML research trends be in the 2020s?,we enter new decad hurrah what think next nmbr year bring ml research what convent accept trend think happen e g will deep learn continu eat everyth will multi task multi domain learn make shot learn avail domain or deep learn slow end sigmoid curv will safe ethic explain ai rise hogwash will advanc decoupl comput power will gari marcu judea pearl win symbol structur causal war deep learn are still major breakthrough languag do finetun gpt nmbr will make big breakthrough theori fundament ml or decad applic healthcar final deploy model beat logist regress
PhYsIcS-GUY227,MachineLearning,1619445711.0,"[P] Integrating Git, DVC, and MLflow into one",hey r machinelearn i one creator dagshub http dagshub com i want share someth cool work dvc dvc org http dvc org mlflow mlflow org http mlflow org two open sourc project wide adopt specialti dvc excel data version mlflow use mani thing actual multipl tool combin one mainli experi track capabl both tool built tradeoff sinc open sourc set storag dvc central track server mlflow pain requir creat cloud account add permiss dagshub alreadi integr dvc sens whenev creat project come free built dvc remot sinc last week also get free mlflow server mean log experi directli dagshub share team colleagu http redd edvlunmbrxivnmbr gif whi i think awesom nmbr zero setup add mlflow remot server uri log experi nmbr access control built team peopl need access view experi log new one easili control nmbr better ui comparison one complaint mlflow user inabl compar run across experi mlflow dagshub easili possibl run appear singl list filter fit singl experi nmbr integr mlflow dvc lot peopl work system build ad hoc system integr integr creat project built type work integr tool need here detail blog post http dagshub com blog launch dagshub integr databrick mlflow engin built i love hear thought
mildlyoverfitted,MachineLearning,1618130003.0,[P] Growing Neural Cellular Automata - Implementation and explanation,hey i made video i tri explain implement articl grow neural cellular automata it nich topic howev i find fascin hope could find use origin articl http distil pub nmbr grow ca http distil pub nmbr grow ca my video http youtu nmbracbwofnmbroo http youtu nmbracbwofnmbroo
temakone,MachineLearning,1617020121.0,[R] Swin Transformer: New SOTA backbone for Computer Visionüî•,swin transform new sota backbon comput vision ms research asia what new vision transform architectur call swin transform serv backbon comput vision instead cnn whi there two main problem usag transform comput vision nmbr exist transform base model token fix scale howev contrast word token visual element differ scale e g object vari size scene nmbr regular self attent requir quadrat imag size number oper limit applic comput vision high resolut necessari e g instanc segment the main idea swin transform nmbr hierarch featur map level hierarchi self attent appli within local non overlap window the size window progress increas network depth inspir cnn thi enabl build architectur similar featur pyramid network fpn u net dens pixel level task nmbr window base self attent reduc comput overhead overal architectur consist repeat follow block split rgb imag non overlap patch token appli mlp translat raw featur arbitrari dimens appli nmbr consecut swin transform block window self attent block window size second block use shift patch _size nmbr window allow inform flow non overlap window downsampl layer reduc number token merg neighbor patch nmbrxnmbr window doubl featur depth http preview redd xtjhyflalypnmbr png width nmbr format png auto webp bnmbrfnmbrbnmbrenmbrbanmbrenmbrffnmbrcnmbrd http preview redd znmbrznmbrycclypnmbr png width nmbr format png auto webp nmbrenmbrbnmbrbnmbrfbnmbrdanmbrbenmbrbnmbrdanmbrbacdnmbrbnmbrdcnmbr result outperform sota signific margin coco segment detect task adenmbrk segment compar accuraci efficientnet famili imagenet nmbrk classif faster http preview redd giwnmbrnznmbrdlypnmbr jpg width nmbr format pjpg auto webp dnmbrebnmbrenmbrddnmbreenmbrenmbrcnmbrdnmbrfbnmbrdnmbrbnmbra conclus while transform super flexibl research start inject transform induct bias similar cnn e g local connect featur hierarchi and seem help tremend paper http arxiv org ab nmbr http arxiv org ab nmbr code promiss soon http github com microsoft swin transform http github com microsoft swin transform tl dr blogpost http xzcode github io post paper review swin transform http xzcode github io post paper review swin transform join telegram channel gradient dude http gradientdud miss latest post like http gradientdud http gradientdud
Kaleidophon,MachineLearning,1616769467.0,[P] deep-significance: Easy and Better Significance Testing for Deep Neural Networks (link below),hey recent i becom somewhat frustrat ml dl paper highlight score stem singl run result tabl claim approach superior outperform other margin thi i implement test packag statist signific test propos dror et al nmbr specif tailor toward neural network i also ad inform statist signific test appli mention test common scenario face ml practition http github com kaleidophon deep signific http github com kaleidophon deep signific i happi receiv feedback commun improv help move field forward
cloud-native,MachineLearning,1616368252.0,[D] How would you migrate a DS team from HPC cluster to the cloud,i want ask could point resourc success move ds team cloud could share experi team compani i work team nmbr old school analysi folk stat natur scienc background need move prem setup microsoft azur we research team ml research domain specif research use hpc ssh connect vscode easili use dask run distribut process via slurm unix filesystem etc what best cloud setup team what peopl research organ big tech compani give ds team member freedom run comput instanc want run pool comput instanc ds team ssh run kubernet cluster use ak use azur ml offer even though much ml someth els we reli heavili cli tool vscode jupyt solut option us ani pointer would greatli appreci
yusuf-bengio,MachineLearning,1616767299.0,[D] Dilemma: Mathematically wrong ICML submission got extremely good reviews,i tangenti involv icml submiss research group differ institut after initi review i realiz main theorem work base mathemat object wrong for anyon work subfield find counterexampl violat theorem pretti straightforward howev none review found error theori even prais paper high score definit accept as i involv work begin e g lay idea roadmap i never thoroughli read theoret part paper submiss the proof exploit subtl differ two definit concept older vs newer literatur moreov final paper use grandios mathemat notat make error harder spot in opinion even appear choic mathemat write style use conflict definit made deliber the problem though i interven pi read beyond abstract phd student respons proof known narcissist tendenc piss i want risk career pi quit bigshot field student extrem well connect fang compani best friend top nmbr research i think i quit worst thing happen research realiz error publish counter paper disprov furthermor i feel i one particular kind dilemma doe anyon experi situat like mine updat thank feedback situat as mani suggest i wrote discuss counterexampl co author dure discuss i realiz three thing nmbr come counterexampl see violat main claim straightforward i origin thought it took even student wrote proof quit realiz might issu nmbr the student pi still convinc correct main theoret result cite good review addit evid claim correct their main argument proof use primarili exist theorem literatur correct reformul mathemat express thu someth wrong claim must come theorem proven literatur alreadi wrong nmbr the submiss withdrawn icml co author intend chang paper
Rokossowsky,MachineLearning,1618739918.0,[D] In what order should one read self-driving related papers?,hi i read book dl self drive i like delv paper i found list http paperswithcod com task autonom drive http paperswithcod com task autonom drive should i go top rate first would guy suggest logic order understand thing thank rokossowski
kakushka123,MachineLearning,1618324760.0,[D] How is Tesla autopilot trained?,i listen podcast howev i sure i understood correctli to understand big nn anyon know architectur train scratch everi releas set milion imag handchosen human evolv time e g imag taken taken base interact model fleet car like human correct etc is correct
Sirisian,MachineLearning,1619820302.0,[R] DINO and PAWS: Advancing the state of the art in computer vision with self-supervised Transformers,http ai facebook com blog dino paw comput vision self supervis transform nmbrx effici train http arxiv org ab nmbr http github com facebookresearch dino http arxiv org ab nmbr http github com facebookresearch suncet the dino research show model automat learn class specif featur lead unsupervis object segment paw method semi supervis learn build principl self supervis distanc metric learn paw pre train model minim consist loss ensur differ view unlabel imag assign similar pseudo label
TheHentaiSama,MachineLearning,1620115041.0,[Discussion] Model to predict a class for a signal based on simpler signals,hello everyon i work someth i struggl find good solut to make simpl let say i origin signal compos simpler signal i make predict simpler signal use model random forest classifi i need make predict origin signal the problem signal compos number simpler signal impact final result i tri simpl method consist major vote make predict simpl signal decid class origin signal major vote result bad so question anyon know model handl task know litteratur could help thank advanc
schienal,MachineLearning,1618586669.0,[N] Probabilistic ML @ T√ºbingen is restarting!,http www youtub com watch v ubavgdnmbrlfi list plnmbrumpnmbrrnmbrijnmbrthaofynmbrmnmbruxnmbrjnmbranmbrynd http www youtub com watch v ubavgdnmbrlfi list plnmbrumpnmbrrnmbrijnmbrthaofynmbrmnmbruxnmbrjnmbranmbrynd is anyon think start discord server studi along cours pace
NominalNom,MachineLearning,1619809526.0,[D] A recent history of my pointless stare down with Nvidia which I lost,just quick comic summari experi tri get gpu sinc prior launch amper card i work film post product i prior deep learn code experi i want gpu lot memori process high re imageri exist tensorflow base open sourc toolset i could figur use small amount python experi i secur titan rtx amazon retail price i decid return i found immin releas amper card nmbr sound lot better nmbr of cours nmbr go around price nmbrk rrp i paid rtx titan i naiv exact moment fact crypto mine go go back full swing although i warn someon sub i expect eth proof stake cancel yet besid avail issu also size nmbr nvidia seem intentionali made huge fit typic deep learn rig graphic workstat no problem i get third parti blower card i find one stock whoop nvidia kill alright i look one rinki dink third parti rgb gamer card suffici low profil i need one card nmbrgb vram okay sold forev get one may expens previou titan so mayb best get anmbr anmbr tbh seem like go rrp make huge step inflat nmbr price better support linux imo i found lhr card though ship soon but also may nmbr lhr seem like suppli necessarili improv there proprietari gui base toolset develop use pytorch back end but still recommend nmbrgb realli want memori wise without need slice input imag much issu go anywher i manag get nmbr super nmbrgb interim card realli bare minimum it also comic much card go i glad i snag one last one best buy nmbr rrp last year
vishnu_subramaniann,MachineLearning,1616496654.0,"[P] Jarvislabs.ai - An Affordable GPU Cloud with Fast launch, Pause and Resume. Scale GPUs post creation. A100/RTX6K/RTX5K",for last year i learn practic deep learn particip sever kaggl competit medal dure year i tri sever cloud platform premis system some offer simplic flexibl afford but none offer one platform after struggl differ platform i know i would need dl research that gave birth jarvislab ai http jarvislab ai aim simpl afford i along friend start work project year back due covid execut project becam challeng as first time entrepreneur underestim complex problem hand persist abl launch beta version product decemb nmbr with amaz feedback earli adopt abl make product smoother we would love invit come tri platform featur nmbr nmbr click jupyt lab nmbr second nmbr paus instanc resum left nmbr ssh instanc nmbr scale gpu storag chang gpu type resum nmbr auto paus use jarviscloud paus code catch good night sleep model train nmbr pay per usag minut bill after first nmbr minut nmbr competit price lowest knowledg price gpu type gpu ram price hr rtx nmbr nmbr gb nmbr rtx nmbr nmbr gb nmbr anmbr nmbr gb nmbr talk us we happi assist spin first instanc mani you use one platform reach us nmbr chat option cloud jarvislab ai nmbr email us hello jarvislab ai mailto hello jarvislab ai nmbr comment we come long way understand lot done we list upcom product featur http github com jarvislabsai jarviscloud chitchat discuss deep learn ai evolv would use cloud platform could evolv come year understand develop open constantli keep touch user pleas help us shape jarvislab ai http jarvislab ai valuabl suggest feedback
olegranmo,MachineLearning,1618557871.0,[Research] Tsetlin Machine Interpretability and Accuracy in NLP Significantly Boosted Using GloVe Synonyms,tsetlin machin boolean bag word boost glove synonym http preview redd nmbrjsnmbrwbbnmbrlhtnmbr png width nmbr format png auto webp nmbrdnmbrfnmbrbfenmbrabaadnmbrafnmbrbcnmbrfnmbrcnmbrdnmbrfnmbrcnmbr by use glove obtain synonym enhanc boolean bag word use tsetlin machin nlp the ad synonym help tsetlin machin produc fewer semant power rule boost accuraci nmbr thi make transpar interpret rule competit deep learn base nlp model http arxiv org ab nmbr http arxiv org ab nmbr
cents_less,MachineLearning,1618511530.0,[P] Announcing Feast 0.10: The simplest way to serve features in production,hey folk over last two year work open sourc featur store call feast the idea behind feast help operation featur mean help build train dataset offlin featur help load featur onlin store structur way provid low latenc access featur product the origin design feast heavi weight you need run big stack kubernet spark we chat bunch user one thing kept hear saw valu feast production data heavi weight so put lot energi toward realli simplifi feast we made easi pip instal you run feast local get start develop test also deploy cloud provid like gcp want someth scalabl we love download tri project we got slack workspac join get involv ask question also hate star github either announc http feast dev blog feast nmbr nmbr announc http feast dev blog feast nmbr nmbr announc web site http feast dev http feast dev github http github com feast dev feast http github com feast dev feast slack http slack feast dev http slack feast dev
ottawalanguages,MachineLearning,1618970325.0,"[D] ""no free lunch"" vs neural networks",i read theorem call free lunch theorem state singl algorithm better algorithm thi somewhat obviou complex algorithm perform better complex problem simpler algorithm perform better simpler problem thi said neural network base algorithm accept main type algorithm solv complex real world problem apart simpl answer observ simpli perform better problem look neural network e g mlp lstm cnn reffer mathemat properti neural network could attribut success whi use neural network instead regress model from certain prespect neural network defi free lunch theorem
Andrew_the_giant,MachineLearning,1618067692.0,[D] SARIMAX - Achieving Stationarity first?,newbi forecast havn abl find answer question yet thi question relat arima type model if i use hyper paramet grid search find best pdq pdq paramet i need differ dataset first or use paramet model achiev stationar assum i use correct paramet
pcaversaccio,MachineLearning,1617613213.0,[R] Dodrio: Exploring Transformer Models with Interactive Visualization,
DaBeastGeek,MachineLearning,1616594581.0,"[D] What are some non transformer based, NLP models?",just curiou well regard model reli transform i look someth prefer small paramet wise test edg devic lot state art thing i see huge even smallest model albert someth like nmbr million param ani help much appreci
PM_ME_UR_FAV_THINGS,MachineLearning,1619476926.0,"[D] Open Source Nudity/NSFW Classification Review, any suggestions?",hello i review open sourc model nuditi nsfw content classif label doe anyon recommend project worth check i googl alreadi i hope might know nich
othotr,MachineLearning,1616651494.0,[R] Minimum-Distortion Embedding,
du_dt,MachineLearning,1618371964.0,[D] Internship at Huawei - your experience?,have internship huawei particular ml research posit what experi would recommend friend huawei activ expand late particular canada top nmbr r d spend link http www newswir ca news releas huawei canada rank nmbrth overal corpor r amp spend canada nmbr html seen lot intern posit activ hire what experi huawei cheer
ykilcher,MachineLearning,1617114145.0,"[D] Machine Learning PhD Survival Guide 2021 (Video) | Advice on Topic Selection, Papers, Conferences & more! - by Yannic Kilcher",http youtu rhqpbqmulxo http youtu rhqpbqmulxo hi everyon let know think thi video advic new phd student field machin learn nmbr the field shift dramat last year navig grad school hard especi clueless i i start the video person recount mistak i learn if alreadi sever publish paper know video howev even sure start select topic goe paper might benefit video exactli i felt main takeaway select nich topic rather hype topic write paper reject don discourag bad review take review teach serious keep focu confer network internship great opportun team complementari skill don work hard outlin nmbr nmbr intro overview nmbr nmbr thesi topic select nmbr nmbr how to publish paper nmbr nmbr deal with review nmbr nmbr how to be a review nmbr nmbr take teach serious nmbr nmbr maintain focu nmbr nmbr navig confer nmbr nmbr internship nmbr nmbr collabor nmbr nmbr don forget to enjoy transcript http www notion yannic kilcher phd surviv guid transcript cnmbrabnmbrenmbrenmbrfbbnmbrcdfdbnmbrdnmbra http www notion yannic kilcher phd surviv guid transcript cnmbrabnmbrenmbrenmbrfbbnmbrcdfdbnmbrdnmbra
sobe86,MachineLearning,1617750723.0,[D] Samy Bengio resigns from Google,sourc bloomberg http www bloomberg com news articl nmbr nmbr nmbr googl ai research manag sami bengio resign email staff archiv fo link http archiv fo yynmbrai n b sami yoshua bengio brother he co found googl brain co author origin torch librari he timnit gebru manag drama end last year he directli refer email today time voic support http www facebook com stori php story_fbid nmbr id nmbr shock happen in februari ethic ai group reshuffl cut sami respons http twitter com alexhanna statu nmbr reuter report http www reuter com articl us alphabet googl research bengio googl ai scientist bengio resign colleagu fire email iduskbnnmbrbtnmbrjt though mention fire farewel note influenc decis resign peopl familiar matter said speak condit anonym
KirillTheMunchKing,MachineLearning,1619877241.0,[D] An Image Is Worth 16X16 Words: Transformers For Image Recognition At Scale - Vision Transformers explained!,an imag is worth nmbrxnmbr word transform for imag recognit at scale http casual_gan nmbr in paper late nmbr author propos novel architectur success appli transform imag classif task the model transform encod oper flatten imag patch by pretrain larg imag dataset author abl show great result number smaller dataset finetun classifi top transform model more detail http casual_gan nmbr vit model architectur overview http preview redd nmbrknmbryszkiwnmbr png width nmbr format png auto webp nmbrenmbranmbrcnmbrfanmbrdnmbrdnmbrbnmbracnmbrfbenmbr nmbr minut paper explan http casual_gan nmbr arxiv http arxiv org ab nmbr
mippie_moe,MachineLearning,1618432999.0,[D] Lambda GPU Benchmark Center for Deep Learning,gpu benchmark machin learn http lambdalab com gpu benchmark thi ongo project lambda we continu add new gpu popular model releas suggest new model feedback would much appreci
hotpot_ai,MachineLearning,1617318941.0,[R][D] CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation,
ancientmooner,MachineLearning,1616904933.0,[R] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,transform make previous satur coco adenmbrk benchmark unblock it creat new sota coco adenmbrk coco det http paperswithcod com sota object detect coco nmbr map nmbr map coco inst http paperswithcod com sota instanc segment coco nmbr map nmbr map ade seg http paperswithcod com sota semant segment adenmbrk val nmbr miou nmbr miou thi paper present new vision transform call swin transform capabl serv gener purpos backbon comput vision challeng adapt transform languag vision aris differ two domain larg variat scale visual entiti high resolut pixel imag compar word text to address differ propos hierarch transform whose represent comput shift window the shift window scheme bring greater effici limit self attent comput non overlap local window also allow cross window connect thi hierarch architectur flexibl model variou scale linear comput complex respect imag size these qualiti swin transform make compat broad rang vision task includ imag classif nmbr top nmbr accuraci imagenet nmbrk dens predict task object detect nmbr box ap nmbr mask ap coco test dev semant segment nmbr miou adenmbrk val it perform surpass previou state art larg margin nmbr box ap nmbr mask ap coco nmbr miou adenmbrk demonstr potenti transform base model vision backbon arxiv http arxiv org pdf nmbr pdf code http github com microsoft swin transform
clint9smith,MachineLearning,1616875481.0,[Discussion] How to create a team recommender when team sizes can change,i tri use user item rate tripl svd recommend model user phase project item team rate team rate the issu i tri solv recommend team team size chang phase phase i could recommend role team separ user item rate tripl role person person _rate best team necessarili best person role put togeth
broutonlab,MachineLearning,1619605595.0,[D] How do you manage Data Science experiments?,we prepar overview http broutonlab com blog data scienc experi manag weight bias platform practic exampl googl colab http colab research googl com drive nmbrefnmbrynmbremyjelxlnmbrqnmbrrgwfpnmbrrsiaqykt usp share use w b platform manag experi what techniqu tool use manag data scienc experi work
petersonsass,MachineLearning,1618921963.0,[D] Why solving the vanishing gradients problem?,it often said recurr neural net vanish gradient problem but understand right the current hidden state less depend distant hidden state what wrong argument do realli want hidden state depend equal
legoonest,MachineLearning,1617351719.0,[P] VinDr Lab - an open-source annotation platform for Medical AI,depart medic imag vinbigdata decid releas dicom annot tool open sourc it call vindr lab it web base tool allow multipl annot work time remot thi softwar use build dataset kaggl competit http www kaggl com c vinbigdata chest xray abnorm detect follow releas larg scale dataset vindr cxr next contribut data share well tool ai develop we encourag commun promot data share tool drive ai research develop hope somebodi find use enjoy send feedback the tool publicli avail http github com vinbigdata medic vindr lab http github com vinbigdata medic vindr lab vindr lab dicom viewer http preview redd gyenmbrbnmbrvpqnmbr png width nmbr format png auto webp nmbrenmbrenmbrfnmbrfcnmbrfdnmbrfnmbrbnmbranmbradbanmbranmbrcnmbref
retro_var,MachineLearning,1619635905.0,[D] Books or Articles in Tree Based Methods with Formal Mathematics?,hi i search book articl explain tree base method random forest gradient boost etc extens mathemat theori background but similar book found classif regress tree brieman friedman nmbr http www amazon com es leo breiman dp nmbr i glad could recommend new inform thank
muzammal-naseer,MachineLearning,1617009271.0,[R] On Generating Transferable Targeted Perturbations,we studi strengthen target perturb otherwis featur neural network context transfer pattern one model anoth we broaden definit black box inform avail attack analyz transfer unknow target model unknow train mechan unknown decis space unknown input process http arxiv org ab nmbr http arxiv org ab nmbr all pretrain gener avail http github com muzamm naseer ttp http github com muzamm naseer ttp we also track progress transfer target attack within easi follow set result updat within day http github com muzamm naseer ttp track sota target transfer http github com muzamm naseer ttp track sota target transfer
Yuqing7,MachineLearning,1620402702.0,[R] MIT & IBM 'Curiosity' Framework Explores Embodied Environments to Learn Task-Agnostic Visual Representations,a research team mit mit ibm watson ai lab propos curiou represent learn crl framework learn understand surround environ train reinforc learn rl agent maxim error represent learner gain incent explor environ here quick read mit ibm curios framework explor embodi environ learn task agnost visual represent http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper curiou represent learn embodi intellig arxiv http arxiv org pdf nmbr pdf
pcaversaccio,MachineLearning,1617532776.0,[R] Labels4Free: Unsupervised Segmentation using StyleGAN,
TheRealMarqupe,MachineLearning,1620562851.0,CNNs Color Invariance [Discussion],we want detect specif object color exampl car if train model imag contain black gray car perform model predict wors imag contain car differ color one use train for exampl model fail classifi correctli car present imag imag contain yellow car if best way achiev color invari explan exampl credibl sourc refer would much appreci thank
prathameshpck,MachineLearning,1619130146.0,Is fine tuning twice a viable thing to do?? [D],don know right place ask goe say i dataset sampl manag find anoth dataset someth similar larger would make sens finetun twice e first second larger dataset fine tune smaller one
dDW5ia5j,MachineLearning,1617178321.0,"[P] Generic template to bootstrap your PyTorch project with PyTorch Lightning, Hydra, W&B, DVC, and Streamlit",link http github com lucmo nn templat gener opinion templat bootstrap pytorch project avoid write boilerpl code pytorch lightn lightweight pytorch wrapper high perform ai research hydra framework elegantli configur complex applic dvc track larg file directori ml model think git data weight bias organ analyz machin learn experi streamlit turn data script shareabl web app minut
NumiAI,MachineLearning,1616346275.0,[D] Barlow Twins: SSL via Redundancy Reduction,paper http arxiv org pdf nmbrvnmbr pdf http arxiv org pdf nmbrvnmbr pdf author jure zbontar li jing ishan misra yann lecun st√©phane deni thi recent publish work self supervis learn base simpl idea yet yield amaz result i like read paper got interest read barlow redund concept neurosci an interest fact i came across barlow public back nmbr revisit opinion redund reduct http preview redd sueixtaiweonmbr jpg width nmbr format pjpg auto webp nmbrdfcenmbrcnmbrbfdnmbrcanmbranmbrcnmbrfnmbranmbrfcnmbrc http preview redd tcnmbrjnmbrxpvweonmbr jpg width nmbr format pjpg auto webp nmbrfenmbrabnmbrenmbrabnmbrbcnmbrfnmbrdbnmbrdnmbr the author paper actual support idea redund reduct i understand barlow paper redund increas decreas i would like hear opinion appar conflict understand thank
l_atze_l,MachineLearning,1620032568.0,[P] MoViNet in PyTorch,tl dr implement movinet pytorch http github com atzenmbr movinet pytorch http github com atzenmbr movinet pytorch i current work video recognit i found movinet http arxiv org ab nmbr quit interest paper i decid implement pytorch sinc code releas tf author i use architectur code weight tf releas bug report comment use let know find incoher paper implement well i hope use someon
jj4646,MachineLearning,1619062368.0,"[D] decline of traditional ""state space models""",it seem recurr neural network overtaken tradit state space model time seri model is tradit state space model requir analyst make certain assumpt system transit differ state wherea recurr neural network consid wide combin state hidden layer deep architectur
igorsusmelj,MachineLearning,1616493351.0,[P] Release of lightly 1.1.3 - A python library for self-supervised learning,we releas new version lightli http github com lightli ai lightli valuabl feedback subreddit thought might interest updat lightli support model in addit simclr moco ad simsiam barlow twin big thank open sourc contributor more model byol swav pipelin we benchmark http doc lightli ai getting_start benchmark html cifarnmbr show variou framework action use differ train epoch batch size most model run well multi gpu setup use pytorch lightn distribut data parallel set we curiou hear feedback
chasep255,MachineLearning,1617563283.0,[D] Why not use momentum based optimizer with WGAN?,i keep read i use momentum optim wgan noth i read offer explan so i use momentum base optim anyon know reason
EscapedLaughter,MachineLearning,1620289418.0,[N] Music Demixing (Audio Source Separation) Competition by Sony | ISMIR 2021,the competit http www aicrowd com challeng music demix challeng ismir nmbr utm_sourc reddit utm_medium ml utm_campaign soni featur nmbr baselin open unmix code http github com sigsep open unmix pytorch paper http www theoj org joss paper joss nmbr nmbr joss nmbr pdf http www theoj org joss paper joss nmbr nmbr joss nmbr pdf crossnet umx code http github com soni ai research code tree master x umx paper http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf the competit hope serv benchmark variou sourc separ model particip get togeth ismir workshop share learn soni also offer nmbr nmbr chf cash prize top particip leaderboard exampl http dnmbrcowzsnmbrinmbrn cloudfront net music demix http reddit com link nnmbrhli video tnmbrorzhnmbrrmgxnmbr player ps thi first post subreddit i transgress norm i apolog
Hi_I_am_Desmond,MachineLearning,1620404887.0,"[D] In Quantum NNs, are the hybrid optimization methods run on classical hardware?",i read mani resourc sinc i know anyon field i start research i hope i find someon work quantum machin learn while mani approach consid common base quantum circuit learn mitarai et al suppos use hybrid hardwar optim comput classic hardwar what exampl quantum hardwar can link paper make clear distinct hardwar run qnn
PK_thundr,MachineLearning,1619199060.0,[D] How to develop a compelling argument for a paper submission?,i work certain loss function train dnn unfortun result mediocr sota match sota how go process develop compel argument paper simpl set experi accuraci result increment progress alreadi done field i realiz depend greatli actual work kind gener guid principl
CoolThingsOnTop,MachineLearning,1617471222.0,[D][R] Blog Post: Why Are Kronecker Products So Effective?,thi week list iclr nmbr outstand paper announc one award paper beyond fulli connect layer quaternion parameter hypercomplex multipl nmbr nnmbr n paramet http openreview net forum id rcqdyclnmbrzyk make use kroneck product build new kind nn layer i look kroneck product pleasant surpris find paper list winner so i decid write blog post point interest connect previou work let know think blog post http santiagnmbrm github io blog nmbr nmbr nmbr kroneck product effect html http santiagnmbrm github io blog nmbr nmbr nmbr kroneck product effect html
antiquark2,MachineLearning,1618348607.0,"[D] Could this network be used to generate the most attractive image possible? What would it look like... -""ComboLoss for Facial Attractiveness Analysis with Squeeze-and-Excitation Networks""",
No_Effective7572,MachineLearning,1619626129.0,[P] Semi Supervised Segmentation on Graphs using Eikonal Equation with PyOpenCl backend.,hey guy i would like share project http github com agitoz semi supervis segment graph http github com agitoz semi supervis segment graph it segment graph it applic imag pointcloud it run time depend eikon equat graph eikon equat use creat gener distanc manifold classic equat solv use fast march method a time depend eikon equat steadi coincid fast march solut basic i creat knn graph gpu backend use pyopencl i run pde gpu backend i hope find interest
shuvob4,MachineLearning,1618401627.0,[R] Drug Target Interaction research using Machine Learning,i comput scienc graduat aim pursu master machin learn as i thesi undergradu i would like know inform research i hope find guidanc post i highli interest healthcar machin learn after scour internet i found drug target interact topic interest but dig littl deeper i found middl sea view land i read paper i found i understand thing describ field i domain knowledg should i seek anoth topic if someon guid topic i look i read paper i understand topic better thank advanc nice day
hardmaru,MachineLearning,1617802883.0,[R] Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences,recent paper fair publish pna http www pna org content nmbr nmbr enmbr they find biolog structur function emerg represent languag model train massiv databas protein sequenc summari learn biolog properti sequenc data logic step toward gener predict artifici intellig biolog here propos scale deep contextu languag model unsupervis learn sequenc span evolutionari divers we find without prior knowledg inform emerg learn represent fundament properti protein secondari structur contact biolog activ we show learn represent use across benchmark remot homolog detect predict secondari structur long rang residu residu contact mutat effect unsupervis represent learn enabl state art supervis predict mutat effect secondari structur improv state art featur long rang contact predict abstract in field artifici intellig combin scale data model capac enabl unsupervis learn led major advanc represent learn statist gener in life scienc anticip growth sequenc promis unpreced data natur sequenc divers protein languag model scale evolut logic step toward predict gener artifici intellig biolog to end use unsupervis learn train deep contextu languag model nmbr billion amino acid across nmbr million protein sequenc span evolutionari divers the result model contain inform biolog properti represent the represent learn sequenc data alon the learn represent space multiscal organ reflect structur level biochem properti amino acid remot homolog protein inform secondari tertiari structur encod represent identifi linear project represent learn produc featur gener across rang applic enabl state art supervis predict mutat effect secondari structur improv state art featur long rang contact predict paper http www pna org content nmbr nmbr enmbr
Artistic-Mushroom974,MachineLearning,1617240597.0,[d] Robotics/ AI PhD Salary Expectations for T1.5 School,i junior first year phd student robot ai gtech cs rank ai robot put gtech nmbr us http csrank org index ai vision mlmine nlp ir robot us http csrank org index ai vision mlmine nlp ir robot us i seen post nmbr nmbrk total comp post ml ai phd big tech fintech i also seen caveat like top nmbr mit stanford cmu berkeley school phd http www reddit com r machinelearn comment bwwmhnmbr _do _a _phd _i _not _worth _it _unless _except http www reddit com r machinelearn comment bwwmhnmbr d_doing_a_phd_is_not_worth_it_unless_except so question realist salari expect next coupl school top nmbr are much wors top nmbr do i still good prospect nmbr nmbrk offer would low mid high rang also prospect i take master rather finish full degre for context mani lab school fair outstand amount top confer public iclr neurip icml corl icra and money reason i chose rout i lot curios possibl ai demand difficult work
_Arsenie_Boca_,MachineLearning,1620455301.0,[D] Worth learning JAX?,recent popular paper vit start use jax implement model i mainli use pytorch past i play thought learn tensorflow i alway felt like tensorflow lot legaci code convent make kinda unneccessarili complic compar pytorch nmbr now googl seem shift jax intern think jax replac tensorflow nmbr and regardless worth learn jax nmbr if would learn jax higher level api compar torch nn would use like stax flax haiku
memgamemotron,MachineLearning,1617048073.0,[P] Need help figuring out how to print out the sentence and sentence predictions from my google trax neural network model.,begin project i help school gain experi i taken plenti deeplearn ai http deeplearn ai cours help build code foundat the data chat bot provid chat text angri label happi label go feed model http preview redd iyonmbrsgfgonmbrqnmbr png width nmbr format png auto webp nmbrdnmbrafnmbrbnmbrbeenmbrefnmbrfnmbr next data preprocess includ split data nmbr nmbr train evalu http preview redd qknmbrdnmbrinmbrwonmbrqnmbr png width nmbr format png auto webp nmbrbnmbrenmbrcnmbrcbanmbrbnmbrfnmbrfnmbraacnmbr the i preprocess text remov special charact space stop word token text like http preview redd kynmbrfnmbrnruqnmbrqnmbr png width nmbr format png auto webp fnmbrfanmbrbacnmbranmbracdnmbrenmbrenmbrfnmbrc next i build vocab list like http preview redd qnmbrfnxnmbrbnmbrrnmbrqnmbr png width nmbr format png auto webp nmbraddenmbrddnmbrfdnmbrfanmbrenmbrbnmbrabnmbrcnmbr then creat pad tensor sentenc http preview redd nmbrmnmbrvanmbrvrnmbrqnmbr png width nmbr format png auto webp dnmbrbnmbrfenmbrdanmbrenmbrdenmbrdcnmbrfbbnmbrdanmbrdnmbrc afterward creat data gener appli train evalu http preview redd nmbrmzlnmbrytisnmbrqnmbr png width nmbr format png auto webp nmbrbnmbrfnmbranmbrcnmbrdnmbrenmbrfnmbreenmbr http preview redd nmbrfnmbrmnmbrksnmbrqnmbr png width nmbr format png auto webp nmbranmbraanmbrenmbrenmbrenmbreaenmbrfcnmbrdenmbrdnmbrcnmbr http preview redd xknmbrunmbrrrlsnmbrqnmbr png width nmbr format png auto webp dnmbrbnmbrcnmbrfnmbrbfnmbrenmbrfnmbrfnmbrfnmbranmbr http preview redd thqavnmbritsnmbrqnmbr png width nmbr format png auto webp nmbrfnmbreanmbrfafdnmbrdeanmbrednmbranmbrbdnmbr http preview redd wnmbrdnmbryxsnmbrqnmbr png width nmbr format png auto webp nmbrcdbnmbrdbfdfnmbrfnmbradfnmbranmbrcnmbraenmbrf i start creat layer forward propag one layer next neigh relu activ function http preview redd hbnmbrczcgftnmbrqnmbr png width nmbr format png auto webp nmbredfbnmbranmbrbnmbrfenmbrcanmbrenmbrcanmbrdbnmbrenmbrenmbrecbf defin dens layer http preview redd rfysjtnmbrptnmbrqnmbr png width nmbr format png auto webp nmbrfnmbrcnmbraefdeanmbrbecnmbrcfnmbrbnmbrfbd http preview redd mmkspnmbrqtnmbrqnmbr png width nmbr format png auto webp nmbrcnmbrfnmbrdnmbrdbnmbrbnmbrenmbraenmbrbaenmbrfnmbr the next step defin model use trax combin layer http preview redd nmbrgnmbrcnmbracunmbrqnmbr png width nmbr format png auto webp anmbrbnmbraecefnmbrenmbrdenmbrafnmbrbnmbref http preview redd nmbrswtlcnmbrdunmbrqnmbr png width nmbr format png auto webp nmbrfnmbrcnmbrfnmbrbnmbrdcfenmbrfacnmbrbdnmbrbdefebnmbrab i creat train evalu loop help us understand model perform http preview redd pnmbrpnmbrghyiunmbrqnmbr png width nmbr format png auto webp nmbrfenmbranmbrcnmbrdnmbrbfnmbrdnmbrabdnmbranmbrcadnmbrdnmbrfenmbrcnmbr next check model accuraci i know pretti low current learn student look improv excit feedback help improv model http preview redd nmbrxcgvnmbrgnmbrvnmbrqnmbr png width nmbr format png auto webp nmbrenmbrabnmbrfbnmbranmbrenmbrfnmbrbfnmbranmbrbnmbrbnmbrenmbrednmbr http preview redd gnmbrhqesznmbrvnmbrqnmbr png width nmbr format png auto webp nmbreanmbranmbrbnmbrcfnmbranmbrenmbrfnmbrcnmbrdbnmbrdnmbr as see model perform nmbr the follow code i need help i tri print observ sentenc follow predict i tri get nmbr output predict angri happi label the purpos help understand custom either angri happi bot custom experi also identifi interfer need agent http preview redd kajgcwtwvnmbrqnmbr png width nmbr format png auto webp anmbrbnmbrcdnmbrdaanmbrcnmbrenmbrcnmbrcnmbrbbnmbr instead get nmbr predict label output look like i would greatli appreci help welcom ml mentor project thank look everyon wait hear
weifz,MachineLearning,1617781633.0,[D] How to define Pearl's causality in time series ?,hi recent i studi granger causal pearl causal i wonder way defin pearl causal time seri relationship granger pearl differ thank lot
PytonRzeczny,MachineLearning,1616604232.0,[D] Wasserstein GAN math,hi could you recommend resourc learn math includ wgan paper read think understand titl paper i want implement without know go loss function quit useless
AerysSk,MachineLearning,1619271507.0,"[D] ML researchers of Reddit, what qualifications do you seek in a research applicant that you have not met?",i third year undergradu cs student recent i appli research train role similar googl brain ai resid compani requir strong math program skill adequ english commun skill countri major languag english to surpris interview postdoc research top us univers i disclos seem like work compani the nmbr hour interview schedul next week met real life dear ml research qualif seek applic what question ask expect answer
bendee983,MachineLearning,1620405956.0,[R] AttendSeg: super-compact NN for semantic segmentation for edge devices,a new neural network develop research darwinai univers waterloo make possibl run semant segment resourc constrain edg devic key highlight model nmbr million param comparison refinenet nmbrm param precis reduc nmbr bit without signific compromis accuraci reduc size model nmbrmb refinenet nmbrmb attendseg use attent condens provid compact self attent the model gener use gener synthesi ml techniqu explor constraint space provid engin accuraci model size etc creat best model attendseg present cvpr june read stori interview u waterloo professor co author alex wong http bdtechtalk com nmbr nmbr nmbr attendseg deep learn edg semant segment http bdtechtalk com nmbr nmbr nmbr attendseg deep learn edg semant segment full paper http arxiv org ab nmbr http arxiv org ab nmbr
AleksanderPet,MachineLearning,1616496675.0,[R] MDMMT: Multidomain Multimodal Transformer for Video Retrieval,the research team lomonosov moscow state univers cooper intellig system data scienc lab moscow huawei r d center develop novel multi modal multi domain textnmbrvideo system outperform current state art result e g googl facebook wide use public dataset msr vtt lsmdc video retriev task paper http arxiv org ab nmbr http arxiv org ab nmbr comparison paperwithcod other msr vtt http paperswithcod com sota video retriev msr vtt msr vtt nmbrka split http paperswithcod com sota video retriev msr vtt nmbrka lsmdc http paperswithcod com sota video retriev lsmdc updat nmbrth fo april nmbr share model test script provid number paper refin list remov train test intersect scientif commun pleas refer github http github com papermsucod mdmmt
vector_machines,MachineLearning,1617491149.0,[D] Resources for crowdsourcing MCQ based dataset,i want crowdsourc dataset mcq format given sentenc user requir pick right option nmbr i explor mechan turk seem templat nlp one gener requir hardcod label thi mean i creat custom one from last emnlp i recal crowdaq bit close form i want learn cost effici crowdsourc option know want spend lot time read doc api ani suggest advic experi appreci
argh_usernametaken,MachineLearning,1618393674.0,[Discussion] which NN architecture is best suitable for analysing the structural data of biomolecules,i tri extract mean structur data biomolecul like protein which ml method appli type data
WigglyHypersurface,MachineLearning,1620230052.0,[D] Making sense of this autoencoder archetecture,i look implement architectur paper http arxiv org pdf nmbr pdf imput miss data i confus coupl point choic made rather encod decod setup autoencod add extra gener network i troubl pars necessari desir though also i confus input gener is input nois mask also input encod handl miss e replac na zero if i understand correctli miss data imput case mask use loss function zero log likelihood valu data miss is correct it seem like would simpler standard encod decod setup initi fill miss data random valu resampl predict miss valu end epoch keep train log likelihood miss valu mask that way need mask addit input encod gener
techsucker,MachineLearning,1617727196.0,[N] Facebook AI Introduces A New Self-Supervised Learning Framework For Model Selection And Hyperparameter Tuning For Large-Scale Forecasting,research facebook ai recent releas new self supervis learn framework model select ssl ms hyperparamet tune ssl hpt provid accur forecast less comput time resourc the ssl hpt algorithm estim hyperparamet nmbr nmbrx faster compar baselin search base algorithm produc accur forecast result numer applic at present forecast one signific data scienc machin learn task perform therefor crucial fast reliabl accur forecast result larg amount time seri data manag variou busi time seri analysi use find trend forecast futur valu a slight differ hyperparamet type analysi could lead differ forecast result given model seriou consequ therefor essenti select optim hyperparamet valu summari http www marktechpost com nmbr nmbr nmbr facebook ai introduc new self supervis learn framework model select hyperparamet tune larg scale forecast http www marktechpost com nmbr nmbr nmbr facebook ai introduc new self supervis learn framework model select hyperparamet tune larg scale forecast paper http arxiv org ab nmbr http arxiv org ab nmbr facebook sourc http ai facebook com blog larg scale forecast self supervis learn framework hyper paramet tune http ai facebook com blog larg scale forecast self supervis learn framework hyper paramet tune
Lunavahid,MachineLearning,1620639107.0,[Vault] [Discussion] Is Human in the Loop the New Thing?,recent discuss around ai ethic goe way one concept do need human ai pipelin loop even ceo declar worri fact ai push peopl percept judgment eventu make bias so ultim question need human loop do need surpris algorithm analys outcom result check hidden bias find potenti pitfal even find pattern might use anoth ai system new frontier ai need data perform better more data better algorithm recip success sever new achiev let look one applic familiar annot tag imag annot never access there billion imag text audio video annot tag provid solid learn background aia system learn nmbr year ago challeng recogn appl number nmbr letter z the new challeng identifi spanish hous sunni day next lake the sophist need form user mean sophist annot tag learn purpos more sophist mean label annot reason need human loop increas
BrettNMartensen,MachineLearning,1618610104.0,[D] Recency versus Frequency in Prediction,a neural net built keep track recent next input symbol sequenc use predict next symbol might given familiar sequenc that expect happen last time or could built keep track frequent next symbol occur that build probabl distribut next stimuli base count experienc then use highest probabl next stimulu predict doe anyon know paper publish compar success rate two approach e recenc versu frequenc predict purpos
janimezzz,MachineLearning,1617183219.0,[N] Deep learning method for generating proteins will speed up drug development,research chalmer univers technolog sweden present way gener synthet protein use gener deep learn the new approach huge potenti develop effici industri enzym well new protein base medicin antibodi vaccin read http news cision com chalmer r uniqu ai method gener protein speed drug develop cnmbr http news cision com chalmer r uniqu ai method gener protein speed drug develop cnmbr read articl expand function protein sequenc space use gener adversari network http doi org nmbr snmbr nmbr nmbr nmbr natur machin intellig
Candid-Wishbone-692,MachineLearning,1619708153.0,[N] Call for Teachable NLP Challenge,hi i found excit teachabl nlp challeng look peopl want particip is anyon want particip all level nlp welcom teachabl nlp challeng free open everyon interest train ai all need prepar good idea dataset when nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr edt how you need submit ai model link explan ai good exampl http forum ainetwork ai c ai showcas nmbr http forum ainetwork ai c ai showcas nmbr prize appl store gift card winner interview broadcast ai network youtub channel nmbrk subscrib to particip submit info via http form gle xfuunssnmbrheannmbrjthnmbr http form gle xfuunssnmbrheannmbrjthnmbr you receiv invit email check teachabl nlp work http forum ainetwork ai teachabl nlp use teachabl nlp nmbr http forum ainetwork ai teachabl nlp use teachabl nlp nmbr or watch nmbr minut tutori video http youtu hzujzotnmbrqznmbr http youtu hzujzotnmbrqznmbr
fernauata,MachineLearning,1620097391.0,[R] House-GAN++: A breakthrough in automated floorplan design via Relational Refinement GAN,hous gan a breakthrough autom floorplan design via relat refin gan w convolut messag pass joint work autodesk research appear cvprnmbr http www facebook com hashtag cvprnmbr __eep__ nmbr __cft__ nmbr azwymnmbrnnmbrkjnmbrspnmbrqgofqgtldlnmbrdsnnnmbrznmbrungeswnmbrqhjiikhfkkbnchxnmbrefusrxjsmjibaxsjnlpumzgnmbrkupnmbrsunmbrjcohsfxnmbrguvayxjslkcqdyvnhpivzplqitwpcurvxcoopnmbrkrzqusjwdxaedyvr __tn__ nk r the video show interact browser demo http reddit com link nnmbrejlo video znmbrenmbrwwnmbrrnmbrxnmbr player arxiv http arxiv org ab nmbr http arxiv org ab nmbr you play around http www houseganpp com http www houseganpp com fbclid iwarnmbrynbszda ssrl_awsuofnmbrlljhnmbrnnmbrugggnmbrg unmbrs_xbvnmbrtzeqgbqnmbrcwanmbrznmbr project websit http ennauata github io houseganpp page html http ennauata github io houseganpp page html fbclid iwarnmbrsnmbrcysrvwxnnmbrcgganmbrtnmbrgrlbsrybtbtnmbrvlinmbrmbqa nmbrexnxnmbrxnmbrtxauijua
ykilcher,MachineLearning,1618408423.0,[P] Video: I built a Neural Network in Minecraft | Analog Redstone Network w/ Backprop & Optimizer (NO MODS),http youtu nmbrodhtaipfwi http youtu nmbrodhtaipfwi i built analog neural network vanilla minecraft without mod command block the network use redston wire power strength carri signal one hidden layer includ nonlinear automat backpropag even weight updat outlin nmbr nmbr intro overview nmbr nmbr redston compon explain nmbr nmbr analog multipl redston nmbr nmbr gradient descent squar root comput nmbr nmbr neural network demonstr nmbr nmbr network schema explain nmbr nmbr the network learn datapoint nmbr nmbr outro conclus i built seri live stream want thank everyon help cheer chat world save http github com yk minecraft neural network http github com yk minecraft neural network game http www minecraft net http www minecraft net multipli inspir http www youtub com channel uclmzknmbrtlnlxcxchcjujenmbrag http www youtub com channel uclmzknmbrtlnlxcxchcjujenmbrag
human_treadstone,MachineLearning,1616807524.0,[D] Choosing correct baseline model for Metric learning,i use match prototyp network perform singl shot learn ssd dataset but i want implement baselin keep track improv i think nmbr nearest neighbour baselin is good baselin i could find github implement nmbr nn ssd case alreadi baselin implemet pleas point resourc
Yuqing7,MachineLearning,1619711797.0,[R] Toward a New Generation of Neuromorphic Computing: IBM & ETH Zurich's Biologically Inspired Optimizer Boosts FCNN and SNN Training,ibm eth zurich research make progress reconcil neurophysiolog insight machin intellig propos novel biolog inspir optim artifici ann spike neural network snn incorpor synapt integr principl biolog grape group respons adjust propag error signal lead improv train time converg accuraci scalabl ann snn here quick read toward new gener neuromorph comput ibm eth zurich biolog inspir optim boost fcnn snn train http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper learn deep neural network use biolog inspir optim arxiv http arxiv org pdf nmbr pdf
SuperFX,MachineLearning,1618524699.0,[D] A100 vs. A6000 for sequence learning tasks?,doe anyon first hand experi perform differ nvidia anmbr anmbr gpu larg sequenc task e g use transform i awar benchmark lambda post wonder research group hand experi use real model done benchmark the lambda number suggest someth order nmbr speed gain price differenti nmbrx i think peopl data wholesal price would use great deal terribl i wonder hold practic i like assembl gpu server use one gpu
_sshin_,MachineLearning,1617440536.0,[D] Short blogpost about EfficientNetV2,http mlpaper com nmbr nmbr nmbr review efficientnetvnmbr smaller model faster train http mlpaper com nmbr nmbr nmbr review efficientnetvnmbr smaller model faster train
Transit-Strike,MachineLearning,1619093209.0,[D] Are we underestimating how important studying theory is?,i hear lot discuss peopl essenti say employ univers care good project prove know learn cours mean noth just go kaggl find cool project work while technic true realli undersel import theori i could open kaggl repo see everyon use leakyrelu batch norm adam so i would tempt look youtub video kaggl submiss recreat output but realli hold weight i think i tri someth similar manag build decent solut would later github repo the logic realli fail tri build someth bigger better though if stylegan exampl understand optimis process like you need know peopl use batch norm etc etc it imposs understand code otherwis and even similar project i found abl apprach nmbrx time better simpl deeplearn ai http deeplearn ai cours sure could cheat way project sound sexi novic know noth ml but learn anyth use tf nn everywher find usabl result i sure realli
OverLordGoldDragon,MachineLearning,1620238337.0,[P] Fastest wavelet transforms in Python + synchrosqueezing,ssqueezepi nmbr nmbr http github com overlordgolddragon ssqueezepi releas w benchmark cwt xnmbr faster pywavelet cpu xnmbr gpu correct stft also cpu gpu acceler synchrosqueez also see kymatio http github com kymatio kymatio sota timeseri limit data fast differenti nice lectur http youtu nmbreyureyipxg
nivter,MachineLearning,1619874458.0,[P] I created a series of YouTube videos on normalizing flows - mostly inspired from UCB's Unsupervised DL code,
dcpyro,MachineLearning,1616358255.0,[D] Is my idea of a Feature Store wrong?,should featur store part enterpris data catalog to featur store seem highli nich data catalog miss lot benefit enterpris data catalog data discoveri tool my need gener featur discover search data for exampl i dataset a b use gener featur set ab i would want know inform i search ever come across dataset a b data catalog along would benefici code git commit gener featur am i miss someth
fripperML,MachineLearning,1616589984.0,"[P] New library for performing nested cross validation, optimizing, calibrating and reporting quality of binary classification models",the titl say everyth you check http github com jaimearboleda nestedcvtrain http github com jaimearboleda nestedcvtrain it first python packag i sure mani thing could improv but find interest pleas let know i appreci lot
gtgski,MachineLearning,1619394734.0,[D] VAE but every neuron models a distribution,variat autoencod model distinct middl layer neuron activ model unit gaussian is experi everi neuron model unit gaussian so rest layer middl layer
proximauri,MachineLearning,1617872991.0,[D] Model does not learn with more classes.,hi everyon i tri train vggnmbr model dataset use transfer learn the task face recognit classif softmax i first tri train nmbr class everyth fine model converg accuraci nmbr howev i train model like nmbr class includ first nmbr ident well network learn accuraci reach nmbr percent what could reason thank
ML_WAYR_bot,MachineLearning,1620590405.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 112,thi place share machin learn research paper journal articl read week if relat research mean elabor give us insight otherwis could interest paper read pleas tri provid insight understand pleas post thing present wiki prefer link arxiv page pdf easili access pdf summari page way around pertin link previou week nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr week nmbr http www reddit com nmbrqyjiq week nmbr http www reddit com nmbrxwnmbr week nmbr http www reddit com nmbrildf week nmbr http www reddit com nmbrsnmbrknmbru week nmbr http www reddit com nmbrtnnmbrax week nmbr http reddit com nmbrsnmbrelnmbr week nmbr http reddit com bfsxnmbrz week nmbr http reddit com dnmbrvnonmbr week nmbr http reddit com fnmbrfnmbriq week nmbr http reddit com hltnmbro week nmbr http reddit com knmbrywb week nmbr http reddit com mygnmbrsm week nmbr http www reddit com nmbrsnmbrxqm week nmbr http www reddit com nmbracbnmbrt week nmbr http www reddit com nmbrjwde week nmbr http www reddit com nmbrabnmbri week nmbr http www reddit com nmbrwvjfk week nmbr http reddit com anmbropot week nmbr http reddit com blnmbrov week nmbr http reddit com denmbrhnmbr week nmbr http reddit com fnmbrfsnmbrz week nmbr http reddit com hunmbrzqnmbr week nmbr http reddit com khnmbrnx week nmbr http www reddit com nmbrtnmbrmqm week nmbr http www reddit com nmbrcwfbnmbr week nmbr http www reddit com nmbr week nmbr http www reddit com nmbrd week nmbr http www reddit com nmbrexnmbr week nmbr http reddit com anmbryaro week nmbr http reddit com bqlbnmbrv week nmbr http reddit com dkoxnmbr week nmbr http reddit com ffinmbrb week nmbr http reddit com iaznmbr week nmbr http reddit com kpsxtc week nmbr http www reddit com nmbrubnmbrkw week nmbr http www reddit com nmbrfcnmbrmh week nmbr http www reddit com nmbrhhhb week nmbr http www reddit com nmbrjsnmbr week nmbr http reddit com nmbraluh week nmbr http reddit com adnmbrssz week nmbr http reddit com bwnmbrjmnmbr week nmbr http reddit com drnmbrnca week nmbr http reddit com fnnmbrrnmbr week nmbr http reddit com ijjcep week nmbr http reddit com kzevku week nmbr http www reddit com nmbrxomfnmbr week nmbr http www reddit com nmbrhynmbrur week nmbr http www reddit com nmbrteiz week nmbr http www reddit com nmbrbnmbravnmbr week nmbr http reddit com nmbrtnnez week nmbr http reddit com ainmbrgi week nmbr http reddit com cnmbritkk week nmbr http reddit com dxshkg week nmbr http reddit com fvknmbrjnmbr week nmbr http reddit com isnmbrhjnmbr week nmbr http reddit com lnmbrlvg week nmbr http www reddit com nmbrzcyvk week nmbr http www reddit com nmbrkdnmbrvd week nmbr http www reddit com nmbrdnmbrnbnmbr week nmbr http www reddit com nmbrenmbrfxnmbr week nmbr http reddit com nmbrxnmbroj week nmbr http reddit com apnmbrctk week nmbr http reddit com cdnmbrgko week nmbr http reddit com enmbrnmyk week nmbr http reddit com gnmbreavg week nmbr http reddit com jnmbrxrnmbr week nmbr http reddit com ljxnmbrn week nmbr http www reddit com nmbrtnmbrmo week nmbr http www reddit com nmbrobnmbrdx week nmbr http www reddit com nmbrgngwc week nmbr http www reddit com nmbrhccnmbrc week nmbr http reddit com nmbrjmh week nmbr http reddit com aucinmbrc week nmbr http reddit com cjnmbrkyc week nmbr http reddit com ebnmbrlxk week nmbr http reddit com gcxnmbruf week nmbr http reddit com jnmbrcbf week nmbr http reddit com luqbxl week nmbr http www reddit com nmbrheol week nmbr http www reddit com nmbrrnmbryd week nmbr http www reddit com nmbrjgdva week nmbr http www reddit com nmbrkgcqr week nmbr http reddit com nmbrupnmbrg week nmbr http reddit com azjoht week nmbr http reddit com cpnmbrjex week nmbr http reddit com ehbfst week nmbr http reddit com glmnmbrsv week nmbr http reddit com jhzznmbrv week nmbr http reddit com mnmbrunmbrz week nmbr http www reddit com nmbrkvsu week nmbr http www reddit com nmbrttnmbrcz week nmbr http www reddit com nmbrmnmbrlnmbrv week nmbr http www reddit com nmbrnayri week nmbr http reddit com nmbrnnmbrrt week nmbr http reddit com bnmbrrnmbri week nmbr http reddit com cvdenmbra week nmbr http reddit com entcxi week nmbr http reddit com gunmbrtnmbrd week nmbr http reddit com jqjgonmbr week nmbr http reddit com mfnmbrmnmbru week nmbr http www reddit com nmbrsnmbroa week nmbr http www reddit com nmbrwhnmbrwb week nmbr http www reddit com nmbrpnmbrhanmbr week nmbr http www reddit com nmbrqelnmbrp week nmbr http reddit com nmbrcfnmbr week nmbr http reddit com bakewnmbr week nmbr http reddit com dnmbrgnmbrknmbr week nmbr http reddit com euctyw week nmbr http reddit com hddfnmbrj week nmbr http reddit com jznmbrevt week nmbr http reddit com moynmbrm most upvot paper two week ago u kadisonsing http arxiv org ab nmbr http arxiv org ab nmbr u znmbrgnmbrd http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf u fakespotanalysisbot link fakespot analysi http fakespot com product make art artifici intellig make sell art ai blockchain nft awesom ai besid rule fun
cbsudux,MachineLearning,1617622290.0,[D] Anyone deploy DL models with AWS Lambda? Trying to estimate costs,ha anyon deploy dl model aw lambda gpu look find minimum would cost deploy serverless aw lambda mid level gpu tnmbr pnmbr equival http www fixmyphoto ai http www fixmyphoto ai deploy serverless react applic aw lambda function handl infer accord github page http github com mathiasgrub pconv kera
WavyShapes,MachineLearning,1618930996.0,[P] Backprop Model Hub: a curated list of state-of-the-art models,hey everyon i want share model hub http backprop co hub work it curat list state art text vision model includ perform benchmark notabl dataset our goal make conveni space find product readi model fast easi use real world scenario we tri keep select focus qualiti quantiti we also got open sourc librari http github com backprop ai backprop make use finetun model possibl line code we want enabl peopl take advantag latest ml research without need massiv dataset deep learn expertis if help like see task model let us know love hear peopl thought
Seankala,MachineLearning,1616906465.0,[D] Not able to reproduce SoTA baseline results due to (assumed) package mismatch. How should I go about this?,hi i student work research project there sota baselin model i manag run unfortun perform quit bit lower report paper search around close issu github led believ may probabl due packag version mismatch unfortun packag origin implement use rel older version order instal i believ i downgrad mani driver server i current use run experi what would advic someon shoe thi first actual project i sure proceed should i use result disclaim i whatev i achiev origin perform first thank
jnforcer,MachineLearning,1620072239.0,[R] XGBoost works best for intelligent Deep Brain Stimulation,http www biorxiv org content nmbr nmbr nmbrvnmbr smart brain implant revolution neurotechnolog improv qualiti life patient brain disord the treatment parkinson diseas pd neural implant deep brain stimul present avenu develop machin learn base individu treatment refin human motor control we develop optim movement decod approach predict grip forc base sensorimotor electrocorticographi subthalam local field potenti pd we demonstr electrocorticographi combin bayesian optim extrem gradient boost decis tree outperform machin learn approach we elucid link dopamin movement code capac pd show neg correl decod perform motor symptom sever medic off state final introduc approach leverag wholebrain connectom predict machin learn base decod perform invas neurophysiolog our studi provid framework aid develop intellig adapt deep brain stimul
FirstTimeResearcher,MachineLearning,1619818763.0,"[D] ICML Conference: ""we plan to reduce the number of accepted papers. Please work with your SAC to raise the bar. AC/SAC do not have to accept a paper only because there is nothing wrong in it.""",icml confer decid lower accept rate nmbr http twitter com tomgoldsteinc statu nmbr accord current meta review statist need rais accept bar pleas coordin ac reduc nmbr accept submiss http twitter com ryan_p_adam statu nmbr
Yuqing7,MachineLearning,1616607343.0,"[N] CMU, Oxford & Facebook Cross-Lingual Vision-Language Model Achieves New SOTA in Zero-Shot Setting",a research team cmu oxford facebook ai propos vision languag model train sourc languag appli differ languag without addit annot train data here quick read cmu oxford facebook cross lingual vision languag model achiev new sota zero shot set http syncedreview com nmbr nmbr nmbr cmu oxford facebook cross lingual vision languag model achiev new sota zero shot set the paper multilingu multimod pretrain zero shot cross lingual transfer vision languag model arxiv http arxiv org pdf nmbr pdf
StellaAthena,MachineLearning,1616370695.0,[P] EleutherAI releases 1.3B and 2.7B GPT-3-style models trained on the Pile,the gpt neo http github com eleutherai gpt neo project eleutherai http www eleuth ai releas nmbrb nmbrb paramet gpt nmbr style model the model train pile http pile eleuth ai nmbr gb curat dataset eleutherai releas januari the releas includ nmbr the full model code written mesh tensorflow design run tpu nmbr train model weight nmbr optim state allow continu train model eai left nmbr a googl colab notebook http colab research googl com github eleutherai gptneo blob master gptneo_example_notebook ipynb show use code base train fine tune sampl model befor peopl inevit get confus size gpt nmbr the nmbrb model littl smaller gpt nmbr nmbrb model twice big gpt nmbr come varieti size includ nmbrb nmbrb chose valu the full gpt nmbr model nmbrb paramet edit we gotten coupl question discord i want share follow well to best knowledg complet list announc autoregress non moe transform a model consid public anyon download train model weight free no typo i say facebook train megatron lm model find weight http github com pytorch fairseq tree master exampl megatron_nmbrb amp xnmbrb model size creator public gpt neo small nmbrb eleutherai ye gpt nmbr nmbrb openai ye meena nmbrb googl no gpt nmbr nmbrb nmbrb openai no gpt neo mid nmbrb eleutherai ye gpt nmbr nmbrb nmbrb openai no megatron lm nmbrb nvidia no megatron lm nmbrb facebook ye gpt nmbr nmbrb nmbrb openai no ture nlg nmbrb microsoft no gpt nmbr nmbrb nmbrb openai no
,MachineLearning,1617032593.0,[P] NeMo Getting Started. Prototyping Conversational AI Application,hey hope everyon great monday i know i i want let everyon know nvidia ai platform piec i use daili nemo nvidia nemo http github com nvidia nemo toolkit build new state art convers ai model nemo separ collect automat speech recognit asr natur languag process nlp text speech tt model each collect consist prebuilt modul includ everyth need train data everi modul easili custom extend compos creat new convers ai model architectur convers ai architectur typic larg requir lot data comput train nemo use pytorch lightn easi perform multi gpu multi node mix precis train cool collab notebook get start nemo http colab research googl com github nvidia nemo blob rnmbr nmbrrcnmbr tutori nemo_getting_start ipynb show construct toy demo show abil translat russian audio file english that neat nemo pipelin divers translat audio file english want use bert nlp task translat english well and anyway i hope enjoy collab book poke around nemo afterward
marcos_pereira,MachineLearning,1620577183.0,[D] Machine Learning Collective is hosting OpenClubHouse: a live discussion open to all featuring researchers from Google Brain and Uber AI Labs. Starts in 40 minutes!,
programmerChilli,MachineLearning,1619010169.0,[R] Rotary Positional Embeddings - a new relative positional embedding for Transformers that significantly improves convergence (20-30%) and works for both regular and efficient attention,thi origin discov chines research circul onlin time publish preprint http arxiv org ab nmbr in meantim eleutherai play around found extrem effect across divers rang set size http blog eleuth ai rotari embed none author arxiv paper part eleutherai eleuth interest pure work realli well i surpris see posit embed becom default
chilled_87,MachineLearning,1620064529.0,[P] Reproducible research: Machine learning for credit card fraud detection,ml credit card fraud detect one field publish research unfortun reproduc real world transact data share confidenti reason also believ author make enough effort provid code make result reproduc we releas five first chapter book topic aim make first step toward improv reproduc research domain http fraud detect handbook github io fraud detect handbook http fraud detect handbook github io fraud detect handbook thi preliminari releas jupyt book format make experi result reproduc open sourc licens publish chapter cover background motiv baselin methodolog forthcom chapter address advanc topic class imbal featur engin deep learn interpret feedback welcom
ispeakdatruf,MachineLearning,1619311145.0,[D] Looking for interesting classification datasets,i new techniqu i want tri small cardin classif problem sota still headroom so exampl mnist sinc sota alreadi nmbr xx and imagenet number class larg the ideal dataset would nmbr class sota nmbr are interest dataset thank advanc
ilikepancakez,MachineLearning,1618773529.0,[D] Neural Nets (1994),http www teamten com lawrenc write plannmbr html http www teamten com lawrenc write plannmbr html i colleg interest neural net written happen later graduat work author post in academia time i believ neural net seen fade trend someth cute idea destin work work well enough even comput anyth use person i fascin i know sever peopl kept hope well one quit well known ai neural net research i pursu neural net person i keep use relat genet algorithm artifici evolut i think view mix skeptic gener pocket enthusiast gate stori probabl share hear academ lawrenc author post incred smart person i doubt abl see past mani research say btw i recent happen across paper nmbr http pageperso lif univ mr fr edouard thiel rech nmbr blum pdf nmbr year ago mention neural network pass popular idea time origin paper medial axi transform scroll nmbrnd page nmbr near top consid continu isotrop plane ideal activ granular materi rudimentari neural net follow properti point
IborkedyourGPU,MachineLearning,1618497148.0,[D] MLFlow vs ClearML vs Gradient Paperspace,the mlop tool scene slightli overcrowd i want limit comparison three tool subject requir run prem got hardwar need want cloud easili launch experi experi databas log metric creat plot compar differ experi visual track model perform time easi instal use set experi tracker requir level devop savvi mani data scienc team nice deploy model api endpoint we use docker realli crucial nice hyperparamet tune it fine hyperparamet tune reli third parti plugin long open sourc exampl mlflow hydra ax plugin abl handl hyperparamet tune bayesian optim fine open sourc afaik mlflow clearml open sourc gradient how mlflow clearml gradient compar respect i especi interest comparison mlflow clearml point view outsid seem pretti similar i could wrong ofc
darkmabler,MachineLearning,1617811607.0,[D] Models in production - what architecture do you use?,hi i new commun ml space time curiou everyon around use serv model product right i implement project util aw ek nvidia triton infer server the project i implement need handl nmbr thousand concurr request i chose ek due scalabl what thought done anyon ever use nvidia triton infer server do like tensorflow serv
DeepML42,MachineLearning,1618953886.0,[D] Marginal Likelihood vs. Likelihood for Variational Autoencoder,in discuss http www reddit com r machinelearn comment nmbrqmnmbrag d_how_to_calculate_variational_autoencoder_log comput likelihood vae discuss here talk likelihood p x margin likelihood is differ margin likelihood likelihood vae if comput vae
Megixist,MachineLearning,1619071095.0,[P] Implementation of MADGRAD optimization algorithm for Tensorflow,i pleas present tensorflow implement madgrad optim algorithm publish facebook ai paper adapt without compromis a momentum adapt dual averag gradient method stochast optim http arxiv org pdf nmbrvnmbr pdf aaron defazio sami jelassi nmbr when algorithm first introduc sever peopl request implement tf kera i decid thi implement main featur includ nmbr simpl integr everi tf kera model sinc madgrad subclass deriv optimizervnmbr superclass use way tf kera optim nmbr built weight decay support nmbr full learn rate schedul support nmbr complet support spars vector backpropag nmbr avail pypi instal import directli ani question concern implement paper welcom you check repositori http github com darshandeshpand tf madgrad exampl test case if like work consid give star
xEdwin23x,MachineLearning,1619117403.0,"[D] In a scale of 1 to 10 how much importance or thought do you guys put into the SWE and quality of the code in general you're writing when doing experiments? I feel its important but at the same time there's lots of pressure to move fast, so how do you strike a balance in this aspect?",i read lot write better code becom better swe better ml research i person feel realli import write good clear modular reusabl code time fast move natur ml academia least dunno industri push get mvp minimum viabl product case model result fast possibl make hard think thing done advanc i see even big research group put code look ugli need quit tweak keep chang im curiou opinion topic approach problem
hardmaru,MachineLearning,1620565245.0,[R] Barlow Twins: Self-Supervised Learning via Redundancy Reduction,
Fun_Huckleberry_8991,MachineLearning,1619411818.0,[P] Reinforcement Learning with multiple simultaneous actions?,hi i current work project relat use reinforc learn the agent larg set possibl discret action for exampl given graph n node possibl action choos nmbr n node check stop criteria we actual solv dqn howev bottl neck agent pick one node step with larg n may make runtim increas doe anyon know possibl rl method agent pick multipl node one node step thank lot
AugustFR,MachineLearning,1619210772.0,College student created AI artists - the future is here - miragegallery.ai [N],
donjuan1337,MachineLearning,1617368020.0,[D] Modeling class errors,i work project i post process predict system use ml both real valu rank variabl predict predict system my strategi model system error for real valu variabl differ target predict trivial i problem regard rank variabl e g nmbr nmbr nmbr nmbr each rank seen class but i unsur model error class variabl do suggest the reason model error make data time invari good sinc data set limit
Equivalent-Choice-75,MachineLearning,1620009742.0,[D] Does Pytorch/TF/Jax work well with M1 GPU?,thi inform surprisingli difficult find onlin there sever conflict sourc inform just simpl question doe pytorch tf jax work mnmbr gpu well nvidia gpu or even compar
SomeParanoidAndroid,MachineLearning,1617702239.0,[D] Choosing ML + numerical computations workstation/server,i start phd machin learn newli establish lab mainli focus wireless commun i task find server workstat get offic my budget around nmbr nmbr i cours util gpu train model part work involv run numer simul optim algorithm physic model sort stuff the rest nmbr nmbr peopl deal latter stuff exclus also i write code python use numba tensorflow other use matlab a final constraint base europ supervisor skeptic order us abroad gener due deliveri time extra complex so i would ideal like someth gener avail supplier anywher lambdalab system nmbr unfortun consid probabl need server concurr code usual take sever hour part i priorit especi i think get rtx nmbr seem one best vfm gpu dl inmbr ryzen xeon supposedli xeon abl handl multipl job better stay without problem longer look way slower i see support ecc memori i know relev field also code could use good cpu thi import dilemma would nmbrgb ram enough i would like get nmbrgb may budget do think i priorit is liquid cool need the server place offic doe dual gpu setup make sens e g nmbrx nmbr it seem ridicul spend huge portion budget i account everyon plu gener question discuss point game pc workstat if opt inmbr alienwar configur hit spec spot should i avoid i would appreci opinion are workstat solut deep learn compani like ibm lenovo hp e c price rang touch realiti they offer setup nmbrgb ram pnmbr nmbrgb vram rtx nmbr closest nmbr seri i find for budget i could dream setup lambda lab someth equival linux vs window i feel way comfort former i kind fear window get way unnecessarili matlab support run code remot right
bendee983,MachineLearning,1617032735.0,[D] Algorithms Are Not Enough,algorithm are not enough provid fresh perspect shortcom current ai system the main idea discuss aan current ai system heavili depend represent a human engin must discov problem simplifi solut distinct step set input data expect outcom set reward action onli ai algorithm design solv problem what lack algorithm solv complic problem algorithm seek discov new problem develop solut without help human review book discuss author herbert roitblat http bdtechtalk com nmbr nmbr nmbr ai algorithm represent herbert roitblat http bdtechtalk com nmbr nmbr nmbr ai algorithm represent herbert roitblat
jayalammar,MachineLearning,1619708819.0,[P] Explainable AI Cheat Sheet (Image + Video),hi r machinelearn i creat high level map major categori ml explain method explain ai cheat sheet http ex pegg io http ex pegg io video go http www youtub com watch v ygnmbrqnmbrxnmbrydem http www youtub com watch v ygnmbrqnmbrxnmbrydem it larg field non exhaust list help orient peopl come domain how think i improv all feedback appreci
Advanced-Hedgehog-95,MachineLearning,1616961935.0,[D] Motivation to use 768 dimensional embeddings from Transformers?,is scientif reason transform model nmbr dimension embed even wavnmbrvecnmbr mockingjay model audio nmbr dimension embed
HashRocketSyntax,MachineLearning,1618613481.0,Why do practitioners still use regular tensorflow? [D],when i look nmbr nn class hand loss mix hidden layer optim when i look tensorflow optim tensorflow loss either point tf kera tf compat vnmbr it understand lot practition use tensorflow kera if case use vnmbr vnmbr are abl low level fanci footwork layer not tri faceti truli seek understand edit takeaway comment custom batch epoch oper perform legaci code embed devic
latticeprep,MachineLearning,1617339115.0,[D] How does stripe use GBT's to find edge similarity?,i read stripe blog post find similar account flag fraudul activ http stripe com blog similar cluster make sens i wonder anyon idea gbt use adjac list like from post over year risk underwrit team manual compil mani exampl exist cluster fraudul account investig fraud ring use refer cluster train data learn similar function by sampl edg group obtain dataset consist pair account along label pair indic whether two account belong cluster we use intra cluster edg posit train exampl inter cluster edg neg train exampl edg denot pair account becaus wide varieti featur construct given pair account decid use gradient boost decis tree http en wikipedia org wiki gradient_boost gbdt repres similar model in practic found gbdt strike right balanc easi train strong predict power robust despit variat data when start project want get someth door quickli effect well understood properti straightforward fine tune the variant use xgboost http xgboost readthedoc io en latest one best perform shelf model case structur also known tabular data well develop infrastructur train serv you read infrastructur use train machin learn model http stripe com en ca blog railyard train model stripe previou post now train model use predict fraudul activ sinc model oper pair stripe account feasibl feed possibl pair account comput score across pair instead first gener candid set edg score we take recent creat stripe account creat edg account share certain attribut although exhaust approach heurist work well practic prune set candid edg reason number onc candid edg score filter edg select similar score threshold we comput connect compon result graph the final output set high fidel account cluster analyz process manual inspect togeth unit in particular fraud analyst may want examin cluster contain known fraudul account investig remain account cluster thi iter process individu cluster grow quickli identifi increas similar fake account fraudster oper creat and fraud ring detect shutdown stripe accur cluster model becom identifi new cluster futur i found baffl i realiz gbt could use effect find cliqu graph ha anyon tri understand work better i realli understand edg candid score past known fraudul edg i sens featur space
fool126,MachineLearning,1616478880.0,[D] Recent (2021-03) review papers of different areas in the field,motiv recent post share review paper deep gener model a compar review vae gan normal flow energi base autoregress model http arxiv org ab nmbr i want crowdsourc compil list review paper area thi especi help look catch specif area ever quickli expand field
zeando,MachineLearning,1619902307.0,[R] RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models ( GPT and CTRL Models ),
Lairv,MachineLearning,1618660227.0,[D] How to handle big datasets in computer vision ?,i current tri use scannet http www scan net org dataset thi dataset contain lot thing nmbrd model depth imag semant segment etc weight total nmbrtb but purpos i need rgb color imag someth like nmbrgb thi still quit huge moment i even download dataset machin i seen sever project e g atla http github com magicleap atla make use dataset train model how is possibl download dataset cloud platform edit seem debat whether realli big data least scale requir work simpli train mnist although i sure noth compar train gptnmbr
n31415926535,MachineLearning,1619809245.0,[P] AdapterHub v2: Lightweight Transfer Learning with Transformers and Adapters,hi r machinelearn yesterday releas vnmbr adapterhub http adapterhub ml http adapterhub ml framework make adapt access nlp integr huggingfac transform librari what adapt lightweight altern full fine tune pre train transform model par perform updat nmbr model weight train adapt modul mb size extract share plug model flexibl composit adapt train differ task e g via stack fuse split what adapterhub adapt transform drop replac huggingfac transform adapt support hub nmbr pre train readi use adapt nlp task similar huggingfac model hub minim chang nmbr nmbr line code switch exist transform script adapt train easi load compos train save share adapt support variou transform model bert roberta gpt nmbr bart github http github com adapt hub adapt transform http github com adapt hub adapt transform document http doc adapterhub ml http doc adapterhub ml pre train adapt http adapterhub ml explor http adapterhub ml explor http preview redd fsnmbrbenmnmbrycwnmbr png width nmbr format png auto webp nmbrbanmbrebnmbranmbrfnmbrdnmbranmbrenmbreebdnmbr
eparlan,MachineLearning,1616950375.0,[P] Implementation of DenStream,i would like showcas someth i work back it python implement denstream algorithm http archiv siam org meet sdmnmbr proceed nmbrcaof pdf http archiv siam org meet sdmnmbr proceed nmbrcaof pdf algorithm base dbscan stream data e acquir data train iter the implement found http github com mrparosk pydenstream http github com mrparosk pydenstream if feedback pleas let know
pianomano8,MachineLearning,1619197053.0,[R] MLC@Home and MLDS: A Dataset for Weight-Space Analysis of Neural Networks,announc mlc home mld tl dr project websit http www mlcathom org http www mlcathom org paper http arxiv org ab nmbr http arxiv org ab nmbr mlc home mlc home volunt base distribut comput project dedic understand explain machin learn model specif neural network it collabor project host umbc http www umbc edu sinc juli nmbr thousand volunt train neural network home comput otherwis idl use boinc http boinc berkeley edu framework seti home the project less chase sota understand network encod data via inspect mlc home also first ml focuss project use boinc framework mld machin learn dataset gener sinc juli nmbr volunt crunch away creat mld dataset hundr thousand way nmbr million neural network small select shape leav weight space variabl we releas http www mlcathom org mld html earli version dataset public commit make entir dataset avail complet thi past week post preliminari find base dataset arxiv http arxiv org ab nmbr a summari preliminari find paper given enough sampl ident shape neural network train differ train data show cluster behavior weight space we classifi network train dataset high accuraci we abl differenti network train backdoor adversari data versu train clean data we believ largest publicli avail dataset dedic weight space analysi least order magnitud still grow the dataset lead sort interest question possibl evalu network via direct inspect weight structur network oppos indirect measur perform observ loss test data mld also captur meta inform train process loss histori hardwar network train window llinux amdnmbr armnmbr armnmbr cpu cuda rocm time inform allow even opportun comparison next step mld continu expand mld dataset current dataset consist small rnn nmbr nmbr paramet less ad support cnn current plan support transform arbitrarili size network mld continu grow use resourc commun mlc home even larger goal leverag volunt comput capabl multipli mani line research mlc home support multipl project mld first while mlc home like never outperform tightli coupl cluster train singl larg network forese mlc home use dataset gener mld reproduc robust studi architectur hyperparamet search neuro evolut name our commun contribut nmbr comput join everi day interest want help mlc home activ see collabor individu contributor have comput you help mlc home instruct instal client join avail websit research mlc home activ look research collabor if interest weight space meta analysi want talk mld improv new project idea could benefit generos mlc home volunt pleas us via email twitter discord love collabor develop data scienc engin run project support cut edg legaci hardwar multipl platform easi if softwar develop data scienc engin would like help pleas let us know our client open sourc written c use pytorch c api comput we specif need osx develop port client mac platform mani enhanc make overal our websit could also use updat summari we excit possibl mlc home past nmbr month made real use grow resourc we love commun feedback collabor make grow new fun way as alway thank volunt make possibl without never would gotten ground mlc home admin websit http www mlcathom org http www mlcathom org forum http www mlcathom org mlcathom forum _index php http www mlcathom org mlcathom forum_index php e mail mlcathomenmbr gmail com mailto mlcathomenmbr gmail com twitter http twitter com mlchomenmbr http twitter com mlchomenmbr gitlab http gitlab com mlcathom http gitlab com mlcathom
giakou4,MachineLearning,1619505394.0,[P] Carotid plaque dataset,recent work thesi applic machin learn techniqu carotid plaqu classifi symptomat asymptomat howev dateset provid consist nmbr imag would like possibl better model train howev abl find free dateset ha anyon work someth similar
kvfrans,MachineLearning,1617836706.0,[R] StampCA: Growing Emoji with Conditional Neural Cellular Automata,visual http imgur com losnmbrnkv mpnmbr blog post http kvfran com stampca condit neural cellular automata twitter thread http twitter com kvfran statu nmbr basic idea neural ca defin local interact togeth grow global design instead one system one design defin gener system grow mani design thi let us condit neural ca give differ design specif seed stampca model encod design specif inform cell state gener inform network paramet thi mean nmbr grow mani design without retrain nmbr grow design world mani emoji grow one world http imgur com rggxhi mpnmbr stamp emoji circl http video twimg com ext_tw_video nmbr pu vid nmbrxnmbr tnmbrlimifaklyhmnmbri mpnmbr we also train gan base stampca thi model use random valu seed grow variou mnist like digit grow fake mnist digit http video twimg com ext_tw_video nmbr pu vid nmbrxnmbr nmbriemnkdnmbriynmbrzhg mpnmbr tag nmbr code replic experi play model colab notebook emoji http colab research googl com drive nmbrfbeurymdpgqidplnmbralprmdpvizumnmbrxpg usp share scrollto nmbr_qze_cnmbruphf colab notebook mnist http colab research googl com drive nmbrkgyynmbrjebulnmbrbpbvlybwtholvnmbrhrclnmbr
bzlister,MachineLearning,1618695659.0,[P] GAN for text generation,i look model train text particular genr produc new text transform exist text style genr use common word phrase i awar gan limit success appli text gener due non differenti natur textual data compar imag i hope nonetheless someth i use
Yuqing7,MachineLearning,1620313621.0,[R] Facebook AI Conducts Large-Scale Study on Unsupervised Spatiotemporal Representation Learning,a research team facebook ai conduct larg scale studi unsupervis spatiotempor represent learn video the work take unifi perspect four recent imag base framework moco simclr byol swav investig simpl object easili gener unsupervis represent learn methodolog space time here quick read facebook ai conduct larg scale studi unsupervis spatiotempor represent learn http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper a larg scale studi unsupervis spatiotempor represent learn arxiv http arxiv org pdf nmbr pdf
ZeroHour999,MachineLearning,1620499138.0,[R] Emotion Recognition of the Singing Voice: Toward a Real-Time Analysis Tool for Singers,http arxiv org ab nmbr http arxiv org ab nmbr
MushiML,MachineLearning,1620243275.0,[D] Shuffling Batch Normalization in MoCo - Self Supervised Learning Method,hi the author mention paper shuffl bn our encod fq fk batch normal bn nmbr standard resnet nmbr in experi found use bn prevent model learn good represent similarli report nmbr avoid use bn the model appear cheat pretext task easili find low loss solut thi possibl intra batch commun among sampl caus bn leak inform we resolv problem shuffl bn we train multipl gpu perform bn sampl independ gpu done common practic for key encod fk shuffl sampl order current mini batch distribut among gpu shuffl back encod sampl order mini batch queri encod fq alter thi ensur batch statist use comput queri posit key come two differ subset thi effect tackl cheat issu allow train benefit bn we use shuffl bn method end end ablat counterpart figur nmbra it irrelev memori bank counterpart figur nmbrb suffer issu posit key differ mini batch past i unabl understand type inform leak due intra batch commun pleas someon help understand point refer sourc thank
ykilcher,MachineLearning,1619799059.0,[D] Paper Explained - Why AI is Harder Than We Think (Full Video Analysis),http youtu uwfvxckuqnmbr http youtu uwfvxckuqnmbr the ai commun gone regular cycl ai spring rapid progress gave rise massiv overconfid high fund overpromis follow promis unfulfil subsequ dive period disenfranchis underfund call ai winter thi paper examin reason repeat period overconfid identifi four fallaci peopl make see rapid progress ai outlin nmbr nmbr intro overview nmbr nmbr ai spring ai winter nmbr nmbr is current ai boom overhyp nmbr nmbr fallaci nmbr narrow intellig vs gener intellig nmbr nmbr fallaci nmbr hard human mean hard comput nmbr nmbr fallaci nmbr how call thing matter nmbr nmbr fallaci nmbr embodi cognit nmbr nmbr conclus comment paper http arxiv org ab nmbr http arxiv org ab nmbr
thunder_jaxx,MachineLearning,1619841163.0,[R] Rip van Winkle's Razor: A Simple Estimate of Overfit to Test Data,
Aurora_HF,MachineLearning,1617526327.0,How to handle 2D geo-spatial grid like data samples in ML [D],i look problem wherein whole geograph area divid number bin pixel get nxn matrix cover whole region now bin pixel number paramet featur associ e g number build bin number peopl live bin poverti level bin crime level bin etc thi whole inform repres one sampl train dataset e matrix like data differ geograph region correspond label how best handl kind dataset machin learn task e g ml train nxn grid differ area like classifi label unseen test nxn grid i think term cnn may repres term channel channel repres associ featur bin what suggest http stack imgur com nmbrilhnmbr png http stack imgur com nmbrgaej png
VinayUPrabhu,MachineLearning,1617472489.0,[P] What do you mean when you say X-is-all-you-need? The landscape and the dataset of all the 80 odd ML papers that have made these claims either in their title or in the body of the paper,github http github com vinayprabhu x need http github com vinayprabhu x need thi part paper titl spice survey paper as interact cheatsheet embed got accept upcom rethink ml paper iclr nmbr workshop http preview redd qnmbrcwxksnmbryzqnmbr png width nmbr format png auto webp nmbrenmbrdnmbrdnmbrfnmbrbcnmbrdnmbrfebabnmbranmbrbnmbrccdnmbr
Ingvariuss,MachineLearning,1620406896.0,[D] Data Collection Crowdsourcing - How to animate people?,hello i start work ambiti ai project would advanc specif field psycholog the thing project need much data would take around nmbr year i collect consist basi the idea commun quit aliv help collect data i wrote thorough document project descript rule data format collect even made littl websit work basic need copi past stuff check box i gave document two friend read see everyth sound get green light i share document around variou social media channel a big chunk peopl ran away document long other fear start attack idea use ai after convers i conclud idea ai model work goe hood which fine background color teach ai work i need data format option ignor my question ha anyon ran someth like overcom how anim find data collector have mind peopl need psycholog knowledg order collect data reason intellig tl dr i need peopl help collect data scare ai how effect crowdsourc project
badge,MachineLearning,1617268644.0,[D] Generalized Additive Models‚Ä¶ with trees?,i look implement gener addit model work speedili possibl entir end end process start look use c ml net http doc microsoft com en us dotnet api microsoft ml treeextens gam i use c sinc nmbr read code bit difficult part fasttre librari clearli tree base implement i test simpl sin x model dread fastforest regressor much better doe anyon insight use refer subject i use gam r python never seen non spline base implement
thunder_jaxx,MachineLearning,1619753760.0,[R] Sharpness-Aware Minimization for Efficiently Improving Generalization,
ottawalanguages,MachineLearning,1620111466.0,[D] Inevitable Manual Work Required in Machine Learning Projects,i feel mani peopl will admit ultim signific part mani data mine project e g check data qualiti pars data etc still done manual for exampl exampl i made relat supervis nlp natur languag process classif suppos i nmbr medic report patient contain unstructur text made doctor hospit visit for given patient report contain text note doctor made patient visit nmbr nmbr these report make mention patient bio data e g age gender medic histori etc detail symptom patient experienc long period time e g let say report nmbr word averag the problem differ doctor differ style write nmbr report differ anoth if human read report human could figur happen patient patient seriou condit let call class nmbr non seriou condit let call class nmbr thi interest predict futur patient base limit medic note made doctor futur patient the problem clear fast way i know take nmbr medic report avail label report class nmbr class nmbr for exampl class nmbr one doctor could clearli write end report medic test conduct result neg anoth doctor could end report say patient serious consid chang lifestyl eat healthier food benign in exampl would someon assign label nmbr case without manual read decid inform report correspond seriou condit non seriou condit i think use someth like sentiment analysi captur mood report use sentiment analysi method inform gaug tone report dark seriou condit light non seriou condit but i sure best way approach problem is way without read report manual decid label in end i interest suppos new patient come first visit doctor make quick note e g patient male nmbr year old nmbr cm nmbr kg non smoker frequent complain chest pain high blood pressur work construct worker take daili medicin acid reflex just base quick note nmbr report avail note i tri illustr point medic note new patient nmbr report do not format research predict supervis classif e g decis tree patient seriou non seriou condit ps suppos doctor detail medic encyclopedia comput medic encyclopedia use alongsid nmbr medic report improv predict result
Ingvariuss,MachineLearning,1619513497.0,[P][D] NLP question - Question Answering AI,hey peopl i work person project quit challeng one featur user interact open domain question answer chatbot train data i provid i want model resembl specif person group fed everyth person group wrote said etc have mind model answer question nmbr nmbr sentenc need base pure fact thi mean user ask model question like what capit franc someth along line existenti question what mean life here question i i dabbl nlp world ai nmbr are pre train prebuilt model i could use i found open sourc pavlov ai librari interest one nmbr which model would suit task best nmbr are featur i watch provid inform the biggest part job collect relev data group i want model resembl what would best practic make data inform also i want nmbr group model resembl do i need train nmbr model i filter model learn nmbr categori thank repli question advanc if interest project feel free send dm could even collabor part project make model great
SQL_beginner,MachineLearning,1620420157.0,"[D] has anyone ever worked on a machine learning model for ""queues""?",ha anyon ever work machin learn model queue suppos bakeri bakeri n peopl work peopl line q order current work the bakeri interest make machin learn model predict long custom wait custom order readi long next custom wait place order ha anyon ever come across machin learn model predict wait process time i seen exampl onlin peopl tri fit exponenti distribut histor wait time see well fit well tri differ k combin anyon ever come across instanc machin learn algorithm e g random forest neural network use predict wait time i saw someth like http arxiv org ab nmbr but python r code paper can anyon recommend sourc blog github websit book youtub lectur etc show provid comput code analyz queue use machin learn model thank
aseigo,MachineLearning,1618740258.0,[P] Livebook: Jupyter-style environment for machine learning and scientific computing with Elixir,
_Arsenie_Boca_,MachineLearning,1620480658.0,[D] Multiple fine-tuning steps order,when tri maxim perform target task transfer learn appli fine tune pretrain model task one might also want incorpor sever fine tune step special model target task thi call domain adapt behavori fine tune terminolog see http ruder io recent advanc lm fine tune depend whether data share domain task set target task thi probabl especi help set amount label data specif target task limit domain significantli differ pretrain data e g http www aclweb org antholog nmbr acl main nmbr pdf relat adapt via languag model the fine tune step might contain domain adapt via languag model task adapt via task set target task differ domain task adapt via task set target task similar domain target task now appli sever fine tune adapt step would one choos order empir test possibl order might feasibl wrong order might make model forget valuabl skill knowledg my intuit would roughli order list reason order ascendingli similar target task lead best model is rule thumb ani literatur investig least appli briefli discuss
savoga,MachineLearning,1618414525.0,[D] Advantages of ML approaches for anomaly detection?,what advantag ml approach anomali detect isol forest autoencod dbscan etc tradit approach find point situat extrem part distribut
blkpingu,MachineLearning,1616784241.0,[D] Looking for Deep Learning Workstation / Server vendor in Europe / Germany,i want buy workstat far i found lambdawork bizon locat us doe anyon know compani sell workstat server germani least eu
KaleidoscopeBest1569,MachineLearning,1620233329.0,[R] Hierarchical Cross-Modal Agent for Robotics Vision-and-Language Navigation,project webpag http zubair irshad github io project robo vln html http zubair irshad github io project robo vln html pytorch code dataset http github com gt ripl robo vln http github com gt ripl robo vln arxiv paper http arxiv org ab nmbr http arxiv org ab nmbr abstract deep learn revolution abil solv complex problem vision languag navig vln thi task requir agent navig goal pure base visual sensori input given natur languag instruct howev prior work formul problem navig graph discret action space in work lift agent navig graph propos complex vln set continu nmbrd reconstruct environ our propos set robo vln close mimic challeng real world navig robo vln task longer trajectori length continu action space challeng obstacl we provid suit baselin inspir state art work discret vln show less effect task we propos decompos task special high low level polici effect tackl task with extens experi show use layer decis make modular train decoupl reason imit propos hierarch cross modal hcm agent outperform exist baselin key metric set new benchmark robo vln
whyhateverything,MachineLearning,1617030324.0,[P] Passing embeddings to faiss for clustering,hi everyon i hard time faiss document cluster i embed creat sentenc transform i want use faiss cluster part get final list show document belong cluster i idea faiss precis pass embed i would endlessli grate help thank advanc
lifeonahilltop,MachineLearning,1620348179.0,[D] How do companies typically develop ML models for different customers?,i work fraud protect industri compani ship fraud protect solut basic binari classifi wrap ui compani e commerc healthcar sector as get custom day decid whether want build singl ml model custom ml model from engin mlop point view singl model scalabl howev combin data multipl custom train take perform tradeoff differ custom seem straightforward can anyon inform typic done industri do peopl use techniqu like domain adapt assumpt brittl realiti i imagin common challeng industri pointer relev materi case studi etc would greatli appreci
lukasus,MachineLearning,1617900076.0,[P] Mask2Face: How We Built AI That Shows the Face Beneath the Mask,can virtual remov face mask see person look like underneath strv machin learn team prove possibl via imag inpaint base ml solut here exactli approach problem precondit implement result futur improv masknmbrfac how we built ai that show face beneath mask http www strv com blog masknmbrfac built ai show face beneath mask engin and link project github http github com strvcom strv ml masknmbrfac http github com strvcom strv ml masknmbrfac
atif_hassan,MachineLearning,1618641825.0,[P] PyImpetus - A Markov Blanket based new SOTA feature selection algorithm for python,pyimpetu markov blanket base featur select algorithm select subset featur consid perform individu well group thi allow algorithm select best set featur also select best set featur play well for exampl best perform featur might play well other remain featur taken togeth could perform best featur pyimpetu take account produc best possibl combin thu algorithm provid minim featur subset so decid mani featur take pyimpetu select optim set pyimpetu complet revamp support binari classif multi class classif regress task it test nmbr dataset outperform state art markov blanket learn algorithm along tradit featur select algorithm forward featur select backward featur elimin recurs featur elimin perform comparison for classif task accuraci metric higher score better use regress task mean squar error metric lower score better use the final model use comparison task decis tree score report nmbr fold cross valid dataset sampl featur task type score use featur score use pyimpetu featur select featur select ionospher nmbr nmbr classif nmbr nmbr nmbr nmbr arcen nmbr nmbr classif nmbr nmbr nmbr nmbr alondsnmbr nmbr nmbr classif nmbr nmbr nmbr nmbr slice _local _data nmbr nmbr regress nmbr nmbr nmbr nmbr link github repo http github com atif hassan pyimpetu link pypi http pypi org project pyimpetu pyimpetu alreadi nmbrk download check pleas let know work machin learn project don forget pen feedback doubt comment section and cours forget star github repo thank amaz day
Quantum_Stat,MachineLearning,1619531012.0,"The NLP Index: 3,000+ code repos for hackers and researchers. [Project]",want introduc the nlp index new asset nlp code discoveri it free open public it hous nmbr nmbr code repositori one search includ side bar import topic nlp today the engin search type typo toler crazi fast the index includ arxiv research paper pdf connectedpap link github repo http index quantumstat com
RyanAI100,MachineLearning,1618772283.0,[D] A Rigorous Study on Pretrained Model for NER | Research Papers Summary 014,
pinter69,MachineLearning,1619975673.0,[R] Few-Shot Patch-Based Training (Siggraph 2020) - Dr. Ond≈ôej Texler - Link to free zoom lecture by the author in comments,
NeoDio_02,MachineLearning,1619551730.0,[D] Question on ROUGE scores for evaluating summaries,i project text summar i want run roug benchmark test summar model one thing i confus larg differ score i see differ sourc for exampl http github com andersjo pyroug http github com andersjo pyroug they get roug nmbr f score nmbr paper http ieeexplor ieee org stamp stamp jsp tp arnumb nmbr http ieeexplor ieee org stamp stamp jsp tp arnumb nmbr show roug nmbr f score like nmbr can someon explain discrep roug score work thank
bert4QA,MachineLearning,1618242156.0,[R] KILT: a Benchmark for Knowledge Intensive Language Tasks,
Yuqing7,MachineLearning,1617673931.0,[N] Yann LeCun Team Uses Dictionary Learning To Peek Into Transformers' Black Boxes,a yann lecun team propos dictionari learn provid detail visual transform represent insight semant structur word level disambigu sentenc level pattern format long rang depend captur transform here quick read yann lecun team use dictionari learn to peek into transform black box http syncedreview com nmbr nmbr nmbr yann lecun team use dictionari learn peek transform black box the paper transform visual via dictionari learn contextu embed linear superposit transform factor arxiv http arxiv org pdf nmbr pdf
SZenne_,MachineLearning,1617887636.0,What cloud computing setup should I get for my Deepfakes [R],hi for graduat project i research creation deepfak now i small budget nmbr i would want spend nmbr week op cloud comput comput right requir run deepfak softwar i want nmbr second basic deepfak test softwar so anybodi recommend onlin cloud comput server i could use i look
chasep255,MachineLearning,1620298405.0,[D] Learning a discrete encoding for raw audio.,i work variou way gener music use neural net i start wgan use nmbrd conv produc best result i would realli like use rnn gener audio like would gener text sampl output feed sampl back input next time step sinc audio i use sampl nmbrhz method practic so i decid first use auto encod gumbel softmax thi way i could compress audio data learn discret encod onc i encod i plan train rnn encod like would text i use decod convert sound current best architectur i follow the encod compress audio nmbrx discret represent nmbr differ valu hard gumbel softmax encod expand the expand expand discret represent back length origin raw audio the decod use rnn predict next sampl base prior sampl input expand i tri wavenet instead rnn far rnn produc better result i care qualiti speed encod nmbr mu law encod input _audio kera input none dtype intnmbr x layer embed nmbr nmbr input _audio x layer convnmbrd nmbr nmbr stride nmbr pad x x layer leakyrelu x x layer convnmbrd nmbr nmbr stride nmbr pad x x layer leakyrelu x x layer convnmbrd nmbr nmbr pad x x layer leakyrelu x x layer convnmbrd nmbr nmbr pad x x layer leakyrelu x x layer convnmbrd nmbr nmbr pad x expand input _data kera input none nmbr e layer convnmbrd nmbr nmbr pad kernel _initi random _normal use _bia fals input _data x layer convnmbrd nmbr nmbr pad e x layer leakyrelu x x layer convnmbrd nmbr nmbr pad e x layer leakyrelu x x layer convnmbrdtranspos nmbr nmbr stride nmbr pad x x layer leakyrelu x x layer convnmbrdtranspos nmbr nmbr stride nmbr pad x x layer leakyrelu x decod prior _audio _input kera input none batch _size nmbr state els none dtype intnmbr expand _input kera input none nmbr batch _size nmbr state els none x layer embed nmbr nmbr prior _audio _input x layer concaten axi nmbr expand _input x x layer timedistribut layer dens nmbr x x layer leakyrelu x x layer gru nmbr return _sequenc true state state x x layer gru nmbr return _sequenc true state state x add expand _input help gradient x layer concaten axi nmbr expand _input x x layer dropout nmbr x x layer timedistribut layer dens nmbr x x layer leakyrelu x x layer timedistribut layer dens nmbr x x layer leakyrelu x x layer timedistribut layer dens nmbr x train r mu law encod audio sampl r _prior r nmbr r r nmbr e encod r train train e _sm tf nn softmax e enc _loss tf reduc _mean e _sm tf math log e _sm nmbre nmbr tf math log nmbr tf cast tf shape e _sm nmbr tf floatnmbr e model gumbel _softmax e nmbr convert e one hot represent e tf stop _gradient model argmaxnmbronehot e e e e expand e train train take random chunk expand output sequenc long also add nois r _prior g decod r _prior e train train sound _loss tf reduc _mean tf kera loss spars _categor _crossentropi r g _logit true total _loss sound _loss enc _loss so i would like ask thing nmbr do think way i use gumbel softmax make sens nmbr sinc i use hard version gumbel softmax stop _graident i still need use temperatur paramet anneal nmbr doe loss function make sens i ad enc _loss term output encod add penalti deviat flat distribut i figur like second term elbo loss function use vae i found help model learn use encod nmbr should i use gumbel softmax mayb make sens use normal softmax alway take argmax i figur random add help explor possibl encod nmbr ani thought
glampiggy,MachineLearning,1620164503.0,Is it common for Transfer Learning to decrease the accuracy of a model? [Project],i train pspnet deeplab scratch also use pre train backbon specif urban scene dataset the pre train backbon i use resnet weight download imagenet dataset i train model without freez layer my accuraci model scratch prove higher model pre train backbon my dataset rel small nmbr imag could happen imagenet dataset gener compar specif dataset i work thu limit learn abil or i like done someth wrong
deadmanscurve,MachineLearning,1617728458.0,[Research] How do you train on and evaluate GLUE STS-B?,hello i experi multi task learn i read literatur around i tri benchmark glue task i figur peopl train evalu st b http huggingfac co dataset viewer dataset glue the label similar score two sentenc rang nmbr nmbr spearman correl use evalu if label discret i could train classif model comput float i read train regress model sigmoid activ normal label rang nmbr nmbr if done lnmbr loss use how spearman correl comput exactli thi inform surprisingli difficult find standard benchmark dataset ani info gladli appreci d
miladink,MachineLearning,1618988935.0,[D]Is im2latex considered solved?,i hope know imnmbrlatex dataset openai need infer equat gener latex imag imag i found littl surpris actual littl work done is read equat imag consid solv problem
minimaxir,MachineLearning,1620230683.0,[N] Wired: It Began As an AI-Fueled Dungeon Game. It Got Much Darker (AI Dungeon + GPT-3),http www wire com stori ai fuel dungeon game got much darker if follow drama around ai dungeon good summari good discuss filter algo difficulti
IglooAustralia88,MachineLearning,1617224051.0,[P] How Bad is a Bad Classifier: Is there any signal here?,i text classif problem i classifi song lyric perform artist right i small dataset nmbr lyric two line nmbr differ artist all train dev test set balanc artist as baselin i encod lyric observ use bert perform logist regress i got nmbr top nmbr nmbr top nmbr held test set i sure phrase classifi anyth worth tri improv origin idea compar word level vs subword level nn classifi task like obvious nmbr artist random classifi would nmbr nmbrx seemingli found signal howev hard look nmbr score think anyth i guess question i hope find signal small amount data text classif text baselin implement tri tell data noisi thu experi hard get signific result thank
Separate_Run2806,MachineLearning,1620376282.0,[D] Tool to help ML Engineering follow code best practices.,hello data scienc team involv increas amount ml engin task small knowledg code qualiti best practic made vs code extens help python develop build unit test quickli effici our ai make suggest input gener test file would love hear feedback will give tri it avail www ponicod com http www ponicod com are unit test implement model are ever test code pre process evalu stage
idg101,MachineLearning,1617314266.0,[D] Hyper-parameter tuning takes the majority of my time!,i nmbrth year phd student paper publish alreadi as i come end phd i find i spend major time hyper paramet tune get best perform possibl thi take forev dual gpu machin doe anyon shortcut i tri tune best nmbr nmbr epoch i find good proxi long term valid loss converg the lifecycl research seem come idea tune network show perform better benchmark after time seem like complet wast research cycl spent there better way
Superb-Drawer5214,MachineLearning,1617108593.0,"[D] If the number of machine learning PhD graduate is increasing rapidly, wouldn't it get exponentially harder to be hired at machine learning related jobs without PhD?",it seem everyon want machin learn day phd machin learn increas rapidli wouldn get harder harder employ machin learn relat job without phd
Yuqing7,MachineLearning,1620141876.0,[R] Huawei & Tsinghua U Method Boosts Task-Agnostic BERT Distillation Efficiency by Reusing Teacher Model Parameters,a research team huawei noah ark lab tsinghua univers propos extract then distil etd gener flexibl strategi reus teacher model paramet effici effect task agnost distil appli student model size here quick read huawei tsinghua u method boost task agnost bert distil effici reus teacher model paramet http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr the paper extract distil effici effect task agnost bert distil arxiv http arxiv org pdf nmbr pdf
opensourcecolumbus,MachineLearning,1617938253.0,[P] BERT-based Financial Question Answering System,built product readi project use jina pytorch hug face transform adapt passag rerank approach first retriev top nmbr candid answer rerank candid answer use finbert qa bert base model fine tune fiqa dataset achiev state art result github repo http github com yuanbit jina financi qa search look feedback question what would need make use easi use use case
mridal,MachineLearning,1620289195.0,[D] ACL-IJCNLP 2021 Acceptances are out,how everyon mine accept acl find score nmbr nmbr nmbr
minidiable,MachineLearning,1619767355.0,[D] Object detection - useful resources,hi i work new compani i drone expert knowledg comput vision main expertis control state estim robot one main macro task new job revolv around topic object detect onboard aircraft small medium larg size i know could divid field object detect two main stream data driven approach e g machin learn deep learn base classic approach use classic comput vision howev i never implement object detector i would realli like know histori main tool i use achiev could point use resourc like book onlin cours best coursera link mileston paper youtub video channel etc thank
bendee983,MachineLearning,1618849898.0,[D] The challenges of applied machine learning,from set data infrastructur break silo creat data lake etc collect clean train data set scalabl network comput cluster deal busi object ethic issu appli machin learn real world applic pose challeng absent academ research set four key challeng appli machin learn includ follow defin problem are solv right problem doe align busi object what desir accuraci model are address special problem anyon els solv can solv pre train model need develop model collect train data are public dataset imagenet mscoco etc enough train model probabl can buy data alreadi collect if alreadi data consolid store silo do need clean label data maintain model how much model affect decay how frequent need retrain model do pipelin continu collect maintain data futur gather right team do talent hous do subject matter expert weigh model perform do product manag defin assess busi object machin learn strategi do process get input feedback end user system do softwar engin integr model exist product it staff provid reliabl scalabl infrastructur train infer these challeng discuss latest articl challeng appli machin learn http bdtechtalk com nmbr nmbr nmbr appli machin learn challeng http bdtechtalk com nmbr nmbr nmbr appli machin learn challeng you find lot real world ai a practic guid respons machin learn http appen com real world ai alyssa simpson rochwerg wilson pang
Bitmore11,MachineLearning,1617281029.0,[D][P] Raven Protocol,i look input raven protocol project raven decentr network comput node util idl comput power ai train speed key is protocol could benefit besid ad librari anyth protocol miss solut problem tri solv i experienc machin learn would like input stand benefit raven protocol websit http www ravenprotocol com github http github com raven protocol
Yuqing7,MachineLearning,1617249392.0,[N] Google Research‚Äôs Novel High Efficient Neural Volumetric Representation Enables Real-Time View Synthesis,a googl research team acceler neural radianc field render procedur view synthesi task enabl work real time retain abil repres fine geometr detail convinc view depend effect here quick read googl research novel high effici neural volumetr represent enabl real time view synthesi http syncedreview com nmbr nmbr nmbr googl research novel high effici neural volumetr represent enabl real time view synthesi the paper bake neural radianc field real time view synthesi arxiv http arxiv org pdf nmbr pdf
montebicyclelo,MachineLearning,1620460319.0,[P] Patchless MLP-Mixer,http github com sradc patchless_mlp_mix thi preliminari explor even simpler mlp mixer style architectur
Tolstoyevskiy,MachineLearning,1617215508.0,[D] Comparison of experiment tracking tools,hey r machinelearn a back i publish post compar data version tool http dagshub com blog data version control tool peopl seem find use so i wrote anoth one compar experi track tool mani option choos make sens consid pro con option http dagshub com blog compar ml experi track tool fit data scienc workflow http dagshub com blog compar ml experi track tool fit data scienc workflow my criteria mainli around nmbr what want track nmbr where data save nmbr what visual capabl nmbr how easi set nmbr how stabl nmbr doe support larg scale experiment as usual summari tabl form though articl cours contain detail tabular comparison ml experi track tool http preview redd bnmbrrlshkcqdqnmbr png width nmbr format png auto webp cnmbradeenmbrbeenmbrfnmbrbnmbrfnmbranmbrcbnmbrabnmbr
haipinglu,MachineLearning,1619300697.0,"[P] An introduction to PyKale https://github.com/pykale/pykale‚Äã, a PyTorch library that provides a unified pipeline-based API for knowledge-aware multimodal learning and transfer learning on graphs, images, texts, and videos to accelerate interdisciplinary research. Welcome feedback/contribution!",
stupidMZ,MachineLearning,1617940296.0,"[R]Group-Free 3D Object Detector: New SOTA on ScanNet V2(69.1 mAP@0.25, 52.8@mAP@0.5) and SUN RGB-D(62.8 mAP@0.25 and 42.3 mAP@0.5)üî•",group free nmbrd object detect via transform anoth work msra visual comput group paper link nmbr group free nmbrd object detect via transform arxiv org http arxiv org ab nmbr code link zeliunmbr group free nmbrd group free nmbrd object detect via transform github com http github com zeliunmbr group free nmbrd what a simpl yet effect method directli detect nmbrd object nmbrd point cloud without handcraft heurist point group mechan whi the mainstream point base object detector base heurist point group step complex divers object real scene may lead wrong point assign degrad nmbrd object detect perform shown fig nmbr fig nmbr with heurist point group step point blue box roi pool blue ball vote assign aggreg deriv object featur result wrong assign our group free base approach automat learn contribut point object abil allevi drawback hand craft group http preview redd mnmbrrbtnmbrfnmbrlnmbrsnmbr png width nmbr format png auto webp nmbrcnmbrbnmbrbnmbranmbrfnmbrdnmbrcnmbradnmbrenmbrfcnmbranmbrbnmbr the main idea nmbr use transform decod model relationship point object all point use form featur object weight point automat learn train nmbr a multi stage iter box predict framework adopt spatial encod refin iter stage nmbr a free lunch multi stage ensembl mechan use improv perform overal architectur pointnet use backbon detect head multi stage transform decod shown fig nmbr fig nmbr thi figur illustr simpl architectur approach includ three major compon backbon network extract featur represent point point cloud sampl method gener initi object candid stack attent modul extract refin object represent point http preview redd nmbrqadvidlnmbrsnmbr png width nmbr format png auto webp nmbranmbranmbrbnmbrcccnmbrdnmbrdfnmbrbnmbrdnmbrfbdcnmbrc result veri high perform achiev scannet vnmbr sun rgb d tabl nmbr result scannet vnmbr http preview redd gahnurnglnmbrsnmbr png width nmbr format png auto webp nmbrafnmbrdnmbrdfefnmbrcnmbranmbrfnmbrdnmbr tabl nmbr result sun rgb d http preview redd lsnmbrkckilnmbrsnmbr png width nmbr format png auto webp nmbrabnmbrbnmbranmbrbfafnmbrefddnmbrefnmbrenmbr
giangblackk,MachineLearning,1618393121.0,[R] Time Series Forecasting Survey,i find thorough survey time seri forecast method benchmark doe anyon suggest
sgevorg,MachineLearning,1616600557.0,[N] Aim 2.2.0 is out! Hugging Face integration and advanced params table management ...,hi r machinelearn commun excit launch aim http aimstack io vnmbr nmbr we build open sourc self host tool ai train run comparison it handl nmbr experi simpl straightforward api super easi get start thank incred support help us democrat ai dev tool check new featur play aimstack io http play aimstack io nmbr explor search eyjjagfydcinmbreyjzzxrnmbrawnmbrncyinmbreyjwzxjzaxnnmbrzwnmbrijpnmbrimrpcnmbrbsyxlpdxrsawvycyinmbrzmfscnmbrusinpvbnmbriomnmbrbgwsimludgvycgnmbrsyxrlijpmywxzzswiawnmbrkawnhdgnmbryijpmywxzzswieefsawdubwvudcinmbrinnnmbrzxailcjwbnmbrludhndbnmbrvudcinmbrntbnmbrfswizmnmbrjdxnlzcinmbreyjjaxjjbguionsiywnnmbraxzlijpmywxzzswicnvusgfzacinmbrbnvsbcwibwvnmbrcmljtmftzsinmbrbnvsbcwidhjhynmbrvdbnmbrzxhnmbrijpudwxslcjzdgvwijpudwxsfxnmbrlcjzzwfyynmbrgionsicxvlcnkioijsbnmbrnzlcbibgvnmbriglmighwyxjhbxmubgvhcmnmbrpbmdfcmfnmbrzsahpsawljawmdaxigfuzcbjbnmbrzxhnmbrlnnnmbrynnldcbpbiaodgvzdcwgdmfsksisinyiojfnmbrlcjjbnmbrzxhnmbrrmlsdgvyijpnmbrimdybnmbrvwqnldbnmbrxvciinmbrwyjwyxjhbxmuahbhcmftcynmbrtyxhfayjdlcjncmnmbrcejnmbrunmbrrnmbrbguioltdlcjncmnmbrcejnmbrqnmbrhhcnqiolsibwvnmbrcmljilnmbrsimfnznmbrjlznmbrfnmbrzwqionrydwusimfnznmbrjlznmbrfnmbrzwrbcmvhijoibwluxnmbrhecisimfnznmbrjlznmbrfnmbrzwrmawnmbrlijoibwfnmbriiwicnmbrvlzcinmbreyjjbnmbrxvciinmbrmtasinnnmbrewxlijoxmhnmbrsinblcnnpcnmbrqionsiynmbrsbnmbriiomzhbhnllcjzdhlszsinmbrzmfscnmbrvnmbrfxnmbr below highlight releas check full releas post http medium com aimstack aim vnmbr nmbr nmbr hug face integr nmbrefanmbreecnmbr nmbr huggingfac integr aim hug face http preview redd wnanmbruqnmbrsvzonmbr png width nmbr format png auto webp bnmbrcnmbrcdenmbrddbanmbrecbnmbrcaanmbrenmbranmbr nmbr metric visibl control hide metric still search hide individu metric well collect http redd nmbrnxdnewiwzonmbr gif nmbr column resiz control screen real estat super long param drag column edg back forth resiz http redd xwnkknmbrikwzonmbr gif if yet drop us star support come say hi aim slack commun http slack aimstack io check version let us know improv
doyougitme,MachineLearning,1618477849.0,"""[Discussion]"" Should I be using DVC (Data Version Control) in my day-to-day work?",i follow dvc org http dvc org yet fulli sold i use everyday work dev work ml seem unduli clumsi experiment natur work i guess i sure whether data version problem whether dvc solut i freelanc i sure stack ml dev look like day i curiou know whether dvc form popular part data ml engin stack work individu team if uniqu advantag provid made life better if use or shortcom made give
questions2067,MachineLearning,1619731841.0,[D] Does anyone here have a career in machine learning that they applied to the medical field?,i realli look ask career like learn i current undergrad sure i want topic interest
htahir1,MachineLearning,1617206594.0,[D] Why ML should be written as pipelines from the get-go,thought id share idea multi step fragment approach production ml flaw rather creat abstract gear toward data scientist incentiv write product readi code day nmbr happi hear thought commun http towardsdatasci com ml written pipelin get go bnmbrdnmbrfnmbr http towardsdatasci com ml written pipelin get go bnmbrdnmbrfnmbr
DNA1987,MachineLearning,1619196786.0,[D] 3D CNN how to deal with empty space,hello i work nmbrd cnn i use voxel repres protein one channel amino acid total nmbr channel there lot empti space voxel nmbr channel encod one type amino acid channel even empti it like rgb imag channel integ gradient posit x my current network work coupl sampl need much train somehow i think could like unbal class problem nmbrd space convolut thing confus
Inferrd_F,MachineLearning,1618153944.0,[P] How to make your Models available ?,i creat tool make model avail peopl inferrd com http inferrd com what creat api model second what put model use right train wast time creat monitor infrastructur creat engag demo show user model real condit whi interest you drag drop deploy model simpl afterward call jupyt notebook ide the whole process registr deploy take nmbr minut you know pay hidden fee we charg littl bit price ram we want nmbrmb ram box nmbr per month i infrastructur engin i built i want everyon abl make model what i usual see model sleep shelf somewher forev wait deploy someon els time shine lastli use inferrd com http inferrd com use aw gcp i think aw gcp azur becom expens captiv so i want build tool allow migrat easili make depend ama
Grid_AI,MachineLearning,1617751199.0,[N] Latest Innovations with Grid.ai and PyTorch Lightning,join us april nmbrth nmbr et hear grid ai pytorch lightn latest innov ceo founder william falcon thoma chaton research engin manag thi discuss excel ai research machin learn engin data scientist look new way acceler improv current ai model train process leav tangibl strategi new tool great idea regist submit question william thoma http zoom us webinar regist nmbr wn _ywnmbrhnmbrhsz mxwngaunmbroog http zoom us webinar regist nmbr wn_ywnmbrhnmbrhsz mxwngaunmbroog
Evening-Use-7142,MachineLearning,1617874115.0,[D] Pytorch (geometric) over neo4j,hi are good guidelin best practic cookbook exampl code run pytorch gnn larg cloud base databas neonmbrj my data go store aw use neonmbrj current small db expect grow are good guidelin work data way i know neonmbrj ds librari allow run algorithm directli data wish design the goal current standard one link predict node classif thank
soulslicer0,MachineLearning,1616883606.0,[D] PSA: IEEE PDF Express stores passwords in Plaintext,for cvpr nmbr i use ieee pdf express pdf check servic it ask creat account forc password rule capit letter etc so i foolishli decid use person bank email password i get email say you creat account etc print password right email plain text absolut bullshit
radjeep,MachineLearning,1620015489.0,[Discussion] A very rudimentary solution to the XOR problem with a single layer (excluding output) neural network.,with two input x nmbr x nmbr binari valu nmbr nmbr we two weight w nmbr w nmbr bia unit b our output neuron z henc equat z w nmbr x nmbr w nmbr x nmbr b let say set bia unit nmbr w nmbr nmbr w nmbr nmbr in way output nmbr input combin nmbr nmbr nmbr nmbr requir and output nmbr input nmbr nmbr except case would output nmbr input nmbr nmbr but mitig use addit condit result nmbr output nmbr nmbr output valu nmbr thought
keepthepace,MachineLearning,1619525246.0,[P] I am writing a copyleft license for machine learning models. I'd love some comments and criticism,hello i softwar develop robot lot love open sourc recent event made ponder one could releas train model order keep realli open free i think would love prove otherwis licens applic right train weight differ beast sourc code execut binari so i tri write one modifi affero gpl licens someth fsf explicitli allow faq i post http github com yquemen mlmpl thi actual old subject i saw discuss debian legal mail list nmbr http list debian org debian legal nmbr nmbr msgnmbr html it also crop http list debian org debian devel nmbr nmbr msgnmbr html occasion debian devel http list debian org debian devel nmbr nmbr msgnmbr html discuss nmbr debconf http saimei ftp acc umu se pub debian meet nmbr debconfnmbr high nmbr_machine_learning_threats_and_opportunities_for_debian_and_free_softwar ogv also discuss ffmpeg team http ffmpeg org pipermail ffmpeg devel nmbr juli nmbr html have read mani case opinion i think necessari new licens open sourc train weight necessarili difficult task i think thank previou free softwar effort alreadi nmbr done need adapt exist licens bit explicit model tri shoehorn licens design compil softwar machin learn world i formal train copyright law i realli appreci someon background poke hole proposit everybodi construct critic welcom
P4TR10T_TR41T0R,MachineLearning,1619775478.0,[P] A review of recent research on transformers in vision,hey folk i recent publish releas review transform vision focus last month research i rememb discuss around vision transform particular i would like highlight fact often seen intellectu curios googl train recent deriv model enjoy signific effici outperform efficientnetvnmbr allow deit like hard label distil efficientnetvnmbr normal free network allow hard label distil imagenet transform base model also advantag larg data regim e g imagenet nmbrk googl intern jft nmbrm dataset due reduc induct bia the post discuss discuss includ interact perform visual consid check http iaml github io post nmbr nmbr nmbr transform vision http iaml github io post nmbr nmbr nmbr transform vision one last thing first time i write blog post feedback format content deepli appreci
DAL59,MachineLearning,1619555922.0,[D] Whats the point of CLIP opposed to Dalle?,clip gener weird imag artifact massiv distort often tile screen request object dall hand creat complet normal look pictur time so would anyon use clip
mlconvergence,MachineLearning,1619949450.0,[R] Generative Minimization Networks: Training GANs Without Competition,
cosapocha,MachineLearning,1619473464.0,[P] How would you measure uncertainty in a classification task?,hello everybodi i use dropout deep ensembl evid bay backprop gener sampl measur uncertainti with sampl i comput mean varianc per class see bar overlap sum varianc see big number see two mean high say model reliabl i mean i think lot method i wonder standard guy good idea measur uncertainti model classif thank much
hardmaru,MachineLearning,1620619558.0,[R] Learning Controllable Content Generators,
KirillTheMunchKing,MachineLearning,1617126474.0,[D] Are there any other GAN based image editing projects with an encoder-generator architecture that actually work in real time?,i mostli see gan imag edit project reli pixnmbrpix distil work realtim author use latent space regress analyz leverag composition gan claim encod gener setup work realtim i tri demo github work pretti fast small edit kinda strang hang larger edit in case familiar paper want learn i explain main idea telegram channel http casual_gan nmbr
thedeepreader,MachineLearning,1618683213.0,[P] Demo of Swin Transformer for Object Detection,
Zweiter,MachineLearning,1619199699.0,[R] Sim-to-Real Learning of All Common Bipedal Gaits,
bjourne-ml,MachineLearning,1616320233.0,[D] Thoughts on unlikelihood training/antitraining?,what sub thought unlikelihood train antitrain the idea dirt simpl model want reward likelihood slap unlikelihood say languag model predict next word such model tend say cheat confus guess word alreadi seen for exampl suppos sentenc particular standard likelihood train decod the model given word except last ask predict next word like assign high probabl preced word well known problem lead continu like particular standard likelihood train particular standard likelihood train particular particular standard likelihood train standard particular standard likelihood train train thi lead repetit text unlikelihood train antitrain attempt solv penal model assign probabl mass preced incorrect word suppos part probabl distribut produc model look like p particular standard likelihood train nmbr p particular particular standard likelihood train nmbr p standard particular standard likelihood train nmbr p standard particular standard likelihood train nmbr then calcul unlikelihood penalti alpha log nmbr nmbr log nmbr nmbr log nmbr nmbr nmbr nmbr alpha weight hyper paramet backprop next time model make predict assign less probabl mass preced word increas divers reduc repetit one use case unlikelihood suppos sentenc recent larg scale languag model the target word model predict penal grammat incorrect same perplex accuraci reward model penal here paper explain concept much better i the author claim achiev impress result neural text gener unlikelihood train http arxiv org ab nmbr don say that make inconsist dialogu unlik unlikelihood train http arxiv org ab nmbr
Present-Percentage88,MachineLearning,1619541186.0,[R] Online study: predicting COVID-19 misinformation in Twitter data using AI,hi everyon i conduct user studi master thesi regard explain ai xai solut predict covid nmbr misinform twitter misinform import topic pandem explain ai solut help us detect misinform simultan explain predict key understand work your particip benefici toward battl misinform pursuit toward transpar respons ai dure onlin studi label covid nmbr relat tweet answer set questionnair requir particip at least nmbr year old run studi laptop desktop comput you particip autonom use follow link http userstudi thesi herokuapp com en groupnmbr http userstudi thesi herokuapp com en groupnmbr thank advanc stay safe
fedetask,MachineLearning,1618071318.0,[R] Applications of Graph Neural Networks to Reinforcement Learning,could point paper appli graph neural network reinforc learn task
luisgasco,MachineLearning,1619167986.0,"[R] - Call For Participants MESINESP2 (BioASQ / CLEF2021 shared task) on semantic indexing of heterogenous health content: literature, clinical trials and patents",cfpnmbr mesinespnmbr track medic semant index bioasq clef nmbr http temu bsc es mesinespnmbr http temu bsc es mesinespnmbr mesinespnmbr award bsc plan tl nmbr nmbr test set addit data avail there press need advanc multilingu semant search strategi health relat content like literatur patent clinic trial cross genr the use semant search techniqu combin structur vocabulari critic sophist search content analysi need healthcar profession research pharmaceut industri patient group privat citizen follow impact past bioasq track benchmark studi e g biobert organ initi like biocr iberlef propos three semant label subtrack use wide use dec vocabulari similar mesh term mesinesp l scientif literatur automat label medic literatur abstract spanish includ recent covid nmbr literatur mesinesp t clinic trial automat label clinic trial summari mesinesp p patent automat label health relat patent spanish improv patent intellig key inform web http temu bsc es mesinespnmbr http temu bsc es mesinespnmbr registr http clefnmbr lab registr dei unipd http clefnmbr lab registr dei unipd bioasq task nmbr mesinesp data http doi org nmbr zenodo nmbr http doi org nmbr zenodo nmbr mesinespnmbr organ close collabor wide use multilingu medic literatur databas birem who isciii spain express direct need advanc technolog acceler manual index effort content spanish spoken global nmbr million peopl they face challeng keep increas number publish medic paper use pure manual index a larg manual index collect train document provid these document alreadi automat annot nmbr million entiti mention medic entiti diseas medic procedur drug symptom facilit use complementari strategi like multi label classif multilingu transform graph match text similar advanc term match name entiti recognit compon particip system directli use ongo medic literatur index effort thu improv competit intellig prior art search enabl complex search queri need evid base medicin clinic decis make elabor clinic practic guidelin serv base futur task semant index medic record content languag import date april nmbr updat train valid test set releas april nmbr addit dataset releas medic entiti present document april nmbr bioasqnmbr lab u clef nmbr registr deadlin may nmbr start evalu period may nmbr end evalu period may nmbr submiss particip paper clefnmbr juli nmbr camera readi paper submiss sep nmbr nmbr clef nmbr confer public bioasq clefnmbr workshop team particip mesinespnmbr invit contribut system descript paper bioasq clef nmbr work note proceed short present approach bioasq nmbr workshop main track organ martin kralling barcelona supercomput center bsc spain lui gasc√≥ barcelona supercomput center bsc spain anastasio nentidi nation center scientif research demokrito greec elena primo pe√±a biblioteca nacion de ciencia de salud instituto de salud carlo iii spain cristina bojo canal biblioteca nacion de ciencia de la salud instituto de salud carlo iii spain georg palioura nation center scientif research demokrito greec anastasia krithara nation center scientif research demokrito greec renato murasaki birem organizaci√≥n panamericana de la salud who brasil scientif committe tristan naumann microsoft research usa prof xavier tannier sorbonn universit√© limic franc luci lu wang allen institut ai ainmbr usa prof david camacho appli intellig data analysi research group universidad polit√©cnica de madrid spain prof oscar corcho ontolog engin group universidad polit√©cnica de madrid spain parmind batia amazon health ai usa prof irena spasic school comput scienc informat co director data innov research institut cardiff univers uk jose lui redondo garc√≠a amazon alexa amazon uk carlo baden olmedo ontolog engin group universidad polit√©cnica de madrid spain prof allan hanburi e commerc research unit faculti informat tu wien austria prof alfonso valencia barcelona supercomput center spain prof stefan j darmoni depart biomed informat rouen univers hospit franc limic franc rezarta islamaj nation center biotechnolog inform usa prof rafael berlanga llavori universidad jaum i spain prof hen m√ºller univers appli scienc western switzerland valai switzerland prof gareth j f jone school comput dublin citi univers ireland georg rehm deutsch forschungszentrum f√ºr k√ºnstlich intelligenz germani petr knoth research studio austria forschungsgesellschaft mbh austria natalia manola ceo openair amk greec prof jes√∫ tramulla departamento de ciencia de la documentaci√≥n e historia de la ciencia universidad de zaragoza spain
Intelligent-Fun-5311,MachineLearning,1619703113.0,[P] Real-time Object Detection on Jetson Nano,hi everyon i need help real time object detect jetson nano i train yolovnmbr model back pretti accur give low fp nmbr nano i tri convert model tflite give even lower fp nmbr pleas tell i achiev real time infer without loss accuraci thank advanc
lkncy,MachineLearning,1619314378.0,[P] ESL Solution,i found realli good websit contain solut exercis esl the element statist learn http yuhangzhounmbr github io esl_solut
ML_WAYR_bot,MachineLearning,1619380804.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 111,thi place share machin learn research paper journal articl read week if relat research mean elabor give us insight otherwis could interest paper read pleas tri provid insight understand pleas post thing present wiki prefer link arxiv page pdf easili access pdf summari page way around pertin link previou week nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr week nmbr http www reddit com nmbrqyjiq week nmbr http www reddit com nmbrxwnmbr week nmbr http www reddit com nmbrildf week nmbr http www reddit com nmbrsnmbrknmbru week nmbr http www reddit com nmbrtnnmbrax week nmbr http reddit com nmbrsnmbrelnmbr week nmbr http reddit com bfsxnmbrz week nmbr http reddit com dnmbrvnonmbr week nmbr http reddit com fnmbrfnmbriq week nmbr http reddit com hltnmbro week nmbr http reddit com knmbrywb week nmbr http www reddit com nmbrsnmbrxqm week nmbr http www reddit com nmbracbnmbrt week nmbr http www reddit com nmbrjwde week nmbr http www reddit com nmbrabnmbri week nmbr http www reddit com nmbrwvjfk week nmbr http reddit com anmbropot week nmbr http reddit com blnmbrov week nmbr http reddit com denmbrhnmbr week nmbr http reddit com fnmbrfsnmbrz week nmbr http reddit com hunmbrzqnmbr week nmbr http reddit com khnmbrnx week nmbr http www reddit com nmbrtnmbrmqm week nmbr http www reddit com nmbrcwfbnmbr week nmbr http www reddit com nmbr week nmbr http www reddit com nmbrd week nmbr http www reddit com nmbrexnmbr week nmbr http reddit com anmbryaro week nmbr http reddit com bqlbnmbrv week nmbr http reddit com dkoxnmbr week nmbr http reddit com ffinmbrb week nmbr http reddit com iaznmbr week nmbr http reddit com kpsxtc week nmbr http www reddit com nmbrubnmbrkw week nmbr http www reddit com nmbrfcnmbrmh week nmbr http www reddit com nmbrhhhb week nmbr http www reddit com nmbrjsnmbr week nmbr http reddit com nmbraluh week nmbr http reddit com adnmbrssz week nmbr http reddit com bwnmbrjmnmbr week nmbr http reddit com drnmbrnca week nmbr http reddit com fnnmbrrnmbr week nmbr http reddit com ijjcep week nmbr http reddit com kzevku week nmbr http www reddit com nmbrxomfnmbr week nmbr http www reddit com nmbrhynmbrur week nmbr http www reddit com nmbrteiz week nmbr http www reddit com nmbrbnmbravnmbr week nmbr http reddit com nmbrtnnez week nmbr http reddit com ainmbrgi week nmbr http reddit com cnmbritkk week nmbr http reddit com dxshkg week nmbr http reddit com fvknmbrjnmbr week nmbr http reddit com isnmbrhjnmbr week nmbr http reddit com lnmbrlvg week nmbr http www reddit com nmbrzcyvk week nmbr http www reddit com nmbrkdnmbrvd week nmbr http www reddit com nmbrdnmbrnbnmbr week nmbr http www reddit com nmbrenmbrfxnmbr week nmbr http reddit com nmbrxnmbroj week nmbr http reddit com apnmbrctk week nmbr http reddit com cdnmbrgko week nmbr http reddit com enmbrnmyk week nmbr http reddit com gnmbreavg week nmbr http reddit com jnmbrxrnmbr week nmbr http reddit com ljxnmbrn week nmbr http www reddit com nmbrtnmbrmo week nmbr http www reddit com nmbrobnmbrdx week nmbr http www reddit com nmbrgngwc week nmbr http www reddit com nmbrhccnmbrc week nmbr http reddit com nmbrjmh week nmbr http reddit com aucinmbrc week nmbr http reddit com cjnmbrkyc week nmbr http reddit com ebnmbrlxk week nmbr http reddit com gcxnmbruf week nmbr http reddit com jnmbrcbf week nmbr http reddit com luqbxl week nmbr http www reddit com nmbrheol week nmbr http www reddit com nmbrrnmbryd week nmbr http www reddit com nmbrjgdva week nmbr http www reddit com nmbrkgcqr week nmbr http reddit com nmbrupnmbrg week nmbr http reddit com azjoht week nmbr http reddit com cpnmbrjex week nmbr http reddit com ehbfst week nmbr http reddit com glmnmbrsv week nmbr http reddit com jhzznmbrv week nmbr http reddit com mnmbrunmbrz week nmbr http www reddit com nmbrkvsu week nmbr http www reddit com nmbrttnmbrcz week nmbr http www reddit com nmbrmnmbrlnmbrv week nmbr http www reddit com nmbrnayri week nmbr http reddit com nmbrnnmbrrt week nmbr http reddit com bnmbrrnmbri week nmbr http reddit com cvdenmbra week nmbr http reddit com entcxi week nmbr http reddit com gunmbrtnmbrd week nmbr http reddit com jqjgonmbr week nmbr http reddit com mfnmbrmnmbru week nmbr http www reddit com nmbrsnmbroa week nmbr http www reddit com nmbrwhnmbrwb week nmbr http www reddit com nmbrpnmbrhanmbr week nmbr http www reddit com nmbrqelnmbrp week nmbr http reddit com nmbrcfnmbr week nmbr http reddit com bakewnmbr week nmbr http reddit com dnmbrgnmbrknmbr week nmbr http reddit com euctyw week nmbr http reddit com hddfnmbrj week nmbr http reddit com jznmbrevt week nmbr http reddit com moynmbrm most upvot paper two week ago u evanatyourservic asam http arxiv org ab nmbr u awesomeai make art artifici intellig http www amazon com dp bnmbrjnmbrtnmbrhm besid rule fun
ML_WAYR_bot,MachineLearning,1616961605.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 109,thi place share machin learn research paper journal articl read week if relat research mean elabor give us insight otherwis could interest paper read pleas tri provid insight understand pleas post thing present wiki prefer link arxiv page pdf easili access pdf summari page way around pertin link previou week nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr week nmbr http www reddit com nmbrqyjiq week nmbr http www reddit com nmbrxwnmbr week nmbr http www reddit com nmbrildf week nmbr http www reddit com nmbrsnmbrknmbru week nmbr http www reddit com nmbrtnnmbrax week nmbr http reddit com nmbrsnmbrelnmbr week nmbr http reddit com bfsxnmbrz week nmbr http reddit com dnmbrvnonmbr week nmbr http reddit com fnmbrfnmbriq week nmbr http reddit com hltnmbro week nmbr http reddit com knmbrywb week nmbr http www reddit com nmbrsnmbrxqm week nmbr http www reddit com nmbracbnmbrt week nmbr http www reddit com nmbrjwde week nmbr http www reddit com nmbrabnmbri week nmbr http www reddit com nmbrwvjfk week nmbr http reddit com anmbropot week nmbr http reddit com blnmbrov week nmbr http reddit com denmbrhnmbr week nmbr http reddit com fnmbrfsnmbrz week nmbr http reddit com hunmbrzqnmbr week nmbr http reddit com khnmbrnx week nmbr http www reddit com nmbrtnmbrmqm week nmbr http www reddit com nmbrcwfbnmbr week nmbr http www reddit com nmbr week nmbr http www reddit com nmbrd week nmbr http www reddit com nmbrexnmbr week nmbr http reddit com anmbryaro week nmbr http reddit com bqlbnmbrv week nmbr http reddit com dkoxnmbr week nmbr http reddit com ffinmbrb week nmbr http reddit com iaznmbr week nmbr http reddit com kpsxtc week nmbr http www reddit com nmbrubnmbrkw week nmbr http www reddit com nmbrfcnmbrmh week nmbr http www reddit com nmbrhhhb week nmbr http www reddit com nmbrjsnmbr week nmbr http reddit com nmbraluh week nmbr http reddit com adnmbrssz week nmbr http reddit com bwnmbrjmnmbr week nmbr http reddit com drnmbrnca week nmbr http reddit com fnnmbrrnmbr week nmbr http reddit com ijjcep week nmbr http reddit com kzevku week nmbr http www reddit com nmbrxomfnmbr week nmbr http www reddit com nmbrhynmbrur week nmbr http www reddit com nmbrteiz week nmbr http www reddit com nmbrbnmbravnmbr week nmbr http reddit com nmbrtnnez week nmbr http reddit com ainmbrgi week nmbr http reddit com cnmbritkk week nmbr http reddit com dxshkg week nmbr http reddit com fvknmbrjnmbr week nmbr http reddit com isnmbrhjnmbr week nmbr http reddit com lnmbrlvg week nmbr http www reddit com nmbrzcyvk week nmbr http www reddit com nmbrkdnmbrvd week nmbr http www reddit com nmbrdnmbrnbnmbr week nmbr http www reddit com nmbrenmbrfxnmbr week nmbr http reddit com nmbrxnmbroj week nmbr http reddit com apnmbrctk week nmbr http reddit com cdnmbrgko week nmbr http reddit com enmbrnmyk week nmbr http reddit com gnmbreavg week nmbr http reddit com jnmbrxrnmbr week nmbr http reddit com ljxnmbrn week nmbr http www reddit com nmbrtnmbrmo week nmbr http www reddit com nmbrobnmbrdx week nmbr http www reddit com nmbrgngwc week nmbr http www reddit com nmbrhccnmbrc week nmbr http reddit com nmbrjmh week nmbr http reddit com aucinmbrc week nmbr http reddit com cjnmbrkyc week nmbr http reddit com ebnmbrlxk week nmbr http reddit com gcxnmbruf week nmbr http reddit com jnmbrcbf week nmbr http reddit com luqbxl week nmbr http www reddit com nmbrheol week nmbr http www reddit com nmbrrnmbryd week nmbr http www reddit com nmbrjgdva week nmbr http www reddit com nmbrkgcqr week nmbr http reddit com nmbrupnmbrg week nmbr http reddit com azjoht week nmbr http reddit com cpnmbrjex week nmbr http reddit com ehbfst week nmbr http reddit com glmnmbrsv week nmbr http reddit com jhzznmbrv week nmbr http reddit com mnmbrunmbrz week nmbr http www reddit com nmbrkvsu week nmbr http www reddit com nmbrttnmbrcz week nmbr http www reddit com nmbrmnmbrlnmbrv week nmbr http www reddit com nmbrnayri week nmbr http reddit com nmbrnnmbrrt week nmbr http reddit com bnmbrrnmbri week nmbr http reddit com cvdenmbra week nmbr http reddit com entcxi week nmbr http reddit com gunmbrtnmbrd week nmbr http reddit com jqjgonmbr week nmbr http www reddit com nmbrsnmbroa week nmbr http www reddit com nmbrwhnmbrwb week nmbr http www reddit com nmbrpnmbrhanmbr week nmbr http www reddit com nmbrqelnmbrp week nmbr http reddit com nmbrcfnmbr week nmbr http reddit com bakewnmbr week nmbr http reddit com dnmbrgnmbrknmbr week nmbr http reddit com euctyw week nmbr http reddit com hddfnmbrj week nmbr http reddit com jznmbrevt most upvot paper two week ago u boy_named_su http arxiv org pdf nmbr pdf u vinay_kumarnmbr http acuv com blog machin learn suppli chain http acuv com blog machin learn suppli chain besid rule fun
Programmierer,MachineLearning,1616598438.0,[R] Mastering Real-Time Strategy Games with Deep Reinforcement Learning: Mere Mortal Edition,by employ array techniqu includ novel form automat domain random curricula canonic spatial featur omnisci valu function network architectur design encod task specif invari train deep reinforc learn agent codecraft real time strategi game within hour singl gpu blog post http clemenswint com nmbr nmbr nmbr master real time strategi game deep reinforc learn mere mortal edit http clemenswint com nmbr nmbr nmbr master real time strategi game deep reinforc learn mere mortal edit code http github com cswinter deepcodecraft http github com cswinter deepcodecraft
kul_xjia,MachineLearning,1616341170.0,[R] Neighbor2Neighbor: Self-Supervised Denoising from Single Noisy Images,http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf
KirillTheMunchKing,MachineLearning,1617985631.0,[R] ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement - Explained,restyl a residu base stylegan encod via iter refin http casual_gan nmbr a great idea improv stylegan invers complex real imag build top recent enmbr psp paper the author propos fast iter method imag invers latent space pretrain stylegan gener acheiv sota qualiti lower infer time the core idea start averag latent vector w predict offset would make gener imag look like target repeat step new imag latent vector start point with propos approach good invers obtain nmbr step more detail http casual_gan nmbr the invers awesom http preview redd sanmbrgunmbrdcnmbrsnmbr png width nmbr format png auto webp nmbranmbrabbbnmbrbnmbrbbnmbranmbrfnmbrcnmbrenmbrfdnmbrbbnmbrecnmbr p s in case familiar paper check http casual_gan nmbr
fripperML,MachineLearning,1617172367.0,"[D] What‚Äôs the simplest, most lightweight but complete and 100% open source MLOps toolkit? -> MY OWN CONCLUSIONS",although i post summari thread http www reddit com r machinelearn comment mfcanmbrp d_whats_the_simplest_most_lightweight_but peopl find make visibl i post anoth thread first i thank reddit ml commun gener particular detail insight interest answer i receiv past day i learnt lot pictur head clearer now i post summari thing make sens opinion serv guidelin make decis bare summari gener advic we start reduc set tool use one order flexibl chang adapt project new infrastructur provid could offer us thi someth could happen end end solut there mainli two solut nmbr open sourc free instal use may solv requir ml practition hopswork http hopswork readthedoc io en stabl clearml http allegro ai clearml doc among two i chose one right clearml hopswork might much complet clearml seem bigger commun behind easier instal use so clearml someth take look case go one packag i also like idea platform ui project python program flakenmbr http flakenmbr pycqa org en latest includ flakenmbr docstr mypi http mypi lang org black http black readthedoc io en stabl huge recommend googl style guid http googl github io styleguid pyguid html someth take look thi morn i found guid http cjolowicz github io post hypermodern python nmbr setup might worth cover mani good practic also articl http martinheinz dev blog nmbr regard ide vscode visual studio recommend one vscode poetri http python poetri org also someth consid but also one care current develop state promis mayb pip secur offici way ci deploy jenkin good tool although mayb easiest one gitlab drone circl easier use docker might total need huge recommend becom standard even mani librari reli exampl clearml in addit work well jenkin we switch svn git strongli recommend gitlab http gitlab com good option project scaffold cookiecutt http cookiecutt readthedoc io en nmbr nmbr kedro http kedro readthedoc io en stabl winner i still think stick kedro templat offer extra function i like think project set pipelin run anyway cookiecutt templat good like one http github com tezromach python packag templat in case use kedro clearml figur integr pipelin clearml task but slack channel clearml team least possibl document sphinx http www sphinx doc org en master index html document total recommend googl style docstr napoleon http www sphinx doc org en master usag extens napoleon html use help thi cover document actual code for document busi object project relat stuff could use jupyt notebook order everyth insid repo project registri clearml final chose otherwis migth use intern wiki repositori clear document data explor prepar we use pyspark thing go big panda thing fit memori test i expect great expect librari recommend nobodi told anyth instead unit test smoke test use pytest http doc pytest org en stabl and check jenkin anyway kedro end project templat i keep eye plugin http github com tamsanh kedro great great expect http github com great expect great_expect featur store data version mayb import begin dvc http dvc org doc look good easi use workflow engin orchestr in case one otherwis import piec prefect mayb option i like simplic luigi also tool i like kedro also relat tool defin pipelin care run pipelin deploy sever engin like luigi prefect airflow kubeflow model registri it import depend sever consider if mani model product if model frecuent retrain if lot model train test parallel if model make real time predict perform critic if previou point happen true model registri import piec mlop solut otherwis consid essenti experi it import piec if use clearml solv otherwis might tri mlflow http www mlflow org doc latest index html use kedro mlflow pipelinex http pipelinex readthedoc io en latest hydra http hydra cc doc intro interest addit defin configur although kedro nice way train apart classic librari case dl simplic pytorch light http www pytorchlightn ai first option anyway hardwar limit could issu model fit memori train must distribut problem least foreseen tensorflow pytorch way deal model serv fastapi http fastapi tiangolo com or even simpler dlnmbrj http deeplearningnmbrj org use java need commun rest applic real time other interest solut bentoml http github com bentoml bentoml cortex http www cortex dev take look when high avail import take account redund node resili infraestructur kubernet could solut visual we take look voila http voila readthedoc io en stabl use html streamlit http streamlit io model monitor we could use jenkin pipelin ad hoc schedul process we need tool
KirillTheMunchKing,MachineLearning,1617381315.0,[R] StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery - SOTA StyleGAN image editing,styleclip text driven manipul stylegan imageri http casual_gan nmbr thi idea eleg yet power the author use recent clip model loss function train map network take text descript imag edit e g man long hair beyonc a woman without makeup imag encod latent space pretrain stylegan gener predict offset vector transform input imag accord text descript edit http preview redd kemgnmbrbcfsqnmbr png width nmbr format png auto webp nmbrcnmbranmbrabenmbrefnmbrbafanmbrcanmbrcenmbrfnmbrabnmbrb p s in case familiar paper check http casual_gan nmbr
meldiwin,MachineLearning,1620241072.0,"[N] Joscha Bach ""cognitive Architectures""",hello everyon we ieee soft robot podcast go joscha bach podcast question argument joscha pleas send http doc googl com form e nmbrfaipqlseginmbrwwnnryaxvkfvvrenmbrpbnmbrfknmbrhuusbislnmbrnnmbrbnmbrrnmbrebnmbrneg viewform vc nmbr c nmbr w nmbr flr nmbr gxid nmbr http doc googl com form e nmbrfaipqlseginmbrwwnnryaxvkfvvrenmbrpbnmbrfknmbrhuusbislnmbrnnmbrbnmbrrnmbrebnmbrneg viewform vc nmbr c nmbr w nmbr flr nmbr gxid nmbr thank http preview redd uxjjlnnmbrmcxnmbr png width nmbr format png auto webp dnmbrdbnmbrbfnmbrbnmbreenmbrenmbrdnmbrcenmbraanmbrb
HashRocketSyntax,MachineLearning,1616324158.0,[P] AIQC (deep learning framework) is now seeking collaborators.,aiqc open contributor link low hang fruit github issu http github com aiqc aiqc issu aiqc framework rapid reproduc deep learn aim drive adopt deep learn scientif research it provid object orient python api similar orm serv bumper rail advanc entri level deep learn workflow the high level api allow perform best practic machin learn simpli call aiqc pipelin aiqc experi http aiqc readthedoc io en latest notebook keras_multi label_classif html http preview redd nmbrbxqknmbrgnmbrdonmbr png width nmbr format png auto webp nmbrenmbraddbfbnmbrbcnmbrdnmbrbnmbrcenmbrcnmbrenmbrdnmbrbnmbr
aminnikanjam,MachineLearning,1617047762.0,"[R] A survey on ""Design Smells in Deep Learning Programs""",our research group swat lab polytechniqu montr√©al supervis prof fouts khomh conduct survey design smell deep learn program we prepar onlin survey take around nmbr nmbr minut complet ask relev sever observ design issu dl program we look particip strong background experi research develop deep learn program special convolut network cnn pleas feel free particip find elig moreov could kindli share survey colleagu friend consid elig particip the result survey publicli access arxiv org anonym form at point survey ask name log ip address allow anonym if would like know studi feel free contact us question link http form gle yedpqnmbrdxnmbrtaoxyklnmbr http form gle yedpqnmbrdxnmbrtaoxyklnmbr we realli appreci time support best regard amin nikanjam amin nikanjam polymtl ca fouts khomh swat lab polytechniqu montr√©al montr√©al canada http swat polymtl ca http swat polymtl ca
skwaaaaat,MachineLearning,1617210746.0,[Discussion] Methods for interpreting the meta knowledge learned by meta-learning methods?,hi i tri draw insight meta learn model e g task relationship summar share task structur etc to specif exampl learn certain chemistri dataset good meta learn method implicitli learn share chemistri principl and question could visual interpret learn meta knowledg i find relev literatur topic could someon point right direct thank lot
Seankala,MachineLearning,1619520030.0,[D] Is there any work highlighting the effectiveness of using bilinear transformations for certain tasks?,i recent read paper comput vision titl _learn deep bilinear transform fine grain imag represent zheng et al nmbr _ http arxiv org ab nmbr particular type bilinear transform coin group bilinear claim bilinear transform work well fine grain imag recognit some work natur languag process particular relat extract also claim bilinear classifi layer work well i curiou work detail _why_ may case most materi i read claim transform learn semant group learn pairwis factor usual end ani recommend opinion appreci thank
ydennisy,MachineLearning,1620044509.0,[D] Many Logistic Regression heads.,i interest build find nn architectur would consist network view embed layer mani logreg head top one predict certain class the purpos learn dens represent featur would good predict variou class henc loss lr head need propag network the interest i would architectur work well new unseen class similar domain problem space ha anyon come across model architectur implement
mLalush,MachineLearning,1618474344.0,[D] Why have the standard data formats in object detection remained as COCO/PASCAL VOC/YOLO as opposed to switching over to a nested columnar format?,in imag classif earli standard gener user divid imag file differ train valid folder well sometim requir separ folder class label while research seem held standard api deep learn librari eventu evolv allow flexibl usag necessarili requir user shuffl around imag file folder want adjust train valid setup keep train valid file differ folder probabl certain benefit reproduc research name make abundantli clear train val split perform howev convent enforc introduc someth barrier beginn look train model exist label data minim data wrangl thu exist librari api imag classif seem converg load refer filepath either list tabular columnar format encourag user perform train val split refer data thi allow maximum flexibl user data organ howev wish easili perform whatev augment wish perform split most approach tutori adapt model custom dataset follow standard user defin dataload thi new standard howev seem prolifer user face object detect semant instanc segment librari here might interject point nmbr the data hierarch natur sever bound box polygon coordin rle may exist imag coco pascal voc yolo natur way store data nmbr store hierarch data nest columnar format introduc memori overhead nmbr data format csv tsv work well nest data none opinion convinc argument mani object detect librari need break convent evolv imag classif hierarch data easili store list nest cell datafram we necessarili repeat row howev mani object exist given imag the arrow http arrow apach org instal http arrow apach org instal librari exist store load nest columnar data am i insan think object detect librari api eventu inevit converg standard imag classif api whi alreadi are establish standard entrench torchvis alreadi seem head http pytorch org tutori intermedi torchvis _tutori html http pytorch org tutori intermedi torchvision_tutori html i say librari standard remain pleas organ data specif instruct execut script nmbr poorli document option arg
hardmaru,MachineLearning,1619877683.0,[R] Emerging Properties in Self-Supervised Vision Transformers,
Science_Squid,MachineLearning,1618565067.0,[D] AutoML MOOC,in collabor group work automl develop free mooc topic if like learn automl mooc live http learn ki campu org cours automl luhnmbr http learn ki campu org cours automl luhnmbr in nmbr video overal nmbrh cover hyperparamet optim hpo neural architectur search na bayesian optim bo evolutionari algorithm ea meta learn automl the cours includ quizz code exercis python r allow deepen expertis if interest check trailer cours http youtu nmbrwzsnmbrtgwinmbrg http youtu nmbrwzsnmbrtgwinmbrg edit tri make appar cours free
akirp001,MachineLearning,1617202841.0,[D] Are there any practical reasons for learning about the Boltzmann machines and how they work?,about three year ago i use replic softmax text data requir special embed i final abl appli someth topic i spent ton time tri understand and yet today even use case i would probabl go hug face it seem notabl paper breakthrough use part machin learn journey go last chapter gener model mit book it certainli slog get lot i wonder even worth spend anytim boltzman section
vonum,MachineLearning,1619692257.0,[D] Audio processing on mobile devices,hello anyon audio process mobil devic i troubl find tool audio process what tool use technolog i use tensorflow js load make predict problem howev transform audio input microphon problem due abl find librari
yusuf-bengio,MachineLearning,1617269822.0,[D] Keras: Killed by Google,first rant tensorflow actual later disclaim i work research project teano jax pt tf nmbr nmbr cours origin kera the origin kera high level api specif machin learn realli nice collabor peopl less engin background the api framework agnost main implement support multipl backend teano tensorflow ms cntk essenti api design resembl abstract modern high level framework pytorch lightn fast ai slightli differ design flavor e g kera model combin network metric train code singl object wherea framework usual separ network learner object the huge advantag kera avail api stabl back nmbr nmbr i think someth remark field move fast but know stori googl announc plan incorpor tensorflow nmbr thi problem slowli kill kera nmbr reason nmbr dure time span merg kera api effect frozen make lag behind altern term featur nmbr the releas tfnmbr came late on top first version buggi even lack basic featur nmbr instead make hard cut tf nmbr nmbr googl decid better carri lot baggag crap tfnmbr make framework extrem bloat when someth work get overwhelm long cryptic error messag stacktrac longer screen visual so post realli intend funer kera api look forward know thought edit i noth person googl far i realli like impress contribut ml colab tpu jax stori kera tfnmbr realli frustrat like work past
hyunwoongko,MachineLearning,1616882340.0,[P] Openchat 1.1 is released! (support 30+ conversational model),http preview redd lakinmbrrlnmbrnpnmbr png width nmbr format png auto webp bdbnmbrbenmbrabfanmbrcnmbrenmbrenmbrdnmbranmbrb hello i hyunwoongko made openchat artifici intellig convers framework openchat open sourc framework allow commun artifici intellig one line code today openchat updat version nmbr i write articl unlik engin chang parlai support nmbr convers model if want talk artifici intellig tri instal openchat for inform plz visit http github com hyunwoongko openchat http github com hyunwoongko openchat thank
Pestocalypse,MachineLearning,1620144671.0,[N] Transformer and Capsule co-inventors launch new API-based NLP startup,announc http twitter com aidanngomez statu nmbr http twitter com aidanngomez statu nmbr articl http www theglobeandmail com busi articl toronto startup back ai expert aim bring googl qualiti http www theglobeandmail com busi articl toronto startup back ai expert aim bring googl qualiti some world lead artifici intellig expert back toronto startup co found prot√©g√© ai luminari geoffrey hinton jeff dean attempt make easier human talk machin coher inc offici launch tuesday offer plug compani machin learn softwar internet upload three line code system provid access technolog http archiv dfsxl http www theglobeandmail com topic technolog coher claim softwar provid richer understand human languag includ semant sentiment tone earli investor includ prof hinton univers toronto professor googl engin fellow known godfath deep learn ian goodfellow appl head ai raquel urtasun chief scientist head uber atg research develop divis nvidia ai director sanja fidler ai pioneer fei fei li pieter abbeel toronto ai financi radic ventur wrote first chequ coher
HybridRxN,MachineLearning,1618034652.0,Machine learning is getting easier software engineering still hard [D],hi first discuss post i current ml graduat student univers what think http towardsdatasci com machin learn get easier softwar engin still hard dnmbrenmbrbcnmbr articl will seek current machin learn role replac sophist framework year drive job or job remain stabl complex demand advanc question enabl tool should machin learn enthusiast student interest industri job focu thing difficult autom like data engin data augment devop reliabl interpret someth els kaggl style architectur stack there may evid least nlp with huggingfac autonlp product http huggingfac co autonlp gpt nmbr enabl applic http openai com blog gpt nmbr app i realli curiou hear thought commun edit articl may behind paywal medium use incognito outlin site editnmbr thi gptnmbr think one sampl i think job market continu grow the tool get easier still lot work i think ml commun go figur make tool easier use also make power i think see lot ml engin expert use tool necessarili expert underli algorithm i think alway need peopl design implement new algorithm i think also alway need peopl understand limit tool design experi test new way use tool
Combination-Fun,MachineLearning,1620065927.0,[R] Video explaining Swin Transformers,in paper seri video present latest swin transform hierarch vision transform use shift window paper week hope use understand transform increasingli get use vision task http youtu tfyxjzbabenmbr http youtu tfyxjzbabenmbr
_conquistador,MachineLearning,1620076306.0,[P] Hi r/machinelearning! We created an AI-assisted video annotation tool that speeds up labelling time by 17x - looking for BETA testers to help us refine web application,as part ml postgrad develop tool lab speed video label time nmbr nmbrx use shot classif human loop input e g person label frame algorithm handl rest we look beta tester help refin platform addit real world use case besid earli access platform give earli tester free lifetim access launch pleas fill form get earli access http form gle cgwdnmbrxnvnmbrkwmnmbrynmbr http form gle cgwdnmbrxnvnmbrkwmnmbrynmbr
SherdyRavers,MachineLearning,1616770387.0,[R] I'm currently doing research about Gaussain Processes and I'm trying to develop a deeper understanding. My main concern is GP prior sampling,i hard time understand gaussian process prior sampl here articl medium i use learn gaussian process articl link http towardsdatasci com understand gaussian process socrat way banmbrdnmbr http towardsdatasci com understand gaussian process socrat way banmbrdnmbr i go start explain understand partconfus so get probabl nmbr function use pdf equat i call equat _nmbr http preview redd nmbrctmvnmbrsoydpnmbr png width nmbr format png auto webp nmbrbnmbrbnmbrenmbranmbrbbnmbrcdnmbrfanmbrfecnmbr http preview redd xmhxvnmbrsoydpnmbr png width nmbr format png auto webp nmbrebnmbrbnmbranmbrdfnmbrbnmbracnmbrafanmbrenmbrdcbanmbr then plot function get probabl function use pdf graph i call graph _nmbr i go ask question later http preview redd nmbrhnmbronmbredqydpnmbr png width nmbr format png auto webp nmbrbnmbrbanmbrfdacenmbrednmbrfnmbrcnmbrbnmbr after assum prior sampl use nmbr data point nmbr function obtain i put graph obtain i call graph _nmbr http preview redd bnmbrbwlfdqydpnmbr png width nmbr format png auto webp nmbrdnmbrdfcnmbrdbnmbrcnmbrabnmbrfcenmbrednmbrcnmbranmbreenmbrenmbr p s if understand question i miss detail refer thsi articl miss detail articl link nmbr my question nmbr when train gp prior x x two data point rain data nmbr for graph _nmbr gaussian distribut come also posit function x axi come standard deviat postion function result nmbr for graph _nmbr what axi is result axi standardis e instead show actual result standardis result shown
King-Little,MachineLearning,1619775635.0,[D] M1 MacBooks versus Google Colab for deep learning,i start get deep learn tf kera i point i decid i want develop the thesi project timeseri predict my option pycharm macbook air mnmbr nmbr nmbr nmbrth gen intel inmbr linux desktop googl colab pleas let know other so question i one faster better suit purops mnmbr got hype http machinelearn appl com updat ml comput train mac lot i thought mnmbr would savag desktop acut hype bias purchas decis well slightli better like nmbr nmbrx faster cifarnmbr benchmark i wonder worth effect nmbr nmbr gb ram left maco vs nmbr gb linux machin further colab i realli tell one win race sinc colab limit resourc demand also allow distribut fit cloud tpu would introduc extra code effort then i say ml appl silicon come hand limit http github com appl tensorflow_maco addit inform peculiar miniconda setup http github com appl tensorflow_maco issu nmbr lot issu http github com appl tensorflow_maco issu also sever one like train error etc problem i would even recogn actual realli work is perspect profession data scientist i hope find clear indic i choos
LynnHoHZL,MachineLearning,1619491098.0,[R] EigenGAN: Layer-Wise Eigen-Learning for GANs,we post paper code new work eigengan unsupervisedli learn hierarch interpret dimens gan welcom discuss paper http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf code http github com lynnho eigengan tensorflow http github com lynnho eigengan tensorflow gender http redd nmbrcsinpunmvnmbr gif pose yaw http redd kfnmbrkonmbrcomvnmbr gif paint style http redd zncvnmbranmbrlomvnmbr gif hue http redd dlnmbrlaanomvnmbr gif
jj4646,MachineLearning,1619378764.0,[D] why are neural networks better than polynomial approximation?,ha anyon ever come across formal mathemat explan neural network power polynomi approxim have result e g paper proven conclus show neural network certain advantag polynomi approxim
Yuqing7,MachineLearning,1616720149.0,[N] Tsinghua & MIT‚Äôs P-Tuning Boosts Performance on NLU Benchmarks,tsinghua mit research break stereotyp gpt gener understand languag show gpt compet bert model natur languag understand task use novel p tune method also improv bert perform shot supervis set here quick read gpt understand too tsinghua mit p tune boost perform nlu benchmark http syncedreview com nmbr nmbr nmbr gpt understand tsinghua mit p tune boost perform nlu benchmark the paper gpt understand too arxiv http arxiv org pdf nmbr pdf
austingwalters,MachineLearning,1619503940.0,[P] Data Profiler | What's in your data?,hello r machinelearn i thought commun might interest project i apart our team work python librari call dataprofil http github com capitalon dataprofil the project two object nmbr quickli accur cheapli identifi sensit data pii npi dataset nmbr gener data profil util downstream ml applic regard sensit data detect publish workshop paper model within librari sensit data detect high throughput neural network model financi institut http aaai kdf github io kdfnmbr asset pdf kdf_nmbr_paper_nmbr pdf in addit sensit data detect librari also calcul statist featur gener characterist dataset thi help team quickli evalu dataset also enabl profil use downstream applic some nifti featur commun may interest can load file datafram singl command http capitalon github io dataprofil doc nmbr nmbr html data_read html identifi header format etc extend current entiti detect model transfer learn http capitalon github io dataprofil doc nmbr nmbr html data_label html extend data label transfer learn easi take line code retrain scratch the model work structur csv tsv json etc unstructur data text it possibl though tad rough add new custom model entiti detect http capitalon github io dataprofil doc nmbr nmbr html add_new_model_to_data_label html profil save load merg http capitalon github io dataprofil doc nmbr nmbr html profil html gener look feedback curiou commun think project
regalalgorithm,MachineLearning,1618964072.0,[D] New Tag for Self Promotion Content?,as sub grown becom normal podcast youtub blog creator post link episod video post d text post littl link content there discuss http www reddit com r machinelearn comment jnmbrsnmbryw d_recent_increase_in_self_promotion_cont specif hald year ago i done quit bit co runner two public podcast ai i stop ago sinc felt potenti obnoxi spammi actual i got call newslett post lol still see lot mayb i salti i wonder spirit sub so want share idea perhap tag sp specif self promot thi would differenti d post actual discuss i sure much commun care gramt pretti easi differenti self promot post normal post base titl but still felt like float idea someon sure cool obnoxi
throwaway_secondtime,MachineLearning,1618380124.0,"[D] Sam Altman, Founder of OpenAI, proposes a ""Wealth For All"" plan for dealing with AI disruption",http moor samaltman com
ScienTecht,MachineLearning,1619845553.0,[P] I created a way to learn machine learning through Jupyter,hey i work new way help peopl practic machin learn concept sinc profession data scienc use jupyt notebook i thought realli cool peopl learn interact jupyt notebook well here i written exercis guid build k nearest neighbor classifi scratch as far i know i seen done elsewher pleas check http www confetti ai question nmbr nmbr utm_sourc reddit utm_medium web utm_campaign jupyterhub knn let know think
a_computer_pun,MachineLearning,1617902342.0,[Research] Companies for compiling training data,i wonder anyon use compani use data retriev i need retriev data machin learn train use sampl data event site train web scraper so far i look use fiverr data result pretti hit miss here list i look far idea whether use lionbridg ai amazon mechan turk clickwork appen globalm googl label servic basicai
this_username_is_tkn,MachineLearning,1620337867.0,[Research] Seeing use of ML for ordinary work puts a smile on my face.,the object paper find altern convent method concret mix design for find altern nmbr machin learn algorithm viz multi variabl linear regress support vector regress decis tree regress artifici neural network design concret mix desir properti origin articl http dx doi org nmbr scce nmbr nmbr
Caffeinated-Scholar,MachineLearning,1619117310.0,[R] Outcome-Driven Reinforcement Learning via Variational Inference,
aledinuso,MachineLearning,1618959406.0,[D] When do you start optimizing hyperparameters when trying out a new idea?,when implement new idea i find hard decid much time i spend get work move next one so i would like know peopl optim hyperparamet alway abandon new approach or like last thing alreadi level success
tdls_to,MachineLearning,1618660921.0,[N] Spotify Confidence - open source for analyzing a/b test data,i think librari spotifi open sourc sound pretti use wonder anyon tri similar one recommend http github com spotifi confid
chasep255,MachineLearning,1617278214.0,[D] Using activity regularization instead of batch norm.,is reason i accomplish goal batch normal use activ regular basic i would add penalti loss function layer activ mean zero varianc one there two reason i might prefer method i tri train gan use batch norm behav differ infer train thi caus discrimin abl someth like nmbr accuraci gener also think nmbr accuraci i solv use realli fast momentum nmbr seem like best solut ideal i want someth behav train infer secondli i nmbrgb vram rtx nmbr realli wish i went nmbr thi pose tight constraint batch size depend size model as i understand batch norm work best larg batch least size nmbr i usual train smaller batch i realli think reason tri ani thought also i unsur would best term add loss function i think someth like follow may better way def normal_reg x return tf squar tf reduce_mean x tf squar tf math reduce_vari x nmbr
Purple-Ad-3492,MachineLearning,1619042230.0,[D] Thoughts on using VADER for sentiment analysis on texts other than social media?,given packag design sentiment analysi tune social media twitter nyto amazon movi review i like tool sentiment rate nmbr nmbr scale limit seem constrain far classif system e word phrase pre set unlik sa tool word ad list would simpli classifi posit neutral neg nmbr nmbr scale vader tool construct score given rang base evalu nmbr nmbr token featur nmbr independ human i seen harri potter book project subsect chapter use vader therefor first question pertain thought reliabl result http towardsdatasci com basic nlp text harri potter sentiment analysi nmbrbnmbrbnmbrd i also look non english text translat e text origin written anoth languag use vader sentiment analysi i rather find sort work around translat text perhap translat lexicon txt file code exampl negat booster special_cas word list although i say word translat would effect score english version so mayb prevent hiccup method would translat first use anoth sa tool like dostoyevski russian
rahulkumar1210,MachineLearning,1618165092.0,[P] Footprint recognition using feature extraction algorithm,if someon help project implement pleas repli i implement flow chart attach imag python got stuck stage code error featur extract algorithm use princip compon analysi pca independ compon analysi ica linear discrimin analysi lda vggnmbr vggnmbr inceptionvnmbr resnetnmbr i want use combin classifi knn svm one time i want conclud compar result algorithm declar best process http preview redd tlqwjkznmbrflsnmbr png width nmbr format png auto webp fnmbrenmbrcdbdnmbrfnmbranmbranmbrdnmbrcfnmbreadcnmbrdnmbrcnmbr
sensetime,MachineLearning,1616860563.0,[D] J√ºrgen Schmidhuber's work on fast weights from 1991 is similar to linearized variants of Transformers,i saw schmidhub tweet http twitter com schmidhuberai statu nmbr new blog post http peopl idsia ch juergen fast weight programm nmbr transform html post discuss schmidhub style work nmbr particular use fast weight principl would allow neural net learn program neural net he mention method propos enabl fast weight chang addit outer product self invent activ pattern similar today self attent mechan use transform recent sever variant transform use linear approxim effici purpos work demonstr similar perform version softmax claim similar fast weight apart blog post schmidhub lab also publish articl recent topic linear transform are secretli fast weight memori system http arxiv org ab nmbr in paper also propos better way linear transform inspir techniqu fast weight day show improv compar linear variant transform i think topic discuss would interest forum
VDevAGI,MachineLearning,1616668296.0,[D] Few-shot learning in practice.,although ton shot learn approach come recent year test omniglot miniimagenet like i wonder method work practic use case for instanc latest cvpr nmbr say sota shot paper use industri problem engin or well known baselin approach like rf svm knn beat sota practic robust
begooboi,MachineLearning,1620577957.0,[D] How do we define a discriminative model?,gener model learn distribut data if gener model approxim distribut data discrimin model learn
Equivalent-Choice-75,MachineLearning,1618590893.0,[D] ML PhD at top 5-10 ranked school vs RE at FAANG (Applied teams),hi i tri decid ml phd nmbr nmbr cs school usa mle faang it one appli team pure research team like fair googl brain if go industri eventu goal two option prefer ml phd highli reput take nmbr year finish not sure effort wait worth reward mle might cut edg work focu still product get decent amount engin research product titl role research engin though eventu i love work place like deepmind ai drug discoveri ai climat chang etc toward benefici nmbr year phd start mle re graduat way realli confus make decis thank
hellohihello__,MachineLearning,1616586780.0,[D] [P] Evaluation Metrics for Pre-Trained Faster R-CNN,hi everyon recent i work creat social distanc detect model i use detectronnmbr faster r cnn pre train weight i use video dataset but issu i unabl perform evalu model i know evalu precis recal map etc sinc pre train is way perform evalu pre train faster r cnn i ground truth valu dataset
ProbablyCloseEnough,MachineLearning,1620535166.0,[R] Slurm Interface Investigation Report,thi followup previou thread r slurm interfac survey nmbr minut http www reddit com r machinelearn comment lfnnmbrdnmbr r_slurm_interface_survey_nmbr_minut utm_sourc share utm_medium webnmbrx context nmbr r slurm interfac prototyp evalu survey nmbr minut http www reddit com r machinelearn comment mfnmbri r_slurm_interface_prototype_evaluation_survey_nmbr utm_sourc share utm_medium webnmbrx context nmbr your respons survey help complet coursework human comput interact cours i take thank the first survey instanc needfind i investig user interfac aim find demograph thing tri interfac context task impress interfac use certain target task case schedul comput job share comput resourc use slurm the follow copi paper there takeaway i get survey result most respond use command line interfac presum one slurm provid satisfi unsatisfi most respond use slurm fewer nmbr time per week expect expect comput job high enough complex worth schedul slurm other insight might compromis bia explain i intend take certain step control bias i anticip limit time respons i would gather respons therefor mechan i intend use reduc bia implement one mechan provid survey mandarin addit english i provid english i time verifi mandarin translat thu english liter user overrepres anoth mechan distribut survey differ commun becaus i limit nmbr respons i stop gather respons i could send commun student take cs nmbr georgia tech r machinelearn http www reddit com r machinelearn reddit frequent machin learn research thu academ user research overrepres i abl implement mechan inher survey design show question particip start survey ask question encourag certain respons other i execut one needfind activ i observ nmbr particip target task give option explain action i also perform heurist evalu slurm interfac target task base activ i defin perform goal propos prototyp interfac a new interfac maintain function common task user includ target task well determin avail partit charg id hardwar configur avail comput cluster criteria evalu whether user perform task at time least accur effici compar command line interfac evalu criteria time keystrok click it requir less time fewer keystrok click perform task predict reliabl at time learnabl new user abl learn use within interfac perform least target task without script error caus forget key word syntax the criterion evalu whether new user in term access appropri file place perform least target task must requir mous click finger tap keyboard requir first time authent the criterion evalu whether user the interfac must compat client devic run linux prefer also window maco the interfac must compat slurm server run linux compli term use the criterion evalu whether instal use linux connect slurm server run linux the develop interfac must cost nmbr hour develop time singl research limit experi graphic user interfac develop at time i sure whether i implement interfac upon learn i i decreas import cost i proceed brainstorm nmbr prototyp interfac i use gut feel evalu anticip perform idea term function accuraci effici learnabl access compat complianc cost weight nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr respect the weight cost neg lower better i found top three idea nmbr a simpl execut form nmbr a dag organ job nmbr a run configur avail ide the third one present second survey thi figur http imgur com nmbrmnmbronoh present follow text consid interfac extens instal integr develop environ ide enabl schedul job way user would run local run configur the configur set panel shown figur enabl chang common set enforc valid configur upon click run button interfac attempt schedul job thi figur http imgur com nmbrahnmbrzcx summar respons i got survey becaus respond need perceiv interv respons option constant i statist test i still eyebal result inform subsequ round needfind the main takeaway prototyp might meet effici requir as expect greatest advantag propos interfac command line interfac i determin user typic use seem accur learnabl memor fit better user workflow i surpris mani respond expect perform target task somewhat slower none expect much quickli nmbr expect much slowli an interpret would mani respond experienc use command line interfac would difficult outperform chang suggest feedback next iter prototyp subject develop tri increas effici howev demograph may find sacrific effici worth advantag area i collect inform rel import aspect at point cours assign chang i investig differ interfac i becom busi work sinc i paid anyon continu investig grade longer held hostag i go leav
sarmientoj24,MachineLearning,1619179833.0,"[P] Is it possible to create a benchmark OSes performance in terms of ML training, prediction?",i think possibl topic advanc os small research paper my goal tri check perform evalu differ oper system ubuntu debian fedora mint window cento etc term train predict simpl ml model cnn rnn is possibl benchmark focus oper system if kind tool i use benchmark for exampl check cpu usag ram usag etc i plan follow creat docker contain specifi os start tool benchmark measur start train nmbr start predict nmbr start train nmbr my question would possibl i seen paper tackl os effect machin learn train is measur tool can i given outlin prefer methodolog
meldiwin,MachineLearning,1617817881.0,"[N] Dieter Fox "" The Next Generation Of Robotics"" New Episode",hello guy pleas feel free remov relev we ieee soft robot podcast recent interview prof dieter fox would like feedback episod comment would help futur guest you find episod audio http soundcloud com ieeera softrobot dieter fox next gener robot http soundcloud com ieeera softrobot dieter fox next gener robot video http youtu sstflcoadsc http youtu sstflcoadsc
ilovemouchou,MachineLearning,1619365371.0,[D] Need help figuring out job offers,i got offer amazon research scientist posit one aw custom face team i realli like idea work ml consult super divers project i bit scare potenti pressur hard deadlin might come on hand i got offer googl data scientist posit one trust safeti team in term work life balanc overal employe well googl amaz compani i intern love i afraid data scientist trust safeti could nich i wonder easi would move anoth team within googl coupl year i care much comp i come academia tech job offer feel like i lotteri compar postdoc salari growth opportun within compani posit would perceiv recruit futur i also care flexibl remot work famili europ partner us would great abl spend extend period time contin anoth thing i declin googl offer go amazon harder get googl later
MohamedRashad,MachineLearning,1620348992.0,[D] Is there an idea similar to SPP but for Convolutions ?,i need way keep output last convolut layer fix nmbrxnmbr exampl whatev input size variabl input size fix featur map size do anyon idea someth like
svantana,MachineLearning,1620286725.0,"[D] Is the concept of an 'epoch' being phased out, or even harmful?",i notic trend paper report number train step rather epoch it kinda make sens sinc dataset vari size dozen billion thi got think concept epoch potenti harm enforc idea data someth finit ideal minibatch train approxim iid sampl infinit dataset true distribut what argument iid sampl train data i recent saw someon scatterplot batch loss train thi inform standard loss per epoch plot it could combin move averag latest k batch gaussian confid interv easili ad and iid sampl leftov batch odd size edit the reason came i model train two dataset differ loss i struggl defin epoch dawn even use epoch just sampl data batch work fine and one less nest loop good health
fasttosmile,MachineLearning,1618593591.0,[R] Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little,http arxiv org ab nmbr
adcamuto,MachineLearning,1620562568.0,[R] Explicit Regularisation in Gaussian Noise Injections,thi work studi regularis induc neural network gaussian nois inject gni though inject extens studi appli data studi understand regularis effect induc appli network activ key find the work deriv explicit regularis inject posit term ad loss function obtain marginalis inject nois thi regularis penalis network learn function high frequenc content fourier domain heavili regularis neural network layer closer output see figur illustr arxiv http arxiv org ab nmbr http arxiv org ab nmbr code http github com alexand camuto exp _reg _gni http github com alexand camuto exp_reg_gni figur we illustr effect gni inject throughout network activ each colour dot repres neuron activ we add gni repres circl layer activ bar output layer gni induc network layer learn progress lower frequenc function repres sinusoid match colour correspond layer http preview redd yknmbrzwagnmbrynmbr png width nmbr format png auto webp fnmbrabnmbrccnmbrcanmbrdnmbrcnmbrdnmbranmbrebanmbra
SQL_beginner,MachineLearning,1617811685.0,[D] Feature Selection for Large Datasets,to begin question i would like quot paper ishawaran et al random forest surviv analysi data author concis outlin difficulti featur select e variabl includ statist model classic regress model problem somewhat allevi advanc model further method e classic regress model e g cox ph regress even though semi parametr often parametr nonlinear effect variabl must model transform expand design matrix includ special basi function often ad hoc approach stepwis regress use determin nonlinear effect exist identifi interact especi involv multipl variabl also problemat thi must done brute forc examin two way threeway interact e g must reli subject knowledg narrow search in contrast difficulti handl automat use forest we illustr eas rsf uncov complex data structur depth case studi prognost implic underweight overweight obes sever stabl coronari arteri diseas investig note complex pattern surround possibl revers causat underweight individu interact smoke unclear inflect point point increas bodi mass confer increas risk some identifi possibl obes paradox among patient establish heart diseas increas bodi mass predict better surviv to clarifi issu analyz larg cohort patient coronari arteri diseas undergo isol coronari arteri bypass surgeri use rsf random surviv forest identifi complex relationship long term surviv bodi mass renal kidney function smoke number intern coronari arteri bypass graft we believ novel find help explain appar contradict previous report sourc http arxiv org pdf nmbr pdf essenti author claim tradit regress model struggl featur select newer model e g bag random forest abl better deal featur select i rememb intro stat class somewhat tediou process determin variabl includ multipl linear regress model as author describ i rememb someth call cp mallow criteria potenti variabl repeatedli includ exclud regress model valu cp mallow criteria monitor final select variabl model decid basi criteria howev select process becom ineffici larg dataset i understand correctli mean would refit model mani differ combin variabl result combinator explos larg number variabl like author mention also manual hard code interact term model e g log varnmbr varnmbrvarnmbr varnmbr varnmbrvarnmbr varnmbr varnmbr varnmbr etc infinit number potenti interact improp featur select also result unwant effect multicollinear the last point i would like bring although knowledg mathemat strong enough fulli substanti classic regress model said tendenc overfit i know i seen visual demonstr i know mathemat explan behind empir observ poorli gener new data i know classic regress model abl recogn linearli separ pattern data intuit i understand e g draw circl red point smaller circl blue point fit red circl singl line separ two color i know mathemat explan behind thi bring question featur select larg dataset with advent technolog data becom bigger bigger everyday convolut neural network go method analyz pictur standard black white pictur said nmbr variabl wherea dna said even in instanc sure must imposs address featur select done convent statist model pleas excus poor understand math understand newer statist model built method handl featur select problem for instanc random forest randomli choos differ combin variabl see combin result better model perform exact random mechan uncorrel tree said also prevent multicollinear i ahv heard creator random forest algorithm leo breiman claim theoret statist random forest definit fit desir error bound converg properti true meanwhil i read data scienc blog i go lie deep neural network abl automat learn consid use combin featur approxim target function i correct all i want ask larg dataset sometim featur immedi mean e g patient blood pressur vs inform contain nmbrst pixel photograph real way handl featur select or usual taken care statist model e g random forest neural network i seen exampl onlin peopl attempt write massiv for loop train model thousand variabl combin i sure feasibl can someon pleas provid comment thank
mikegartrell,MachineLearning,1619447583.0,[N] Deadline extended: Call for papers: KDD 2021 Workshop on Bayesian Causal Inference for Real-World Interactive Systems,http bcirwisnmbr github io http bcirwisnmbr github io august nmbr nmbr nmbr final workshop date tbd submiss deadlin extend may nmbr nmbr anywher earth format nmbr page extend abstract refer appendic acm proceed templat submiss websit http cmtnmbr research microsoft com bcirwisnmbr http cmtnmbr research microsoft com bcirwisnmbr increasingli use machin learn build interact system learn past action reward obtain theori suggest sever possibl approach contextu bandit reinforc learn calculu plain old bayesian decis theori what theoret appropri practic approach causal infer interact system we particularli interest case studi appli machin learn method interact system use bayesian likelihood base method discuss choic made term practic theoret argument we also welcom submiss follow area offlin evalu recommend interact system comparison bayesian polici heurist approach offlin metric probabilist approach appli contextu bandit reinforc learn approach probabilist approach increment attribut non bayesian approach trade off bayesian likelihood approach bayesian method product environ organ nichola chopin ensa mike gartrel criteo ai lab dawen liang netflix alberto lumbrera criteo ai lab david rohd criteo ai lab yixin wang uc berkeley
xdtolm,MachineLearning,1618772636.0,[P] VkFFT now supports OpenCL,hello i creator vkfft gpu fast fourier transform librari in latest updat i ad opencl backend option addit vulkan cuda hip interest opencl fft feel free check ask question the perform level backend github link http github com dtolm vkfft http github com dtolm vkfft
zy415,MachineLearning,1616513517.0,[D] IJCAI 2021 Paper Reviews,ijcai nmbr paper review suppos releas soon tomorrow creat discuss thread year review
gokuresearch,MachineLearning,1617167679.0,[D] Is it worth buying a GPU workstation as a graduate student?,i graduat student pursu master thesi i also hope pursu phd futur right i laptop gtx nmbr help lot learn variou algorithm ml dl also indirectli help publish research paper well known confer undergradu but grow comput requir dl i wonder worth invest proper workstat nmbrx rtx nmbr similar high config graduat student alreadi part well fund research lab access gpu cluster lab research work i love person experi explor latest research whenev possibl and current trend requir comput explor thing apart global chip shortag also concern lead increas gpu price overal therefor i would like receiv kind suggest thought note admin pleas let know post scope
thisisdhruvagarwal,MachineLearning,1619340081.0,Bullet Physics vs Pandas3D [D],sinc know mujoco free henc i look altern got bullet physic pandasnmbrd but i sure one use which think easi learn one would prefer
techsucker,MachineLearning,1616957686.0,[R] Researchers at Lawrence Livermore National Laboratory (LLNL) Developed a Novel Deep Learning Framework for Symbolic Regression,at lawrenc livermor nation laboratori llnl scientist develop novel framework accompani visual tool util deep reinforc learn symbol regress problem outperform baselin method benchmark problem their paper recent accept oral present intern confer learn represent iclr nmbr in paper research describ appli deep reinforc learn discret optim discret optim focus problem deal discret build block must combin particular order configur optim desir properti they focus type discret optim call symbol regress symbol regress find short mathemat express fit data gather experi it aim discov underli equat dynam physic process summari http www marktechpost com nmbr nmbr nmbr research lawrenc livermor nation laboratori llnl develop novel deep learn framework symbol regress http www marktechpost com nmbr nmbr nmbr research lawrenc livermor nation laboratori llnl develop novel deep learn framework symbol regress paper http openreview net forum id mnmbrqshnmbrkbqg http openreview net forum id mnmbrqshnmbrkbqg
user692646,MachineLearning,1620387919.0,[D] Element-wise multiplication instead of Convolution,i consid use element wise multipl fundament oper net i want know done literatur the oper singl layer would work follow nmbr given m x n input imag multipli element wise m x n weight matrix nmbr add m x n matrix bias output step nmbr nmbr comput non linear e g relu element wise output step nmbr nmbr use k x k averag pool kernel stride k sampl output step nmbr the reason i consid use oper instead conv layer i think conv layer bit regular problem by i mean convolut oper treat matrix vector multipl input conv layer imag shape column vector matrix would spars if need i could enforc sparsiti later lnmbr regular exampl ha sort oper consid literatur
regularized,MachineLearning,1620406026.0,[D] Have you heard of MBZUAI (Mohamed bin Zayed University of Artificial Intelligence)?,when i look faculti i see promin ml research eric xing le song http mbzuai ac ae studi faculti sec http mbzuai ac ae studi faculti sec have heard univers what think are professor realli base abu dhabi mayb someon cmu eric xing former univers gatech le song former univers comment
mistermysterioyster,MachineLearning,1618110169.0,[D] Paper Reading Group #017 - Adversarial vulnerabilities of human decision-making. (Link to full slides in comments!),
davex32,MachineLearning,1620599656.0,[P] Latest TensorFlow 2.5.0rc3 optimized wheels with CUDA 11 and Python3.9,i built wheel new tensorflow nmbr nmbrrcnmbr cuda nmbr cudnn nmbr case anyon find use thi includ ssenmbr x avxnmbr fma instruct i usual build skylak march case glibc nmbr architectur request depend avail whi use for instal offici binari see warn like your cpu support instruct tensorflow binari compil use avx avxnmbr http github com davidenun tensorflow wheel http github com davidenun tensorflow wheel case anyon find use contribut coffe addict support build relat project http github com sponsor davidenun http github com sponsor davidenun http ko fi com davidenun http ko fi com davidenun say hi davidelnun http twitter com davidelnun twitter
post_hazanko,MachineLearning,1618592038.0,[D] Filling in missing data for bad video on client end,i think would interest applic i start see make blurri imag becom super clear so i wonder would thing point integr model client side think web js video transmiss usual see local sourc crisp recipi littl wors make sens concern accur fill
thunder_jaxx,MachineLearning,1617344522.0,"[D] For Anyone Who Has Clocked More Than 50+ Days Of DL Model Training Time, Do You Use Anything Other Than Adam or AdamW?",for almost all ml project dl i use adamw work so fuck well so question fellow redditor might train model frequent do use differ optim whi do tune beta valu have conscious ever chosen use adam whi i seen recent fanci optim like pcgrad http arxiv org pdf nmbr pdfhttp arxiv org pdf nmbr pdf never found need use when use
brandonrussell757,MachineLearning,1619633167.0,[D] TP/FP Object Detection Question,hey everyon i middl implement map metric scratch i get detail data associ calcul map ie ap precis recal tp fp fn i understand logic behind calcul tp fp tp class detect iou iou _thresh fp class detect iou iou _thresh my question would calcul situat singl predict bound box overlap two more ground truth bound box iou meet iou _thresh ground truth box my initi thought would would rule one highest iou tp other fp am i right assumpt
ilikepancakez,MachineLearning,1618923355.0,Generative Adversarial Transformers [R],
SubstantialRange,MachineLearning,1616789302.0,[D] What are the CASP competition equivalents for scientific fields other than protein folding?,the critic assess protein structur predict bi annual contest measur progress comput method domain protein fold it famous last year deepmind alphafold what similar benchmark scientif field peopl may know
Firehead1971,MachineLearning,1617264663.0,[D] Collecting ideas and hot topics for possible PhD thesis,hi i argentinian ml research begin dissert e choos suitabl interest topic i think would bad could collect hot topic thu simpl overview for exampl edg topic world right which topic still shadow might come soon so i start write come mind transform model still hot topic neural network optim techniqu mathemat comparison basi ml integr differ area life health care road traffic mlop enterpris product environ look realiti make ml understand use ml teach ml comput vision certainli lot possibl also alreadi lot thing done do fanci audio ml classif stuff recogn approach killer insect anim cross field ml biolog you might continu list idea
Puzzleheaded-Drop297,MachineLearning,1617041579.0,"[D] EMNIST dataset down, network unreachable",i use torchvis download emnist dataset but moment can someon send copi thank http www itl nist gov iaui vip cs _link emnist gzip zip http www itl nist gov iaui vip cs_link emnist gzip zip perhap need better way host dataset like the dataset went back onlin
mistermysterioyster,MachineLearning,1616330212.0,[D] Paper Reading Group #014 - Accurate uncertainties for deep learning using calibrated regression.,
AlexCroft-n-Co,MachineLearning,1620629854.0,"[D] New to reddit. Delete or reddit?? Have deleted facebook, instagram and everything else. Your votes matters",privaci concern view poll http www reddit com poll nnmbrynmbrjz
dsmlthrowaway,MachineLearning,1617121603.0,[D] Looking for advice: hiring data practitioners,i work larg compani focus suppli chain medium cost live citi we start incorpor machin learn techniqu improv lot process we good success goal cushion blow invest met so look invest scale team hire mayb nmbr nmbr addit peopl the rub matter i realli sure attract right talent job we need cut edg stuff for busi problem valu immens get someth good enough door pragmat hacker enterpris i come comp sci program background move data basic use tool without much depth knowledg busi domain knowledg know success appli ideal i would love hire problem solver care busi gener valu accomplish i think type posit start pop lot barrier entri decreas i damndest time attract right peopl it realli data scienc role data engin role ml role it kind jack trade a data practition i call i see similar post inde anyon know i could cheat great so question nmbr do guy advic job titl post nmbr what would expect salari rang like type posit midlevel data folk vs mid level program seem pay less i want drive away anyon nmbr what type phrase i use make clear necessarili data scienc role ml role it problem solv role around data i hate anyon disappoint work
Yuqing7,MachineLearning,1618591151.0,[N] ETH Zurich Leverages Spiking Neural Networks To Build Ultra-Low-Power Neuromorphic Processors,a research team eth zurich leverag exist spike base learn circuit propos biolog plausibl architectur highli success classifi distinct complex spatio tempor spike pattern the work contribut design ultra low power mix signal neuromorph process system capabl distinguish spatio tempor pattern spike activ here quick read an error propag spike neural network compat with neuromorph processor http syncedreview com nmbr nmbr nmbr eth zurich leverag spike neural network build ultra low power neuromorph processor the paper an error propag spike neural network compat with neuromorph processor arxiv http arxiv org pdf nmbr pdf
ArulVendhan,MachineLearning,1617187489.0,[P] Hawking Date Time Parser is Open-Source Now,it great pleasur announc natur languag date time parser use stanford corenlp backend open sourc do check let us know feedback github http github com zoho hawk http github com zoho hawk blog http www zoho com blog gener zia nlp base hawk date time parser open sourc html http www zoho com blog gener zia nlp base hawk date time parser open sourc html tweet stanford univers http twitter com stanfordnlp http twitter com stanfordnlp statu nmbr nmbr http twitter com stanfordnlp statu nmbr nmbr nlp stanfordnlp datetimepars
TheElementsOf,MachineLearning,1620638064.0,[D] Trustworthiness in current AI applications,i current research trustworthi current applic ai would like discuss issu i believ import aspect ai use daili basi everyon my main interest automot industri e trust self drive car weaker decis support system drive i believ discuss benefici everyon especi mani peopl differ field contribut subject trust ethic never done one person organis pleas includ idea current futur problem mayb also refer i see main problem trustworthi ai applic interpret black box model howev even research would somehow understand decis process model arriv decis ensur consum safe use machin set process possibl situat outcom anyway on hand model interpret ensur consum data still privat is interpret model problem privaci preserv and explain pro con wide popul
strngelet,MachineLearning,1620054250.0,[P] Python library to boost T5 models speed up to 5x & reduce the model size by 3x,edit tnmbr text text transfer transform larg seqnmbrseq transform model encod decod pre train cnmbr coloss clean crawl corpu dataset flexibl fine tune varieti downstream task it achiev state art result mani nlp benchmark tnmbr model use sever nlp task summar translat q a text gener etc info model refer http ai googleblog com nmbr nmbr explor transfer learn tnmbr html articl googl i want share new librari i work i open sourc link librari github repositori http github com kinmbran fasttnmbr pypi project http pypi org project fasttnmbr logo http preview redd eznmbrghvocnmbrxwnmbr png width nmbr format png auto webp nmbranmbranmbrbnmbrenmbrdnmbrbnmbrenmbrdnmbrenmbrdnmbr titl suggest increas infer speed pretrain tnmbr model also decreas model size singl line code the librari instal pip instal fasttnmbr thi code snippet repositori readm give concis overview usag http preview redd nmbrwkzenmbrlnmbrxwnmbr png width nmbr format png auto webp fnmbracbnmbrenmbrenmbrbbnmbrbnmbrcenmbrdnmbrfnmbraanmbrbfnmbrecnmbr the fasttnmbr librari export tnmbr model onnx past_key_valu quantiz run onnxruntim the export onnx model support gener method huggingfac transform inferenc inform project refer repositori http github com kinmbran fasttnmbr reduc tnmbr model size nmbrx increas infer speed nmbrx
OnlyProggingForFun,MachineLearning,1620476125.0,[R] Learning to Relight Portraits based on the Background,a novel per pixel light represent deep learn framework explicitli model diffus specular compon appear produc relit portrait convincingli render effect like specular highlight thi might great extens realist onlin zoom call background read articl http www louisbouchard ai background light watch video http youtu rvpnmbrtcf_yri whatev prefer refer pandey et al nmbr total relight learn relight portrait background replac doi nmbr nmbr http preview redd enonmbrppwvxnmbr png width nmbr format png auto webp nmbrdnmbrbbanmbrdbanmbrdnmbrdnmbranmbrefnmbrd
pcaversaccio,MachineLearning,1617109338.0,[R] Can Vision Transformers Learn without Natural Images?,
mamrollahi,MachineLearning,1616615847.0,"[D] Compare my word embedding models (Count based, PMI, SPPMI) #",i go build model wiki dump dataset tri compar result wsnmbr word similar so i need check whether understand correct firstli i need read text wiki file token i abl build co occurr matrix i go build co occurr matrix nmbr way base count base pmi base sppmi then i go build embed matrix use svd so i word embed matrix i compar result wsnmbr so way correct thank
New-Psychology-1148,MachineLearning,1620287525.0,[D] Why git is not enough for data science,hi r machinelearn http www reddit com r machinelearn i wrote blog post http dagshub com blog use git data scienc git good enough day day job data scientist i think lot potenti use git combin tool track code take advantag featur also help us track data model what think git ml flow doe anyon know workflow http dagshub com blog use git data scienc http dagshub com blog use git data scienc tl dr git use almost everi softwar develop project track code file chang base abil track everi chang also tremend increas git adopt data scienc project in post discuss nmbr benefit git data scienc nmbr the gap limit git nmbr best practic use git data scienc project
PaganPasta,MachineLearning,1616769689.0,[D]Doubt in Bayes by Backprop,i tri go work http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf blundel et al i familiar bayesian side thing dnn tri summar stuff i understood other much like also i highlight thing i fail understand it help someon clarifi nmbr point estim base mle map give sort solut p w d nmbr p w d written bayesian form intract comput the altern find proxi p w d call variat posterior q w Œ∏ minim l Œ∏ w kl q w Œ∏ p w d nmbr eq nmbr break known elbo form nmbr proposit nmbr introduc generalis gaussian parameteris trick i understand intent behind somewhat get proof result part where first term right hand express come help nmbr l Œ∏ w estim empir mont carlo sampl eq nmbr nmbr the gaussian variat posterior estim part appli proposit nmbr practic howev eq nmbr nmbr stem proposit nmbr henc clear nmbr for prior w p w author suggest sampl mixtur nmbr gaussian also appear param prior remain constant train nmbr lastli weight scheme contribut loss param likelihood vs complex i gone coupl blog post proposit nmbr still unclear ani help appreci sorri advanc basic common knowledg
PsychologicalDemand0,MachineLearning,1617212778.0,[R] Explainability Guided Multi-Site COVID-19 CT Classification,happi share recent paper covid nmbr detect ct imag our method achiev state art result multipl dataset sizabl margin explain guid multi site covid nmbr ct classif http arxiv org ab nmbr abstract radiologist examin chest ct effect way screen covid nmbr case in work overcom three challeng autom process limit number supervis posit case ii lack region base supervis iii variabl across acquisit site these challeng met incorpor recent augment solut call snapmix new patch embed techniqu perform test time stabil analysi the three techniqu complementari base util heatmap produc class activ map cam explain method compar current state art obtain increas five percent fnmbr score site rel high number case gap twice larg site much fewer train imag joint work tal shaharabani lior wolf
ai_researcherr,MachineLearning,1617050577.0,[Discussion] AI and Memory Wall,a brief blogpost analyz overhead train recent sota model especi transform argu memori soon becom main bottleneck train flop it would great commun feedback whether agre disagre conclus http medium com riselab ai memori wall nmbrcbnmbrcbnmbrbnmbr http medium com riselab ai memori wall nmbrcbnmbrcbnmbrbnmbr tldr the comput cost train recent sota transform base model nlp scale rate nmbrx nmbryr model paramet count scale nmbrx nmbryr in contrast gpu tpu dram capac scale rate nmbrx nmbryr in meantim peak hardwar flop scale rate nmbrx nmbryr to put number perspect peak hardwar flop increas nmbr nmbrx dram interconnect bandwidth scale factor nmbrx past nmbr year no exponenti continu forev delay exponenti rate nmbrx nmbryr feasibl long we need rethink train deploy design ai model hardwar deal increasingli challeng memori wall
kaleb7589,MachineLearning,1617994609.0,[N] GTC 2021 Free Registration,free gtc nmbr registr http www nvidia com en us gtc ncid gtcsnmbr nvkasmith sign folk free amaz talk key note want miss
bendee983,MachineLearning,1619457034.0,[R] ThreeDWorld Transport Challenge -- Embodied AI,new challeng research ibm mit stanford aim provid realist simul environ train test rl model task motion plan tamp problem the challeng take place threedworld environ visual audibl physic realist simul the agent place insid multi room hous must locat carri object specifi destin within specifi number step the agent two arm robot it carri two item simultan but environ also contain agent use carri multipl item the agent must find right balanc explor carri task use contain etc accord research pure end end rl approach perform poorli challeng on hand hybrid approach rl agent control rule base high level planner improv perform though problem still far solv the challeng make use simplif term comput vision action state complex agent use magnet hand need handl object finger environ view first person though agent provid rgb depth segment map movement rotat limit specif increment nmbrm movement nmbr degre rotat the challeng still open submiss present cvpr embed ai workshop june it interest see new innov challeng usher full stori comment lead research http bdtechtalk com nmbr nmbr nmbr reinforc learn embodi ai http bdtechtalk com nmbr nmbr nmbr reinforc learn embodi ai challeng websit http tdw transport csail mit edu http tdw transport csail mit edu gym code tdw environ http github com chuangg tdw transport challeng starter code http github com chuangg tdw transport challeng starter code arxiv paper http arxiv org ab nmbr http arxiv org ab nmbr
SomeParanoidAndroid,MachineLearning,1617579186.0,[D] Practical tips for Active Learning (my approach does not outperform random sampling),hello fellow practition i dataset classif label process output comput expens physic simul i run everi datapoint so i propos incorpor activ learn framework limit amount data need i implement approach es yarin gal et al deep bayesian activ learn imag data http arxiv org ab nmbr in use mc dropout bayesian neural network take advantag abil quantifi uncertainti predict thi allow appli acquisit function pool unlabel data includ argmax datapoint train set everi iter my problem function better randomli choos train instanc everi time dataset the paramet set correspond figur i show follow self explanatori i believ specif paramet mc dropout cnn dropout_p nmbr higher valu make network less certain reg nmbre nmbr higher valu make network less certain mc_sampl nmbr the higher number accur predict paramet activ learn iter initial_dataset_s nmbr nmbr train dataset nmbr datapoint training_set_incr nmbr how mani new datapoint add pool everi iter training_epochs_per_iter nmbr for refer train full dataset converg nmbr epoch i experi differ valu run comparison take half day i would grate anyon dealt situat pratic tip choos appropri valu guestim anyon welcom well briefli i found increas initial_dataset_s nmbr training_epochs_per_iter nmbr provid advantag random sampl meddl regular valu howev help result i show best i get far comparison perform differ acquisit function function size dataset http preview redd nmbrbzrajnmbrprnmbrrnmbr png width nmbr format png auto webp nmbranmbrcffnmbracnmbrcbdnmbrccccnmbrcecnmbreenmbrbnmbrbnmbrbnmbrcbnmbr
Competitive-Rub-1958,MachineLearning,1620563385.0,[D] Are ViT's good enough for moderate/low data conditions?,the og vit pretti data heavi improv data effici flavour but signific advanc place like cifar nmbr without huge pre train dataset i would hardli classifi imagenetnmbrk someth use real world i nmbrk imag nmbr class million song dataset pre train nmbrk subset magnatun fine tune should i use latest visual transform standard cnn thank take time address queri
