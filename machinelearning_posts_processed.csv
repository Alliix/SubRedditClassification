Author,Subreddit,Date,Title,Post
SisyphusGuy,MachineLearning,1617898792.0,[D] Are there any reliable open-source out-of-the-box Face Anti-Spoofing detectors?,look face anti spoof section http paperswithcod com task face anti spoof latest paper code find ani reliabl implement open sourc face anti spoof detector rgb imag implement found paper code requir depth imag make pre train weight avail even make wrong pre train weight avail one actual use box model present veri good gener project ideal would like reliabl passiv face anti spoof detector e detector activ challeng user
dadadidi,MachineLearning,1616942192.0,"[P] Guide: Finetune GPT2-XL (1.5 Billion Parameters, the biggest model) on a single 16 GB VRAM V100 Google Cloud instance with Huggingface Transformers using DeepSpeed",need finetun gptnmbr nmbr billion paramet model project model fit gpu figur run deepspe gradient checkpoint reduc requir gpu memori fit one gpu explain setup command get run http github com xirid finetun gptnmbrxl http github com xirid finetun gptnmbrxl wa also abl fit current largest gpt neo model nmbr b paramet one nmbr gb vram gpu finetun think might issu huggingfac implement hope thi help peopl also want finetun gptnmbr want set distribut train
mroc_lak,MachineLearning,1616579417.0,[D] How does one test for shortcut learning of deep neural networks in computer vision?,hi come across review covid nmbr diagnosi base chest x ray mani studi flaw learn shortcut e g use hospit specif token imag doe one systemat test neural net use ani shortcut
jafioti,MachineLearning,1617299891.0,[D] Adaptive Computation Time Uses?,read paper adapt comput time http arxiv org ab nmbr http arxiv org ab nmbr alex grave ago onli play around basic question whi ha thi use onli mainstream project seen wa albert one version use adapt comput time determin number copi layer run seem like thi would huge import allow iter refin specul output like mani network dynam number time decid network origin wa implement rnn think pretti trivial implement architectur would sure think thi could implement mixtur expert model model rerun layer choos differ expert time could allow big paramet space without constrain use one two expert forward pass mayb overhyp act realli veri use ani reason seen widespread adopt
goktugkt,MachineLearning,1618608106.0,[P] Minimal PyTorch Library for Natural Evolution Strategies,http github com goktugnmbr ne torch main goal thi project wa test new configur system librari pipc http github com goktugnmbr pipc see practic write librari also act exampl pipc also support mpinmbrpi without chang anyth run script mpirun train parallel
Yuqing7,MachineLearning,1618587259.0,[N] ETH Zurich & UC Berkeley Method Automates Deep Reward-Learning by Simulating the Past,research team eth uc berkeley propos deep reward learn simul past deep rlsp algorithm repres reward directli linear combin featur learn self supervis represent learn enabl agent simul human action backward time infer must done quick read eth zurich uc berkeley method autom deep reward learn simul past http syncedreview com nmbr nmbr nmbr eth zurich uc berkeley method autom deep reward learn simul past paper learn simul past arxiv http arxiv org pdf nmbr pdf
BRadoslaw,MachineLearning,1620071706.0,[D] Transformer Positional Embeddings for the nth time - are the representations unique?,hi tri get intuit behind posit embed describ famou paper attent need http arxiv org ab nmbr make total sens notic one caveat make case particular token word posit x might result vector anoth word anoth posit let make case representation_nmbr token learn positional_embed posit nmbr representation_nmbr token positional_embed posit nmbr representation_nmbr representation_nmbr would mean word represent uniqu whi doe model learn sequenti natur input case valid http kazemnejad com blog transform _architectur _posit _encod http preview redd tjrnmbrziednywnmbr png width nmbr format png auto webp nmbrebnmbranmbranmbrdnmbrbadnmbrdnmbrfnmbrdnmbr
limarg,MachineLearning,1618568522.0,[D] Marginal Likelihood Estimation based on VAE,whi margin likelihood estim propos vae base import sampl would expect straightforward way estim margin likelihood base import sampl 𝑝 𝑥 𝑧𝑝 𝑧 𝑝 𝑥 𝑧 𝑞 𝑧 𝑥 𝑞 𝑧 𝑥 𝑑𝑧 𝔼 𝑞 𝑧 𝑥 𝑝 𝑥 𝑧 𝑝 𝑧 𝑞 𝑧 𝑥 howev nmbr origin vae paper author suggest differ method appendix base import sampl good reason thi nmbr author furthermor suggest estim 𝑞 𝑧 𝑥 densiti estim draw sampl whi thi necessari know 𝑞 𝑧 𝑥 explicitli
mistermysterioyster,MachineLearning,1617448235.0,[D] Paper Reading Group #016 - Tackling climate change with machine learning. (Link to full slides in comments!),
yaxu,MachineLearning,1617265002.0,[D] Non-automated machine learning?,machin learn bit unfathom peopl machin learn ai algorithm reason work paper way understand ann get nmbr peopl togeth exchang number adjust state way machin learn without machin guess lot system complex onli work scale would interest least de autom least part machin learn system kid learn sort algorithm like bubblesort school stand line follow algorithm anyth like thi possibl ml algorithm
Tuba202,MachineLearning,1617219025.0,My fork of RameenAbdal's StyleFlow! [P],know styleflow super cool ai http youtu ltnmbrznmbrooaeey edit facial paramet like age gender onli issu run week work final got work decid share work form fork project styleflow fork http github com tubanmbr styleflow made easi long window comput cuda compat gpu pleas take time check exampl http preview redd nmbrlhtfnmbreqnmbrfqnmbr png width nmbr format png auto webp bnmbrdnmbrecdcnmbranmbrdfadnmbrfenmbrbnmbrdbnmbranmbrenmbrfenmbrb
Vegetable_Ganache_37,MachineLearning,1616679356.0,[R] New Pre-Print: Bio-Inspired Robustness: A Review,hello everyon recent ad new pre print human visual system inspir compon help adversari robust studi recent attempt area analyz properti evalu criteria robust pleas let us know think paper ani feedback highli appreci p pleas forgiv word format tt tt first last time thi life els latex way titl bio inspir robust review arxiv link http arxiv org ab nmbr http co mnmbrlzbqqhew amp nmbr abstract deep convolut neural network dcnn revolution comput vision often advoc good model human visual system howev current mani shortcom dcnn preclud model human vision exampl case adversari attack ad small amount nois imag includ object lead strong misclassif object human nois often invis vulner adversari nois fix dcnn taken seriou model human vision mani studi tri add featur human visual system dcnn make robust adversari attack howev fulli clear whether human vision inspir compon increas robust becaus perform evalu novel compon dcnn often inconclus propos set criteria proper evalu analyz differ model accord criteria final sketch futur effort make dccn one step closer model human vision
Seankala,MachineLearning,1618615742.0,[D] If I can't reproduce the exact reported scores of a paper (1-2% difference) then is it okay to report the scores I obtained or should I copy the originally reported scores?,sorri titl littl confus sure mani peopl experienc thi refer situat take code releas author particular model set virtual environ match still reproduc exact report score exact refer differ mayb nmbr nmbr particular sota baselin use show thi behavior get nmbr nmbr differ fine use score copi past origin report score thank
Shoulder_Feeling,MachineLearning,1619417114.0,[Project] DataTap provides droplets ( containers for datasets) to make working on popular deep learning datasets easy.,excit share datatap http www datatap dev open sourc dataset manag tool make easi container dataset let focu machin learn data op datatap let build data set droplet think droplet docker contain data droplet encapsul dataset easili use import share across differ team project data droplet consist nmbr item droplet templat similar docker file thi specifi dataset schema dataset annot metadata media thi typic imag video rich media learn start use thi http github com zensor datatap python http github com zensor datatap python mani machin learn project use proprietari data format requir tool util written scratch accommod onli doe thi slow develop substanti also increas probabl develop introduc bug veri code valid model perform part datatap effort allow machin learn engin focu onli machin learn introduc open sourc data interchang format call droplet data contain format call annot provid standard way describ imag datatap design data platform softwar nmbr machin learn reach media like imag audio video need special data pipelin version manag data much like mlop tool version manag model current project ha common dataset avail download stream nmbr line code coco open image ai food dataset larg person dataset combin vehicl dataset see full list http app datatap dev databas nmbrbnmbrecnmbra bnmbr nmbrcfnmbr banmbr nmbrenmbrcadanmbr http app datatap dev databas nmbrbnmbrecnmbra bnmbr nmbrcfnmbr banmbr nmbrenmbrcadanmbr request ad use open sourc tool import data droplet format use thi exampl http zensor typeform com wxonmbrzlsn http zensor typeform com wxonmbrzlsn
s-lilo,MachineLearning,1620223692.0,[N] Call for Participation in a Shared Task about occupations detection in clinical texts,hi everyon research text mine unit barcelona supercomput center want share inform meddoprof share task current organ focus detect normal profess employ statu clinic text spanish even type entiti might seem realli nich everi day learn import think someon occup radic impact physic mental health habit lifestyl choic even entir medic specialti occup medicin center around thi topic context current pandem mani peopl specif occup special affect instanc health profession essenti worker detect term help research better character health risk specif occup outsid medicin forese system result meddoprof may use field social care human resourc legal nlp even gender studi person think one main contribut task inclus employ statu broad sens annot unemploy retir peopl famili caregiv peopl homeless peopl depend govern subsidi etc strengthen social side thi project addit mention corpu includ nmbr document nmbr differ medic specialti ha normal either european skill compet qualif occup classif esco snome ct multilingu vocabulari hope might inspir similar task languag best knowledg ani similar task yet releas train set week ago june nmbrst releas test set interest task want see annot exampl data annot guidelin pleas check task websit http temu bsc es meddoprof http temu bsc es meddoprof thank read hope see least task
jj4646,MachineLearning,1619072260.0,"[D] is this the ""unanswered question"" of machine learning?",gener perform classifi deep learn ha recent becom subject intens studi deep model typic heavili parametr tend fit train data exactli despit thi overfit perform well test data phenomenon yet fulli understood sourc http proceed mlr press vnmbr belkinnmbra belkinnmbra pdf http proceed mlr press vnmbr belkinnmbra belkinnmbra pdf consensu thi question statist commun thi equival big bang dinosaur go extinct question statist machin learn commun fundament imposs answer thi question extrem difficult veri naïv answer thi question e whi deep learn model gener well unseen data unseen data appar level well repres complex e g non linear combin seen data deep learn model veri good recogn figur complex combin b show nmbr closest friend tell level data probabl display nearest neighbor principl big complex data set small pocket homogen data model use step stone gener thi cours doe explain mathemat whi deep learn model abl gener unseen data thi basic essenc matter deep learn model abl gener unseen data becaus level unseen data similar seen data silli extrem exampl unlik even strongest recurr neural network provid data certain stock nmbr nmbr would abl predict today weather thi becaus data fundament differ allow even best model gener suppos want use regular statist model predict inform normal distribut variabl certain mean standard deviat drastic chang mean standard deviat thi variabl ask previous train model continu make predict assum model know anyth ha chang natur expect predict less accur statist model matter great abl gener unseen data long thi unseen data come ballpark seen data understand thi correctli
RandomTensor,MachineLearning,1618938639.0,[N] Workshop on the Theory of Overparameterized Machine Learning **Going on right now!!**,fyi workshop theori overparameter machin learn topml happen right lot big name hard hit talk thi fascin phenomenon registr free although sure still open http topml rice edu http topml rice edu
universome,MachineLearning,1618499655.0,[P] Aligning Latent and Image Spaces to Connect the Unconnectable,hi want share latest project infinit imag gener http universom github io ali http universom github io ali method work without ani condit learn dataset unrel squar imag http reddit com link mrgrdn video nmbrapkxnmbrasctnmbr player basic work follow way put latent code posit coordin grid imag pixel locat comput pixel interpol nearbi latent code dure train gener frame random posit thi coordin grid feed discrimin test time thi allow us produc imag ani posit infinit plane stitch seamlessli one anoth gener comput imag independ patch like cocogan http arxiv org ab nmbr doe less extrem version inr gan http arxiv org ab nmbr cip http arxiv org ab nmbr independ pixel level thi technic tweak coordin embed make period spatial equivari shift coordin output imag shift accordingli pixel valu common coordin equal numer precis illustr 𝛿 valu coordin shift pixel valu insid circl equal differ gener numer precis http preview redd nmbrwbquwfgsctnmbr jpg width nmbr format pjpg auto webp bnmbrenmbrffecnmbranmbranmbrcdabanmbrbnmbrfnmbranmbrebfnmbrd surpris thing approach work onli dataset natur landscap ha spatial invari imag statist also extent lsun bedroom veri difficult dataset infinit imag gener becaus wall close object make hard imposs extrapol imag left right sinc dataset doe ani pictur wall close object middl model ha nowher learn knowledg result lsun bedroom http preview redd ugyrknposctnmbr jpg width nmbr format pjpg auto webp nmbrenmbrcnmbrbnmbrcnmbrfnmbranmbrdnmbrafcnmbranmbracnmbrc besid also collect preprocess high qualiti dataset nmbrk landscap imag landscap hq unsplash flickr releas soon drawback approach gener patch complet independ limit gener qualiti nmbr experi moreov due patchwis gener model learnt ignor nois inject power tool imag edit thi also happen inr gan cip dataset connect lsun bedroom work onli filter away imag contain spatial invari statist see sec nmbr appendix c ffhq imagenet imagin work see studi thi tabl nmbr nmbr appendix c project page http universom github io ali http universom github io ali code http github com universom ali http github com universom ali paper http arxiv org ab nmbr http arxiv org ab nmbr
pmp-dash1,MachineLearning,1619732343.0,[R] Improving ETA Prediction Accuracy for Long-tail Events - Doordash ML Blogpost,interest improv accuraci long tail event ml model check thi blog articl wrote make doordash deliveri eta nmbr accur order take longer expect arriv ad key histor real time featur mix iter custom loss function improv accuraci predict overal custom experi check technic detail learn long tail predict problem link http doordash engin nmbr nmbr nmbr improv eta predict accuraci long tail event machinelearn http www linkedin com feed hashtag keyword machinelearn highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr datasci http www linkedin com feed hashtag keyword datasci highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr eta http www linkedin com feed hashtag keyword eta highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr map http www linkedin com feed hashtag keyword map highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr logist http www linkedin com feed hashtag keyword logist highlightedupdateurn urn nmbrali nmbraactiv nmbranmbr
amasterblaster,MachineLearning,1619128441.0,[Discussion] Any new / good hyperparam tuning approaches?,look tune veri slow function one call take nmbr min nmbrhr guy handl optim someth thi slow ani good advanc new librari thi problem feel like techniqu use suck look see everyon
grid_world,MachineLearning,1617182279.0,[R] Dataset for research paper,process publish paper deep learn compress compar model origin size perform vs compress size perform dataset major research paper either focu cifar nmbr imagenet imagenet becom infrastructur challeng sinc dataset size upward nmbr gb problem cifar nmbr smaller dataset nmbrk imag scale well model size grow think resnet nmbr bigger therefor suggest dataset sit somewher whose result accept journal confer etc academ point view
regalalgorithm,MachineLearning,1619187929.0,[D] Your Favorite AI Podcasts / Blogs / Newsletters / YouTube Channels?,hi want write littl blog post summar differ way keep ai way podcast blog newslett youtub channel yeah million well curat miss lot stuff date criteria still activ focus primarili ai high qualiti far would appreci suggest ani addit podcast machin learn street talk http www youtub com channel ucmltbahinmbrdmrtnmbrnpvdsoirq lex fridman mainli first nmbr ep gigaom voic ai data skeptic eye ai gradient dissent robot brain work podcast ai today podcast chat time data scienc let talk ai machin trust public gradient toward data scienc analyt vidhya distil person blog lil log http lilianweng github io lil log gwern sebastian ruder alex irpan chri olah democrat autom approxim correct convex path arg min blog bandit academ blog sail blog berkeley ai blog machin learn berkeley blog cmu ml blog ml mit ml georgia tech googl facebook salesforc microsoft baidu openai deepmind journalist karen hao cade metz knight khari johnson newslett last week ai batch ai sebast ruder artifici intellig weekli new wire ai newslett paper code algorithm ai weekli weekli robot import ai deep learn weekli h weekli chinai newslett europeanai newslett youtub channel talk amii intellig http www youtub com channel ucxxisinvrnmbrupxvnmbryuhsgdba cmu ai seminar http www youtub com channel uclhnmbroumbgenmbrwpyvziinmbrng robot institut seminar seri http www youtub com playlist list plcfdnmbrbcnmbrfenmbrdf machin learn center georgia tech http www youtub com channel ucuginmbrcnmbrsnmbr yvinmbrkfdkdunmbraw video robot today http www youtub com channel uctfixxnmbrnjnmbrqz zxgewdcynmbra stanford mlsi seminar http www youtub com channel uczznmbrructabnmbrunmbrqpinmbrhpzeq mit embodi intellig http www youtub com channel ucnxgbvgunmbrinmbrkofooncaw interview see podcast paper summari ai coffe break letitia http www youtub com c aicoffeebreak featur henri ai lab http www youtub com channel uchbnmbrvepynmbrkyvzjjnmbrbgxnpbw yannic kilcher http www youtub com channel uczhmqknmbrmsjgfcctnnmbrxbfew arxiv insight lesson nmbrbluenmbrbrown http www youtub com c nmbrbluenmbrbrown featur jordan harrod http www youtub com channel ucnmbrhnmbrnwntgnmbrxinmbrptnmbrykvsha vcubingx http www youtub com channel ucvnmbrnfnmbrzwevessvcmznmbrmlwnmbra leo isikdogan http www youtub com channel uc yaxubpanmbrhvryfjbkfncja demo bycloud http www youtub com channel ucgfenmbroozdnmbrvjpbnmbrajanuqng two minut paper http www youtub com channel ucbfypyitq nmbrlnmbrupoxnmbrnvctg code bullet http www youtub com channel ucnmbrenmbrqhiyukixghnmbrvvpkhhnmbrq ai http www youtub com c whatsai video
New_Date5540,MachineLearning,1618921283.0,[P] I have created a script to convert video into slides (ppt) for StatQuest,wa wonder get slide video content awesom decid creat script extract slide video use opencv gener ppt slide check code ani feedback would highli appreci repo http github com ninjakx youtub videonmbrppt
VerySecretCactus,MachineLearning,1618782264.0,"[D] Is the ""Super Harsh Guide to ML"" reddit post out of date yet? (2021 version)",last time thi wa post wa year ago wonder anyth chang origin post http www reddit com r machinelearn comment nmbrznmbr d_a_super_harsh_guide_to_machine_learn last year updat http www reddit com r machinelearn comment emmxpnmbr d_is_the_super_harsh_guide_to_ml_reddit_post_out
L-MK,MachineLearning,1620290611.0,[R] Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet,tl dr got scoop mlp mixer releas writeup code model hope someon find interest use late tri coupl variant simpl vision transform better understand make perform well month ago found could replac attent layer feed forward layer get quit good result last week start short writeup experi page see full paper today googl put paper mlp mixer propos exactli architectur saw paper earlier today consid scrap done figur might well put interest github repo http github com lukemela even need attent pretrain model w b log http wandb ai lukemelasnmbr deit experi report even need attent vmlldzonmbrnjuxmzi accesstoken nmbrkebvweuenmbrgdnmbrsnmbrqiavnmbrorconmbrvnmbrglogsinmbrinmbrjnmbrbbnmbrgnmbrenmbrpxnmbrlkknmbrzu experi nmbr page writeup http github com lukemela even need attent blob main even need attent pdf also anyon ha stori get scoop feel free share imagin peopl crazi stori edit wow thank support realli expect thi base suggest also upload version report arxiv http arxiv org ab nmbr http arxiv org ab nmbr
patrickkidger,MachineLearning,1617795134.0,"[P] torchtyping -- documentation + runtime type checking of tensor shapes (and dtypes, ...)",hello everyon excit announc torchtyp http github com patrick kidger torchtyp way document check pytorch tensor correct shape dtype name layout turn thi def batch_outer_product x torch tensor torch tensor torch tensor x ha shape batch x_channel ha shape batch y_channel return ha shape batch x_channel y_channel return x unsqueez nmbr unsqueez nmbr thi def batch_outer_product x tensortyp batch x_channel tensortyp batch y_channel tensortyp batch x_channel y_channel return x unsqueez nmbr unsqueez nmbr runtim check size channel line consist bye bye bug say hello enforc clear document code person find leav comment shape tensor code keep track function expect torchtyp design fix thi check document github http github com patrick kidger torchtyp usag exampl way extend torchtyp final curiou look torchtyp faq librari similar thing e g jax torchtyp quit option
Transit-Strike,MachineLearning,1616942574.0,[D] Does Dataset balance matter for a Style GAN?,look classifi class nmbr domin class nmbr lot sampl realli hurt accuraci model sinc strong bia toward one class model blindli assum sampl class nmbr would right veri often style gan look fear similar issu need convert photo fake paint would say easi lot photo paint would someth like affect binari cross entropi think would sinc one class better repres time sinc fake imag gener base real imag could ensur gener number fake imag number real imag class nmbr paint gener nmbr fake paint number photo may may matter sure case would wasserstein loss bce help mitig ani issu sinc care distribut class label
jj4646,MachineLearning,1619072295.0,[D] why did kernel methods become less popular than neural networks?,wa read today earlier neural network popular choic activ function neural network wa radial basi function rbf thi appar whi earlier neural network call kernel approxim thi wa bit surpris see peopl right away assum popular choic activ function neural network relu seem transit away rbf activ function happen around time neural network overtook svm term popular doe anyon know whi thi happen read neural network rbf function also along standard neural network univers approxim properti e theoret abl approxim ani target function ani level accuraci effici thi anoth question reason rbf lost popular doe anyon know whi relu go activ function neural network day guess perhap neural network relu activ abl better consist converg approxim target function compar rbf given resourc e g number neuron layer thank
zhangboknight,MachineLearning,1617946769.0,[P] Colorizing the legacy videos with attention mechanism,recent releas code paper deep exemplar base video color code along colab demo avail http github com zhangmozh deep exemplar base video color http github com zhangmozh deep exemplar base video color welcom tri http preview redd qsxnmbramqnmbrsnmbr png width nmbr format png auto webp nmbreeenmbrcenmbrdbnmbrcnmbrfnmbrcfnmbrbnmbrfnmbrdefnmbrdnmbrf youtub demo avail http youtub com watch v hxwrnmbrhnmbrvvyi featur share http youtub com watch v hxwrnmbrhnmbrvvyi featur share
rafcy,MachineLearning,1617542304.0,[P] Object Detection and Tracking,share thi project github sinc thi version publish codeocean well note chang darknet yolo train weight yolo detector use thi repositori detector tracker object choic languag python project refer thi paper http arxiv org ab nmbr http arxiv org ab nmbr also ieee public found repo descript github repositori http github com rafci harpytm http github com rafci harpytm brief descript main purpos applic extract traffic data vehicl road use aerial footag taken static uav process footag deep neural network detector use yolo alongsid opencv librari order execut python furthermor multipl algorithm use kalman hungarian order match detect sequenti frame extract vehicl trajectori henc veloc move direct vehicl also calcul vehicl everi frame free discuss suggest ani improv featur
Yungpastorphillswift,MachineLearning,1616744476.0,[D] Is it possible to combine the weights of multiple CNN Models?,first want thank guy help given sinc first took dive data scienc machin learn post often gone almost materi resourc data scienc wiki lurk around almost everyday pick littl jewel inform clock nmbr dedic hour learn super excit wild interest thing still know deeper go realiz thi rabbit hole never end real honestli thank guy question current work semi larg scale facial recognit project small group scrape compil label huge dataset imag file aprox nmbrmil imag store cloud databas train model batch download unzip directli cloud notebook idea would extrem time effici everyon group pull differ batch imag train model respect machin combin save weight final model theori idea sound good howev search around googl bit clear thi possibl even benefici idea look ani input direct toward resourc help advic gener thank advanc
optimized-adam,MachineLearning,1620252116.0,[D] Sub-pixel convolutions vs. transposed convolutions,tri understand differ type convolut use upsampl particular differ sub pixel convolut transpos convolut lack thereof current understand equival oper understand author sub pixel convolut shown thi equival origin paper http arxiv org ab nmbr http arxiv org ab nmbr howev differ sub pixel convolut implement effici thi understand correct whi peopl e g http github com atriumlt subpixel http github com atriumlt subpixel strongli recommend sub pixel convolut transpos convolut seem reason perform
natalieberlin,MachineLearning,1618937360.0,[P] Applied our research (ML on dynamic knowledge graphs) to files and documents,built first smart featur app show similar content like need chang say nmbr file invoic contract job post includ address compani descript name iban rout number legal claus open one edit claus chang address iban compani descript engin say nmbr file probabl requir chang use lsh minhash file similar run ml dynam knowledg graph determin nmbr similar file still activ paper quick graphic http preview redd imrsumxnmbrxcunmbr png width nmbr format png auto webp nmbrenmbrdnmbrdbbanmbrdnmbrcbfnmbrenmbranmbr paper http dl acm org doi ab nmbr nmbr http dl acm org doi ab nmbr nmbr http arxiv org ab nmbr http arxiv org ab nmbr http proceed mlr press vnmbr tabibiannmbra http proceed mlr press vnmbr tabibiannmbra http www pna org content nmbr nmbr nmbr short http www pna org content nmbr nmbr nmbr short http dl acm org doi ab nmbr nmbr http dl acm org doi ab nmbr nmbr http dl acm org doi ab nmbr nmbr http dl acm org doi ab nmbr nmbr http arxiv org ab nmbr http arxiv org ab nmbr good measur build littl commun r reason http www reddit com r reason get survey get access close beta reason al http reason al utm_sourc reddit com utm_medium referr utm_campaign comm rd nmbr nmbr mling
svij137,MachineLearning,1620442366.0,[D] Number of businesses that actually spend money on training their own AI models?,look thi data seem report heavili skew toward larger compani like amazon googl get gener answer compani spent nmbrb last year answer look nmbr spend could top nmbr compani best way get around thi
designer1one,MachineLearning,1618667070.0,[P] *Semantic* Video Search with OpenAI’s CLIP Neural Network,made simpl tool let search video semant ai live web app http whichfram com http whichfram com exampl video frame ha person sunglass earphon queri power openai clip neural network perform zero shot imag classif interfac wa built streamlit tri search text imag text imag pleas share discoveri exampl http twitter com chuanenlin statu nmbr http twitter com chuanenlin statu nmbr
ykilcher,MachineLearning,1618150557.0,"[D] Paper Explained - DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning (Full Video Analysis)",http youtu qtunmbrastdenmbri http youtu qtunmbrastdenmbri classic machin learn struggl shot gener task human easili gener hand exampl exampl sort list number human thi come short program algorithm explain data point compact way dreamcod emul thi use neural guid search languag primit librari build time thi iter construct complex program build abstract therefor solv difficult task shot manner gener veri short program solv given datapoint result system onli gener quickli also deliv explain solut problem form modular hierarch learn librari combin thi classic deep learn low level percept veri promis futur direct outlin nmbr nmbr intro overview nmbr nmbr dreamcod system architectur nmbr nmbr wake phase neural guid search nmbr nmbr abstract phase extend intern librari nmbr nmbr dream phase train neural search fiction program replay nmbr nmbr abstract compress program refactor nmbr nmbr experiment result logo draw nmbr nmbr ablat studi nmbr nmbr discov physic law nmbr nmbr discov recurs program algorithm nmbr nmbr conclus discuss paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com ellisknmbr ec http github com ellisknmbr ec
RyanAI100,MachineLearning,1618164984.0,[D] NER for Social Media Texts with Semantic Augmentation | Research Papers Summary 013,
eatpasta_runfastah,MachineLearning,1619618374.0,[D] Masking gradients before the update,hello wa read thi paper learn explan hard vari http arxiv org ab nmbr found rel github repo http github com gibiparanmbr learn explan hard vari blob main notebook linear_regression_ilc ipynb keep short befor updat paramet theta theta lr final_grad pytorch cuda comput default arithmet mean gradient wherea want comput geometr mean appli mask shown code way thi leverag pytorch autograd cuda without need write custom train loop
prestodigitarium,MachineLearning,1619288479.0,"[P] Gourdian Free Dataset Download: OpenStreetMap Points of Interest (Restaurants, Bars, Grocery Stores, Transit, Shops, Swingers Clubs, Hospitals, etc)",hi friend work someth help peopl search filter download subset dataset excit share incorpor point interest openstreetmap broken group ontolog http wiki openstreetmap org wiki key amen http wiki openstreetmap org wiki key shop group tag went peopl think might use mayb make version walkscor perhap cross referenc real estat list find hous within walk distanc bakeri librari cafe pyrotechn shop lovehotelmapp com possibl endless restaur bar http gourdian net g eric osm_points_of_interest restaurants_and_bar amen point interest label bar biergarten cafe fast_food food_court ice_cream pub restaur educ servic http gourdian net g eric osm_points_of_interest education_servic amen point interest label colleg driving_school kindergarten language_school librari toy_librari music_school school univers transport relat http gourdian net g eric osm_points_of_interest transportation_rel amen point interest label bicycle_park bicycle_repair_st bicycle_rent boat_rent boat_shar bus_stat car_rent car_shar car_wash vehicle_inspect charging_st ferry_termin fuel grit_bin motorcycle_park park parking_entr parking_spac taxi financi http gourdian net g eric osm_points_of_interest financi amen point interest label atm bank bureau_de_chang healthcar facil http gourdian net g eric osm_points_of_interest healthcare_facil amen point interest label baby_hatch clinic dentist doctor hospit nursing_hom pharmaci social_facil veterinari entertain http gourdian net g eric osm_points_of_interest entertain amen point interest label arts_centr brothel casino cinema community_centr conference_centr events_venu fountain gambl love_hotel nightclub planetarium public_bookcas social_centr stripclub studio swingerclub theatr public servic http gourdian net g eric osm_points_of_interest public_servic amen point interest label courthous embassi fire_st polic post_box post_depot post_offic prison ranger_st townhal facil http gourdian net g eric osm_points_of_interest facil amen point interest label bbq bench dog_toilet drinking_wat give_box shelter shower telephon toilet water_point watering_plac wast manag http gourdian net g eric osm_points_of_interest waste_manag amen point interest label sanitary_dump_st recycl waste_basket waste_dispos waste_transfer_st amen http gourdian net g eric osm_points_of_interest other_amen amen point interest label animal_board animal_breed animal_shelt baking_oven childcar clock crematorium dive_centr funeral_hal grave_yard gym hunting_stand internet_caf kitchen kneipp_water_cur lounger marketplac monasteri photo_booth place_of_mourn place_of_worship public_bath public_build refugee_sit vending_machin food shop http gourdian net g eric osm_points_of_interest food_shop shop point interest label alcohol bakeri beverag brewing_suppli butcher chees chocol coffe confectioneri conveni deli dairi farm frozen_food greengroc health_food ice_cream organ pasta pastri seafood spice tea wine water gener shop http gourdian net g eric osm_points_of_interest general_shop shop point interest label department_stor gener kiosk mall supermarket wholesal cloth shop http gourdian net g eric osm_points_of_interest clothing_shop shop point interest label baby_good bag boutiqu cloth fabric fashion fashion_accessori jewelri leather sew shoe tailor watch wool second hand shop http gourdian net g eric osm_points_of_interest second_hand_shop shop point interest label chariti second_hand variety_stor health beauti shop http gourdian net g eric osm_points_of_interest health_and_beauty_shop shop point interest label beauti chemist cosmet drugstor erot hairdress hairdresser_suppli hearing_aid herbalist massag medical_suppli nutrition_suppl optician perfumeri tattoo hardwar shop http gourdian net g eric osm_points_of_interest hardware_shop shop point interest label agrarian applianc bathroom_furnish doityourself electr energi fireplac florist garden_centr garden_furnitur ga glazieri groundskeep hardwar housewar locksmith paint secur trade window furnish shop http gourdian net g eric osm_points_of_interest furnishing_shop shop point interest label antiqu bed candl carpet curtain door floor furnitur household_linen interior_decor kitchen lamp light tile window_blind electron shop http gourdian net g eric osm_points_of_interest electronics_shop shop point interest label comput electron hifi mobile_phon radiotechn vacuum_clean vehicl outdoor shop http gourdian net g eric osm_points_of_interest vehicle_and_outdoor_shop shop point interest label atv bicycl boat car car_repair car_part caravan fuel fish golf hunt jetski military_surplu motorcycl outdoor scuba_div ski snowmobil sport swimming_pool trailer tyre hobbi shop http gourdian net g eric osm_points_of_interest hobby_shop shop point interest label art collector craft frame game model music musical_instru photo camera trophi video video_gam stationari gift shop http gourdian net g eric osm_points_of_interest stationary_and_gift_shop shop point interest label anim book gift lotteri newsag stationeri ticket shop http gourdian net g eric osm_points_of_interest other_shop shop point interest label bookmak cannabi copyshop dry_clean e cigarett funeral_director laundri money_lend parti pawnbrok pet pet_groom pest_control pyrotechn religion storage_rent tobacco toy travel_ag vacant weapon outpost user defin bit tri build filter option click button csv arriv hard drive download alway singl csv bundl weird directori structur format csv index filter column type lat long date time moment download part want open licens dataset free download signup requir download open dataset search within across dataset feedback welcom ani dataset like see ad let us know also like updat put dataset got twitter gourdiandata http twitter com gourdiandata
spot4992,MachineLearning,1619196341.0,[D] Going From 4 Core/8 Thread CPU To 32 Core/64 Thread CPU,kind speed could expect go nmbrc nmbrt cpu nmbrc nmbrt cpu train run parallel thread specif method use catboost cpu train consid upgrad cpu significantli thread current cpu want make sure worth find anyth googl
everybody_wants_some,MachineLearning,1618599546.0,[P] Is such a project/task doable using machine learning?,hello everyon hope thi right subreddit thi kind question want apologis advanc problem wa offer solv problem machin learn sure actual possibl could find ani literatur background stori wa offer research internship topic univers would nmbr week full time expect level bachelor thesi master thesi supervisor much knowledg machin learn sinc thi main focu work therefor help much undergrad knowledg machin learn main knowledg classic ml algorithm svm knn etc dl mainli cnn howev sure thi topic solv machin learn ye go describ goal internship expect good possibl goal get accur wind veloc valu small area region use machin learn thing mera dataset ha hourli weather data like wind veloc pressur etc entir world resolut data nmbr km time nmbr km go refer nmbr km nmbr squar big squar one divid europ big squar howev sinc squar veri big accuraci wind veloc good therefor second dataset wind atla dataset ha higher resolut squar nmbr km time nmbr km go name thi squar small squar big squar divid mani small squar approxim nmbr small squar fit one big squar howev thi squar hourli data onli one wind veloc valu per year addit topolog data e g height forest mountain etc lie thi suppos somehow suppos predict help ml thi small squar wind speed dure time past exampl small squar wa wind veloc may nmbr nmbr option nmbr nmbr pm test set onli valu weather station cours veri accur onli veri small region number weather station veri small like mayb nmbr weather station entir germani meanwhil germani consist approxim nmbr big squar nmbr nmbr small squar question much knowledg regard thi kind problem thi actual done machin learn gut instinct sinc seem utopian task seem difficult hardli ani use test data would like verifi way experienc thi doabl gener onli machin learn without ani mathemat method someon knowledg someth like nmbr week doabl method algorithm p sorri format good someon usual post reddit realli need help also sorri ani grammar error sinc nativ speaker
SQL_beginner,MachineLearning,1619582066.0,"[D] understanding the ""bottleneck"" principle in machine learning",http openreview net forum id ry_wpg someon pleas tri explain simpl term bottleneck principl machin learn whi import thank
Massive-Marzipan,MachineLearning,1617927599.0,[P] Feedback requested on nlp project related to news story chains changing over time,thi sub ha veri help past hope get feedback project essenti tri find way detect chang time news narr thi stage appli algorithm success group togeth stori follow develop event need find way track analyz mayb quantifi event coverag chang current approach use topic model find import keyword articl use key word map stori chang overtim basic term identifi key word first articl narr chain compar keyword chang differ key word identifi subsequ articl event doe thi approach sound reason anyth els tri instead thank everyon
kanxx030,MachineLearning,1616756076.0,[D] How to get into prestigious research labs,hi complet master would like explor phd opportun howev hard get touch anyon research group interest mention recent move countri current uk would love get advic commun get notic top research lab way start convers research besid cold email thank advanc
Arioxel_,MachineLearning,1620586861.0,[P] How do you cope with very little data ?,current work project machin learn interpol less know classif output vector float issu veri littl data uniqu set data around nmbr item train test model noth fortun quit simpl pictur whatsoev think could cope thi issu especi divid set train test thought mayb could build new data thin air exampl averag two data
trackerFF,MachineLearning,1616484384.0,[D] What's the most comprehensive book on mathematical theory behind Deep Learning?,hi look book math behind current deep learn topic lot paper read simpli refer ian goodfellow et al book come mathemat proof ha releas ani comprehens book focus mathemat rigor behind deep learn anyth past nmbr nmbr year worth check
QueasyArm8328,MachineLearning,1619987846.0,[Discussion] Graphics in Python,hello wonder librari use graphic python profession ml use pygam pet project someth tell thi industri standard thank
Yuqing7,MachineLearning,1617841746.0,"[N] DeepMind, Microsoft, Allen AI & UW Researchers Convert Pretrained Transformers into RNNs, Lowering Memory Cost While Retaining High Accuracy",research team univers washington microsoft deepmind allen institut ai develop method convert pretrain transform effici rnn transform rnn tnmbrr approach speed gener reduc memori cost quick read deepmind microsoft allen ai uw research convert pretrain transform rnn lower memori cost retain high accuraci http syncedreview com nmbr nmbr nmbr deepmind microsoft allen ai uw research convert pretrain transform rnn lower memori cost retain high accuraci paper finetun pretrain transform rnn arxiv http arxiv org pdf nmbr pdf
study_ai,MachineLearning,1616922070.0,[D][R] Best way to pick up functional analysis for kernel methods' research,look appli phd ml quit possibl research area would kernel method problem never cours function analysi background cs master ml self learn real analysi level babi rudin chapter nmbr nmbr abstract algebra statist probabl stat depart current read casella berger look concis book function analysi nmbr option found kreiszig introductori function analysi applic axler measur integr real analysi problem sure much effort book would like rigor materi simpl exercis someth way simpler babi rudin term exercis would recommend book mayb approach problem incorrectli learn kernel method prerequisit
kaiser_17,MachineLearning,1617537298.0,[D] How is the current research in Long tailed classification?,go lot literatur long tail distribut base classif recent seem cluster paper like belong one nmbr type nmbr sampl base nmbr class weight loss nmbr meta learn base new trend question ani paper go beyond nmbr categori ha research limit onli nmbr
yourpaljon,MachineLearning,1619119971.0,[D] Why isn't quantile regression used more in neural networks?,quantil regress good solut estim uncertainti neural network seen much use ani reason whi
craffel,MachineLearning,1620323975.0,"[R] ICLR Workshop on Enormous Language Models - May 7th, 2021 (livestream)",iclr workshop enorm languag model take place may nmbrth nmbr virtual workshop includ talk panel expert train larg lm goal answer question like scale lead model outperform human text base task limit scalabl model focu simpli scale model design sophist architectur train scheme current benchmark effect test capabl human master larg languag model lack address legal ethic issu aris use unstructur web crawl train languag model learn field cognit linguist philosophi attempt measur intellig machin full inform avail http welmworkshop github io http welmworkshop github io livestream appear http welmworkshop github io livestream http welmworkshop github io livestream
GiuPaolo,MachineLearning,1617648036.0,[R] Call for Papers: Evolutionary Reinforcement Learning workshop @ GECCO 2021,time pass fast onli nmbr week go befor deadlin nmbrst evolutionari reinforc learn workshop gecco nmbr premier confer evolutionari comput thi year held virtual lill franc juli nmbr nmbr nmbr recent year reinforc learn rl ha receiv lot attent thank perform abil address complex task time evolutionari algorithm ea proven competit standard rl algorithm certain problem simpler scalabl recent advanc ea led develop algorithm like novelti search qualiti divers capabl effici address complex explor problem find wealth differ polici result develop spark strong renew interest popul base comput approach nevertheless even ea perform well hard explor problem still suffer low sampl effici thi limit less present rl method notabl becaus sampl reus contrari struggl hard explor set complementari characterist rl algorithm ea push research explor new approach merg two order har respect strength avoid shortcom goal workshop foster collabor share perspect spread best practic within grow commun intersect rl ea topic heart workshop includ evolutionari reinforc learn evolut strategi popul base method polici search neuroevolut hard explor spars reward problem decept reward novelti divers search method diverg search sampl effici direct polici search intrins motiv curios build design behaviour character meta learn hierarch learn evolutionari automl open end learn autor invit submit new origin work new perspect recent publish work topic top submiss select oral present present alongsid keynot speaker jeff clune ex team leader uberai lab current research team leader openai import date submiss deadlin april nmbr nmbr notif april nmbr nmbr camera readi may nmbr nmbr find info workshop websit http site googl com view evorl
Hydra1721,MachineLearning,1620342579.0,"Has There Been Any Follow Up Research Papers for the Anti-FRS AI Called ""Fawkes"" ""[Discussion]""",last year research paper wa publish describ ai could alter imagin certain manner prevent fr correctli identifi individu face without chang appear photo viewer http www theverg com nmbr nmbr nmbr nmbr facial recognit block ai selfi cloak fawk http www theverg com nmbr nmbr nmbr nmbr facial recognit block ai selfi cloak fawk wa state time fawk wa veri comput expens therefor wa unabl perform modif real time sinc public read ani research paper deriv origin work ha ani develop thi field research sinc ha anyon manag develop network run real time
Krisztian_Endre_,MachineLearning,1620639066.0,I am looking for a Final Year Project Idea which can be done in Android [Project],hello second year informat univers student look final year project idea decid work android becaus favorit technolog problem find perfect topic thi purpos want someth basic applic also necessari conduct research
ottawalanguages,MachineLearning,1620432416.0,[D] Reinforcement Learning with R software,reinforc learn seem becom popular topic day doe anyon know peopl work reinforc learn problem use r doe anyon ani link tutori show reinforc learn game theori materi done use r softwar thank
JosiahWGibbs,MachineLearning,1619932666.0,"[D] How do you try out architecture changes, etc. when a model takes days to train?",current train model take extrem long time converg accuracti good excel tri introduc modif architectur tune hyperparamet etc sinc model take long train coupl day close week veri hard get immedi feedback wether chang make mean anyth keep thing worsen notic mani sota model also take extrem long time train thi probabl issu mani peopl use deal research typic deal thi problem ani recomend first thought extract subset dataset train hope result would extrapol whole thing seem result extrapol veri well sometim idea seem work veri well subset introduc ani chang full dataset revers also happen usual wors
DeMorrr,MachineLearning,1619215359.0,[P] TorchPQ: Efficient Nearest Neighbor Search and Clustering on GPUs,hi everyon happi introduc open sourc project work torchpq http github com demoriarti torchpq python librari approxim nearest neighbor search gpu ha effici implement ivfpq http hal inria fr inria nmbrvnmbr document algorithm well variant e g ivfpq r project written mostli python use pytorch librari custom cuda kernel acceler cluster search index torchpq allow search ten thousand queri million vector within second set high recal rate priorit torchpq outperform implement algorithm faiss http github com facebookresearch faiss benchmark result see bottom part readm page also spent lot time optim k mean cluster algorithm gpu result ultra fast memori effici recommend give tri even interest nearest neighbor search project still earli stage could bug perform issu feel free creat issu encount ani contribut welcom
kaia_1527,MachineLearning,1617626377.0,[P] Basic Floor Plan Image Recognition,hi everyon first time poster thi one easi model given imag recogn whether imag floor plan typic residenti properti boolean need anyth els quick train one want check whether gener accept model thank
putinwhat,MachineLearning,1618758422.0,[D] MLOps Stack,research differ librari tool avail use experi reproduc recent implement open sourc tool like mlflow track model storag well dvc data version pipelin gener wa curiou know tool tri work
born_in_cyberspace,MachineLearning,1618471311.0,[R][D] On the Impossibility of Supersized Machines,found excel satir typic argument artifici gener intellig garfinkel et al nmbr imposs supers machin http arxiv org ab nmbr abstract recent year number promin comput scientist along academ field philosophi physic lent credenc notion machin may one day becom larg human mani argu machin could even come exceed human size signific margin howev least seven distinct argument preclud thi outcom show onli implaus machin ever exceed human size fact imposs
divergentdata,MachineLearning,1620228956.0,[D] Leveraging Dropout for Uncertainty Quantification / Adversary Rejection,hey use uncertainti quantif lot work product model risk mitig made write underli idea http www rossidata com dropouttensorflowuncertaintyerrormnist background put demo notebook http github com nicholasarossi uq_method blob master notebook nmbr_neural_network_uncertainty_quantification_with_dropout ipynb would love feedback onli ml engin compani thank
Caffeinated-Scholar,MachineLearning,1617713834.0,[R] Facebook AI: An Empirical Study of Training Self-Supervised Visual Transformers,
bendee983,MachineLearning,1617629350.0,[R] Data poisoning circumvents certified adversarial training methods,paper accept cvpr introduc new data poison method undermin random smooth train techniqu make machin learn model adversari attack call poison certifi defens pacd method gener poison data optim target robust techniqu result dataset reduc averag certifi radiu acr distanc within train machin learn model remain robust adversari perturb techniqu wa test ga macer smoothadv three popular random smooth techniqu thi grey box attack attack need knowledg target ml model architectur train method use need access model weight pacd data gener one random smooth techniqu also transfer method though optim state main takeaway paper data secur underr aspect adversari attack mani defens techniqu focus make model weight robust adversari perturb need effort detect adversari perturb train data also need measur certifi proven train data protect machin learn develop deploy pipelin prevent compromis train data read coverag paper interview lead author http bdtechtalk com nmbr nmbr nmbr machin learn data poison nmbr http bdtechtalk com nmbr nmbr nmbr machin learn data poison nmbr full paper http arxiv org ab nmbr http arxiv org ab nmbr implement http github com akshaymehranmbr poison _certifi _defens http github com akshaymehranmbr poisoning_certified_defens
Kal217,MachineLearning,1617403979.0,[P] Intuitive StarGAN Implemented in Tensorflow 2.3,late lot work ha involv stargan want creat easi read implement architectur function freeli use importantli explain go stargan http arxiv org ab nmbr http arxiv org ab nmbr class translat model use singl gener translat freeli number class advanc gan although outdat share import idea implement document aim familiar machin learn pleas let know ani feedback might thi first time share project http github com kalnmbr stargan tutori tensorflow nmbr http github com kalnmbr stargan tutori tensorflow nmbr
TheCockatoo,MachineLearning,1618916138.0,[D] Arguments for supervised approach when an unsupervised one already exists?,assum nich topic ha receiv littl attent term machin deep learn paper onli one doe unsupervis deep learn like propos supervis approach argu presenc unsupervis one work without label trump anyth supervis
thunder_jaxx,MachineLearning,1616434209.0,[2103.06326] S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning,
pcaversaccio,MachineLearning,1617645967.0,[R] Facebook AI: Self-supervised learning for fast and scalable time series hyper-parameter tuning,
mcbal31,MachineLearning,1620119944.0,[P] Deep Implicit Attention: A Mean-Field Theory Perspective on Attention Mechanisms,thi project model attent term collect respons statist mechan system consid vector gener ise like spin system treat incom data appli magnet field output attent modul spin expect valu order rephras attent inner loop fix point optim introduc slow explicit attent modul implement adapt thouless anderson palmer mean field theori fast neural one parametr call onsag self correct term latter modul look lot like transform modul approxim constrain mean field equat show simplifi updat step appear mirror vanilla transform architectur explain origin feed forward layer import residu connect blog http mcbal github io post deep implicit attent mean field theori perspect attent mechan code http github com mcbal deep implicit attent tl dr project model attent collect respons statist mechan system use deep equilibrium model solv set self consist equat provid mean field theori perspect transform gist post combin physic mean field interpret deq transform introduc deep equilibrium model http arxiv org ab nmbr bunch paper boltzmann machin nmbr comment welcom
juliensalinas,MachineLearning,1616595392.0,[D] Production-Ready Machine Learning NLP API with FastAPI and spaCy,hey fastapi ha nice addit python ecosystem opinion make api creation easier less error prone also come great perform make perfectli suit machin learn api nlpcloud io http nlpcloud io utm_sourc reddit utm_campaign lnmbranmbr aaaf nmbreb bcbc nmbracnmbr api ha develop use fastapi thought would interest write concret articl set nlp api fastapi serv spaci model ner http juliensalina com en machin learn nlp api product fastapi nlpcloud http juliensalina com en machin learn nlp api product fastapi nlpcloud love feedback thi guy also fastapi user notic caveat awar think better tool machin learn api thank
yusuf-bengio,MachineLearning,1616429243.0,[D] Jürgen Schmidhuber - But what has he published recently (Ep. 2),becaus mani peopl request last time jürgen schmidhub ha work truli revolutionari idea algorithm back earli nmbr among thing propos artifici curios ac framework earli prototyp known gener adversari network gan nmbr togeth hi student hochreit propos infam lstm architectur still consid de facto standard rnn architectur today sinc onli sporad publish interest paper compar hi high statu gener fund machin learn group led famou research hi research output rel low question ha publish recent
CvikliHaMar,MachineLearning,1618568912.0,[D] Pushforward vs Pullback algorithms,hello guy long time skip pushforward read http juliadiff org chainrulescor jl dev http juliadiff org chainrulescor jl dev wa veri clear descript term frule rrule tri googl internet get whi use pushforward gradient comput whi use pullback faster downsid use pushforward comput gradient doe anyon know
flippy98026,MachineLearning,1616699703.0,[N] Common Application Framework (CAF) for Synthetic Data Generation by Rendered.ai at GTC21,caf support container simul applic tool need produc analyz integr synthet data comput vision project thi includ tool scenario gener comput manag collabor analysi data manag gui api interfac chain abl agent factori standard custom scene modifi framework caf host render ai nmbrrd parti simul synthet data engin nir wmir thermal rada sar satellit eo xray sensor nathan kundtz render ai http render ai gtcnmbr synthet data http preview redd bnbcnmbrhvdnmbrpnmbr png width nmbr format png auto webp nmbrenmbrccdnmbrenmbrfnmbraaanmbrcdnmbrenmbranmbraanmbrdbcabnmbr
mgalarny,MachineLearning,1619030679.0,[P] Attention Nets and More with RLlib’s Trajectory View API,hey everyon want share two new featur stabl rllib http doc ray io en master rllib html support attent network custom model trajectori view api rllib http doc ray io en master rllib html popular reinforc learn librari part open sourc ray project http github com ray project ray blog post http medium com distribut comput ray attent net rllib trajectori view api dnmbranmbrenmbr code snippet thi work want share motiv import thi well motiv goal ani rl algorithm train neural network action choic becom optim respect reward signal also provid environ often refer neural network function polici π action π observ eq nmbr common case abov eq nmbr observ current frame seen agent often see rllib user tri model thi enough exampl frame stack model see last n observ account fact singl time frame doe captur entir state environ think ball seen screenshot game know whether fli left right http preview redd pnmbrkrnmbrhuknkunmbr png width nmbr format png auto webp nmbrenmbrcnmbrbfnmbranmbrfnmbrddcnmbrenmbr action π observ nmbr nmbr eq nmbr recurr neural network rnn model see last observ also track hidden state memori vector ha previous produc model alter time action memori π observ memori nmbr eq nmbr furthermor attent net e g transform model model see last observ also last n track memori vector action memori π observ memori n eq nmbr rllib new trajectori view api make complex polici model possibl fast build function show thi enabl effici attent net support rllib http medium com distribut comput ray attent net rllib trajectori view api dnmbranmbrenmbr let know ani thought question
mediaml,MachineLearning,1619099948.0,[D] What are good places to advertise PhD and post-doc positions in ML?,princip investig european research group focus appli machin learn interest experi good place advertis phd post doc posit specif phd student go look machin learn phd post doc posit faculti found good venu advertis phd post doc posit experi worth invest money ad portal like findaphd com http findaphd com advertis group webpag social media promot way go would particular like reach femal candid applic underrepres group ai adequ qualif ani insight advertis reach group also veri welcom edit comment seem misconstru look exclus hire femal candid thi cours case want increas pool femal applic peopl underrepres group increas probabl find excel candid group thi partial becaus believ build divers research group lead interest healthier lab life partial becaus strongli believ research concern gender bia http curt rice com nmbr nmbr nmbr evid littl scienc bia gender equal affirm action http www gse harvard edu news uk nmbr nmbr case affirm action
Andy_Reds,MachineLearning,1619795835.0,[2104.14421] What Are Bayesian Neural Network Posteriors Really Like?,
OnlyProggingForFun,MachineLearning,1618588775.0,"[News] Create 3D Models from Images! AI and Game Development, Design... GANverse3D & NVIDIA Omniverse",omnivers nvidia nmbr http www nvidia com en us omnivers http www nvidia com en us omnivers zhang et al nmbr imag gan meet differenti render invers graphic interpret nmbrd neural render http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf ganversenmbrd offici nvidia video http youtu nmbrpqnrnuiblu http youtu nmbrpqnrnuiblu nvidia ganvers nmbrd blog articl http blog nvidia com blog nmbr nmbr nmbr gan research knight rider ai omnivers http blog nvidia com blog nmbr nmbr nmbr gan research knight rider ai omnivers watch video demo http youtu dvjwrbznmbrhnw http youtu dvjwrbznmbrhnw
davidbun,MachineLearning,1620139610.0,[N] Access Google Objectron (~1.92 TBs) in less than 5 seconds with Activeloop Hub,http redd ynmbrsnmbrunmbrxnmbr gif hi r machinelearn team activeloop http activeloop ai utm_sourc social utm_medium reddit utm_campaign objectron partner googl make googl objectron avail nmbr second per dataset categori googl objectron one googl popular dataset contain short object centric video clip pose annot nmbr annot video nmbrm annot imag need get start instal hub open sourc packag http github com activeloopai hub convert comput vision dataset cloud nativ numpi like array enabl nifti featur like stream pytorch tensorflow dataset version control collabor etc pip instal hub load data bike categori import hub bike hub dataset googl bike nmbr second dataset avail work e g filter appli transform etc whole dataset nmbr tb metadata would take nmbr second access thank hub visual googl objectron ani comput vision dataset web app app activeloop ai http app activeloop ai dataset popular tag googl nmbrfshoe utm_sourc social utm_medium reddit utm_campaign objectron detail use objectron hub avail releas blogpost http www activeloop ai blog nmbr nmbr nmbr access googl objectron data less nmbr second utm_sourc social utm_medium reddit utm_campaign objectron pleas make sure use latest updat hub http redd enmbrxanmbrxnmbr gif work get dataset platform improv github com activeloopai hub http github com activeloopai hub tool let us know ani feedback like deliv maximum valu commun thank davitbun
Tea_Pearce,MachineLearning,1618352493.0,[R][P] Counter-Strike from Pixels with Behavioural Cloning,http reddit com link mqdnmbrho video lnmbronmbrnnmbrtnmbr player deep neural network play csgo deathmatch pixel train dataset nmbr hour nmbr million frame human play use behaviour clone arxiv paper http arxiv org ab nmbr http arxiv org ab nmbr gameplay exampl http youtu pnmbrvwknmbrumvm http youtu pnmbrvwknmbrumvm counter strike deatmatch larg scale behaviour clone tim pearc twitter http twitter com tea _pearc http twitter com tea_pearc jun zhu tsinghua unviers univers cambridg
windbreaker14,MachineLearning,1616513372.0,[D] Disappointed with the reviews in ICML21.,submit paper icmlnmbr receiv review nmbr day ago wa suppos receiv nmbr review review nmbr nmbr nmbr nmbr howev onli receiv onli nmbr review review nmbr nmbr two miss even though sent messag thi contact e mail icmlnmbrchair gmail com mailto icmlnmbrchair gmail com receiv ani respons also qualiti nmbr review veri poor review weakli reject paper reason paper well organ onli three sentenc critic issu alreadi submit iclrnmbr paper wa prais well written well organ sum wa expect receiv nmbr review two miss one veri poor therefor wa quit disappoint
proof_required,MachineLearning,1616753332.0,[D] How Facebook got addicted to spreading misinformation,behind paywal new machin learn model come onlin daili compani creat new system track impact maxim user engag process still today team train new machin learn model fblearner whether chang rank order post better catch content violat facebook commun standard rule allow platform test new model small subset facebook user measur chang engag metric number like comment share say krishna gade serv engin manag news feed nmbr nmbr model reduc engag much discard otherwis deploy continu monitor twitter gade explain hi engin would get notif everi day metric like comment deciph caus problem whether ani model need retrain thi approach soon caus issu model maxim engag also favor controversi misinform extrem put simpli peopl like outrag stuff sometim thi inflam exist polit tension devast exampl date case myanmar viral fake news hate speech rohingya muslim minor escal countri religi conflict full blown genocid facebook admit nmbr year downplay role done enough help prevent platform use foment divis incit offlin violenc facebook may oblivi consequ begin wa studi nmbr intern present year review wall street journal compani research monica lee found facebook wa onli host larg number extremist group also promot user nmbr extremist group join due recommend tool present said predominantli thank model behind group join discov featur http www technologyreview com nmbr nmbr nmbr nmbr facebook respons ai misinform
LSTMeow,MachineLearning,1620131082.0,[N] ClearML release: v1.0 (open source MLOPs solution),hi r ml ha almost two year sinc first post open sourc solut thank amaz github star bump btw guy rock today seem like nmbr person year work tinker long night pleas announc clearml ha hit version nmbr follow quickli releas clearml nmbr nmbr ad last remain featur felt nmbr need name multi model support well improv batch oper ha long sometim bumpi path get us version nmbr good time mi step everi journey differ help along way one nicest slack commun could ever wish thi feel truli like mileston birthday hope help us celebr detail nmbr releas http clear ml horrayvnmbr http clear ml horrayvnmbr commun roadmap http clear ml roadmapnmbr http clear ml roadmapnmbr formal changelog http github com allegroai clearml releas tag nmbr nmbr http github com allegroai clearml releas tag nmbr nmbr special episod show featur tiger http youtu rnmbrbmmdzfyanmbr http youtu rnmbrbmmdzfyanmbr celebratori meme http twitter com clearmlapp statu nmbr http twitter com clearmlapp statu nmbr ps still owe thi commun call comparison matrix like glanc thi wa hard thing especi sinc mlop tool ecosystem constantli grow chang happi say form comparison thi week edit thi post arriv
hardmaru,MachineLearning,1618215799.0,"[R] A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes",
RaivoK,MachineLearning,1616590712.0,Fair Model Comparison [R],publish befor need advic compar accuraci differ video classif model train one train environ train trick would like make comparison fair possibl differ model nmbr model use certain number input frame might use nmbr nmbr nmbr nmbr model use certain spatial size nmbrxnmbr nmbrxnmbr complet sure standard thi experi train model exact choic made paper use spatial size frame number model review might say forc model use nmbrxnmbr nmbr input frame fair becaus valu model design hand train everi model valu use paper might get advantag use way comput would like use spatial size number frame compar fast vs accur thi review critic thi like thi
ElCobo,MachineLearning,1618694910.0,[P] Wiggle-GAN: Stereoscopic camera simulation using generative adversarial neural networks,hello everyon want post grad thesi tri simul use stereoscop camera util monocular imag input main goal wa give new altern someon want creat wigglegram http www reddit com r wigglegram becaus way could achiev effect limit exampl could use normal camera take mani pictur scene move effect would mimic stop motion wigglegram hand could use array camera expens could use stereoscop camera nmbr nmbr lens kind camera analog take time effect reason whi took approach use neural network ani limit thi project use wgan improv consist regular lnmbr loss compar output real imag see result adjust thi valu github http github com rocobonmbr wiggl gan code also see train multipl multipl solut autoencod ae onli one net wiggl gan solut two net fight wiggl gan solut extract metric see doe wiggl gan cr input wiggl gan imag want move depth map direct left right output new imag move depth map estim could iter multipl time want tri made googl colab http colab research googl com drive nmbrnnmbrhjnmbrgevmnmbrymloenmbrcnmbrjklsnmbrf_tqn r usp share download checkpoint limit net train imag nmbrxnmbr pixel except last one colab nmbrxnmbr code automat chang scale imag size need chang manual sometim gener wiggl expect may due depth map estim happen could download depth map imag folder imag input test name number _d png edit softwar could chang upload name place want tri problem feel free ask anyth lot love
TuSharma,MachineLearning,1616862277.0,[R] Suggestions welcome: Code smell detection using deep learning,recent paper code smell detect deep direct learn transfer learn wa accept jss http www sciencedirect com scienc articl ab pii snmbr may find preprint http tusharma preprint jssnmbr_code smell detect use deep learning_preprint pdf key contribut paper nmbr detect smell without explicit featur engg e g metric esp impl smell nmbr autoencod work best among option cnn rnn nmbr transfer learn work thi context github reposiotori http github com tushartushar deeplearningsmel autoencod implement articl medium http tusharma medium com autoencod sourc code analysi use case nmbrdanmbrbnmbr provid implement detail would like provid ani opinion suggest feedback thi work
chasep255,MachineLearning,1617966989.0,[D] Loss function for audio auto encoder.,tri build auto encod raw audio data time domain thi onc befor back never got good result tri use mean squar error loss output realli onli captur mute version low frequenc signal also tri comput mean squar error fft output much better tri combin wgan gp sort loss function thi approach last week imag combin wgan vggnmbr perceptu loss thi produc realli sharp imag howev ani sort pretrain model raw audio suppos could make one tri combin fft loss wgan kick train seen result yet howev worri fft loss prevent model learn higher frequenc signal sinc larger penalti guess someth sound realist say nmbr degre phase doe anyon know better loss function could tri sound data right fft loss defin fft _loss tf reduc _mean tf squar tf ab tf signal stft g nmbr nmbr tf signal stft r nmbr nmbr
Jump2Fly,MachineLearning,1618672265.0,[P][Code Release] A neural network implementation to detect whether a given video clip is in-game or not using transfer learning (can be applied to all sorts of games),
wasabi_toast,MachineLearning,1616635709.0,[Discussion] PlaidML and Intel's Iris Xe GPU support...?,thi probabl wish think sinc plaidml http github com plaidml plaidml part intel ai project upcom releas discret integr iri xe unit soon abl use chip gpu machin learn ye know new iri xe unit power compar nvidia amd offer doe look like end thi cryptomin craze gpu shortag come soon would realli like abl test dl code someth work ani sort gpu would help tremend
__Julia,MachineLearning,1616598885.0,"[D] Research in the Global South: Academic conference should build bridges, not barriers",hello last month seen academ commun twitter r machinelearn strive promot divers defend research http www wire com stori second ai research say fire googl question compani approach silenc controversi ethic ai howev stand awe think commun gate keep research group commun commun organ intern academ confer ask high fee base nation life standard research global south high rel life standard countri hard forg path without includ hard student professor learn share becaus need pay tax includ hard see peopl defend group thi commun ignor anoth group hard see intern academ confer place ban sever nation http twitter com andrewyng statu nmbr lang eu today order student global south make good univers us canada eu phd program student need least paper top tier confer obvious thi doabl peopl initi thi one http www datascienceafrica org dsanmbraddi think commun better thi messag sound like rant mayb think thi stumbl upon thi tweet student africa wish start career research doe best self learn submit workshop get accept onlin confer ask pay nmbr month hous rent present work zoom call whi gatekeep research http twitter com hadyelsahar statu nmbr http twitter com hadyelsahar statu nmbr review paper confer organ confer make differ defend democrat scienc better better lower bar live part world
KingHultan,MachineLearning,1617799367.0,[D] Metric for computational efficiency?,tri find metric measur amount predict power model relat complex model similar fuel effici car metric penalti loss flop object minim penalti model find predict effici model configur quit use scenario comput power sever limit like phone autonom vehicl tri find similar metric literatur avail ani know metric measur comput effici model
dummy-gummy,MachineLearning,1619449303.0,"[P] Pytorch reimplementation of Encode-Attend-Navigate, a RL-based TSP solver",http github com astariul encod attend navig pytorch http github com astariul encod attend navig pytorch recent implement encod attend navig http github com micheldeudon encod attend navig tsp solver base rl offici repo wa use tensorflow nmbr x decid implement pytorch want share get opinion train model use free gpu googl colab colab notebook provid readm
CireNeikual,MachineLearning,1619882590.0,"[P][R] AOgmaNeo ""Imagination"" after reinforcement learning",
sensetime,MachineLearning,1619065013.0,[R] Carbon Emissions and Large Neural Network Training (Google Brain and Berkeley paper with Jeff Dean as the last author),
nicolas-gervais,MachineLearning,1620053920.0,"[D] Half of my team knows Tensorflow, the other half PyTorch. How can we decide on which to use?",sadli titl say know use need start collabor togeth find onlin pytorch often use research probabl even true anymor sinc everyon say becaus onli thing peopl say
SmittyMcSmitherson,MachineLearning,1617948856.0,[D] MLCommons & inference benchmarking,whi mlcommon mlperf constantli ad new result better resourc benchmark result variou inferenc asic
mistermysterioyster,MachineLearning,1616923147.0,[D] Paper Reading Group #015 - DERAIL: Diagnostic Environments for Reward And Imitation Learning. (Link to full slides in comments!),
InvestingScientist,MachineLearning,1620645601.0,"[P] - Help me implement ""Neural Assimilation"" for my research project",hi attempt reproduc neural assimil model architectur describ thi paper neural assimil http www ncbi nlm nih gov pmc articl pmcnmbr essenti tri design architectur would much faster use kalman filter bypass correct step despit author provid code kera issu tri implement thi pytorch simpli see built model link code final code googl drive http drive googl com drive folder nmbrtbgnmbrzfpyxiegoxbnnmbrszurpjpmlnmbrtwqio understand need two lstm one use model forecast data use observ data tricki part lstm requir input hidden state cell state lstm difficulti tri implement anyon ani idea could thi far onli use simpl lstm mani mani predict thi diagram architectur http preview redd gnmbrelnmbrwnmbraynmbr png width nmbr format png auto webp anmbrcnmbrcnmbrdnmbrbnmbrenmbrcfccnmbrdnmbrfnmbraanmbrdcnmbrfdnmbr work thu far implement class neural_assimil nn modul def __init__ self n_input n_hidden num_lay n_output super neural_assimil self __init__ self n_input self n_hidden self k n_output self l num_lay self rnn_f nn lstm input_s self hidden_s self num_lay self l batch_first true self rnn_o nn lstm input_s self hidden_s self num_lay self l batch_first true self fc nn linear self self k bidir lstm need multipli self x nmbr def forward self x_f x_o initi hidden state hnmbr_f torch zero self l x_f size nmbr self devic bidir lstm need multipli self l x nmbr cnmbr_f torch zero self l x_f size nmbr self devic bidir lstm need multipli self l x nmbr get rnn unit output out_f h_t_f c_t_f self rnn_f x_f hnmbr_f cnmbr_f out_o h_t_o c_t_o self rnn_o x_o h_t_f c_t_f out_f h_t_o c_t_o self rnn_f x_f h_t_o c_t_o want h c final time step feed thi rnn out_f self fc out_f nmbr hidden_st h_t nmbr hidden_out self fc hidden_st cell_stat c_t nmbr cell_out self fc cell_stat return hidden_st cell_out issu havent abl think good way coupl lstm rnn ha input either observ model forecast well hidden cell state network would realli appreci expertis
PetarVelickovic,MachineLearning,1619684755.0,"[R] Geometric Deep Learning: Grids, Groups, Graphs, Geodesics and Gauges (""proto-book"" + blog + talk)",hi everyon proud share first version project geometr unif deep learn ha kept us busi throughout covid time start februari nmbr releas nmbr page proto book geometr deep learn michael bronstein joan bruna taco cohen current releas arxiv preprint companion blog post http geometricdeeplearn com http geometricdeeplearn com len symmetri invari group theori attempt distil need build neural architectur need usual suspect cnn gnn transform lstm cover also includ recent excit develop spheric cnn nmbr transform gaug equivari mesh cnn henc believ work use way navig increasingli challeng landscap deep learn architectur hope find worthwhil perspect also recent gave virtual talk fau erlangen nuremberg birthplac felix klein erlangen program wa one key guid principl attempt distil key concept text within nmbr hour slot http www youtub com watch v nmbrcxhvqknmbralq http www youtub com watch v nmbrcxhvqknmbralq goodi blog talk come soon attend iclr nmbr keep eye michael keynot talk work veri much work progress welcom ani feedback
prestodigitarium,MachineLearning,1617931758.0,"[P] Gourdian Free Dataset Download: EPA Air Quality System Daily CO, NO2, O3, SO2 Concentrations since 1980",howdi ad anoth free dataset download project gourdian thi time epa air qualiti system daili level follow pollut measur station throughout us go back nmbr carbon monoxid co http gourdian net g eric epa_aq co_daily_summari nitrogen dioxid nonmbr http gourdian net g eric epa_aq nonmbr_daily_summari ozon onmbr http gourdian net g eric epa_aq ozone_daily_summari sulfur dioxid sonmbr http gourdian net g eric epa_aq sonmbr_daily_summari thi dataset onli updat twice per year whi care thing well pretti nasti pollut frequent affect human health especi long exposur period perhap concentr affect build home exampl also use proxi variou type human activ carbon monoxid deadli high concentr bind hemoglobin make one blood carri much oxygen creat via combust fossil fuel nitrogen dioxid one result road traffic fossil fuel combust one precursor harm pollut ozon particul play role format acid rain becom nitric acid also gener correl exposur byproduct road traffic mani link respiratori ill system inflamm lead whole host health issu ozon power oxid make caus damag respiratori tissu also attack variou polym like rubber eventu caus crack form primarili photochem reaction nitrogen oxid like nonmbr volatil organ compound voc high concentr limit urban area howev travel hundr mile downwind sourc final sulfur dioxid form larg combust fossil fuel high level sulfur well volcan activ precursor acid rain becom sulfur acid sulfur dioxid known least mildli toxic hazard high concentr long term exposur low concentr also problemat amount sulfur fossil fuel vari wide type automot gasolin ha much less bunker fuel commonli use contain ship exampl like download ani part filter part care part via lat long filter button map select area year via slider thi download size note download button upper right chang got part want click download get csv bit goal tri build filter option click button csv arriv hard drive download alway singl csv bundl weird directori structur format csv index filter column type lat long date time moment download part want open licens dataset free download signup requir download open dataset search within across dataset feedback welcom ani dataset like see ad let us know
weifz,MachineLearning,1620356445.0,[D]A question about causal discovery and causal inference,hi know causal consist causal discoveri causal infer wonder exist order two compon e g konw causal structur causal discoveri befor causal infer
Electronic-Lie4077,MachineLearning,1617117959.0,[P] OpenAI CLIP: Connecting Text and Images Gradio web demo,http reddit com link mgiimg video qstepjlnmbronmbrqnmbr player web demo open ai clip visual classif tri http gradio app hub aknmbr clip http gradio app hub aknmbr clip
TartarQ,MachineLearning,1620576418.0,[Discussion] Defining optimal false-positives and false-negatives balance with a cost function,roc _curv http preview redd nmbrmnmbreenmbrybnmbrynmbr png width nmbr format png auto webp nmbraanmbrfnmbrenmbrenmbrenmbraenmbrcnmbra http preview redd sheqqonmbrzbnmbrynmbr png width nmbr format png auto webp enmbranmbrbnmbrdnmbrbnmbrdbnmbranmbrcnmbreanmbr http preview redd qifabnmbrrzbnmbrynmbr png width nmbr format png auto webp nmbrcnmbraenmbrfnmbrfnmbranmbracnmbrdnmbrdefnmbrenmbrdnmbrdenmbr
prakhar21,MachineLearning,1620325388.0,[D] graph2vec: Learning Distributed Representations of Graphs | ML with Graphs (Paper Walkthrough),recent work represent learn graph structur data predominantli focu learn distribut represent graph substructur node subgraph graphnmbrvec propos techniqu emb entir graph high dimens vector space inspir docnmbrvec learn approach graph root subgraph paper walkthrough http youtu hnmbr_omwnlo
False-Grape7566,MachineLearning,1620578000.0,[P] Keytotext Convert Keywords to Large texts,hello present keytotext keytotext nlp model convert keyword sentenc larger text built use tnmbr model keytotext ha pypi instal demand infer api also featur ui built use streamlit gpu enabl colab notebook easi usag pleas check github http github com gagannmbr keytotext http github com gagannmbr keytotext pleas star like work
CC_sciguy,MachineLearning,1618532149.0,[D] Anyone have experience running pytorch with AMD GPUs,march pytorch mainstream rocm support mean amd gpu could viabl dl workflow seen compel benchmark amd minmbr gpu noth doe end end test real deep learn workflow doe anyon experi run pytorch amd gpu speed realli better top line nvidia gpu importantli support good nvidia thi point sw side still matur
Philipp,MachineLearning,1618835247.0,[P] [D] Using GPT-3 to write short stories,hop thi interest creat ongo seri http aiwrotethi substack com short stori substack co written wih gpt nmbr ai video http www youtub com watch v nmbrfwknmbrknmbrasr show approach move stori certain direct would also love discuss thi topic ai fiction write utterli fascin use gtp nmbr creativ tool
PresentCompanyExcl,MachineLearning,1618111444.0,[mocov3] An Empirical Study of Training Self-Supervised Visual Transformers,
setzRFD,MachineLearning,1617646105.0,[Discussion] What metaheuristics are interesting as an exercise to expand my knowledge of AI/ML?,interest metaheurist search specif interwoven neural network interest result work particl swarm genet algorithm train neural network want tri sinc fun exercis look ant coloni bee coloni optim metaheurist seem onli work problem reduc graph travers metaheurist think suit optim error function
Ziinxx,MachineLearning,1618173390.0,[P] Using StyleGAN2-Ada and Pixel2Style2Pixel to Become a Professional Artist,
xdtolm,MachineLearning,1617563498.0,[P] Nvidia A100 and AMD MI100 benchmarks - join VkFFT panel on Nvidia GTC 2021,hello creator vkfft http github com dtolm vkfft vulkan cuda hip fast fourier transform librari would like invit gtc nmbr http gtcnmbr event nvidia com panel vkfft happen april nmbrth nmbr pm cest higher educ research categori focus implement optim creat cross platform code scale raspberri pi nmbr hpc gpu like nvidia anmbr session also compar vulkan cuda hip comput platform nvidia anmbr amd minmbr gpu thi post would like give sneak peek part talk regard vkfft cufft rocfft perform comparison singl precis nmbrd batch fft test system nmbr nmbr represent arbitrari multipl nmbr nmbr nmbr nmbr nmbr nmbr bandwidth calcul total memori transfer nmbrx system size divid time taken higher better nvidia anmbr result http preview redd jooknmbryvtfnmbrrnmbr png width nmbr format png auto webp nmbreadnmbrcnmbraenmbrenmbrfcnmbrcnmbrenmbrecnmbrenmbrb amd minmbr result http preview redd nmbrokfnmbrjevfnmbrrnmbr png width nmbr format png auto webp enmbrcanmbrbnmbrabdnmbrdnmbranmbrfnmbrcnmbrcnmbrdnmbrbdnmbrfab talk also cover doubl precis multidimension test analysi would realli appreci check
lfolle,MachineLearning,1620324878.0,[R] Deep learning methods allow fully automated segmentation of metacarpal bones to quantify volumetric bone mineral density,check latest research appli deep learn base segment network field rheumatolog http www natur com articl snmbr nmbr nmbr nmbr open access
seagullonthetop,MachineLearning,1619320683.0,Machine learning for a theoretical physicist [D],hi background theoret high energi physic cosmolog comfort mathematica use matlab python past though larg scale project interest learn machin learn way suit someon background experi ha anyon trod similar path use resourc book onlin cours alreadi done project exampl prefer someon physic run get hand practic experi ml thank
chimp73,MachineLearning,1620077927.0,[D] An RL agent based on a large NN that one-shot learns in single SGD updates. Recall and planning through generalization from one-shot learned predictions and policy updates,yesterday http www reddit com r machinelearn comment nnmbrtsnmbrl d_how_far_can_we_get_with_oneshot_learn explor consequ scale hypothesi true particular upscal give us one shot learn singl sdg updat well super human level infer predict gener abil today think concret implement thi approach could look like idea cheap goe model come simpli fulli connect wide vae step perform one infer produc two gaussian sampl two predict base sampl first sampl use predict futur second sampl use predict predict base first sampl consequ model would one shot learn thought sensori experi occur let x _t n x tensor contain time step say nmbr second sampl nmbr hz n p nmbr featur length sensor vector p number motor neuron p muscl contract nmbr nmbr e sigmoid one extra dimens experienc reward r let first predict x _t vae concat x _ nmbr x _ nmbr second predict x _t correspond second sampl vae produc way minim loss sgd x_t x _t nmbr x _t x _t nmbr kld z kld z p _t p _t α r_t nmbr p _t p _t α r _t nmbr λ p _t _nmbr kld kl regular gaussian sampl α scale constant reward strong absolut reward nmbr p _t _nmbr sparsiti prior polici encourag competit action two rl loss simpli punish reinforc action coincid reward though slight tempor delay would like help second loss act imagin polici imagin reward unsur thought actual becom goal direct thi way extrem surpris thi actual work fun think
Superb-Drawer5214,MachineLearning,1618760402.0,[D]What universities are considered top10 and top20 for ML/CV/NLP?,seem topnmbr berkeley mit stanford cmu sure univers consid top nmbr top nmbr ml cv nlp whenev person mention ha appli top nmbr school ml school refer
grid_world,MachineLearning,1617303683.0,[D] Quantization in Deep Learning,deep learn model compress standard step appear prune cluster quantiz experi implement first two step detail interest learn quantiz techniqu appli deep learn compress point nice resourc research paper blog tutori video etc start point thank
m1900kang2,MachineLearning,1617071083.0,[R] Predicting Multiple Sclerosis from Gait Dynamics Using an Instrumented Treadmill – A Machine Learning Approach,thi paper research univers illinoi urbana champaign look ml abl spot gait problem individu multipl sclerosi nmbr min present video http crossmind ai video predict multipl sclerosi gait dynam use instrument treadmil machin learn approach nmbranmbrebnmbrenmbrfabnmbr paper link http ieeexplor ieee org document nmbr abstract multipl sclerosi ms one common neurolog condit worldwid whose preval greatest among peopl nmbr nmbr year age clinic present ms highli heterogen mobil limit one frequent symptom aim thi studi examin ms disabl relat chang spatiotempor kinet gait featur normal evalu effect gait data base machin learn ml framework ms predict gmlnmbrm method thi studi gait data dure self pace walk instrument treadmil nmbr person ms nmbr age weight height gender match healthi older adult hoa obtain explor two normal strategi name size n standard bodi size base normal regress n regress base normal use scale factor deriv regress gait featur multipl subject demograph minim depend deriv gait featur subject demograph propos gmlnmbrm ml base methodolog classifi individu stride older person ms pwm healthi control gener across differ walk task subject gait normal result observ regress n improv accuraci identifi patholog gait use ml compar size n gener comfort walk walk talk gradient boost machin achiev optim subject classif accuraci auc nmbr nmbr respect subject gener multilay perceptron result best accuraci auc nmbr nmbr respect regress n normal data conclus integr gait data ml predict ms may provid viabl patient centric approach aid clinician diseas monitor relaps treatment thi work first attempt employ demonstr potenti ml thi domain signific result thi studi futur implic way regress normal gait featur may clinic use design ml base diseas predict strategi monitor diseas progress pwm butterfli diagram center pressur trajectori dure subject walk http preview redd nmbrvqlbvnmbrxsnmbrqnmbr png width nmbr format png auto webp nmbreanmbraanmbrbcfnmbrbenmbrbnmbrcnmbrfcaenmbr author rachneet kaur zizhang chen robert motl manuel enriqu hernandez richard sower univers illinoi urbana champaign
fripperML,MachineLearning,1617772778.0,[D] Is it always recommended to scale features to be predicted the same way as the training data was scaled?,know thi ha ask befor question might seem somewhat silli let start briefli standard approach gener advic alway seen decid scale data gener recommend fit _transform scaler dure train process appli scaler data predict thi make lot sens allow model predict one onli sampl whatev number sampl question feel sometim best approach let give exampl let suppos deal model predict probabl default person use econom featur like annual incom amount debt etc let suppos onli preprocess make scale data let suppos train model data nmbr still use thi model product thi set veri like kind drift worsen perform one could retrain model use recent data intuit least partial one could reduc problem scale featur instanc predict use inform year cours think becaus kind econom featur affect inflat exampl annual incom nmbrk nmbr compar annual incom say nmbrk present year scale move ruler better scale fix ruler thi approach could use whenev featur ha mean chang time think think doe make sens cours one limit easi implement onli way think use model make batch predict big enough chunk scale featur accord distribut chunk meaning
jnbrrn,MachineLearning,1616769447.0,[R] Baking Neural Radiance Fields for Real-Time View Synthesis,real time photorealist neural render browser http nerf live http nerf live live demo http nerf live demo http nerf live demo paper pdf http nerf live bake _neural _radianc _field _for _real _time _view _synthesi pdf http nerf live baking_neural_radiance_fields_for_real_time_view_synthesi pdf explain video http www youtub com watch v nmbrjkrynmbrnnmbryonmbr http www youtub com watch v nmbrjkrynmbrnnmbryonmbr
hardmaru,MachineLearning,1616737639.0,[R] Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields,
SanjivGautamOfficial,MachineLearning,1619603499.0,[P] MLOverflow - A Webapp for ML/DL,hello ml ai enthusiast creat small minimalist design webapp machin learn feed paper event thi webapp liter ha feed event paper section link http mloverflow com http mloverflow com current ad content peopl engag would delight let check featur webapp could spare moment feed share medium articl anyth find interest internet relat ml ai may linkedin post ml dl even reddit link project relat ai ml made impress detect app upload youtub share thi websit ani medium blog wrote read paper share link event share link event relat ml ai paper discuss research paper peopl comment differ blog video link use user come comment section comment section feed paper would easier peopl post relat ml dl post nmbr type comment audio video text explain audio video text contain link websit audio video blog post respect link actual video audio explain clarifi write thing comment section need help link motiv point creat site alreadi r machinelearn http www reddit com r machinelearn subreddit medium articl share cours googl search believ thi make navig thing easier central place ml dl relat post would make conveni peopl interest ml dl consolid understand miscellan realli great develop think might help enthusiast one note option upload audio video gif imag see point need futur would happi add well p suggest report section ani bug ani featur think need resolv add kindli tell log go http mloverflow com report http mloverflow com report write thank read till cheer
mikegartrell,MachineLearning,1617917905.0,[N] Call for papers: KDD 2021 Workshop on Bayesian Causal Inference for Real-World Interactive Systems,http bcirwisnmbr github io http bcirwisnmbr github io august nmbr nmbr nmbr final workshop date tbd submiss deadlin may nmbr nmbr anywher earth format nmbr page extend abstract refer appendic acm proceed templat submiss websit http cmtnmbr research microsoft com bcirwisnmbr http cmtnmbr research microsoft com bcirwisnmbr increasingli use machin learn build interact system learn past action reward obtain theori suggest sever possibl approach contextu bandit reinforc learn calculu plain old bayesian decis theori theoret appropri practic approach causal infer interact system particularli interest case studi appli machin learn method interact system use bayesian likelihood base method discuss whi thi choic wa made term practic theoret argument also welcom submiss follow area offlin evalu recommend interact system comparison bayesian polici heurist approach offlin metric probabilist approach appli contextu bandit reinforc learn approach probabilist approach increment attribut non bayesian approach trade bayesian likelihood approach bayesian method product environ organ nichola chopin ensa mike gartrel criteo ai lab dawen liang netflix alberto lumbrera criteo ai lab david rohd criteo ai lab yixin wang uc berkeley
TrainYourMonkeyBrain,MachineLearning,1616507632.0,[D] Polyline prediction literature,encount multipl occas need predict line curv often repres polylin nmbrd nmbrd imag far alway obtain postprocess standard cnn predict like segment like wa wonder ani exist research cnn base model directli predict polylin unabl find ani imagin dedic loss function base somehow minim area predict ground truth curv would work best run issu difficult determin point defin line segment aka mani point one predict place best doe anyon literatur experi thi
pinter69,MachineLearning,1619361089.0,[R] Introduction to Photogrammetry and Points2Surf (ECCV 2020) - Link to free zoom lecture by the author in comments,
CarlJohnson2222,MachineLearning,1618958279.0,"[D] How long does it take to publish a research paper? How long is the the time from the moment you think of an idea, to the moment you submit the research paper to a journal (not including the time it takes for the journal to approve your paper)?",question state abov know research long doe take publish paper normal amount time abl conduct research fulli finish write paper submit
p_ranav,MachineLearning,1616342193.0,[P] Monocular Depth Estimation - I ran a number of fairly well-known pre-trained models and looked at the average,
DaredevilMeetsL,MachineLearning,1617157406.0,[D] What would you advice to make the most of a virtual conference?,present attend confer intern symposium biomed imag venu dedic medic biolog imag analysi next month virtual huge confer technic program http emb papercept net confer confer isbinmbr program isbinmbr_programataglanceweb html like cvpr neurip etc miccai much larger medic imag becaus focu venu quit nich phd student confer could quit use forg profession contact find potenti collabor advic suggest would make experi virtual confer ideal would like thi opportun network build connect ani advic suggest would appreci thank veri common advic look confer program beforehand select relev work thi limit know much work mere titl abstract anoth minor inconveni time zone event cet make confer program nmbr nmbr
jj4646,MachineLearning,1618637941.0,[D] Is there such a theorem in machine learning?,offici theorem statist machin learn state machin learn algorithm work gener well test data must similar train data know thi common sens search internet see offici refer thi principl thi formal codifi somewher thi referenc literatur pac theori turn provid basi machin learn algorithm
ZenDragon,MachineLearning,1617152883.0,[Discussion] What do you think would happen if a GPT model was continuously fine-tuned on its own I/O?,edit ai doe simpli talk talk human respons parti use train batch pair togeth symbol indic say thi would quit comput expens obvious suppos got hardwar lot time patienc suppos daili convers system input output everi interact immedi fed back train set learn rate higher normal becaus strong fit would actual good thi case sinc natur convers singl person would take long time gener appreci volum text wa think mayb also introspect period train gener side convers pretend still human particip could even add simpl judgement pass weight fine tune ai output adjust depend human respond worth tri complet stupid idea
Ok_Reality2341,MachineLearning,1617487648.0,[D] How large can you go with CNN input images?,larg reason go cnn regard input imag train week worth acceleromet signal data nmbr data point per second convert spectrogram higher resolut spectrogram better someth like nmbrxnmbr feasibl tri nmbrxnmbr imag enough resolut pick detail full week ani paper relat use cnn larg imag also plu
ubcengineer123,MachineLearning,1618605741.0,[R] Graphs for training loss per epoch in publications,hello research write paper use ml cnn architectur semant segment medic imag hope creat figur look someth like thi graph http www researchg net profil mohammad pashaei nmbr public nmbr figur fignmbr nmbr nmbr averag loss per epoch train valid step ppm nmbr nmbr train imag patch epoch goe steadi state valu nmbr nmbr epoch ha anyon encount thi befor lower batch per epoch accur becaus epoch consist full train dataset small detail use weight binari cross entropi account posit neg label imbal default adam optim anyon suggest possibl solut whi happen bad thing per se becaus model work abl get nice look figur reach steadi state quickli thank
zawerf,MachineLearning,1617278796.0,[D] Cheating Detection (from a recent a Google Code Jam competition),problem statement found http codingcompetit withgoogl com codejam round nmbra nmbrdnmbr rough summari nmbr player nmbr question player ha skill level s_i question ha difficulti q_j s_i uniform nmbr nmbr q_j uniform nmbr nmbr player skill s_i answer question difficulti q_j correctli probabl sigmoid s_i q_j except one cheater answer correctli probabl nmbr sigmoid s_i q_j nmbr result player answer question identifi cheater pass onli need find cheater nmbr time possibl much better sinc thi wa code competit expect come simpl heurist see analysi tab intend solut curiou stat ml peopl would approach thi instead
allasamhita,MachineLearning,1617799679.0,[P] Accelerate Your Machine Learning and Data Workflows to Production using Flyte!,imagin pain behind orchestr ml workflow take care maintain model artifact cach result facilit backtrack error sourc share result team member container job ensur scalabl time thi cheap lot ha happen backend ensur ml workflow run seamlessli part promin compani veri much vital ensur fool proof ml servic span multipl team flyte could solut flyte make easi creat concurr scalabl maintain workflow machin learn data process heard right ml data process flyte use product lyft spotifi freenom lyft flyte ha serv product model train data process four year becom de facto platform team like price locat eta map autonom fact flyte manag nmbr nmbr uniqu workflow lyft total nmbr nmbr nmbr execut everi month nmbr million task nmbr million contain check flyte http github com flyteorg flyte http github com flyteorg flyte websit http flyte org
the_travelo_,MachineLearning,1617795448.0,[D] what's the best approach to document a machine learning project?,compani struggl correctli document project use confluenc govern found proper rythm document everyth involv develop project tool process code anyth use solv thi problem
cereal_final,MachineLearning,1620446819.0,[P] How to get better performance with styleGAN2-ada for cartoons,tri gener pokemon stylegannmbr ada get best result http imgur com hnmbrunmbrnvh would say nmbr look like legit pokemon nmbr kinda trash like imag link tri train longer believ model collaps http imgur com nmbrzivjnmbr improv result dataset nmbrk imag pokemon headshot like thi http imgur com bxzunmbrvu
JFHermes,MachineLearning,1618835916.0,[D]Ethics in famous Machine Learning papers.,hi ask write ethic review stat class univers paper would think alreadi done know lot great research happen ai thought would ask advic need singl paper uneth even gray would better someth talk yeah throw case anyon know one top head thank time
LosinCash,MachineLearning,1617995159.0,[D] Looking for some clarification on Big Sleep variables.,hi hope may abl produc insight variabl insid big sleep hope u whiskey ha moment respond instal run big sleep nvidia jetson xavier python jupyt notebook use nmbrgb ram plenti left abus drill variabl coupl stump like know experi specif seed gradient accumul torch_determinist class_temperatur thank ani help resourc point toward
timscarfe,MachineLearning,1617499307.0,"[D] Christian Szegedy - Formal Reasoning, Program Synthesis [Video Show]",http youtu ehnggyfonmbrm http youtu ehnggyfonmbrm dr christian szegedi googl research deep learn heavyweight invent adversari exampl one first object detect algorithm inceptionnet architectur co invent batchnorm think bet comput softwar nmbr would right bet ai think program comput way sinc nmbr ha huge stagnat ever sinc mathemat process take fuzzi thought formalis could autom could creat system act like super human mathematician talk natur languag thi christian call autoformalis christian think autom mani thing mathemat first step toward softwar synthesi build human level agi mathemat abil litmu test gener reason abil christian ha fascin take transform touch promis path toward autoform gener artifici intellig szegedi http link springer com chapter nmbr nmbr nmbr nmbr nmbr nmbr _nmbr http link springer com chapter nmbr nmbr nmbr nmbr nmbr nmbr_nmbr learn reason larg theori without imit bansal szegedi http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf mathemat reason via self supervis skip tree train rabe szegedi http openreview net pdf id ymqanynmbrcmey http openreview net pdf id ymqanynmbrcmey lime learn induct bia primit mathemat reason wu szegedi http arxiv org ab nmbrvnmbr http arxiv org ab nmbrvnmbr deep learn symbol mathemat lampl http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf machin learn teach yehuda http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf investig limit transform simpl arithmet task nogueira http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf provabl bound learn deep represent arora http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf neural net learn program neural net fast weight schmidhub http peopl idsia ch juergen fast weight programm nmbr transform html http peopl idsia ch juergen fast weight programm nmbr transform html doe batch normal help optim ilya http gradientsci org batchnorm http gradientsci org batchnorm train resnet nmbr batch norm http myrtl ai learn train resnet nmbr batch norm http myrtl ai learn train resnet nmbr batch norm train resnet nmbr accuraci cifar nmbr nmbr second singl gpu kuhn http efficientdl com train resnet effici nmbr batch norm doe reduc intern covari shift http efficientdl com train resnet effici nmbr batch norm doe reduc intern covari shift
Mjjjokes,MachineLearning,1617939562.0,[R] CPU algorithm trains deep neural nets up to 15 times faster than top GPU trainers,link http techxplor com news nmbr nmbr rice intel optim ai commod html fbclid iwarnmbruvvwnmbrfohdmlijxsinmbravownmbrjnwtykdiucfnmbrtmucnmbrdwwdahnmbrirttmabyj whole industri fixat one kind improv faster matrix multipl shrivastava said everyon look special hardwar architectur push matrix multipl peopl even talk special hardwar softwar stack specif kind deep learn instead take expens algorithm throw whole world system optim say let revisit algorithm articl
pcaversaccio,MachineLearning,1618587670.0,[R] GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds,
meldiwin,MachineLearning,1617392472.0,"[N] ""DeepDream"" Questions for Alexander Mordvintsev, a research scientist at Google",hello mayb famiilar deepdream comput vision http en wikipedia org wiki computer_vis program creat alexand mordvintsev ieee soft robot podcast go podcast ani question send http doc googl com form e nmbrfaipqlsdthtdlnmbrbkfbrrpoanmbrsczwfddqnmbrhijwqgtnmbrslsughnmbrndanmbrlna viewform vc nmbr c nmbr w nmbr flr nmbr gxid nmbr http doc googl com form e nmbrfaipqlsdthtdlnmbrbkfbrrpoanmbrsczwfddqnmbrhijwqgtnmbrslsughnmbrndanmbrlna viewform vc nmbr c nmbr w nmbr flr nmbr gxid nmbr http preview redd kqdkznmbraoctqnmbr png width nmbr format png auto webp enmbrbnmbrbnmbrbnmbrenmbraabnmbrcnmbrbnmbrbcnmbrfcnmbrenmbrc
SieunPark,MachineLearning,1617422929.0,[R] How to download the DIV8K dataset for Super-Resolution?,divnmbrk http peopl ee ethz ch timoft public gu iccvw nmbrb pdf dataset use super resolut thi wa use nmbr aim challeng nmbr ntire challeng link challeng http competit codalab org competit nmbr learn _the _detail evalu http competit codalab org competit nmbr learn_the_detail evalu unfortun find link download dataset anywher internet download divnmbrk dataset thank
OShackathon,MachineLearning,1618620959.0,[P] Darknet on AMD Hardware,http github com alexeyab darknet compar master os hackathon master http github com alexeyab darknet compar master os hackathon master
iarai-weather4cast,MachineLearning,1617294382.0,[N] Join our new IARAI Multi-sensor Weather Forecast Competition!,join new multi sensor weather forecast competit studi multi channel weather movi predict weather product variou earth region appli transfer learn new earth region goal goal competit short term predict select weather product three region core challeng appli transfer learn predict weather product three addit region transfer learn challeng follow recent success trafficnmbrcast competit neurip nmbr nmbr thi challeng similarli present weather forecast video frame predict task competit goal predict next nmbr imag nmbr hour nmbr minut interv weather movi imag contain four channel encod follow weather product temperatur access surfac top cloud earth convect rainfal rate probabl occurr tropopaus fold cloud mask base meteorolog satellit data obtain collabor aemet nwc saf pixel imag repres area nmbr km x nmbr km region contain nmbr x nmbr pixel region span vari landscap includ mountain desert island sea challeng offer real world benchmark shot transfer learn allow test multi sensor data fusion join us learn data websit weathernmbrcast ai http weathernmbrcast ai prize winner core competit transfer learn competit award follow prize nmbrst place voucher cash prize worth nmbr nmbr particip team nmbrnd place voucher cash prize worth nmbr nmbr particip team nmbrrd place voucher cash prize worth nmbr nmbr particip team deadlin competit start april nmbr nmbr submiss deadlin may nmbr nmbr nmbr nmbr aoe held dataset avail june nmbr nmbr abstract submiss held dataset predict june nmbr nmbr nmbr nmbr aoe announc winner june nmbr nmbr
StrasJam,MachineLearning,1617867075.0,[D] Facebook's use of Softmax in multi-label classification,wa read thi paper http arxiv org pdf nmbr pdf put group research facebook found use softmax ce loss function dure train led improv result sigmoid bce dure train chang one hot label vector nmbr divid number label given imag e g nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr howev mention thi could use infer stage becaus requir threshold select correct label clear would theoret need set base upon expect number label imag inform avail infer ha anyon els read thi paper idea thi could work
jj4646,MachineLearning,1619296637.0,[D] relationship between svm and neural networks,thi correct svm project data higher dimens look pattern project back lower dimens make final decis wherea neural network directli project data lower dimens make decis
zy415,MachineLearning,1619705753.0,[D] IJCAI 2021 Paper Acceptance Result,ijcai nmbr paper accept result releas creat discuss thread thi year result
huseinzol05,MachineLearning,1618732918.0,"[P] Malaya-Speech, Speech-Toolkit library for Malay language, powered by Deep Learning Tensorflow",featur age detect detect age speech use finetun speaker vector speaker diariz diariz speaker use pretrain speaker vector emot detect detect emot speech use finetun speaker vector gender detect detect gender speech use finetun speaker vector languag detect detect hyperloc languag speech use finetun speaker vector multispeak separ multispeak separ use fastsep nmbrk wav nois reduct reduc multilevel nois use stft unet speaker chang detect chang speaker use finetun speaker vector speaker overlap detect overlap speaker use finetun speaker vector speaker vector calcul similar speaker use pretrain speaker vector speech enhanc enhanc voic activ use waveform unet speech text end end speech text malay mix malay singlish use rnn transduc super resolut super resolut nmbrx waveform text speech text speech malay singlish use tacotronnmbr fastspeechnmbr vocod convert mel waveform use melgan multiband melgan univers melgan vocod voic activ detect detect voic activ use finetun speaker vector voic convers mani one one mani mani mani zero shot voic convers hybrid nmbr bit quantiz provid hybrid nmbr bit quantiz model reduc infer time nmbrx model size nmbrx pretrain model wave unet multi scale neural network end end audio sourc separ http arxiv org ab nmbr wave resnet unet ad resnet style wave unet paper produc wave resnext unet ad resnext style wave unet paper produc deep speaker end end neural speaker embed system http arxiv org pdf nmbr pdf speakernet nmbrd depth wise separ convolut network text independ speaker recognit verif http arxiv org ab nmbr vggvox larg scale speaker identif dataset http arxiv org pdf nmbr pdf ghostvlad utter level aggreg speaker recognit wild http arxiv org ab nmbr conform convolut augment transform speech recognit http arxiv org ab nmbr alconform lite conform paper produc jasper end end convolut neural acoust model http arxiv org ab nmbr tacotronnmbr natur tt synthesi condit wavenet mel spectrogram predict http arxiv org ab nmbr fastspeechnmbr fast high qualiti end end text speech http arxiv org ab nmbr melgan gener adversari network condit waveform synthesi http arxiv org ab nmbr multi band melgan faster waveform gener high qualiti text speech http arxiv org ab nmbr srgan modifi version srgan nmbrd convolut photo realist singl imag super resolut use gener adversari network http arxiv org ab nmbr speech enhanc unet http github com haoxiangsnr wave u net speech enhanc speech enhanc resnet unet ad resnet style speech enhanc unet paper produc speech enhanc resnext unet ad resnext style speech enhanc unet paper produc univers melgan univers melgan robust neural vocod high fidel waveform gener multipl domain http arxiv org ab nmbr fastvc faster accur voic convers use transform paper produc fastsep faster accur speech separ use transform paper produc wavnmbrvec nmbr framework self supervis learn speech represent http arxiv org ab nmbr check latest document http malaya speech readthedoc io check github repositori http github com huseinzolnmbr malaya speech
marksteve4,MachineLearning,1617752955.0,[D] state of art for Speaker Diarization?,tri resemblyz http github com resembl ai resemblyz method yet alway either cut much hi voic includ much also requir clip talk qualiti clip heavili impact perform
malia912,MachineLearning,1620140015.0,YOLOV5 with a second stage classifier [D],hello everyon thi question regard yolovnmbr detect py modul saw second stage classifi set fals problem statement want classifi imag secondari classifi first stage yolovnmbr draw bound box around imag dog basic localis dog imag help secondari classifi want classifi dog respect breed result bound box around dog name breed ha anyon tri thi approach thank time
ztzyz615,MachineLearning,1619087386.0,[D] Any statistical theory for mixture density network?,want ask whether ani paper work relat statist theori mixtur densiti network http public aston ac uk id eprint nmbr nmbr ncrg _nmbr _nmbr pdf http public aston ac uk id eprint nmbr nmbr ncrg_nmbr_nmbr pdf like converg rate estim error bound lot search fail find mani thank
PaganPasta,MachineLearning,1618989276.0,[D] Adding under review/submitted papers on Resumé?,recent skim resum potenti candid research role came across plenti add submit review cvpr icml etc public list thi common practic becom annoy paper arxiv candid wish present also share time paper underwhelm lack rigour mani front see poor effort ad reput confer name resumé perhap miss util thi inform
say_wot_again,MachineLearning,1618230205.0,[R] What Will it Take to Fix Benchmarking in Natural Language Understanding?,
hnipun,MachineLearning,1617549237.0,[P][D] Dynamic Hyper-parameters,hyper paramet control learn process model set befor train start either intuit hyper paramet search either stay static chang base pre determin schedul introduc dynam hyper paramet manual adjust dure train base model train stat github http github com lab ml labml http github com lab ml labml app http app labml ai http app labml ai hyper paramet hyper paramet paramet control learn process model learn rate batch size weight decay model might learn hyper paramet set correctli set hyper paramet key part deep learn research research find base intuit run hyper paramet search hyper paramet search model train repeatedli differ hyper paramet find best set hyper paramet hyper paramet search becom costli number hyper paramet increas model train time increas hyper paramet chang dure train base pre determin schedul exampl could slowli decreas learn rate could decreas coeffici auxiliari loss model learn find schedul nearli imposs hyper paramet search usual determin base intuit research whi hard determin hyper paramet set hyper paramet requir quit bit experi kind model size train well dataset instanc consid fine tune pre train languag model classifi tweet get pre train languag model backbon attach layer two classif head first freez paramet backbon train head certain number updat unfreez paramet train paramet number step keep backbon frozen gener set nmbr epoch thi hyper paramet common practic freez nmbr epoch might small larg depend size model well dataset size someon ha work similar model dataset good intuit thi hyper paramet new tri train model get feel introduc dynam hyper paramet dynam hyper paramet hyper paramet research adjust model train thi allow research activ control model train instead let model train pre determin set hyper paramet dynam hyper paramet help train model faster better singl train session also let research play around hyper paramet dure singl train run gather insight sometim research save model checkpoint restart train chang hyper paramet valu thi ha similar effect dynam hyper paramet quit cumbersom doe work need creat dynam hyper paramet regist along configur labml import experi labml config import floatdynamichyperparam lr floatdynamichyperparam nmbre nmbr range_ nmbr nmbr experi config learning_r lr call dynam hyper paramet get current valu exampl def train batch optim set_lr lr optim step call lr return current learn rate set labml ai http labml ai app http github com lab ml app thi http github com lab ml labml raw master guid dynamic_hp png screenshot mobil web interfac chang dynam hyper paramet thi demo http app labml ai run nmbreffnmbranmbrenmbrebnmbrbnmbrdbnmbrenmbrf hyper_param demo adjust learn rate clip rang number train epoch per sampl speed train ppo agent http nn labml ai rl ppo experi html atari breakout standard learn rate decay static hyper paramet valu would taken lot train updat get score nmbr exampl use case freez pre train layer fine tune languag model train backbon frozen rate improv loss drop chang hyper paramet affect layer frozen thi better faster go common practic keep backbon frozen nmbr epoch model dataset learn rate warm decay learn rate manual increas dure initi train updat could decid long warm base loss curv similarli decay learn rate loss valu stabil thi allow use higher learn rate initi speed train increas sequenc length recurr model train faster bptt length shorter need higher bptt length improv accuraci therefor common practic start shorter bptt length increas later decid thi beforehand hard chang thi dynam lot easier adjust regular paramet start lower weight decay lower dropout probabl initi especi sure represent capac model increas regular paramet later valid loss stop improv higher varianc adjust reinforc learn hyper paramet reinforc learn tend hyper paramet need chang dure train discount factor entropi bonu coeffici learn rate etc pre determin almost imposs without observ train run train run go mani hour day even simpl game environ chang dure train base agent perform stat lot easier next updat hyper paramet schedul current implement onli allow user updat hyper paramet valu thi take much user time instanc let say base current loss curv user figur want drop learn rate nmbre nmbr nmbre nmbr dure next nmbr nmbr updat current implement would make sever manual chang want let user set updat hyper paramet schedul user ha manual interven onli necessari rewind often train dynam hyper paramet feel like experi sort like small hyper paramet search model train thing go wrong want reset enabl thi work simpl rewind undo option user could restart ani checkpoint coupl tap screen
init__27,MachineLearning,1620470429.0,[P] Video/Discussion on Building an Aircooled rig to accommodate 3x GPUs,video url http www youtub com watch v snmbr lmnmbrmzjnnmbr http www youtub com watch v snmbr lmnmbrmzjnnmbr nmbr hi everyon thi project start tri find guid effect air cool nmbr nmbr gpu dl box find ani detail discuss pick correct part lot iter wa abl build one decid publish video discuss part reason behind select anyon could use thi templat build rig pc part list http pcpartpick com list gfgtfnmbr http www youtub com redirect event video_descript redir_token quffluhqanmbrnylpnduvnmzhldjvnmbrmldnsuunmbrnuonmbrmvrsqxxbqnmbrjtcnmbrttqnmbrozunmbrenfnpawfdvwnmbrzvfzgrnmbrpnmbraktdehdxbnmbrjpvnmbrotzedpntanmbrsnbnvxzkbuknmbrqjlsatlcotzemwrnmbruzhwdnmbrdhmkfsbmtiluzxcenmbrbvllyrgvcwuytmfvkytbzqvhoylfnxnmbrpozwnbttzdenunmbruq q http nmbra nmbrf nmbrfpcpartpick com nmbrflist nmbrfgfgtfnmbr note show correct gpu msi game x trio nmbr msi ventu nmbrx anmbr resourc apart thi would highli encourag refer solid writeup u emilwalln http www emilwalln com p ml rig http www emilwalln com p ml rig well legendari tim detter blog http timdettm com http timdettm com happi answer ani qs tia
phenomenonical,MachineLearning,1620462828.0,[D] Tech stack and resources for a ML project,would best tech stack resourc would need thi potenti ml product assum input data alreadi store azur could possibl store intern server cloud provid end product would web app show predict map web app would ideal regist user would collect light data user info activ machin learn model would collect new data retrain make new predict annual model mainten would done compani unless thi good idea client municip administr budget small would onli provid url host eu ani user data collect would need gdpr compliant background solo ing data scientist msc data scienc actual ml work experi seen preced tri get ml run larg nmbr nmbr person firm came good idea weav ml tradit servic firm provid need figur actual thing done proof concept toy data gave promis result could end end product done within azur cheaper option sinc ml model would onli need updat annual compani ha difficulti fund innov tie directli client project essenti budget get client buy team member would make sens bring outsourc ani part thi extern compani handl model build idea happen make api broadcast predict compani lawyer overse countri gdpr complianc sure much free time ha also current work close develop ish person wa involv creat web app sure much technic knowledg ha whenev press detail seem clue exampl never heard azur befor mention said someth use github web app
Daddy_Long_Legs,MachineLearning,1619199043.0,[D] Hyperparameter tuning with a budget constraint on total number of model parameters,thi possibl ani hyperparamet framework convolut network hypterparamet kernel size number layer number channel would like search paramet place limit total number paramet present model due deploy found thi paper http arxiv org pdf nmbr pdf could find ani code implement strategi ha anyon implement someth like thi alreadi facebook ax allow someth similar onli linear combin paramet tough sinc number paramet conv layer superlinear n nmbr k seem like thi common problem curiou whi thi well
MacaronFraise,MachineLearning,1619255019.0,[D] Improve KNN calculation time,hey guy current work machin learn project use knn perform issu moment knn load flask server host heroku whenev want make predict send flask server paramet predict problem encount take much time make singl predict nmbr second project actual need make nmbr predict one go post order ask solut way optim knn handl nmbr predict quickli host knn anoth host servic comput power adapt machin learn like azur quit new thank lot help updat test realiz use nmbrmb ram avail heroku know normal figur code optim use much memori
dptzippy,MachineLearning,1619208491.0,[D] What are some projects/tutorials that I could use to get started with ML?,hello everybodi tri learn ml improv find ani project tutori explain exactli go look ani free prefer written form tutori help start ml side question tri find way creat program model fed text file add vocabulari use gener text find someth thi sure want see anybodi knew project framework tutori new python ml program sever year might need dumb specif stuff probabl understand broader concept thank
pircherth,MachineLearning,1619201704.0,[R] The structure dilemma in biological and artificial neural networks,role intern structur inform process network artifici biolog base model thi structur chang dure learn show structur lead edg weight structur problem exclus http www natur com articl snmbr nmbr nmbr nmbr
RchGrav,MachineLearning,1618790215.0,[D] I made a script that does all the work to deploy GPT-NEO on Windows 10. (Please Test),envis purpos window nmbr gpt neo local demo averag joe http gist github com rchgrav nmbrbbnmbranmbranmbrenmbrcenmbreanmbr http gist github com rchgrav nmbrbbnmbranmbranmbrenmbrcenmbreanmbr thi doe deploy minicondanmbr configur base environ download run one gpt neo model either cpu cuda capabl devic gpu w cuda instal chose minicondanmbr becaus concept behind thi wa allow someon run gpt neo local experiment foundat base environ thi work pleas report back detail thi privat gist moment may put github page peopl say thi would benefit anyon onli ha window system struggl get work system go onli start journey actual work machin learn hand deploy script year field technic note script instal use choco command model apt linux chocol org http chocol org bootstrap minicondanmbr use echo gener support script request elev reload path environ variabl one step process run script final script also creat exampl python file execut text gener text also condit main script run tri redeploy everyth drop gpt neo demo note bottom gist help anyon look run gpu use larger transform model minimum recommend spec ton core nmbrgb fast storag nvme ssd suggest nmbrgb hdd space smaller model nmbrx bigger model nmbrx run gpu know geforc rtx nmbr work sure need instal cuda nvidia thi much know side note person wa hope get gpt neo work jetson nano board even swap think go realli tight fit sound like gon na cost nmbr wan na pretend michael knight convers car p pleas share feedback thi may help look quick easi bootstrap way play gpt text gener mess anaconda sinc minicondanmbr run environ far surmis see mess anyth system
TheCockatoo,MachineLearning,1618909454.0,[D] How to do stratified train/test split for semantic segmentation?,word ensur similar class distribut train test set sampl arbitrarili pixel class b pixel class b
techsucker,MachineLearning,1618502126.0,"[R] Brown University Researchers Introduce DeepONet, A Model Based On Deep Neural Network, To Approximate Both Linear and Nonlinear Operators (Paper and Github link included)",research brown univers built deeponet novel neural network base model effici learn linear nonlinear oper thi novel model wa inspir earlier studi led research fudan univers continu function doe ani abrupt chang valu precis small chang continu function output assur restrict suffici small chang input mani studi show artifici neural network ann highli effici approxim continu function howev mani studi yet focus abil approxim nonlinear oper inspir paper publish chen chen fudan univers discuss function approxim use singl layer neuron research decid explor possibl build neural network could approxim linear nonlinear oper summari http www marktechpost com nmbr nmbr nmbr brown univers research introduc deeponet model base deep neural network approxim linear nonlinear oper http www marktechpost com nmbr nmbr nmbr brown univers research introduc deeponet model base deep neural network approxim linear nonlinear oper paper http www natur com articl snmbr nmbr nmbr nmbr http www natur com articl snmbr nmbr nmbr nmbr github http github com lululxvi deeponet http github com lululxvi deeponet
maroxtn,MachineLearning,1617669407.0,[D] Is there better options than beam search in translation ?,better sampl strategi beam search use big compani translat googl translat train transform translat get lot repeat ngram use beam search longer sentenc
crack_pop_rocks,MachineLearning,1620581059.0,Any suggestions for deep learning textbooks that have a neuroscience perspective? [Discussion],wa wonder anybodi expert ani suggest textbook address deep learn neurosci perspect sever good public subject difficulti find someth comprehens studi ml nmbr month pretti steadi progress start get neural network background neurobiolog cognit neurosci fundament principl behind dlnn model architectur behavior alreadi familiar deep learn much statist orient neurosci given natur model eas access quantit data actual surpris littl biolog system discuss referenc especi given much know variou mechan modul learn synapt integr dendrit tree http sci hub se nmbr neu nmbr function signific passiv activ dendrit properti synapt integr identifi nonspik interneuron crayfish http journal physiolog org doi full nmbr jn nmbr also ani phd read thi look jellyfish primordi neural net compos ganglia anatom seem similar deep learn model architectur abstract jellyfish nerv net provid insight origin nervou system taxonom posit evolutionari age impli jellyfish resembl earliest neuron bear activ swim anim develop first neuron network model nerv net jellyfish specif focu moon jelli aurelia aurita control energi effici swim motion propos singl neuron model disentangl contribut differ current spike network model identifi factor ensur non patholog activ suggest optim transmiss signal model jellyfish muscl system bell hydrodynam environ explor swim elicit neural activ find differ delay nerv net activ lead well control differ direct movement model bridg scale singl neuron behavior allow comprehens understand jellyfish neural control locomot http elifesci org articl nmbr http elifesci org articl nmbr
bachier,MachineLearning,1617909974.0,"[D] CVPR 2021 paper ""The Affective Growth of Computer Vision""",http authent sice indiana edu public su _crandal affectivegrowthcv cvprnmbr pdf http authent sice indiana edu public su_crandal affectivegrowthcv cvprnmbr pdf author norman makoto su david j crandal abstract success deep learn ha led intens growth interest comput vision along concern potenti impact societi yet know littl chang affect peopl research practic comput vision commun spend much effort tri replic abil human littl time consid impact thi work ourselv thi paper report studi ask comput vision research practition write stori emot salient event happen analysi nmbr respons found tremend affect emot strain comput vision commun mani describ excit success found strikingli frequent feel isol cynic apathi exasper state field thi especi true among peopl share unbridl enthusiasm norm standard comput vision research see themselv part incrowd find suggest feel close tie kind research profession practic expect comput vision argu commun signific statur need work toward inclus cultur make transpar address real emot toil member
uhtiloah,MachineLearning,1617282793.0,AutoLoss-Zero: Searching Loss Functions from Scratch for Generic Tasks,
cloudone,MachineLearning,1618589798.0,[R] Efficient Large-Scale Language Model Training on GPU Clusters,
ilia10000,MachineLearning,1617749313.0,"[D] Is ""data"" plural in modern machine learning literature?",titl suggest tri figur whether modern machin learn literatur consid data plural noun e g data spars singular mass noun e g data spars phd supervisor argu plural form correct feel like sound quit right least cs ml context hit ear googl search suggest plural form histor consid correct one gener usag data sever time higher usag data appar scientif literatur usag equal doe anyon ani statist comment thi topic specif contemporari machin learn literatur
givdwiel,MachineLearning,1616408714.0,[P] pyRDF2Vec 0.2.0 is out!,pyrdfnmbrvec nmbr nmbr thi releas pack mani new featur optim hood entir overview new found changelog http github com ibcnservic pyrdfnmbrvec releas tag nmbr nmbr http github com ibcnservic pyrdfnmbrvec releas tag nmbr nmbr overview major updat nmbr rdfnmbrvec rdfnmbrvec techniqu gener embed node entiti knowledg graph often repres rdf format henc name techniqu unsupervis therefor task agnost gener embed node use multipl downstream task concret exampl graph contain inform chemic compound exampl snippet thi data compound rdf dnmbr cytogen_sc rdf datatyp xsd boolean true cytogen_sc hasatom rdf resourc dnmbr _nmbr mouse_lymph rdf datatyp xsd boolean fals mouse_lymph amestestposit rdf datatyp xsd boolean fals amestestposit hasatom rdf resourc dnmbr _nmbr hasbond rdf resourc bondnmbr hasbond rdf resourc bondnmbr hasbond rdf resourc bondnmbr hasatom rdf resourc dnmbr _nmbr hasbond rdf resourc bondnmbr hasatom rdf resourc dnmbr _nmbr hasatom rdf resourc dnmbr _nmbr hasbond rdf resourc bondnmbr cytogen_ca rdf datatyp xsd boolean fals cytogen_ca compound turn numer represent rdfnmbrvec http preview redd xdqhknmbrzevnmbrpnmbr png width nmbr format png auto webp nmbrenmbrdnmbranmbrdcnmbranmbrdnmbrcbnmbrddebnmbr nmbr rudimentari liter support addit node embed pyrdfnmbrvec extract numer inform neighbourhood around node user specifi path predic follow obtain numer inform http preview redd wnmbrueuoevnmbrkonmbr png width nmbr format png auto webp cdnmbrfcnmbrcnmbrednmbrenmbrenmbreenmbrbanmbradnmbraenmbr nmbr onlin learn origin entir model train underli knowledg graph chang thi longer case pyrdfnmbrvec nmbr nmbr featur onlin learn updat embed model dynam http preview redd nmbrwasofiynmbrkonmbr png width nmbr format png auto webp nmbrdnmbranmbrenmbranmbrdfnmbrbnmbrfnmbranmbrenmbrfbnmbranmbrebnmbrfnmbrcnmbrd nmbr revers walk origin walk algorithm extract children start certain root recurs pyrdfnmbrvec nmbr nmbr parent extract well thi enabl better interact underli window use wordnmbrvec http preview redd rijlnmbrpdznmbrkonmbr png width nmbr format png auto webp nmbrcnmbrdnmbrbnmbrbfednmbrbnmbrfnmbrecnmbrfnmbrdeenmbrc nmbr blaze fast walk mani optim made hood speed walk extract optim includ multiprocess cach asynchron oper etc speedup order magnitud easili achiev http preview redd nmbrthhykcnmbrkonmbr png width nmbr format png auto webp nmbrecdnmbrdnmbrfnmbrcnmbrfaenmbrenmbrfbnmbrfnmbrbnmbr extra blog post thi publish shortli moreov notic pyrdfnmbrvec increasingli use within differ studi great see compil overview http pyrdfnmbrvec readthedoc io en latest post paper html http pyrdfnmbrvec readthedoc io en latest post paper html
hyunwoongko,MachineLearning,1616353077.0,[P]Summarizers: Easy to use controllable summarization package,http preview redd nmbrtlzfppwhfonmbr png width nmbr format png auto webp dabbnmbranmbrcnmbrenmbrfnmbrbafnmbrecfnmbrdnmbrf hello studi natur languag process made packag thi weekend write post share becaus think might abl use well packag name summar name suggest easi tool summar text howev summar support varieti control summar option like abov imag well varieti domain gener articl summari paper summari patent summari inform pleas visit http github com hyunwoongko summar http github com hyunwoongko summar
davidbun,MachineLearning,1617030776.0,"[N] do well in a CVPR/Kaggle Plant Pathology Challenge, win $500",tl dr top nmbr team use packag activeloopai hub cvpr plant patholog kaggl challeng win nmbr hey r machinelearn team creat hub github com activeloopai hub http github com activeloopai hub packag make unstructur dataset ani size access ani machin ani scale help seamlessli stream data pytorch tf local part ongo effort support machin learn commun support team well thi year cvpr fgvcnmbr challeng start plant patholog challeng http site googl com view fgvcnmbr competit plantpathologychallengenmbr authus nmbr team place top nmbr challeng kaggl leaderboard use packag solut receiv nmbr addit inform see wiki http github com activeloopai hub wiki hub plant patholog nmbr challeng let know short notebook http github com mynameisvinn hub tutori blob master push nmbrplant nmbrpatholog nmbrdataset nmbrto nmbrhub ipynb use hub cvpr dataset featur hub might find relev dure challeng creat larg dataset huge nmbr nmbr x nmbr nmbr size array store local hub storag ani cloud collabor team dataset version control dataset api filter dataset onli get sampl need creat data pipelin transform data easili access visual ani slice dataset without download entir dataset directli plug hub dataset tensorflow pytorch start train transfer dataset across differ locat easili good luck davidbun
user01052018,MachineLearning,1616920279.0,[D] Pointer sentinel mixture model - Why is $P_{ptr}$ is $V$ dimensional?,check thi paper http arxiv org ab nmbr http arxiv org ab nmbr research paper said model capabl predict onli rare less frequent word also unseen word notic p _ ptr size v mean way encod inform unseen word v size vector wonder possibl unseen word train consid v size vocabulari appear softmax vocabulari clear suppos rnn vocabulari contain nmbr word reddit user unk suppos nmbr unseen word text like quora stackoverflow lichess wikipedia would nmbr size vocabulari handl
ykilcher,MachineLearning,1616435112.0,[D] Paper Explained - Perceiver: General Perception with Iterative Attention (Full Video Analysis),http youtu p _xeshtnpzg http youtu p_xeshtnpzg inspir fact biolog creatur attend multipl modal time deepmind releas new perceiv model base transform architectur perceiv make assumpt modal input data also solv long stand quadrat bottleneck problem thi achiev latent low dimension transform input data fed multipl time via cross attent perceiv weight also share across layer make veri similar rnn perceiv achiev competit perform imagenet state art modal make architectur adjust input data outlin nmbr nmbr intro overview nmbr nmbr built assumpt comput vision model nmbr nmbr quadrat bottleneck transform nmbr nmbr cross attent transform nmbr nmbr perceiv model architectur learn queri nmbr nmbr posit encod via fourier featur nmbr nmbr experiment result attent map nmbr nmbr comment conclus paper http arxiv org ab nmbr http arxiv org ab nmbr
AerysSk,MachineLearning,1620222682.0,[D] A small dataset with high resolution?,hello everyon test augment strategi current use cifar small nmbrxnmbr visual result ani dataset small size like nmbr imag smaller ha high resolut abov nmbrxnmbr mayb use pytorch code load greatli appreci
MrAcurite,MachineLearning,1619615551.0,[D] Recommendations for increasing training stability with extremely small batches?,howdi folk current situat batch size basic exceed nmbr cluster abl much better thi think lead stabil issu becaus phenomena model take input homogen given step model simpli tri optim toward give appropri output gener rather condit tri bump beta adam optim hold onto gradient multipl batch appli onc ani idea
yashchandak,MachineLearning,1619781819.0,[R] Universal Off-Policy Evaluation,hi everyon happi share first step toward univers polici estim uno one provid polici estim high confid bound ani paramet return distribut http arxiv org ab nmbr http arxiv org ab nmbr joint work scott niekum bruno silva erik learn miller emma brunskil phil thoma use uno estim simultan bound mean varianc quantil median inter quantil rang cvar entir cumul distribut return polici counterfactu set also discuss uno applic variou set includ fulli observ partial observ e unobserv confound markovian non markovian stationari smoothli non stationari discret distribut shift uno use mani critic applic requir think metric beyond expect return exampl medic set tail sensit risk measur like valu risk cvar essenti avoid catastroph outcom onlin recommend metric like median inter quantil essenti tackl high nois data collect human machin interact metric like varianc entropi essenti quantifi uncertainti system outcom believ bare scratch surfac thi direct welcom ani feedback
SeasonedLeo,MachineLearning,1617925125.0,Multi classification issue [R],hello work multi classif problem three class use light gbm model fnmbrscore test data set pretti good three class nmbr howev tri classifi use thi model new set model misclassif huge abl understand thi possibl happen ani pointer idea dat featur thank help
dokluch,MachineLearning,1620367447.0,[D] Deploying ML model for inference on user devices,hi would like creat simpl app coupl pre train ml model would run varieti user devic window maco machin nvidia amd even gpu ani guidelin infrastructur current look tflite sure right way thank
cdossman,MachineLearning,1618397655.0,[D] Understanding Hinton’s Capsule Networks Series,whi capsul neural network architectur import intuit behind dive technic detail part intuit http pechyonkin capsul nmbr part ii capsul work http pechyonkin capsul nmbr part iii dynam rout capsul http pechyonkin capsul nmbr part iv capsnet architectur http pechyonkin capsul nmbr
SrData,MachineLearning,1619252993.0,[D] Recovering images from bottlenecks or training dataset.,wonder possibl gener imag use train cnn possibl gener imag input bottleneck know paper post could check investig thi http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf imag compress spars code vs bottleneck autoencod although similar point investig thi understand level privaci imag bottleneck produc imag store go beyond level privaci imag use train model
runcep,MachineLearning,1617622899.0,[D] Are there attempts at a large German-language LM?,awar smaller attempt huggingfac ha german gpt nmbr model also zamia model wonder univers research group project want build proper german languag lm size gpt nmbr xl model especi interest learn train set made saw pile interest build open sourc model differ languag could find anyth german one ani hint appreci
AhmedAl93,MachineLearning,1617316167.0,[D][R] Solutions for handwritten text generation,hello aim post discuss possibl solut synthet handwritten text gener specif constraint context current work data scientist french compani encount issu deal handwritten text recognit mainli becaus amount avail data simpli enough nmbrk imag handwritten text first idea came mind gener larg artifici handwritten text dataset assembl singl handwritten charact check charsnmbrk dataset made script take string input assembl charact imag provid imag contain handwritten text thi strategi gave realli promis result train text recognit model call deep text recognit benchmark artifici dataset nmbrk imag finetun real dataset got nmbr accuraci howev even thi result good improv mainli gener handwritten text similar real one possibl wa think use gan model problem need lack first place big amount data ani idea solv thi dilemma also thought thi dilemma seen phd thesi propos plan discuss manag share view thi would great
VeterinarianTight102,MachineLearning,1618891530.0,[P] Awesome Semantic Search,edit thank current support repositori paper tool project librari dataset conf relat multimod semant search task current ha mainli text base stuff http github com agrovernmbr awesom semant search believ plethora content relat topic less consolid one place
techsucker,MachineLearning,1618244638.0,[R] Researchers At The University of Tokyo Present A Frequency-Based Inpainting Method To Generate Missing Image Portions,research univers tokyo introduc frequenc base inpaint method use frequenc spatial inform gener miss imag portion imag inpaint comput vision cv techniqu fill miss pixel imag allow remov unwant object photo recreat miss region occlud imag inpaint popularli use predict miss imag data howev difficult synthes miss pixel realist coher summari http www marktechpost com nmbr nmbr nmbr research univers tokyo present frequenc base inpaint method gener miss imag portion http www marktechpost com nmbr nmbr nmbr research univers tokyo present frequenc base inpaint method gener miss imag portion paper http www spiedigitallibrari org journal journal electron imag volum nmbr issu nmbr nmbr imag inpaint use frequenc domain prior nmbr nmbr jei nmbr nmbr full sso nmbr
andyljones,MachineLearning,1617866914.0,[R] Scaling Scaling Laws with Board Games,studi sequenc small problem let extrapol behaviour order magnitud larger problem paper http arxiv org ab nmbr tweet thread http twitter com andy_l_jon statu nmbr work board game friendliest domain possibl thi scale behaviour potenti show mani place resourc constrain research think realli promis avenu look keen hear thought
elbogotazo,MachineLearning,1617384423.0,Discovering column mappings [R],challeng work work tri figur approach intern system store transact data tabular form receiv daili file data domain transact metadata column name standardis data field alway exact e g amount field may nmbr digit behind comma system expect nmbr digit system call amount might call quantitynmbr incom file etc multipl amount date free text categor field relationship field note sourc data come extern parti control format incom file manual map transform defin incom file volum differ format sourc ever increas im look way take ani input file train model predict column like correspond column target file look thing use nlp spaci train model recognis pattern column data e g numer period comma like correspond amount also look model data extract rdf represent use open sourc tool call karma see train model network graph realli struggl see implement thi regex would onli get us part way realli tri see scalabl way implement thi anyon awar formal name thi type problem tri test approach implement could build upon
Mundane_Definition_8,MachineLearning,1619678595.0,"[D] I'm kaggler and hate waiting result, what makes you feel good?",hi guy usual programm enjoy watch result immedi ml although want creat model hate wait result know realli like ai viewpoint make limit programm grow happi point creat model train
marksteve4,MachineLearning,1617819843.0,[D] Does anyone use huggingface hosted interface?,tri bunch mani disabl default much use miss sth thought sourc hf make money
DietMediocre8993,MachineLearning,1617816736.0,[D] ML Engineer with Data Engineer,hello fellow enthusiast upcom interview data engin role one round data scientist problem solv sure focu prep even kind question expect ani suggest seem focu would around product de scientist work collabor togeth think
Yuqing7,MachineLearning,1617162546.0,[N] Microsoft & Princeton’s Text-Game Agents Achieve High Scores in Complete Absence of Semantics,research team princeton univers microsoft research discov autonom languag understand agent capabl achiev high score even complet absenc languag semant indic current rl agent text base game might suffici leverag semant structur game text quick read microsoft princeton surpris discoveri text game agent achiev high score complet absenc semant http syncedreview com nmbr nmbr nmbr microsoft princeton surpris discoveri text game agent achiev high score complet absenc semant earli version paper read act blindfold need semant text game agent wa featur neurip nmbr workshop http wordplay workshop github io modern wordplay languag meet game updat paper avail arxiv http arxiv org pdf nmbr pdf
tars9999,MachineLearning,1617288820.0,Mixture of experts - tradeoffs vs traditional single nets [D],wa person surpris branch nn seemingli call mixtur expert wa popular sucess techniqu eg imagenet entri appear recent stori ani research compar train time model size evalu time nmbr dens net mixtur expert e g would pan tri imagenet eg nmbr branch nmbr categori nmbr vs nmbr also ani research tradeoff branch heirach moe like nmbr caterogi nmbrxnmbrxnmbr perhap particular problem optimum branch depth happen certain size optimum number branch nmbr guess singl net work better expect becaus featur cooper attempt moe model common trunk share branch
jostmey,MachineLearning,1616375436.0,[R] Dynamic Kernel Matching for Non-conforming Data: A Case Study of T-cell Receptor Datasets,preprint http arxiv org ab nmbr http arxiv org ab nmbr abstract statist classifi design find pattern data number fit row column like spreadsheet mani kind data conform thi structur uncov pattern non conform data describ approach modifi establish statist classifi handl non conform data call dynam kernel match dkm exampl non conform data consid dataset cell receptor tcr sequenc label diseas antigen ii dataset sequenc tcr repertoir label patient cytomegaloviru cmv serostatu anticip dataset contain signatur diagnos diseas success fit statist classifi augment dkm dataset report perform holdout data use standard metric metric allow indetermin diagnos final identifi pattern use statist classifi gener predict show pattern agre observ experiment studi
Yuqing7,MachineLearning,1617987945.0,"[N] TUM, Google, Nvidia & LMU München's CodeTrans Pretrained Models Crack Source Code Tasks With SOTA Performance",research team technic univers munich googl nvidia lmu münchen propos codetran encod decod transform model achiev state art perform six task softwar engin domain includ code document gener sourc code summar code comment gener etc quick read tum googl nvidia lmu münchen codetran pretrain model crack sourc code task sota perform http syncedreview com nmbr nmbr nmbr tum googl nvidia lmu munchen codetran pretrain model crack sourc code task sota perform codetran code avail project github http github com agemagician codetran paper codetran toward crack languag silicon code self supervis deep learn high perform comput arxiv http arxiv org ftp arxiv paper nmbr nmbr pdf
OnlyProggingForFun,MachineLearning,1619005027.0,[D] Will Transformers Replace CNNs in Computer Vision?,recent wrote articl transform replac cnn comput vision http pub towardsai net transform replac cnn comput vision nmbranmbr show transform appli onli text also imag type input cover paper call swin transform http arxiv org pdf nmbr pdf give way appli transform architectur comput vision know mani quit promis like perceiv http arxiv org ab nmbr question think transform better suit comput vision convolut neural network viabl comput time result compar cnn optim properti imag especi classif
m_nemo_syne,MachineLearning,1617723592.0,[R] Timers and Such: A Practical Benchmark for Spoken Language Understanding with Numbers,timer new speech dataset timer alarm unit convers math use test speech model train offlin voic assist paper http arxiv org ab nmbr http co nmbritxnmbrkkvyo amp nmbr code speechbrain http github com speechbrain speechbrain tree develop recip timer http github com speechbrain speechbrain tree develop recip timer pre train model hug face http huggingfac co speechbrain slu timer direct librispeech asr http huggingfac co speechbrain slu timer direct librispeech asr
jj4646,MachineLearning,1618972573.0,[D] Complexity of Time Series Models: ARIMA vs. LSTM,nmbr come time seri analysi tri understand make newer model lstm capabl captur complex pattern data compar older modei arima statist learn theori someth call vc dimens algorithm http en wikipedia org wiki vapnik enmbr nmbr nmbrchervonenkis_dimens vc dimens appar describ relart level complex machin learn algorithm captur doe thi concept vc dimens carri model time seri analysi possibl show lstm higher vc dimens compar arima style model supposedli neural network base time seri model develop becaus modeol like arima wa unabl provid reliabl estim bigger complex dataset mathemat speak allow lstm captur variat complex dataset compar arima nmbr late seen mani peopl start suggest convolout neural network cnn also use purpos time seri forecast gener question instanc would better use cnn time seri forecast compar lstm thank
AirZealousideal1342,MachineLearning,1618671696.0,[D]What is this in ontonotes dataset?,found ontonot mani punctuat preced slash e g error whi ha fix verionnmbr http preview redd brnmbrpnmbrtngnmbrrtnmbr png width nmbr format png auto webp nmbrenmbrenmbrcbnmbrbenmbrbfnmbrenmbrabnmbrdfnmbrcnmbrbenmbrccnmbrdnmbr normal http preview redd atckggnmbrvrvtnmbr png width nmbr format png auto webp anmbrednmbrdnmbrdnmbrenmbrbenmbrdbnmbrdnmbrdnmbrcnmbrdnmbr
Stingeymingey,MachineLearning,1617265463.0,[D] What's out there in terms of Video comprehension/understanding?,hi wonder peopl could point ani paper project work video subsequ frame understand object detect use previou frame context guid futur predict thank
cloudone,MachineLearning,1616563801.0,[N] Pieter Abbeel launched a new podcast,first guest andrej karpathi http www therobotbrain ai
BodybuildingPhD,MachineLearning,1616747965.0,[D] Does the NN really learns probability distribution?,current tri understand doe neural net learn probabl distribut first glanc thi seem imposs sinc basic neural net determinist non linear function vae encod vae take x input result main paramet distribut mostli mean covari gaussian distribut thi seem plausibl ad random variabl epsilion n nmbr construct normal distribut decod though mani literatur assum decod ha form probabl distribut p x z yet unlik encod part random structur vae decod moreov mani decod vae assum normal distribut could sure anyth miss
Koyset,MachineLearning,1617640968.0,"[Discussion] ""Developers should take philosophy classes to make ethical AI""",hello commun still third semest cs student alreadi rather confus workshop student job telecommun firm start two consult undergrad social scienc code provid us within day ai ethic guidelin develop implement dure work ask make guidelin like de bia code make inclus algorithm function code sinc first job said take addit philosophi class hidden bia implement ethic guidelin code doe everi compani ha guidelin sorri wa veri uncomfort ask question sinc understand overal workshop hope provid real life exampl job
the21st,MachineLearning,1619516433.0,[P] I missed writing native SQL queries inside jupyter so I built a Python+SQL interop feature in our notebook tool,hi simon engin deepnot previous work ml team lead e commerc compani recent built new featur deepnot want brag littl bit becaus proud nativ sql cell python interop check exampl project http deepnot com project rna explor duplic xlarwicernqqnmbridnmbrvnmbrrynmbra nmbrfnotebook ipynb full doc thi featur http doc deepnot com featur sql cell thi wa possibl thank stand shoulder open sourc giant panda jinjasql huge appreci make truli happi appreci ani feedback thought innov love see around notebook futur
New-Sound8660,MachineLearning,1616886907.0,[R] Teaching a machine to paint like a painter comparing photos and associated paintings,hello everybodi approach ml need guidanc idea set photo set human made paint base photo tri replic faith possibl photo give algorithm two set imag ask learn creat paint style painter ho realiz dataset start new photo ani suggest book articl cours blog follow learn thi would greatli appreci thank much
vladiliescu,MachineLearning,1616591206.0,[D] [P] How do you use tools like AutoML?,hi girl guy wa wonder use tool like automl day day life like anyth hnmbro googl automl auto sklearn ask sinc person onli find automl use train initi baselin know manag get dataset clean enough use itch see thi time need use someth lightgbm alway lightgbm though alway anyway apart thi initi phase realli use tool work azur flavor http doc microsoft com en us azur machin learn concept autom ml least revers engin model take whatev adapt whatev take kinda like picasso http quoteinvestig com nmbr nmbr nmbr artist steal imagin written short ish blog post creat model base azur automl train one find http vladiliescu net revers engin autom ml focus time seri underli principl appli regress classif model hope like appreci ani feedback may realli curiou use tool think approach
otso_ai,MachineLearning,1618355393.0,[P] otso Annotator - A cloud-based Text Annotator built for Machine Learning Engineers and Data Scientists working in teams.,otso ha launch annot built need mani thi sub check cloud base text annot built machin learn engin data scientist work otso annot two year began intern tool use manag annot data label machin learn project tool interfac develop began provid select enterpris custom receiv much signific posit feedback client decid launch annot standalon product otso annot provid three key benefit user experi prioritis eas use understand project manag featur let alloc manag annot task final cloud first tool longer need annot use cli get start make much easier tool team use whi focu user experi team text annot best done team environ ideal machin learn engin data scientist set run project subject matter expert provid annot built otso annot differ user type mind enabl seamless project setup project admin easi keyboard enabl annot experi annot thi public launch grant user team sign dure april extend trial period nmbr day check head otso ai annot http otso ai annot credit card requir
artificial_intelect,MachineLearning,1616734142.0,[P] NAS repos,look git repo implement mnasnet efficientnet onli ever seem implement network found neural architectur search doe anyon know git repo implement proxim polici optim find efficientnet similar na algorithm repo
tanelai,MachineLearning,1618087578.0,[P] Using PyTorch + NumPy? A bug that plagues thousands of open-source ML projects.,use numpi random number gener multi process data load pytorch caus ident augment unless specif set seed use worker _init _fn option dataload thi bug silent regress model accuraci mani ha thi bug done damag curiou download hundr thousand repositori github import pytorch analys sourc code kept project defin custom dataset use numpi random number gener multi process data load less straightforward analys use abstract syntax tree nmbr repositori plagu thi problem insid pytorch offici tutori openai code nvidia project even karpathi admit fall prey exampl follow imag show duplic random crop augment get blindli follow offici pytorch tutori custom dataset http preview redd pccynmbrwskpesnmbr png width nmbr format png auto webp fnmbrdnmbradnmbrcbacnmbrcnmbranmbrdnmbrfanmbrddnmbr read detail http tanelp github io post bug plagu thousand open sourc ml project
PT_Lightning,MachineLearning,1619457247.0,[N] Lightning Transformers - Train HuggingFace Transformers at scale with PyTorch Lightning,lightn transform http github com pytorchlightn lightn transform user want train evalu predict use huggingfac model dataset pytorch lightn full customiz code use lightningmodul trainer hydra config composit quick easi experiment boilerpl code requir easili swap model optim schedul without touch code check blog post train transform scale pytorch lightn http pytorch lightn medium com train transform scale pytorch lightn enmbrcbnmbrfnmbrdbnmbr inform document http lightn transform readthedoc io http redd ufmoebjbwjvnmbr gif
Mephistothelessa,MachineLearning,1616657297.0,[D] What is the best way to publish an image dataset?,hello peopl small team look around dataset need project find one decid properli creat one ourselv publish peopl use futur want properli publish dataset mean want use kaggl thi mayb dedic websit might work want look profession mayb github page may use suggest think best way publish dataset open suggest curiou guy think input appreci cheer
artificial_intelect,MachineLearning,1616542211.0,[D] PipeMare paper discussion,mayb pipemar paper rant back read paper mitig effect asynchron pipelin train call pipemar http proceed mlsi org paper nmbr hash nmbrcnmbrccnmbraenmbrenmbrbnmbranmbrf abstract html method seem novel super help ignor paper wa notic wa accept confer mlsysnmbr guess worth put thought onlin pipemar propos two method mitig asynchron pipelin nn train issu nmbr type asynchron pipelin nn train mitig pipelin backpropag petrowski et al nmbr petrowski et al nmbr even cite paper becaus pipedream cite petrowski et al nmbr doe mean note pipelin backpropag ha nmbr issu inconsist weight delay gradient pipedream use weight stash elimin inconsist weight still ha delay gradient pipemar elimin overhead weight stash discrep correct realli deal delay gradient except use lr warmup two method pipemar propos tnmbr learn rate reschedul type learn rate warm warm period base pipelin delay tnmbr discrep correct type backward weight predict reconcil weight use forward backward pass tnmbr deal weight inconsist doe mitig gradient delay issu nmbr tnmbr type learn rate warm whi doe paper show baselin run regular learn rate warm guess regular learn rate warm would well thi new convolut method tnmbr issu nmbr tabl nmbr pipemar paper show tnmbr work well tnmbr tnmbr whi use tnmbr seem help ha overhead pipedream weight stash elimin weight inconsist tnmbr onli mitig weight inconsist doe elimin nmbr chen et al http arxiv org ab nmbr propos method call spectrain work show weight inconsist big issu elimin use weight stash useless weight inconsist big issu shown spectrain paper whi use tnmbr especi sinc tabl nmbr show useless tnmbr novel evid simpl lr warm well tnmbr look like useless method neither novel use review mlsi see thi mean paper interest pipelin execut model interest analysi interest mitig method ie paper contribut increment best doe thi get person think spectrain paper http arxiv org ab nmbr similar topic better mitig method analysi good much better paper publish conf note author spectrain paper anyon attend mlsysnmbr could question author point brought thi post onli request question ask nice like said analysi delay optim still realli interest explor world fine grain pipelin train ie actual explor non mainstream execut model even pipelin backpropag ha exist sinc nmbr realli use modern nn edit paper figur nmbr figur nmbr show pipelin depth artifici increas veri larg tnmbr becom use point pipelin train ha hard time achiev accuraci sgd point mayb even use pipelin train
memgamemotron,MachineLearning,1619183370.0,[D] data science and ML bootcamp check!,anyon complet ani data scienc boot camp meti flatiron brain station gener assembl look see legit help land job data scienc complet boot camp advertis nmbr hire rate top tech compani curiou anyon contribut ani thought
TopIndependent5791,MachineLearning,1618733779.0,[D] Which AWS tools/services are necessary to learn for Machine Learning Engineer?,aw tool need learn order qualifi industri person involv machin learn colleg person project feel lack entri level industri knowledg would right resourc aw
mgl96,MachineLearning,1617264240.0,[N] Trankit v1.0.0 - An open-source Transformer-based Multilingual NLP Toolkit for 56 languages is out.,hi everyon releas version vnmbr nmbr transform base multilingu nlp toolkit name trankit outperform popular sota stanford nlp stanza mani task nmbr differ languag new version vnmbr nmbr offer trainabl transform base pipelin fundament nlp task nmbr languag nmbr new pretrain transform base pipelin nmbr languag new pipelin train xlm roberta larg boost perform significantli nmbr treebank univers depend vnmbr corpu english trankit significantli better stanza sentenc segment nmbr depend pars nmbr ua nmbr la arab toolkit substanti improv sentenc segment perform nmbr chines observ nmbr nmbr improv ua la depend pars perform languag also significantli improv detail comparison trankit stanza udpip spaci languag found http trankit readthedoc io en latest perform html univers depend vnmbr nmbr auto mode multilingu pipelin auto mode languag input automat detect enabl multilingu pipelin process input without specifi languag check turn auto mode http trankit readthedoc io en latest news html auto mode multilingu pipelin command line interfac avail use thi help user familiar python program languag use trankit easili check command line tutori thi page http trankit readthedoc io en latest commandlin html trankit written python easili instal via pip code pretrain model publicli avail http github com nlp uoregon trankit http github com nlp uoregon trankit also creat document page demo websit trankit document page http trankit readthedoc io en latest index html http trankit readthedoc io en latest index html demo websit http nlp uoregon edu trankit http nlp uoregon edu trankit technic detail trankit found paper http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf thank time read thi post hope enjoy trankit
RyanAI100,MachineLearning,1620584248.0,[D] Pooled Contextualised Embeddings for NER | Research Papers Summary 017,
hardmaru,MachineLearning,1620197291.0,[R] MLP-Mixer: An all-MLP Architecture for Vision,
orenog,MachineLearning,1619488275.0,[D] Node Collapse with StyleGAN2 - ada,hey reddit problem train stylegannmbr ada nmbr hearthston card result amaz start look got point gener nmbr card nmbr spell nmbr nmbr minion veri similar artwork tri augment pipelin option got result node collaps nmbr tick got less less variat went want ask way deal node collaps way deal node collaps specif stylegannmbr ada dataset seem like ha lot variat nmbr card look similar part differ type card card ha uniqu artwork somehow gener artwork look nmbr tick realli want work ani advic direct toward solut super help even know caus thank edit appar mode collaps node collaps
Farconion,MachineLearning,1620326515.0,[D] Any value in negative / null results?,middl complet small independ research project ml professor colleg ideal project wa aim reimplement replic result previou paper coupl year ago decent number citat nmbr extend upon work simpl worthwhil way howev reimplement code realli old pytorch compat hardwar run basic experi fail replic even basic result plan run experi confirm thi get hope obvious ani number reason thi chang pytorch error implement feel confid still etc tri write publish someth say techniqu x work becaus replic feel worthwhil correct doe anyon ani tip best way util null result like thi wa hope use thi project part grad school app current state sure best way frame even
robust_melon,MachineLearning,1619475121.0,[D] ethical considerations with launching a website with vehicle accident density forecasts,work project predict distribut accid citi local short term forecast horizon nmbr hour wish creat public page dashboard updat hourli forecast assum great model predict accid hot spot geograph like occur next hour ethic ramif forecast made public assum someon ill intent use thi inform crimin intent e g infer emerg respons resourc like edit bold emphasi
downtownslim,MachineLearning,1618939161.0,[R] The Power of Scale for Parameter-Efficient Prompt Tuning,
RyanAI100,MachineLearning,1619377883.0,[D] BERTweet (SOTA) for Named Entity Recognition in Social Media | Research Papers Summary 015,
biotechdood,MachineLearning,1617993459.0,[D] Looking for an interesting paper in the field of biotech and AI,hi present chosen paper day look revolutionari scientif discoveri contain ai domain bio biotech pharma bioprocess engin etc would realli thank could help ideal complic laymen come bio area would appreci wa someth supposedli revolutionari alphafold nmbr thank advanc kind regard would also appreci paper recommend field comput vision microscopi
hotpot_ai,MachineLearning,1617654345.0,[D] Overview on SOTA methods for deep learning model compression,intro thi post cover model infer optim compress breadth hope depth march nmbr thi includ engin topic like model quantiz binar research orient topic like knowledg distil well well known hack year larger larger model abl find method extract signal nois machin learn particular languag model get larger everi day model comput expens runtim memori costli serv custom slow larg function edg environ like phone research practition come mani method optim neural network run faster less memori usag thi post go cover state art method know anoth method think includ happi add thi ha slight pytorch bia haha becaus familiar url http rachitsingh com deep learn model compress http rachitsingh com deep learn model compress
federico-bianchi,MachineLearning,1620243697.0,[N] Coveo SIGIR Data Challenge for Ecommerce,interest coveo http www coveo com organ sigir data challeng use appli deep learn ml skill one biggest ecommerc dataset ever releas includ fine grain shop behavior search queri click unclick item product meta data catalog great chanc get creativ write research paper challeng websit http sigir ecom github io data task html repositori http github com coveooss sigir ecom data challeng import date registr end june nmbrst nmbr final leaderboard june nmbrth nmbr sigir ecom full day workshop juli nmbrth nmbr
Chriscbe,MachineLearning,1617135089.0,[R] Please point me in the right direction: decision trees or possibly something better,ml practition scientist studi purifi recombin protein gener profici python look way fortifi decsion make dure purif protein creat e coli cell cultur part ml would best learn order improv plan decis make decion tree like format seen literatur issu like start point understand exampl part sci kit learn might address issu etc thank ani help
amaigmbh,MachineLearning,1620394984.0,"[N] i.am.ai Newsletter - Updated AI Conference Calendar, Crowdsourced Speech Recognition, Dinos and more",hello http www youtub com watch v eaemskzqgag share latest edit http www ai en blog newslett nmbr utm_campaign newslett nmbr post r machinelearn utm_medium social utm_sourc reddit ai newslett hope thi interest annoy self promot read whole thing feel free subscrib http ai newslett utm_campaign newslett nmbr post r machinelearn utm_medium social utm_sourc reddit feedback welcom import iclr nmbr confer landmark deep learn confer iclr http iclr cc take place may nmbrrd may nmbrth second time gather held complet virtual research around world gather poster session keynot workshop nmbr paper nmbr accept confer offici outstand paper award award nmbr paper except qualiti lead confer find full list http iclr conf medium com announc iclr nmbr outstand paper award nmbraenmbrab meanwhil topbot made select iclr confer paper breakthrough potenti includ visual transform vit detr deberta perform paper previous introduc thi newslett read breakthrough paper topbot com http www topbot com iclr nmbr research paper come iclr onli mark begin annual confer summer global health situat onli improv slowli confer move virtual meet find updat version ai confer calendar import ai confer http www ai en blog ai confer nmbr utm_campaign newslett nmbr post r machinelearn utm_medium social utm_sourc reddit http preview redd ynmbrrbhnmbrecpxnmbr png width nmbr format png auto webp dnmbrbcnmbrcbnmbrenmbrabccnmbrbdnmbranmbrdnmbrfnmbr thing found worth share contribut crowdsourc project common voic aim creat free databas speech recognit nmbr languag sinc nmbr mozilla ask volunt record sampl sentenc review record recent saw usd nmbr million invest nvidia continu look particip contribut switch languag top right http commonvoic mozilla org en person recommend amai http linkedin com compani amai gmbh ceo jürgen stumpp http www linkedin com juergen stumpp book real world ai practic guid respons machin learn provid execut quick thorough overview step necessari success ai project moreov help soon univers graduat prepar work field book http www goodread com book show nmbr real world ai alyssa rochwerg director product blue shield appen cto wilson pang share practic experi present approach claim nmbrx higher success rate ai project compar industri averag learn real world ai practic guid respons machin learn thi author interview http www forb com site tomtaulli nmbr nmbr nmbr real world ai great guid manag paper dino paper emerg properti self supervis vision transform arxiv http arxiv org ab nmbr research inria facebook ai sorbonn univers introduc dino short self di stillat label thi method segment imag self supervis manner mean without label requir upfront read dino accompani paw venturebeat com http venturebeat com nmbr nmbr nmbr facebook detail self supervis ai segment imag video facebook ai blog ai facebook com http ai facebook com blog dino paw comput vision self supervis transform nmbrx effici train one man paper discuss group yannic kilcher walk hi viewer paper detail nmbr minut youtub com http www youtub com watch v hnmbrijnmbrfnmbrcpik self attent map select head gener use dino video hors bmx rider puppi fish boat facebook ai http reddit com link nnmbryspn video xghumnmbrcpxnmbr player market microsoft acquir nuanc april massachusett compani focuss ai driven speech recognit usd nmbr billion thi merger mark second highest acquisit microsoft histori linkedin wa acquir nmbr billion nmbr nuanc commun behind speech recognit capabl appl voic assist siri axio com http www axio com microsoft readi deal frenzi bbcnmbranmbr fdnmbrb nmbranmbr nmbrdnmbr cfnmbrdnmbranmbr html regul european commiss releas artifici intellig act nmbr page http digit strategi ec europa eu en librari propos regul lay harmonis rule artifici intellig artifici intellig propos regul ai propos legisl hurdl ahead politico eu http www politico eu articl nmbr key battl europ ai law artifici intellig act outsid eu chines regul begun enforc data local local compani data onli store china certain applic facial recognit biometricupd com http www biometricupd com nmbr china push standard face biometr plenti tongu cheek xkcd http xkcd com nmbr post nmbr type scientif paper natasha jaqu http twitter com natashajaqu max kleiman weiner http twitter com maxhkw two phd mit put togeth nmbr type machin learn paper http twitter com natashajaqu statu nmbr xkcd edit natasha jaqu http preview redd nmbrmownmbrenmbrcpxnmbr jpg width nmbr format pjpg auto webp nmbrbnmbracefnmbranmbrbanmbrbnmbrebaefnmbranmbr brief nmbr graph need see understand ai nmbr last issu share stanford nmbr ai index report http hai stanford edu research ai index nmbr eliza strickland take nmbr visual highlight import develop scroll ieee org http spectrum ieee org tech talk artifici intellig machin learn state ai nmbr graph educ one best educ resourc ai andrew ng deep learn special coursera cours receiv nmbr updat program exercis tensorflow nmbr syllabu includ transform network find updat cours coursera org http www coursera org special deep learn event may nmbr onlin nmbr nmbr cet ai turn exist busi model upsid join onlin interact hear astonish input disrupt ai busi model harvard post doc johann merantix lab organ ki garag fro institut entrepreneurship innov research stuttgart univers partner german digit hub initi regist http www bwstiftung de de veranstaltungen ai turn exist busi model upsid
czhu12,MachineLearning,1617908894.0,[P] A torchvision transforms visualizer,torchvis transform librari use almost cv project document bit hard visual threw app togeth http pytorch transform builder chriszhu teammat also found use figur share commun built streamlit host googl cloud run found nice way deploy kind thing see http pytorch transform builder chriszhu let know thi use anyon els happi spend weekend make better help http preview redd nneznmbrsvnmbrzzrnmbr png width nmbr format png auto webp fcnmbrenmbranmbrffnmbrenmbrbnmbrbnmbrfnmbrafnmbrdnmbreenmbrfnmbr http preview redd gnmbrcktqvnmbrzzrnmbr png width nmbr format png auto webp nmbrafnmbrcnmbrfcnmbrfnmbrcnmbrcnmbranmbrabnmbrbbnmbrenmbr
Combination-Fun,MachineLearning,1617887342.0,[R] Video explaining Normalization Free Nets paper,video explain idea nf net paper titl high perform larg scale imag recognit without normal hope use enjoy http youtu azkfgjrbrnmbro http youtu azkfgjrbrnmbro
jary93,MachineLearning,1620411298.0,Structured Ensembles: an Approach to Reduce the Memory Footprint of Ensemble Methods,
ashubham,MachineLearning,1617060191.0,[P] Prediction Trees in Pure Javascript,recent learnt compact predict tree thought thi would great use case web browser henc built thi librari http github com ashubham cpt http github com ashubham cpt feedback welcom
PeupleDeLaMer,MachineLearning,1618982723.0,[R] Looking for Paper Recommendations for characterising model performance/ Assurance,hello rel new ml research read literatur help user characteris perform model order understand point input space consid reliabl point exampl includ algorithm assur http paperswithcod com paper algorithm assur activ approach adversari attack http openai com blog adversari exampl research thi exactli right track found huge amount work relat thi figur ask
techsucker,MachineLearning,1617380494.0,[N] Introducing PyTorch Profiler – The New And Improved Performance Debugging Profiler For PyTorch,analysi refin larg scale deep learn model perform constant challeng increas import model size owe lack avail resourc pytorch user hard time overcom thi problem common gpu hardwar level debug tool pytorch specif background oper wa avail user merg multi tool appli minim correl inform manual make sens data retriev miss inform pytorch profil came rescu open sourc tool precis effici troubleshoot perform investig larg scale deep learn model summari http www marktechpost com nmbr nmbr nmbr introduc pytorch profil new improv perform debug profil pytorch http www marktechpost com nmbr nmbr nmbr introduc pytorch profil new improv perform debug profil pytorch sourc http pytorch org blog introduc pytorch profil new improv perform tool
hyunwoongko,MachineLearning,1617286558.0,"[P] Asian language BART models (English, Chinese, Japanese, Korean and ECJK mixed)",http preview redd wznspjnmbrklkqnmbr png width nmbr format png auto webp anmbracnmbrafnmbrdnmbrabnmbrfnmbrfnmbrdnmbrbfnmbranmbrenmbr hello hyunwoongko studi natur languag process mani asian languag chines korean japanes pre train sequenc sequenc model necessari current lack made chines japanes korean english bart model prune embed layer facebook mbart model mbart model multilingu languag model nmbr languag howev onli need one languag e g japanes mbart vocab token embed unnecessari take space therefor organ onli necessari token languag thi model use monolingu set pleas check follow link detail usag http github com hyunwoongko asian bart http github com hyunwoongko asian bart
kongxianxingren,MachineLearning,1620585692.0,[D] Are Centroidal Voronoi tessellation and Voronoi tessellation unsupervised learning in machine learning?,centroid voronoi tessel cvt special type voronoi tessel gener point voronoi cell also centroid center mass view optim partit correspond optim distribut gener voronoi tessel partit plane region close given set object follow simpl pictur centroid voronoi tessel found wiki http en wikipedia org wiki centroidal_voronoi_tessel http preview redd ircxpnmbrxrnmbrynmbr png width nmbr format png auto webp nmbrafnmbrbnmbrdnmbrfnmbrenmbrcnmbrbaaanmbrenmbrfnmbranmbrdnmbr like k mean algorithm conclud cluster method unsupervis learn right reason ask see anybodi relat cvt machin learn algorithm
Uncommented_python,MachineLearning,1616368763.0,[D] An example of machine learning bias on popular. Is this specific case a problem? Thoughts?,
mrathi12,MachineLearning,1618417597.0,[D] Addressing Gender Bias in Neural Machine Translation,hey everyon made video discuss fix bia neural machin translat http youtu pnmbrfjlmfnmbrfw http youtu pnmbrfjlmfnmbrfw everi often get viral tweet come assign gender gender neutral languag like hungarian googl translat default stereotyp translat thi video look evalu gender bia use dataset winomt http www aclweb org antholog pnmbr nmbr pdf http www aclweb org antholog pnmbr nmbr pdf discuss current solut googl translat add intellectu debt final believ practic approach debias larg languag model domain adapt http arxiv org ab nmbr http arxiv org ab nmbr person think curat larg dataset scale need impract much practic fine tune small curat dataset http link springer com articl nmbr snmbr nmbr nmbr nmbr http link springer com articl nmbr snmbr nmbr nmbr nmbr would interest hear thought think practic approach debias twitter thread discuss thi http twitter com mukulrathi _ statu nmbr nmbr http twitter com mukulrathi_ statu nmbr nmbr transcript http mukulrathi co uk googl translat bias http mukulrathi co uk googl translat bias
CrypticParagon,MachineLearning,1617351673.0,[D] When does stratified k-fold cross-validation provide worse performance than standard k-fold?,use sklearn train random forest model default paramet dataset nmbrk data point nmbr featur binari classif nmbr nmbr nmbr featur simpl likelihood label nmbr given specif valu categor featur use built cross valid nmbr fold onli thing chang standard vs stratifi stratifi perform slightli wors whi would thi
jj4646,MachineLearning,1619239890.0,"[D] Relationship Between Kernels, Neural Networks and Gaussian Process",initi artifici neural network ann equival gaussian process infinit width limit thu connect kernel method someon pleas provid intuit exampl whi sort connect neural network gaussian process kernel thank sourc http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf
Seankala,MachineLearning,1620131965.0,[D] Do you guys take out time to study math?,month take time everyday studi math nmbrth semest msc degre undergrad background stem alway feel like lack strong mathemat foundat also read paper lot mathemat formul sometim get intuit understand equat mean often take hour even day googl curiou whether anyon els goe way brush studi math stuff sometim feel futil tri tell otherwis
jj4646,MachineLearning,1619239577.0,[D] Automatic Feature Engineering during Deep Learning,often heard one reason deep learn method prefer machin learn method becaus algorithm like deep neural network requir analyst spend much time select variabl model e featur engin featur select featur extract appar deep neural network abl intellig background consid creat mani differ combin featur conduc model problem natur wa curiou thi claim intuit understand hidden layer weight activ function neural network make new combin featur pass forward ultim use make predict new data beyond thi sure think ani refer paper document either theoret empir deep neural network abl larg take care task featur engin compar tradit algorithm like regress model decis tree random forest ani experi done mani irrelev featur ad dataset deep neural network wa abl ignor
NotThatGuy97,MachineLearning,1617633514.0,[D][P] Feedforward Noise Cancelling Project. Looking for some advice before i dive into details.,hi beginn ml finish one minor project yet use simpl neural network head toward new project complex search good approach sinc much experi want introduc project hope idea approach make sens nn rnn rl altern approach main goal project find paramet amplitud _i phase p _i fix frequenc nmbrhz nmbrhz sinusoid signal gener gener signal ad main signal order cancel nois consist n x nmbrhz frequenc basic nois channel problem solv feedforward algorithm input measur durat nmbr nmbr second main signal fourier transform fft perform amplitud nmbrhz harmon nmbrhz nmbrhz nmbrhz clearli observ fft correct _i p _i amplitud frequenc suppress frequenc compens addit introduc signal creat signal gener goal find perfect _i p _i frequenc first measur shown fft _amplitud frequenc uniqu minimum found gradient toward thi minimum ha observ simplifi fft _amplitud _i nmbr p _i nmbr loop optim would look like nmbr measur main signal fft nmbr input n x nmbr array fftamptitud _nmbr fftamptitud _n nmbr optim algorithm nn rnn rl nmbr output n x nmbr array _nmbr p _nmbr _nmbr p _nmbr _n p _n nmbr signal process nmbr measur main signal ad signal loss function could look like loss sum fftamptitud _i tri minim loss function sinc fft _amplitud _i nmbr p _i nmbr train simul creat order pre train algorithm hope made situat clear one problem output array paramet loss function ha calcul measur point nmbr see abov would treat output layer order get backpropag work right pleas add advic furthermor algorithm ha alway wait measur issu want use kera think nn rnn rl capabl solv thi task would best approach problem see know ani compar project paper pleas share
timscarfe,MachineLearning,1618582221.0,[D] Francois Chollet interview on ML Street Talk,today show join francoi chollet ha extrem interest view intellig generalis abstract inform convers ratio wrote measur intellig end nmbr huge impact think think nn onli model continu problem well smooth learnabl manifold mani type nmbr problem involv reason plan suitabl nn think mani problem type nmbr type nmbr enmesh togeth think futur ai must includ program synthesi allow us generalis broadli exampl search could guid neural network becaus search space interpol extent video http youtu jnmbrp _thjjnoo http youtu jnmbrp_thjjnoo pod http anchor fm machinelearningstreettalk episod nmbr francoi chollet intellig generalis evnmbrinmbr http anchor fm machinelearningstreettalk episod nmbr francoi chollet intellig generalis evnmbrinmbr
anon-burner-5981,MachineLearning,1620412872.0,[D] Parting Gifts for Lab Director and Ph.D. Student,spent last two year work amaz lab next year leav tremend impact like abl give someth show appreci would good gift mentor ph student
Square365,MachineLearning,1617649803.0,[D] Good video dataset labeling services? (Frame By Frame),hello sort new ml tri make dataset train imag recognit yolovnmbr week im use darklabel aproxim nmbrk frame nmbr video label im plan label anoth nmbr would like know ani good servic label rate seen amazon mturk onli box imag video onli topic got estim someon nmbrvideo nmbr would like get opinion thi
AristocraticOctopus,MachineLearning,1619491330.0,[N] Toyota subsidiary to acquire Lyft's self-driving division,zoox sale amazon uber layoff ai research thi look grim self drive commerci doubt mani thi sub terribl surpris given difficulti thi problem still sad see anoth one bite dust person fan comma ai technic approach human polici clone still think dozen high qualiti research paper away superhuman drive agent interest see peopl valu divis lyft receiv total approxim nmbr million cash thi transact nmbr million paid upfront subject certain close adjust nmbr million payment five year period transact also expect remov nmbr million annual non gaap oper expens net basi primarili reduc r spend acceler lyft path adjust ebitda profit
Symbiot10000,MachineLearning,1618176734.0,[D] Practical benefits of unlocking vGPU functionality in NVIDIA cards for ML?,weekend ha lot attent http news ycombin com item id nmbr given http old reddit com r hardwar comment mnordnmbr unlock_vgpu_functionality_for_consumer_grade_gpu new softwar method http github com dualcod vgpu_unlock unlock vgpu function consum nvidia card doe thi mean anyth smaller ml outfit could divid gpu resourc across vm subdivid gpu across differ ml task
Competitive-Rub-1958,MachineLearning,1618587934.0,[D] Can some other organization/company replicate GPT-3 for their own use?,gpt nmbr doe creat much new innov per se overfit model huge amount data larg number paramet probabl base predecessor architectur less easi compani like googl faang compani replic gpt nmbr size nlp model use million dollar question inde easi much advantag doe openai prevent googl launch new model bigger better offer consum cheaper openai ms
lukeiy,MachineLearning,1617422679.0,[P] A TF implementation of AdamW with a One-Cycle policy,http preview redd nmbrwucnmbrrluvqnmbr png width nmbr format png auto webp nmbrbnmbrcnmbrbcnmbrfbnmbrenmbrfdnmbreacnmbrcnmbrenmbrccnmbr http github com lukebolli onecycleadamw http github com lukebolli onecycleadamw articl fast ai http fast ai wa origin post recept wa mix recent implement though model sped train remain stabl higher learn rate ad small exampl compar regular adam adamw let know ani issu cheer
proximauri,MachineLearning,1616976163.0,[D] Face recognition: classification vs distances between embeddings,hi new face recognit method notic one popular approach use pre train model new dataset measur distanc two embed understand howev whi thi prefer use pre train network without top layer fine tune new fulli connect layer top model honestli even understand train model first approach could someon clarifi pleas
alexandrea_pierrick,MachineLearning,1617958906.0,[D] Unsupervised document similarity state of the art,set n document length rang nmbr nmbr charact want calcul similar score nmbr nmbr pair document higher number indic higher similar assum deploy supervis model infeas due resourc constraint necessarili data scienc relat gather label expens infrastructur approv supervis model whatev reason etc approach consid nmbr tf idf nmbr smooth invers frequenc sif embed develop usif p sif http openreview net pdf id syknmbrvnmbrxx http openreview net pdf id syknmbrvnmbrxx http www aclweb org antholog wnmbr nmbr http www aclweb org antholog wnmbr nmbr http arxiv org ab nmbr http arxiv org ab nmbr nmbr bert bert like embed e g http arxiv org ab nmbr http arxiv org ab nmbr nmbr hierarch optim transport document represent hott http paper nip cc paper nmbr hash nmbrbnmbranmbranmbrbafnmbrenmbrenmbrcnmbrenmbranmbrbnmbr abstract html http paper nip cc paper nmbr hash nmbrbnmbranmbranmbrbafnmbrenmbrenmbrcnmbrenmbranmbrbnmbr abstract html question unsupervis techniqu ha shown peer review set achiev higher accuraci fnmbr similar long text say nmbr charact hott background hott paper benchmark variou approach k nn classifi show hott perform best dramat better tf idf hott ha nmbr vs tf idf nmbr normal error note hott algorithm unsupervis dataset paper label otherwis benchmark would possibl sif paper mostli deal st dataset long text p sif ha benchmark reuter dataset use svm supervis approach interestingli hott paper find sif doe perform well k nn approach nmbr normal error mani case bert requir pre train doe max averag pool perform pool bert layer appear wors glove embed http arxiv org ab nmbr http arxiv org ab nmbr page nmbr also abl find unsupervis benchmark docnmbrvec univers sentenc encod use addit question calcul similar onc embed obtain e g http www aclweb org antholog nnmbr nmbr pdf http www aclweb org antholog nnmbr nmbr pdf scope thi question unless affect comparison unsupervis benchmark e g k nn approach use variou distanc metric may affect accuraci benchmark hott repres method exist perform substanti better tempt make conclus tf idf still strong approach sinc simpl implement understand certainli simpler hott case think remark conclus given deep learn develop last nmbr nmbr year edit ad pool bert layer
noodlepotato,MachineLearning,1619701885.0,[D]Anyone reading Probabilistic Machine Learning: An Introduction? (Murphy's new textbook),alreadi post r learnmachinelearn answer far ani addit differ edit like notat wise heard first edit ha pretti inconsist notat ask becaus plan buy nmbr machin learn probabilist perspect physic book check tabl content new one might consid buy physic book thi edit instead want know think read
Guest_Basic,MachineLearning,1617344944.0,[D] AUC vs F-measure for binary classification for unbalanced target variable,work build binari classif predict model target variabl extrem unbalanc nmbrk nmbr nmbrmillion nmbr understand auc veri good metric evalu model f measur might better altern question nmbr assumpt correct model built ha decent auc nmbr realli low f measur nmbr thi make think actual built realli bad model howev exist publish literatur onli claim auc nmbr none report f measur question nmbr goal build better model current exist take victori lap right
amourav,MachineLearning,1619529111.0,[D] Distributed data platform / framework,thought aw sagemak horovod distribut data train method choic
moajjem04,MachineLearning,1618508700.0,[D] Best Literature Review Practices,supervisor ha assign new topic research typic ani project mostli handl experi part thi time thought literatur review well know huge defici part want know best practic ts beyond search googl scholar keyword tl dr help senpai provid knowledg
SlickBlueML,MachineLearning,1619025945.0,[P] Multilingual translation like Google Translate with PyTorch (+explanation),recent put togeth tutori multilingu translat think code alon might use peopl includ demo play around get run support chines japanes english right bat small amount train work surprisingli well colab need worri setup use use non pro version colab though make sure chang model repo googl mtnmbr base googl mtnmbr small els get memori error cuda github code http github com ejmejm multilingu nmt mtnmbr blob main nmt _full _version ipynb http github com ejmejm multilingu nmt mtnmbr blob main nmt_full_vers ipynb colab code http colab research googl com drive nmbregscodnmbrsjwd _yofwbnmbrkmjoedzgunmbrlp usp share http colab research googl com drive nmbregscodnmbrsjwd_yofwbnmbrkmjoedzgunmbrlp usp share also video seri goe anyon interest http www youtub com watch v huzqnmbrkklxnmbrq list pl _nmbrvdnmbrkwq _obgmwnmbrgnmbrhmolndynmbrnhvnmbr index nmbr nmbr http www youtub com watch v huzqnmbrkklxnmbrq list pl_nmbrvdnmbrkwq_obgmwnmbrgnmbrhmolndynmbrnhvnmbr index nmbr nmbr
wecmiw,MachineLearning,1618074938.0,[D] How do you share your models/ demos with others?,hi phd student work deep learn often show demo model current simpli share result present use notebook want show explicit experi spot anoth way could see thi done lot especi industri talk mani stakehold awar gradio wa wonder way ani insight appreci
hubert0527,MachineLearning,1617996004.0,[R] InfinityGAN: Towards Infinite-Resolution Image Synthesis,synthes infinit resolut imag finit resolut input nmbr nmbr imag compos nmbr patch independ synthes infinitygan spatial fusion two style gener train nmbr nmbr patch e g mark top left sampl nmbr nmbr real imag note train infer ani resolut perform singl gtx titan x gpu http preview redd nmbrdrmgnmbreznmbrsnmbr png width nmbr format png auto webp nmbrdnmbranmbraanmbrcnmbrenmbrenmbranmbrenmbrcnmbrbnmbrenmbrb tl dr propos infinitygan toward new problem synthes infinit resolut imag model train imag limit resolut gener arbitrari resolut test demonstr sever applic train gener spatial style fusion imag outpaint imag inbetween project page http hubertnmbr github io infinitygan http hubertnmbr github io infinitygan paper http arxiv org ab nmbr http arxiv org ab nmbr releas code soon http github com hubertnmbr infinitygan http github com hubertnmbr infinitygan
SensitiveAnteater420,MachineLearning,1616960506.0,[D] Would it be possible to make a model that predicts where a picture is taken?,love osint geoloc python dev wonder extend boundari titl self explain possibl make model predict pictur taken exist dataset
InsightFinder,MachineLearning,1617028825.0,[News] Women in computer science leadership talk on 4/9,event alert women tech leadership discuss exec bank america dell insightfind april nmbr nmbr nmbr est insightfind cto founder helen gu particip women tech leadership panel host nc state women comput scienc wic organ professor gu teach nc state also faculti leader wic join industri leader liz holland vice presid dell technolog betsi bradi manag director bank america moder nc state professor wic faculti leader dr lina battestilli leader agre share stori includ limit earli career decis watersh career moment would advis young student profession today welcom attend join regist websit form http insightfind com event googl form http doc googl com form e nmbrfaipqlsenmbrhyyvpgljvqiwoblsnmbrifmcztdgrynrznmbryotnmbrmnnmbrcnnmbrwrnmbrg viewform
asivokon,MachineLearning,1617719141.0,[N] Grammarly releases a grammatical error correction (GEC) dataset for the Ukrainian language,thi dataset contain nmbr nmbr sentenc annot grammat error fluenci correct licens cc nmbr thi blog post provid context http www grammarli com blog engin announc ua gec http www grammarli com blog engin announc ua gec data code github http github com grammarli ua gec http github com grammarli ua gec paper draft http arxiv org ab nmbr http arxiv org ab nmbr one author happi answer question
shreyansh26,MachineLearning,1620580380.0,[P] BERT - Annotated Paper + Paper Summary,everyon interest nlp even dl ml matter ha definit heard bert famili model bert roberta distilbert mani mani thi paper bert pre train deep bidirect transform languag understand first introduc thi ha complet chang way ai practition solv look nlp problem day part paper note seri gone paper creat inform summari paper thi time goe bit longer previou paper summari done paper contain mani tini interest nugget includ check link happi read paper summari bert pre train deep bidirect transform languag understand http shreyanshnmbr github io post nmbr nmbr nmbr_pretraining_deep_bidirectional_transformers_bert annot paper http github com shreyanshnmbr annot ml paper blob main bert pdf http github com shreyanshnmbr annot ml paper blob main bert pdf
techsucker,MachineLearning,1618972153.0,[R] Researchers Introduce a Convolutional Neural Network (CNN)-Based Model that Automates the Distinction Between Natural Images and Computer-Generated Images (CGI),increas perform accuraci comput softwar system realist appear comput gener imag cgi deepfak often lead assum authent imag research changsha univers scienc technolog hunan univers hunan china recent develop imag sourc pipelin forens method base convolut neural network cnn autom distinct natur imag cgi work announc intern journal autonom adapt commun system describ cnn base model fine tune use databas nmbr imag summari http www marktechpost com nmbr nmbr nmbr research introduc convolut neural network cnn base model autom distinct natur imag comput gener imag cgi http www marktechpost com nmbr nmbr nmbr research introduc convolut neural network cnn base model autom distinct natur imag comput gener imag cgi paper http www indersci com offer php id nmbr
Yuqing7,MachineLearning,1617064776.0,[N] DeepMind & Alberta U Introduce Novel Search Algorithm: Policy-Guided Heuristic Search with Guarantees,research team deepmind alberta univers propos polici guid heurist search ph novel search algorithm use heurist function polici offer guarante search loss relat qualiti heurist polici quick read deepmind alberta u introduc novel search algorithm polici guid heurist search guarante http syncedreview com nmbr nmbr nmbr deepmind alberta u introduc novel search algorithm polici guid heurist search guarante paper polici guid heurist search guarante arxiv http arxiv org pdf nmbr pdf
vwxyzjn,MachineLearning,1619399521.0,[P] Open Reinforcement Learning Benchmark 0.5.0,
ilikepancakez,MachineLearning,1619018686.0,On the Relationships Between the Grammatical Genders of Inanimate Nouns and Their Co-Occurring Adjectives and Verbs [R],
Xxyjoel,MachineLearning,1617007872.0,ML + Infrastructure [P],hey data scienc machin learn space major career recent spent time meddl around infrastructur could naiveti though complex ineffici bundl cloud tool bother built tool help manag cost still requir polici finagl self servic yet howev love candid feedback tool bluearch io http bluearch io apolog thi sub rule share work scari pretti excit project
thermokopf,MachineLearning,1617657632.0,[D] Can the same convolutional network be used on different image sizes?,convolut network perform convolut imag array pixel basic decreas size imag input thi typic feedforward network doe thi gener handl differ imag size exampl train network bunch nmbrxnmbr imag abl use thi network make predict nmbrxnmbr imag size
flaviojuvenal,MachineLearning,1619445763.0,[P] Entity Embed: fuzzy and scalable Entity Resolution using Approximate Nearest Neighbors,http github com vintasoftwar entiti emb http github com vintasoftwar entiti emb entiti emb base special case autoblock model describ amazon http www amazon scienc public autoblock hand block framework entiti match allow transform entiti like compani product etc vector support scalabl record linkag entiti resolut use approxim nearest neighbor use entiti emb train deep learn model transform record vector n dimension embed space thank contrast loss vector organ keep similar record close dissimilar record far apart thi embed space embed record enabl scalabl ann search http ann benchmark com index html mean find thousand candid duplic pair record per second per cpu thi first deep learn project launch hope use pleas feel free reach feedback
hardmaru,MachineLearning,1617347384.0,[R] On the role of planning in model-based deep reinforcement learning,
,MachineLearning,1619991678.0,"[D] What is the reason behind the recent explosion in NLP-based research, jobs, and tools?",notic nlp ha quit renaiss moment past nmbr year kinda came nowher sure expert saw come anyway see much nlp research publish well everi compani seek peopl nlp knowledg whi thi ha caus led thi explos nlp past nmbr nmbr year
mhj,MachineLearning,1619270649.0,"[P] Implementations of Apriori, Eclat and FP-Growth in Go",
ObjectiveDue9905,MachineLearning,1617205094.0,[D] How important is controls theory in machine learning?,hi wa wonder import control theori machin learn seem go hand hand applic current comput engin major student taken mostli onli cs cours come machin learn control theori cours ece electr comput engin depart wa interest take seem applic could see use hardwar softwar futur
samk2104,MachineLearning,1617093257.0,[D] Not all independent variables available for same time period..how to handle such situations for ML models?,nmbr nmbr independ variabl inform avail last nmbr year includ depend variabl nmbr nmbr variabl inform onli avail last nmbr month thi featur wa recent launch simplest way would build model nmbr month variabl avail number data point enough way incorpor new featur model e use nmbr month data nmbr nmbr featur still build model use nmbr year data
NotAHomeworkQuestion,MachineLearning,1616962377.0,"[D] Instead of taking an approach like Invariant Risk Minimization, why is it not enough to control for environmental factors (confounders) by including them as regressors?",onli start dive thi fascin topic pleas excus ignor realli enjoy read irm paper left wonder whi accomplish someth similar includ environment variabl regressor peopl causal infer exampl mnist color applic could final layer model take top layer usual plain vanilla cnn well indic color imag thu control color confound imag cnn part model architectur account everyth worri shenanigan futur data point effect color revers thu creat predict futur data point ignor color effect predict thi think would give similar result gray imag wa shown give excel perform miss
rom1504,MachineLearning,1616491364.0,[P] fromconfig: A library to instantiate any Python object from configuration files.,fromconfig http github com criteo fromconfig act gener command line interfac configur file absolut chang code fromconfig http preview redd xnmbrlnmbrlzwqonmbr png width nmbr format png auto webp cnmbrdnmbrfenmbrdnmbrfnmbrbanmbrcnmbrdnmbr particularli well suit machin learn see exampl http github com criteo fromconfig machin learn launch train job remot cluster requir custom command line argument need propag call stack e g set paramet particular layer usual way write custom command reduc set argument combin assembl creat differ object fromconfig command line becom gener specif kept config file result thi preserv code ani backward depend issu allow full reproduc save config file job artifact also make easier merg differ set argument dynam way refer interpol
TheOverGrad,MachineLearning,1619902564.0,Memory-Efficient Semi-Supervised Continual Learning (IJCNN2021 oral),
cowgod2007,MachineLearning,1617853595.0,[D] Sourcing medical data?,hey ml project doe one sourc buy obtain medic label data train data e g label radiolog imag data thank
JST99,MachineLearning,1619188054.0,[D] How to properly version control ML models amid rapid experimentation?,come softwar engin background use git version control file along config json includ model train hyperparamet trainer class would read specifi configur file train model save best one highest valid score thi pipelin work begin wa iter slow pace recent howev increasingli realiz save checkpoint file obsolet becaus non trivial chang made model architectur sinc last experi checkpoint realli refer torch load some_state_dict question framework agnost could cours check experi wa conduct git checkout repositori specif point time howev part believ thi incred common thing ml engin must eleg solut far research ha brought sacr http sacr readthedoc io en latest index html got thi post http www reddit com r machinelearn comment nmbrnpgnmbrd how_to_keep_track_of_experi keepsak http keepsak ai dvc http dvc org appear tangenti sinc question pertain model data thank advanc share insight
charles96322,MachineLearning,1618968095.0,[D] How Valuable Would Cutting Your ML Models Computation Time (at Inference) By 30-50% Be?,hello everyon current work person project tri optim deep learn algorithm respect hardwar deploy far pretti decent result idea hardwar handl comput better build simul show util block neural network arrang model keep capac improv comput time significantli e g see thi paper http arxiv org pdf nmbr pdf eventu goal would select piec hardwar model deploy optim model click button wonder solut like would made ani busi sens love know use case deploy machin learn model edg devic nmbr kind applic deploy iot devic latenc typic problem nmbr much time spend optim model comput time nmbr valuabl would cut comput time nmbr nmbr infer wonder applic e g robot medic thi nmbr nmbr would becom veri valuabl love speak someon work field
ijovab,MachineLearning,1620598087.0,[D] What are some promising areas in privacy-preserving learning in medical data?,eu new propos gener problem relat usag medic data topic seem becom fairli import read feder learn continu learn differenti privaci recent think promis area simplifi guarante safeti medic imag data dure train ani paper suggest also appreci
binaryfor,MachineLearning,1618678509.0,[P] Flashlight - A C++ standalone library for machine learning. Open-sourced by Facebook.,
kamil-rafalko,MachineLearning,1618305825.0,[Project] Better neurobiological research with AI,instanc segment star shape cell call astrocyt nmbrd alreadi known comput vision techniqu thi task may seem simpl first turn unexpectedli tricki share detail process find solut thi problem blog post http blog softwaremil com better neurobiolog research ai dnmbreacafnmbr http blog softwaremil com better neurobiolog research ai dnmbreacafnmbr hope would interest ani comment welcom
proximauri,MachineLearning,1617183404.0,"[D] Is uploading dataset to personal Google Drive and use it in Google Colab against ""No distribution agreement""?",hi machin learn databas accept agreement agreement state distribut data ani third parti prohibit question upload dataset person gdrive load googl colab thi want share anyon
dh27182,MachineLearning,1619591958.0,[D] Open source projects for interpretability,ani good open sourc project model interpret catch sever distil pub http distil pub articl recent author show impress visual unfortun seem open sourc wonder anyon use built ani project visual inspect model
ykilcher,MachineLearning,1619540955.0,[P] We gave GPT-3 random ingredients and cooked the recipe it came up with (Video),http youtu hiocn _nmbrqtvu http youtu hiocn_nmbrqtvu went store bought set complet random ingredi openai gpt nmbr come recip cook ate rule nmbr vegan nmbr follow recip close possibl nmbr must finish plate recip nmbr boil potato carrot nmbr meantim prepar vegan minc meat use pre cook soy meat nmbr fri vegan butter add garlic mushroom stir nmbr minut nmbr add soy cream stir cook three minut nmbr add pickl tomato bean stir simmer five minut nmbr cut bread small squar fri vegan butter golden brown nmbr cut lime cube squeez juic bean mixtur nmbr add soy sauc parsley salt pepper cumin cilantro dri fig stir add kale nmbr pour bean mix blender nmbr bake nmbr minut oven nmbrc nmbr cut sweet potato cube add pot remain butter add red bean mixtur nmbr cut bell pepper cube add pot nmbr add vegan minc meat cook oven nmbrc nmbr minut nmbr add avocado nmbr add chickpea nmbr add chocol nmbr serv bread mustard pommegrenad top video outlin nmbr nmbr plan nmbr nmbr ingredi nmbr nmbr gpt nmbr nmbr nmbr let cook nmbr nmbr tast test gpt nmbr wikipedia http en wikipedia org wiki gpt nmbr http en wikipedia org wiki gpt nmbr gpt nmbr paper http arxiv org ab nmbr http arxiv org ab nmbr
Stargor14,MachineLearning,1616875179.0,[D] Efficient ways of quantitatively classifying price movements for algorithmic trading using machine learning,hi everyon current high school student recent experi algorithm cryptocurr trade start gener condit strategi howev prove rel ineffici simpl tri move onto machin learn approach use xgboost python tri figur effici way classifi short term price movement thi case depend variabl tri predict model tri use chang next nmbr nmbr candl work well realli look specif answer tbh curiou everyon thought thi applic predict short term price movement random forest think post wa bit vagu feel free ask away ani answer appreci
RenYang_ETHZ,MachineLearning,1619719239.0,"[N] NTIRE 2021 Challenge on Quality Enhancement of Compressed Video: Dataset, Methods and Codes",organ ntire nmbr challeng video enhanc conjunct cvpr nmbr propos larg scale divers video databas challeng propos method challeng advanc state art enhanc compress video homepag includ databas open sourc code keep updat benchmark http github com renyang home ntirenmbr _venh http github com renyang home ntirenmbr_venh dataset method report http arxiv org ab nmbr http arxiv org ab nmbr http arxiv org ab nmbr http arxiv org ab nmbr hope databas benchmark benefit futur research thi direct ntire workshop held first day june nmbr cvpr nmbr welcom attend workshop
bin_wang_osl,MachineLearning,1617079701.0,[N] Live IEEE-NASPI Contest calls for ML experts' participation!,machin learn better solv power system problem expert live contest co host ieee naspi apr nmbr jun nmbr nmbr see detail http www naspi org node nmbr http www naspi org node nmbr veri welcom regist solv import real world problem root power energi system need someon power system background form team worri way find one http doc googl com spreadsheet nmbrzanmbrqdlknmbr nmbroiczh nmbrianmbrzmzuirdndnmbriqnmbrxkpnjokvha edit gid nmbr http doc googl com spreadsheet nmbrzanmbrqdlknmbr nmbroiczh nmbrianmbrzmzuirdndnmbriqnmbrxkpnjokvha edit gid nmbr
AirZealousideal1342,MachineLearning,1618023079.0,[D] Why we must use weight demodulation in stylegan2,whi scale specif style control use architectur figur c must use architectur figur paper say practic style modul may amplifi certain featur map order magnitud style mix work must explicitli counteract thi amplif per sampl basi otherwis subsequ layer would abl oper data meaning way understand undertand whi weight demodul solv thi problem http preview redd ynmbrljnsdmfnmbrsnmbr png width nmbr format png auto webp nmbrenmbrcnmbrcnmbrcnmbrfanmbranmbranmbrecenmbrfbnmbrdnmbranmbrc
Cosack,MachineLearning,1617493961.0,[Project] Estimating fine-tuning cost,model size grow larger larger mention time retrain prohibit individu fine tune reason cours tune intens would depend task size avail data would go estim cost tune fix amount data say look fine tune gpt neo open sourc gpt nmbr nmbrb paramet nmbrk short input nmbrm token could estim cost
ByteHubAi,MachineLearning,1617650022.0,[P] ByteHub: simple timeseries data preparation in Python,hi everyon share project work help make time seri data easier store access transform build machin learn model python base featur store avail open sourc librari http github com bytehub ai bytehub low cost cloud host servic http bytehub ai bit background written http medium com bytehub ai make featur store simpl nmbraenmbrdnmbrdcacnmbr whi built summari want help data scientist save time build machin learn model someth simpl use e compat jupyt notebook complex infrastructur setup manag appreci feedback anyon interest check
gospodin_dan,MachineLearning,1619896827.0,[N] Fresh paper: Detecting objects in images by describing them with keywords 🔥,
evanatyourservice,MachineLearning,1618239686.0,[2102.11600] ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks,
ilikepancakez,MachineLearning,1620598303.0,Open Catalyst 2020 (OC20) Dataset and Community Challenges [R],
dev_bes,MachineLearning,1618317666.0,[R][P]MobileStyleGAN: A Lightweight Convolutional Neural Network for High-Fidelity Image Synthesis,recent year use gener adversari network gan ha becom veri popular gener imag model style base gan architectur yield state art result high fidel imag synthesi comput highli complex work focu perform optim style base gener model analyz comput hard part stylegannmbr propos chang gener network make possibl deploy style base gener network edg devic introduc mobilestylegan architectur ha xnmbr fewer paramet xnmbr less comput complex stylegannmbr provid compar qualiti main goal work democrat ai start work modern ai base high fidel face gener need two python command pip instal random_fac python random_fac demo paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com dev mobilestylegan pytorch http github com dev mobilestylegan pytorch python librari http github com dev random _face http github com dev random_fac youtub video http www youtub com playlist list plstkhmdpwbtwsvq _nmbralmpbf _mblmknmbrui http www youtub com playlist list plstkhmdpwbtwsvq_nmbralmpbf_mblmknmbrui
bci-hacker,MachineLearning,1617472841.0,[D] Trustworthy Machine Learning talk | ideas and potential research,hey recent gave talk http www youtub com watch v nmbrcqnmbreutcurc virginia tech trustworthi machin learn discuss research idea model interpret influenc function gradient base attribut structur learn would love check provid feedback possibl still ug apolog rigor academ talk tryin best improv haha would love sub cuz love make video research
grid_world,MachineLearning,1618074601.0,[R] Finding important neural network connections,research work relat neural network prune revolv around iter prune ever gener idea prune p connect per iter round either local global structur vs unstructur common criterion absolut magnitud weight base prune han et al frankl et al sinc thi iter prune techniqu number round larg say prune nmbr nmbr prune techniqu overcom thi shortcom kind like tri identifi import connect befor entir train process thi iter process skip
levi97zzz,MachineLearning,1618010691.0,[D] how useful is OS knowledge in AI/ML?,question titl choos sever class next semest one class os use os knowledg want get ai ml futur
peaked-too-early,MachineLearning,1619992949.0,"[D] With ICLR starting, how do you make the most of an online conference?",befor end time person confer would product least could make acquaint later lead ph internship job offer collabor could natur learn convey research casual convers poster hall fact block entir schedul confer week obvious help us focu confer luxuri anymor tri wing onlin ml ml adjac confer littl success ani tip resourc make thi suboptim situat
abpan8,MachineLearning,1618930656.0,[P] Open data about logistics,could suggest dataset good site take data scrape forecast cost transport good truck us
medwatt,MachineLearning,1617829959.0,[D] Explain Energy Based Models,electr engin student basic practic understand neural network work understand basic idea multi layer perceptron mlp convolut layer etc even implement binari neural network use kera electr engin student taken ani hardcor machin learn cours even optim theori probabl yet work way curriculum univers attend knowledg field self interest recent saw project involv build hardwar acceler machin learn task project requir background energi base model unsurprisingli never heard thi befor came across paper onlin even found yann lecunn video lectur topic needless say abl understand much moment unfamiliar lot idea thi field would like someon could give explan whi energi base model interest differ probabilist model train applic suitabl etc mayb thi make easier revisit paper understand second read
Egan_Fan,MachineLearning,1617299603.0,[D] Statistical Significance in Deep RL Papers: What is going on?,icml review read author respons primarili rl research mani paper review use deep network rl reject nmbr nmbr paper becaus empir result reli nmbr nmbr trial author perform ani sort hypothesi test statist analysi would help littl data one author respons said someth like well everyon els doe thing comput cost veri high excus wrong either point whi thi seen accept field e g medic journal manuscript nmbr nmbr data point statist analysi would immedi reject right author respond said well afford larger studi one would see legitim excus howev none review paper rais concern whi onli one concern whi paper like get accept top confer even win best paper award miss someth thi deep problem field case stick firmli reject paper thank advanc thought repli discuss
fripperML,MachineLearning,1616972625.0,"[D] What’s the simplest, most lightweight but complete and 100% open source MLOps toolkit?",know thi ha ask mani time mani differ way ton blog post articl video cours address thi compar hundr tool librari framework part problem face mani option feel like buridan ass die starvat know although want write much need speak littl situat order put question context team team small onli four peopl could qualifi beginn data scientist one us ha profil littl bit engin data engin could suitabl anyway much experi neither python project machin learn passion love ml coupl year function sa plan chang python landscap much vivid excit last year made two project python without use ani good practic everi step wa made hand prone error model neither monitor even deploy onli use make batch predict project properli structur document wa pain know need chang befor becom unmanag expect size team grow fast let say coupl year expect nmbr nmbr peopl work us organ know import machin learn econom issu obstacl project moment onli made classic machin learn mean deep learn use panda scikit learn xgboost etc onli batch mode expect chang less year becaus need train imag classifi need train use deep learn convolut network integr applic code java fast real time chang expect need distribut comput need manag huge databas simpli fit panda datafram import challeng face compani work big compani also impos restrict us mainli budget spend mlop solut everyth ha open free hire data scientist data engin moment tool use team use part mlop stack although best class regard last item short list thi set restrict follow cloudera express instal basic cheaper cloudera option doe come ani tool machin learn manag onli give us hdf impala spark set node run python script control orchestr workflow manag tool datastag etl tool use svn code version system ye git deploy project use veri simplifi self made version docker littl bit awkward think push littl bit could convinc organ let us use docker docker reachabl kubernet capabl jenkin ci visual studio code profession licens toolset thi premis two differ oppos concern even fear fear use enough tool good practic arriv coupl year state manag code project model fear use mani tool impos burden small team bear clear need mlop much know review thing read hope help choos right tool python program look like program use visual studio use remot interpret becaus run thing cloudera node although program local integr code svn repositori need tool standard code like pylint flakenmbr mypi black would recommend ani ci deploy use jenkin deploy code docker brainer minimum standard tend think read like sure good argument need tool project scaffold read pyscaffold cookiecutt best point view kedro think stick kedro templat becaus offer much function like think project set pipelin run think kedro document would recommend separ document gener document project use sphinx anoth similar tool tend prefer second option becaus first one veri like tend gener obsolet doc know burden second big gener doc suffic typic ml project project registri ani tool could use project registri like simpl web app could navig project read doc think like know registri svn repo project folder data explor prepar think matplotlib seaborn panda suffic thing go big use pyspark scala even plain sql impala howev know dask exist newer tool like koala vaex think creat data transform pipelin use kedro although lot tool look interest like dagster enter deep learn realm keep use tool use anoth framework like tfx prefer caus learn one framework hard two wors solut valid project better tfx valid classic ml deep learn test think unit test much burden us come great expect librari think well suit ml project would recommend import part mlop stack way kedro great expect plugin could benefit featur store realli need especi consid team size experi read feast snorkel data version realli need especi consid team size experi read dvc experi think import piec although wonder realli need tool could use standard report artifact follow tri risk goe unmanag high kedro ha journal know suffic also ha kedro mlflow plugin could benefit use mlflow experi tool also read guild seem realli lightweigh easi know much train develop librari nest cross valid within function optim hyperparamet model pipelin gener report train assess qualiti model build mainli top skopt pip instal http github com jaimearboleda nestedcvtrain http github com jaimearboleda nestedcvtrain might use trane workflow least project along typic model like xgboost lightgbm scikit learn need framework like tensorflow kera see model registri think import piec although know even could build standard databas mlflow seem matur option model serv sure includ previou point anyway read streamlint fastapi would recommend ani apach kafka need real time predict visual thi mean share organ basic web app customiz plot explain predict thing like read panel ha abil transform jupyt notebook simpl web app might interest model monitor good free tool monitor model detect loss accuraci data drift thing like better gener script monitor run period bigdata said befor plan use mainli spark need know lot info mayb overcompl use onli nmbr think mayb idea ani help greatli appreci thank advanc edit add coupl thing first one spread among two comment work spanish public administr lot data use explor thi also ha rigid budget thing explain thi also explain whi cloud option us data protect legal even polit reason forbid us ani data outsid scope piti becaus think aw anoth provid help part thi stack cover alreadi use datastag ibm provid told us soon unifi cloud pak data might soon cloud pak data licens mix feel product think might benefit us opposit
jj4646,MachineLearning,1619315323.0,[D] how accurate were the statistical models you developed on real-world data?,come real world data accur statist model develop model abl consist accur make predict e g supervis binari classif ha anyon abl develop model high accuraci high sensit high specif
Yuqing7,MachineLearning,1618849550.0,[N] DeepMind 'Podracer' TPU-Based RL Frameworks Deliver Exceptional Performance at Low Cost,research team deepmind introduc anakin sebulba two architectur demonstr reinforc learn platform base tpu effici deliv except perform scale low cost quick read deepmind podrac tpu base rl framework deliv except perform low cost http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost paper podrac architectur scalabl reinforc learn arxiv http arxiv org pdf nmbr pdf
xiikjuy,MachineLearning,1619173343.0,[D] Should I report the pretraining results?,hello use transform base model pretrain unlabel larg data finetun pretrain model label smaller dataset regular learn pipelin follow idea bert question report pretrain result like learn curv need describ pretra step optim etc literatur use transform base model thi learn paradigm pretrain finetun seem paper report pretrain result result donwstream task first show pretrain model well pretrain matter much even model perform poorli pretrain phase somehow checkpoint work well downstream task problem thank edit report mean show regular ml dl confer paper
ilikepancakez,MachineLearning,1619293570.0,Team Polk’s Bryan Pellegrino Talks About His AI Research And How It Helped Formulate Strategies To Win $1.2 Million [P],http www cardplay com poker news nmbr team polk bryan pellegrino talk hi ai research help formul strategi win nmbr nmbr million realli interest use game theori honor watch thi happen live moment silenc human r poker player pleas
alexirpan,MachineLearning,1618168907.0,[D] Thoughts on industry research vs academia,hi go grad school go straight indsutri instead work ml nmbr year thought interest look back turn post http www alexirpan com nmbr nmbr nmbr grad school nmbryear html http www alexirpan com nmbr nmbr nmbr grad school nmbryear html got feedback across ml career spectrum straight ml engin phd industri academia post phd tri address experi hope match realiti help consid similar decis
glassAlloy,MachineLearning,1617285861.0,[P] How to group every data point with HDBSCAN to some group to have no noise?,task cluster product nmbr dimens ex price rate nmbr nmbr product tag clean toy food fruit use hdbscan goal goal user come site show similar product view question get data point part group goal ani nois code cluster hdbscan hdbscan min_cluster_s nmbr min_sampl nmbr fit data color_palett sn color_palett pair nmbr cluster_color color_palett x x nmbr els nmbr nmbr nmbr x cluster labels_ cluster_member_color sn desatur x p x p zip cluster_color cluster probabilities_ plt scatter project nmbr linewidth nmbr c cluster_member_color alpha nmbr label cluster labels_ number cluster label ignor nois present n_clusters_ len set label nmbr nmbr label els nmbr print estim number cluster n_clusters_
cbsudux,MachineLearning,1616679371.0,[D] Cheapest GPU server options for deploying a side-project?,hey guy cheapest option deploy ml model aw gcp cost nmbr nmbr usd mo use tnmbr pnmbr instanc much side project vast ai http vast ai independ gpu provid cost around nmbr nmbr usd per month still bit pricey nmbr ani pay go option aw elast equival nmbr ani cheap option nmbr nmbr usd mo
KirillTheMunchKing,MachineLearning,1620480849.0,[D] Solving computer vision without convolutions! MLP-Mixer explained.,mlp mixer mlp architectur vision http casual_gan nmbr thi paper spiritu successor vision transform last year thi time around author onc come mlp multi layer perceptron model solv comput vision task thi time around self attent block use either instead two type mix layer propos first interact featur insid patch second patch see detail http casual_gan nmbr model architectur overview http preview redd nanmbreawfwxnmbr png width nmbr format png auto webp fbnmbraenmbrfbnmbrbnmbrcnmbrenmbrbnmbrdbcnmbrbnmbrccnmbrbbdnmbrfnmbr nmbr minut paper explan http casual_gan nmbr arxiv http arxiv org pdf nmbr pdf
st-memory,MachineLearning,1616860882.0,[P] Generating Galaxies using StyleGAN2-ADA,thi http www youtub com watch v kxpenmbrouxnmbrjq video stylegannmbr ada http github com nvlab stylegannmbr ada train imag hubbl http esahubbl org imag archiv categori galaxi involv travel latent space differ truncat valu varieti imag increas exchang qualiti video progress imag scrape manual clean fair either diagram defect dataset nmbr nmbr imag network ha train improv fid note
roVinchi,MachineLearning,1620639086.0,[D] Will the talks of ICLR21 be publicly available?,known releas date could find ani inform websit
Yuqing7,MachineLearning,1617322595.0,[N] Google Research's SOTA GNN 'Reasons' Interactions over Time to Boost Video Understanding,research team googl research propos messag pass graph neural network explicitli model spatio tempor relat use either implicitli explicitli represent object gener previou structur model video understand quick read googl research sota gnn reason interact time boost video understand http syncedreview com nmbr nmbr nmbr googl research sota gnn reason interact time boost video understand paper unifi graph structur model video understand arxiv http arxiv org pdf nmbr pdf
sharvil,MachineLearning,1620146526.0,[P] ArxivDiff: view diffs of arXiv paper revisions,built tool show diff ani two revis paper arxiv take ani arxiv url replac arxiv org arxivdiff org e g http arxiv org ab nmbr becom http arxivdiff org ab nmbr edit first reddit award thank much fellow um net surfer
ottawalanguages,MachineLearning,1619997683.0,[D] correct application of autoencoders for classification,autoencod perform data way princip compon analysi perform dimension reduct data use autoencod use random forest reduc data thi counterproduct
CauchySchwartzDaddy,MachineLearning,1619047967.0,[D] Is it just me or is it getting harder and harder to get access to cloud GPUs with regions being out of resources almost all the time,nmbr vm set googl cloud basic everi region get vnmbr yet multipl time day cant access ani due region resourc mayb thi gcloud thing combin cutthroat gpu market interest know anyon els ha thi problem
xela-sedinnaoi,MachineLearning,1618815073.0,"[P] [D] The benefits of training the simplest model you can think of and deploying it to production, as soon as you can.",mani success thi approach thi mind put togeth exampl http www bodyworkml com post scikit learn meet product make thi agil approach develop machin learn system realiti demonstr take nmbr minut deploy scikit learn model use fastapi bodywork http github com bodywork ml bodywork core open sourc mlop tool built doe thi compar experi interest get peopl thought background larg structur data
prestodigitarium,MachineLearning,1617376157.0,"[P] Gourdian Free Dataset Download: Daily weather of the world, back to 1929",hi ever thought use train model histor weather data chunk world want deal grungi data wrangl massiv dataset get conveni format ever curiou averag temperatur egypt nmbr wa well friend made webpag let filter nmbr gig noaa global summari day weather dataset small fraction download part care csv http gourdian net g eric noaa_gsod global_summary_of_day tabl preview left geograph time filter download button right deliv singl clean csv easi import panda r databas whatev els like use work tabular data csv work everyth bit goal tri build filter option click button csv arriv hard drive download alway singl csv bundl weird directori structur format csv index filter column type lat long date time moment download part want open licens dataset free download signup requir download open dataset search within across dataset basic focu build someth veri simpl power fine grain queri someth like bigqueri easier get go thi super earli version web javascript download client never shown publicli befor client python librari tri figur make better love ani feedback especi break whatev reason would make life easier pleas note work well mobil yet figur mani peopl would want brows download dataset two us prioriti wrong pleas let us know
SQL_beginner,MachineLearning,1619323632.0,[D] Reservoir Computing/Echo State Networks vs RNN's and LSTM's,ha anyon ever heard reservoir comput echo state network http en wikipedia org wiki reservoir_comput doe anyon ani idea situat use compar model rnn lstm
marcovirgolin,MachineLearning,1619510512.0,[R] Model Learning with Personalized Interpretability Estimation,high stake applic e g cancer treatment ai use lightli recklessli need model trust achiev trust interpret key factor field explain ai xai concern method explain behavior black box deep neural network method gener white box e model interpret think e g spars linear model small decis tree symbol express veri good reason whi latter desir former see e g famou paper cynthia rudin http arxiv org ab nmbr propos new proof concept work look whether xai interpret model gener person follow essenti taken abstract fact current algorithm synthesi potenti interpret model reli object regular term repres interpret onli coars e g model size design specif user yet interpret intrins subject propos approach synthesi model tailor user enabl user steer model synthesi process accord hi prefer use bi object evolutionari algorithm synthes model trade accuraci user specif notion interpret latter estim neural network train concurr evolut use feedback user collect use uncertainti base activ learn maxim usabl user onli ask tell given two model time one less complex experi two real world dataset involv nmbr particip find approach capabl learn estim interpret veri differ differ user moreov user tend prefer model found use propos approach model found use non person interpret indic preprint http arxiv org ab nmbr accept appear ec dm workshop gecco nmbr
Last-Programmer2181,MachineLearning,1617364678.0,"[R] Why can a single large SL model be broken down into smaller SL models, and have better accuracy?",refer use learn classifi system lc perform supervis learn dataset larg synthet gener set data nmbr differ input predict action output gener nearli million differ data point train sl model achiev roughli nmbr classif accuraci normal hyperparamet sweep accuraci vari anywher nmbr nmbr data veri uniqu sens mani differ combin eleven input lead twenti seven differ possibl classif action know number pretti specif want give sens deal action could rang noth someth x someth someth x mani possibl variant similar action someth decid wa break thi one larger sl problem small chunk broke singl larger problem four much manag model one lead next model b c ultim predict result larger singular model first model would simpli decid noth someth combin someth x singl predict achiev model predict accuraci nmbr kept make model specif ultim lead twenti seven differ possibl classif one larger model model accuraci nmbr refer model would alway nmbr input remov data point longer relev base previou model choic whi would one larger model tri everyth much lower classif accuraci multipl model thing classif accuraci nmbr
fedetask,MachineLearning,1616519398.0,[R] RL Papers using graph techniques on sampled trajectories,paper construct graph state action reward collect someth find thi idea intrigu found much
downtownslim,MachineLearning,1617383464.0,[R] Scaling Local Self-Attention for Parameter Efficient Visual Backbones,
programmerChilli,MachineLearning,1619417306.0,[D] Huawei just announced that they trained a 200 billion transformer model on an entirely Chinese stack,tweet http twitter com chhille statu nmbr train nmbr billion paramet decod onli dens transform nmbrb token nmbr huawei ascend nmbr chip moreov thi wa done use mindspor huawei ml framework contrast gpt nmbr wa nmbrb paramet model train nmbrb token thi alreadi quit impress even though onli done nmbrb token thi biggest model yet china repres one biggest model yet world howev thing realli impress thi wa done chines stack huawei mindspor framework compil huawei ascend chip known huawei wa work ai chip wa unawar matur point could feasibl train model thi scale code http git openi org cn pcl platform intellig pangu aipha paper http co nmbrwqepoviyq amp nmbr
OnlyProggingForFun,MachineLearning,1618063607.0,[News] From Amputee to Cyborg with this AI-Powered Hand! 🦾[Nguyen & Drealan et al. (2021)],paper involv thi arm nmbr nguyen drealan et al nmbr portabl self contain neuroprosthet hand deep learn base finger control http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf nmbr luu nguyen et al nmbr deep learn base approach decod motor intent peripher nerv signal http www researchg net public nmbr _deep _learn base _approach _for _decod _motor _intent _from _peripher _nerv _signal http www researchg net public nmbr_deep_learn based_approaches_for_decoding_motor_intent_from_peripheral_nerve_sign nmbr nguyen et al nmbr redund crossfir techniqu achiev super resolut neurostimul design exploit transistor mismatch http ieeexplor ieee org document nmbr http ieeexplor ieee org document nmbr nmbr nguyen xu et al nmbr bioelectr neural interfac toward intuit prosthet control ampute http www biorxiv org content nmbr nmbr nmbrvnmbr full http www biorxiv org content nmbr nmbr nmbrvnmbr full video demo http youtu wnbrcrzlbvw http youtu wnbrcrzlbvw
FormerYogurtcloset17,MachineLearning,1617233499.0,"[D] How can I augment an existing model with new training data, preferably on the edge?",augment exist model new train data built app use mobilenet model tensorflow lite detect object live steam camera wish retrain model somehow augment new train data e new photo accomplish object edg e devic even remot server fast
satprepnow124,MachineLearning,1618955447.0,[P] Time Series Forecasting,hey dataset polic complaint want time seri forecast got offic wage year promot year complaint file want predict futur complaint base wage past complaint promot ani suggest method use sorri never done time seri forecast bit confus
pinter69,MachineLearning,1617552299.0,[R] Graph Convolutional Networks in Videos and 3D Point Clouds - Dr. Ali Thabet - Link to free zoom lecture by the author in comments,
WigglyHypersurface,MachineLearning,1618503893.0,[DISCUSSION] How do the different versions of the bootstrap work with deep neural networks?,look deep learn method possibl way imput miss data thi ha lead question deep neural network interact variou version bootstrap statist miss data context goal estim posterior predict distribut miss data condit observ data fill miss data draw thi distribut lead version dataset observ data miss data vari analysi time use simpl formula combin analys give nice clean pictur much uncertainti miss data reduc confid whatev hypothesi test ok deep net part statist literatur miss data thi idea proper say want posterior distribut miss data reflect sourc uncertainti model use fill miss data model fill miss data either need fulli bayesian approxim fulli bayesian model possibl simplest way approxim proper posterior miss data world often use either parameter nonparametr bootstrap parametr bootstrap nmbr train model say learn mu sigma linear regress nmbr sampl predict valu outcom variabl ie make new outcom variabl sampl learn mu sigma nmbr retrain model use sampl valu new depend variabl nmbr make whatev predict infer want thi second model thi bunch time aproxim bayesian posterior nonparametr bootstrap resampl data replac train resampl data repeat mani time get approxim posterior question deep neural network nmbr advantag disadvatag doe deep net use variat bay versu deep net use either version bootstrap ani known expect bias either form bootstrap deep neural network nmbr caus bia train network scratch multipl iter bootstrap would problem exampl resampl data carri weight previou bootstrap iter nmbr good resourc chang fulli bayesian deep network chang sort choic make dropout batch normal activ etc
timscarfe,MachineLearning,1619855005.0,[D] Unadversarial Examples video with Hadi Salman (MIT lab),perform reliabl unseen shift data distribut difficult challeng modern vision system even slight corrupt transform imag enough slash accuraci state art classifi adversari allow modifi input imag directli model manipul predict anyth even percept chang thi known adversari exampl ideal definit adversari exampl human consist say two pictur machin disagre hadi salman ph student mit ex uber microsoft research start think adversari robust could leverag beyond secur realis phenomenon adversari exampl could actual turn upsid lead robust model instead break hadi actual util brittl neural network design unadversari exampl robust object object design specif robustli recogn neural network video http youtu _ehrichlgnmbrk http youtu _ehrichlgnmbrk pod http anchor fm machinelearningstreettalk episod nmbr unadversari exampl hadi salman mit enmbrknmbr first nmbr min give intro cover mit featur bug paper non robust featur etc adversari exampl bug featur http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf adversari robust prior learn represent http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf imag synthesi singl robust classifi http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf unadversari exampl design object robust vision http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf adversari robust imagenet model transfer better http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf convex relax barrier tight robust verif neural network http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf provabl robust deep learn via adversari train smooth classifi http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf denois smooth provabl defens pretrain classifi http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf imagenet train cnn bias toward textur increas shape bia improv accuraci robust http arxiv org ab nmbr http arxiv org ab nmbr
pinter69,MachineLearning,1618759421.0,[R] Putting visual recognition in context - Link to free zoom lecture by the authors in comments,
ploomber-io,MachineLearning,1617292408.0,[D] Incremental builds for ML pipelines,hi everyon like get perspect increment build develop ml pipelin often revisit process step e g updat sql python script sinc output outdat rerun pipelin skip unaffect task save time pipelin grow thi ha signific impact common exampl make increment build must sinc allow modifi someth bring everyth date quickli orchestr thi featur ploomber http github com ploomber ploomber develop dvc drake r dagster kedro prefect surprisingli user latter group seem miss mayb awar featur onli guess peopl mostli work deep learn see much benefit make like tool becaus fewer pre process step miss anyth ensur task use recent data importantli quickli get output date
thejuror8,MachineLearning,1616768727.0,[D] Class-incremental learning and Reviewer 2,disclaim one author connect author ani shape form follow iclr nmbr reject paper review access http openreview net forum id munmbrwnwwwwc result present seem promis although quit fresh cil wa surpris read review two conclus summari premis class increment learn appear weak practic vision applic often label manual highli time consum major bottleneck get suffici mani accur label mani class label arriv train retrain time space batch train issu exist batch train method comput power besid fact thi classic review nmbr move traction around paper present new cil method vision special confer ha quit signific especi recent suggest least degre relev lead question consensu relev cil peopl share review opinion im practic
Haunting-Garbage-364,MachineLearning,1620036485.0,"[D] Companies that sell ""creative"" AI/ML products and services",hey everyon write final thesi artifici intellig use creativ sector lookout creativ sector compani use ai specif autom creation product servic exampl thi compani http ironov artlebedev com http ironov artlebedev com sell logo design ai look compani someth similar find ani ani ani idea compani know pleas let know would realli appreci
hardmaru,MachineLearning,1617335153.0,[R] EfficientNetV2: Smaller Models and Faster Training,
downtownslim,MachineLearning,1618984939.0,[N] Cerebras launches new AI supercomputing processor with 2.6 trillion transistors,cerebra system http venturebeat com nmbr nmbr nmbr cerebra wafer size chip nmbr time faster gpu ha unveil new wafer scale engin nmbr processor record set nmbr trillion transistor nmbr nmbr ai optim core built supercomput task second time sinc nmbr lo alto california base cerebra http cerebra net ha unveil chip basic entir wafer chipmak normal slice wafer nmbr inch diamet ingot silicon process chip factori onc process wafer slice hundr separ chip use electron hardwar cerebra start seamicro founder andrew feldman take wafer make singl massiv chip piec chip dub core interconnect sophist way core interconnect design keep core function high speed transistor work togeth one full text http venturebeat com nmbr nmbr nmbr cerebra system launch new ai supercomput processor nmbr nmbr trillion transistor http venturebeat com nmbr nmbr nmbr cerebra system launch new ai supercomput processor nmbr nmbr trillion transistor
TheoreticallyBlank,MachineLearning,1619406224.0,[R] Fractional pooling layers in CNNs,ani recent public survey relat improv replac standard pool layer fraction one
Yuqing7,MachineLearning,1618933498.0,"[R] Rice University, IBM & USC Study Pushes Quantum State Tomography Beyond Current Computation Capabilities",research team rice univers ibm usc combin compress sens non convex optim acceler techniqu introduc new algorithm momentum inspir factor gradient descent mifgd push qst beyond current capabl quick read rice univers ibm usc studi push quantum state tomographi beyond current comput capabl http syncedreview com nmbr nmbr nmbr rice univers ibm usc studi push quantum state tomographi beyond current comput capabl paper fast quantum state reconstruct via acceler non convex program arxiv http arxiv org pdf nmbr pdf
FreddeFrallan,MachineLearning,1616355252.0,[P] [R] Pre-trained Multilingual-CLIP Encoders,http preview redd nnmbrvkznmbrceofonmbr png width nmbr format png auto webp bfnmbrbnmbrdnmbrbnmbrafnmbrenmbrdnmbrfdnmbrenmbrcnmbrdnmbrbnmbradnmbr start creat set pre train text encod match openai clip http openai com blog clip imag encod see github page http github com freddefrallan multilingu clip tree main model nmbrcard bert nmbrdistil nmbr inform list current avail model current onli perform minor qualit evalu french russian spanish german green swedish model seemingli yield reason result test languag see result http github com freddefrallan multilingu clip tree main model nmbrcard bert nmbrdistil nmbr everi column softmax correspond imag given text idea creat multilingu clip encod via teacher learn coupl machin translat veri creativ unlik write ani proper paper thought might well share preliminari model directli releas bigger multilingu model soon finish train hope guy find use enjoy
hhh312,MachineLearning,1619813787.0,[D] Optimizing the top of a network only,hey guy use backbon bart model huggingfac transform librari fine tune addit head right provid weight optim onli hand weight head howev suspect dure train _grad appli non head weight henc lot comput resourc wast case enforc grade weight thank
jj4646,MachineLearning,1618864084.0,"[D] Has anyone ever heard of ""scissor plots"" being used in machine learning?",http imgur com dnmbrtnmbrgii came across thi interest graph call scissor plot never heard befor ha anyon els heard thi well known plot would interest know wa way roughli approxim n point perhap n point could use decid make sens use complex model simpl model
JollyEye3,MachineLearning,1620281484.0,[D] Anomaly detection in sequential data under budget constraint,work problem need detect anomali collect n sequenti exampl coupl requir nmbr exampl multipl anomali e exampl may contain nmbr nmbr anomali howev goal detect atleast one anomali per exampl detect singl anomali good enough nmbr number detect anomali allow b thi becaus onli fix annot budget confirm detect anomali human review review confirm anomali train data avail problem thi constrain optim problem need maxim number exampl cover anomali detect per exampl atleast one ani thought constrain optim view problem ani research paper around thi topic cost constrain anomali detect corpu sequenti data
dhekurbaba,MachineLearning,1620448897.0,[D] just accepted an offer upon graduation..... what do you do in-between?,phd ha realli mess work life balanc thi first job upon graduat join nmbr week mean thi mani day noth wa think email boss ask refer tool concept teach thing wa wonder thi norm play video game instead guy
Brahimce,MachineLearning,1618321567.0,[R][P] How to handle equality constraints in mutation of evolutionary algorithms?,new evolutionari algorithm field chromosom nmbr variabl real variabl sum variabl equal one look mutat formula gener new chromosom respect equal constraint sum new chromosom alway equal one
LakeTurbulent5878,MachineLearning,1617513587.0,"[D] Having published at top ML conference, how to be nominated as a reviewer?",use believ somebodi invit publish paper neurip icml iclr publish two first author paper confer receiv invit review actual quit enjoy review paper would happi review think qualifi least advisor mainli work ml field ha idea nomin contact ha right nomin review review ac pc
ptoews,MachineLearning,1620036509.0,[D] CPU choice for machine learning server (Epyc vs. Threadripper),plan build rig nmbr rtx nmbr nmbr gb ram applic area comput vision preprocess like necessari read dali might use sure yet current look threadripp vs epyc ani benchmark experi two line compar imag preprocess task far read threadripp higher clock speed run hotter support less memori capac bandwidth wherea epyc opposit doe thi translat border applic ml side question import core count preprocess appar nmbr core per gpu recommend doe scale
statsIsImportant,MachineLearning,1618647712.0,[D] Looking for the extreme classification + Language modelling video,hi look video icml nmbr workshop invit talk nmbr histor perspect extrem classif languag model toma mikolov talk http icml cc confer nmbr schedulemultitrack event nmbr collapsenmbr somebodi point websit provid link would great
elTope,MachineLearning,1618161239.0,[D] Industry vs Learning process gap,mayb thi hole post rason anyon still alway feel tri learn machin learn stuff obvious constantli amaz develop archiv ml industri research whenev enrol cours search guid etc wrap head around thi end interact product environ mani cours may explain model attach toy exampl come implement end end solut specif problem still rather clueless mayb thi mayb best way learn lack enough inform know better neither case would like know someon could provid differ aproach method resourc remov abstract bitch tell also thank attent
jhanytime,MachineLearning,1618156293.0,[D] Video - Why would you use graphs for machine learning data?,phd student studi machin learn applic transport system autonom system think rl robot sever gcn made easi video youtub feel like video often miss forest tree especi sinc gcn nmbr algorithm wa develop nmbr video often cover broader histor context gnn develop differ variat allow model new type system thi first video seri make graph graph neural network applic area potenti make big impact pleas let know think video learn anyth new http youtu munmbrinznmbrltlo
srcho,MachineLearning,1619696052.0,[R] Ethical consideration in AI(Machine learning) decision-making process,dear commun desper need help part master thesi universiteit van amsterdam conduct studi ai machin learn ethic consider relationship decis make outcom qualiti would like kindli ask help particip survey thi survey onli peopl experi decis make process busi project befor work experi ai machin learn deep learn would even better pleas fill thi survey support survey link http uva franmbr qualtric com jfe form sv _nmbrbwwzrfretjmgsa thi survey take nmbr minut maximum find relationship need help suffici particip pleas fill thi survey contribut help finish academ work feel free distribut thi survey network look forward hear answer
emilwallner,MachineLearning,1617697075.0,[P] How I built a €25K Machine Learning Rig,link http www emilwalln com p ml rig http www emilwalln com p ml rig hey made machin learn rig four nvidia rtx anmbr amd epyc nmbr nmbr core includ nmbr gb gpu memori nmbrgb ram part list http doc googl com spreadsheet nmbrvmtilzbglachkscbabcnmbrvovvwsi_nmbrynmbrbbawnmbrrnmbrrcnmbri edit usp share made nmbr word guid peopl look build nvidia amper prosum workstat server includ differ budget tier place home offic data center etc constraint consum gpu reason buy prosum enterpris gpu build workstat server key compon rig pick list retail build list let know ani question build four rtx anmbr epyc nmbr http preview redd nmbrhnmbrfbtbnmbriirnmbr jpg width nmbr format pjpg auto webp nmbraanmbrcnmbrfnmbranmbrdnmbrdnmbranmbrcnmbraenmbrbcnmbr
lkhphuc,MachineLearning,1618873310.0,[R] ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning,zero infin glanc zero infin novel deep learn dl train technolog scale model train singl gpu massiv supercomput thousand gpu power unpreced model size leverag full memori capac system concurr exploit heterogen memori gpu cpu non volatil memori express nvme short learn paper zero infin break gpu memori wall extrem scale deep learn http www microsoft com en us research public zero infin break gpu memori wall extrem scale deep learn highlight zero infin includ offer system capabl train model nmbr trillion paramet nmbr nvidia vnmbr tensor core gpu nmbrx larger state art deliv excel train effici superlinear throughput scale novel data partit map exploit aggreg cpu nvme memori bandwidth cpu comput offer nmbr petaflop sustain throughput nmbr nvidia vnmbr gpu mission deepspe team democrat larg model train allow data scientist singl gpu fine tune model larger open ai gpt nmbr nmbr billion paramet elimin barrier entri larg model train make simpler easier zero infin scale beyond trillion paramet without complex combin sever parallel techniqu without requir chang user code best knowledg onli parallel technolog thi http www microsoft com en us research upload prod nmbr nmbr nmbrxnmbr_deepspeed_nologo nmbr mpnmbr blog post http www microsoft com en us research blog zero infin deepspe unlock unpreced model scale deep learn train http www microsoft com en us research blog zero infin deepspe unlock unpreced model scale deep learn train massiv prop microsoft deepspe team work thrill everi time see new zero paper deepspe releas github
cedricdb,MachineLearning,1618850067.0,[R] [D] Label info in Adversarial Autoencoders,question adversari autoencod paper makhzani et al nmbr http arxiv org ab nmbr http arxiv org ab nmbr let look figur nmbr concern architectur semi supervis adversari autoencod softmax use obtain soft label input imag thi soft output encourag close categor sampl object upper gan question happen soft label optim decod suppos draw hard sampl take argmax semi supervis set import later figur nmbr dimension reduct adversari autoencod thi architectur reus softmax output use cluster head selector thi soft hard selector way see make kind sens follow optim upper gan use soft label optim decod use reconstruct error sampl thi impli gradient reconstruct error flow softmax layer someon clarifi thi thank
roma-glushko,MachineLearning,1618823116.0,[P] How I built my Deep Learning workstation,recent built deep learn workstat share experi follow blogpost http www romaglushko com blog built ml workstat http www romaglushko com blog built ml workstat tri cover aspect build machin learn pc theori choos pc part ml hardwar instal troubleshoot guid softwar cuda setup hope go help
touchanimize,MachineLearning,1618075882.0,[P] Fine tuning Magenta ML model,hi bit novic machin learn undergrad work fine tune onset frame model googl http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf use thi code base http github com greenbech onset frame http github com greenbech onset frame tri fine tune thi model jazz music differ classic music use train origin model wa bit unsur go thi process wa hope anyon could given ani insight thing could done follow thu far acquir dataset jazz music convert midi train differ mix jazz music larger maestro dataset use train onset frame model gotten fnmbr score mix wa think increment train progress checkpoint mayb batch dataset mix need hyper paramet search exactli sure move forward ani idea would much appreci thank guy time
omnipotent_i,MachineLearning,1620326101.0,[D] Paths to become a Productive Non-Academic Researcher,hello veri much fortun work research role post bachelor start tri almost nmbr year get accept confer iclr neurip etc alway unsuccess research interest unfortun afford get academ due situat ani part could take go ahead thi path fantasi get accept confer come non academ research lab top compani provid clear direct guidanc thank
meowklaski,MachineLearning,1618758483.0,[P] MyGrad: Drop-In Autodiff for NumPy,http github com rsokl mygrad http github com rsokl mygrad mygrad lightweight librari add automat differenti numpi onli depend numpi mygrad primari goal make automat differenti access easi use across python numpi ecosystem strive behav feel exactli like numpi user need learn yet anoth array base math librari import mygrad mg import numpi np x mg tensor nmbr nmbr nmbr like numpi array support backprop f np sum x x tensor work numpi function f backward trigger automat differenti x grad store df dxnmbr df dxnmbr df dxnmbr array nmbr nmbr nmbr work leverag numpi new ish protocol overrid function thu mygrad could eventu use bring autodiff cupi xarray spars array array base librari thi ha proven also veri use librari help folk learn auto diff machin learn first creat support class teach ha becom fulli fledg autodiff librari sinc
diffgram-anthony,MachineLearning,1618524641.0,[P] Diffgram - Open Annotation Platform,share http github com diffgram diffgram http github com diffgram diffgram thi ha someth anthoni work last nmbr year close sourc recent grown small team make diffgram differ list benefit http github com diffgram diffgram benefit pick one thing complet system run nmbr minut http youtu ynmbrlenmbrqpxxenmbr docker scale big tech co level multipl knmbr cluster http diffgram readm io doc open instal product time goal continu defin abstract need smoothli work data anyway desir ani system thi goe far beyond ui custom specif speed approach implement realli complet one system would love feedback http preview redd acknmbrfznmbrvetnmbr png width nmbr format png auto webp bnmbranmbrcnmbrcnmbrfnmbrdnmbrenmbrdnmbrcnmbrdnmbranmbraa
JuanPRamirez,MachineLearning,1617358083.0,[D] What would you say are the biggest hurdles for people looking to get into ML?,hey context junior year undergrad current take first cours ml hope look get deeper academia either becom research professor field origin plan thi post ask better prepar come feel like better gaug first ask common major hurdl whether academ industri life hurdl commonli show ani info highli appreci
tomkoker,MachineLearning,1616612505.0,"[P] Torchsort - Fast, differentiable sorting and ranking in PyTorch",introduc torchsort implement fast differenti sort rank blondel et al http arxiv org ab nmbr pytorch complet custom c cuda kernel fast perform pip instal torchsort http github com teddykok torchsort http github com teddykok torchsort differenti sort rank oper open door new loss function exampl easili implement spearman rank coeffici use torchsort model learn output predict monoton relationship target import torch import torchsort def spearmanr pred target kw pred torchsort soft_rank pred kw target torchsort soft_rank target kw pred pred pred mean pred pred pred norm target target target mean target target target norm return pred target sum pred torch tensor nmbr nmbr nmbr nmbr nmbr requires_grad true target torch tensor nmbr nmbr nmbr nmbr nmbr spearman spearmanr pred target tensor nmbr torch autograd grad spearman pred tensor nmbre nmbr nmbre nmbr nmbre nmbr nmbre nmbr nmbre nmbr algorithm n log n run quit fast cpu gpu even larg batch size sequenc length thank custom isoton regress kernel hope thi help tool ml commun
SentientHero,MachineLearning,1616998376.0,[Project] Resumeasy: Our first attempt to create a data product: An application to recommand relevant jobs and useful skills based on user profile.,
crubier,MachineLearning,1619634130.0,"[P] Labelflow, the open source image labeling and dataset cleaning platform.",hi announc labelflow http www labelflow net http www labelflow net open sourc imag label dataset clean platform team nmbr peopl experi imag label dataset curat build qualiti dataset deep learn frustrat amount script requir move data back forth tool lack control data especi data easili share start build labelflow imag label tool bell whistl open sourc backend connect data stack easili let know think feel free request earli access get nmbr releas month
abhijithneilabraham,MachineLearning,1619615635.0,Question Answering on Covid-19 data [research],hi upload first model huggingfac lonfgorm model question answer covid nmbr data find sourc code http github com abhijithneilabraham covid qa give star like project also test huggingfac api link given readm http preview redd dmknmbrfnmbriazwvnmbr png width nmbr format png auto webp enmbradnmbrfanmbrbnmbrceffnmbrenmbrcnmbraadnmbrcnmbr
Ziinxx,MachineLearning,1618165769.0,[P] Trained StyleGAN2-ADA on Naruto picture and plugged it through Lucid Sonic Dreams.,
episodeyang,MachineLearning,1620097999.0,"Paper claims scale invariance, Yet implicitly uses data augmentation?",
KirillTheMunchKing,MachineLearning,1616775591.0,[D] Encoding in Style (Pixel2Style2Pixel - pSp) explained,guy seen result psp encod found paper extrem use research gan invers latent space project deep learn base imag edit want know main idea paper encod style stylegan encod imag imag translat pixelnmbrstylenmbrpixel psp richardson et al head telegram channel http casual_gan break main idea popular gan paper case miss pixelnmbrstylenmbrpixel nowaday use mani imag edit app becaus ha simpl yet effect idea work read http casual _gan nmbr http casual_gan nmbr
jj4646,MachineLearning,1619157754.0,[D] neural tangent kernel,ha anyon heard neural tangent kernel origin thought thi wa activ function neural network look http en wikipedia org wiki neural_tangent_kernel neural tangent kernel ntk kernel describ evolut deep artifici neural network dure train gradient descent allow ann studi use theoret tool kernel method someon pleas help understand thi mean whi neural tangent kernel import thank http rajatvd github io ntk
Rishit-dagli,MachineLearning,1616898697.0,[P] Implementing Geoffery Hinton's latest idea paper,glad today present attempt implement geofferi hinton latest idea paper repres part whole hierarchi neural network also ml way human brain doe http github com rishit dagli glom tensorflow http github com rishit dagli glom tensorflow consid give star like
opensourcecolumbus,MachineLearning,1619664415.0,"[Project] Framework to build AI powered search with just 7 lines of code. Supports semantic, text, image, audio & video search",befor thi open sourc project jina http github com jina ai jina one ha depend close sourc solut implement neural search jina help build semant search engin text text search imag imag search text imag search audio audio search text audio search text video search open sourc apach nmbr licens modifi host infrastructur complet control data differ solr elasticsearch solr elasticsearch implement symbol search rule base base jina implement neural search base pre train deep learn model result better semant search new capabl cross modal e g text video multi modal e g text imag video imag video text search appreci feedback question
RoyalScores,MachineLearning,1619528216.0,[D] Is Object Detection a sub-optimal way to do triage and diagnosis in Medicine?,current microscopi object detect fastest feasibl method diagnosi parasitosi triag underdevelop countri basic model given hundr microscopi imag fece appli object detect order find least one possibl case infect way thi impact problem bulk neg imag elimin model imag might contain egg parasit analyz biomed thi person review detect classifi accordingli recent ha come classif part scheme isnt import problem could solv approach similar anomali detect creat network classifi imag suspici infect neg imag ani current research go specif problem triag ml thi problem novel seem urgent solv thi issu ha declar intend elimin ntd nmbr biggest obstacl achiv thi scalabl cheap diagnosi
hardmaru,MachineLearning,1616392175.0,[R] A rapid and efficient learning rule for biological neural circuits,
hardmaru,MachineLearning,1620018399.0,[R] DriveGAN: Towards a Controllable High-Quality Neural Simulation,
bendee983,MachineLearning,1617367196.0,[D] Machine learning business models in robotics,boston dynam latest robot stretch bore comparison compani previou robot danc backflip ani trick spot handl atla could might commerci success robot compani ha creat far success autonom mobil robot hing versatil robust one hand cost effici versatil side follow rule machin learn narrow domain robust ml model robot mani trick fail often one trick veri robustli stretch fit thi descript perfectli doe one thing move box predict environ flat ground warehous reli work safe robustli case given bd long histori comput vision robot push limit versatil beyond competitor without compromis robust safeti cost effici side sinc bd ha acquir hyundai better posit manufactur robot low cost ship enhanc prop make even versatil stretch cool ha potenti turn bd profit compani meanwhil continu work push limit scienc research humanoid bipe robot kinda like patent clerk job einstein held earli nmbr help pay bill use hi idl time develop import scientif theori histori read full analysi bd new robot mean compani futur http bdtechtalk com nmbr nmbr nmbr boston dynam stretch robot http bdtechtalk com nmbr nmbr nmbr boston dynam stretch robot
GiuPaolo,MachineLearning,1618831031.0,[R] Sparse Reward Exploration via Novelty Search and Emitters,excit announc work deal spars reward environ novelti search emitt ha accept gecco nmbr public find http arxiv org ab nmbr http arxiv org ab nmbr code instead releas http gpaolo github io seren http gpaolo github io seren check ani question hesit ask abstract reward base optim algorithm requir explor find reward exploit maxim perform need effici explor even signific spars reward set perform feedback given sparingli thu render unsuit guid search process thi work introduc spars reward explor via novelti emitt seren algorithm capabl effici explor search space well optim reward found potenti dispar area contrari exist emitt base approach seren separ search space explor reward exploit two altern process first process perform explor novelti search diverg search algorithm second one exploit discov reward area emitt e local instanc popul base optim algorithm meta schedul alloc global comput budget altern two process ensur discoveri effici exploit disjoint reward area seren return collect divers solut cover search space collect high perform solut distinct reward area evalu seren variou spars reward environ show compar favor exist baselin
huggingface,MachineLearning,1617809911.0,[R] A prompt is worth a thousand data points: combining GPT3-style prompting and traditional fine-tuning,
MushiML,MachineLearning,1619776404.0,[D] Temperature term in SimCLR or MoCo papers.,hi read interest articl simclr wa quit help http amit com nmbr nmbr illustr simclr http amit com nmbr nmbr illustr simclr real purpos term temperatur loss function pleas anyon help understand intuit exampl also found thi temperatur term moco paper mean found follow comment thi blog post http towardsdatasci com contrast contrast loss function nmbrcnmbrcanmbrfnmbr http towardsdatasci com contrast contrast loss function nmbrcnmbrcanmbrfnmbr think realli understood doe mean chen et al found appropri temperatur paramet help model learn hard neg addit show optim temperatur differ differ batch size number train epoch thank
OnlyProggingForFun,MachineLearning,1619878190.0,[R] Infinite Nature: Fly into an image and explore it like a bird!,
tdls_to,MachineLearning,1619374980.0,[D] Can you train a privacy-aware language model,pretrain languag model memor train data uncov probe model appropri prompt thi ha seriou privaci implic paper discuss would love hear thi http arxiv org ab nmbr http arxiv org ab nmbr
kk_ai,MachineLearning,1619004138.0,[D] Convenient libs to use for new research project at the intersection of GNN and RL.,start new research project start point rough idea want potenti take nmbr year tool would pick number librari domain gnn rl base tf kera pytorch jax end bit overwhelm review make inform choic homework befor candid mind intent share becaus want bia discuss toward ani particular direct gener mind learn new librari promis flexibl futur ha grow commun user pl advic thx
hardmaru,MachineLearning,1617242521.0,[R] Fast Adaptation with Linearized Neural Networks,
techsucker,MachineLearning,1619587796.0,"[R] Researchers at JAIST, the Japan Advanced Institute of Science and Technology, Have Proposed a Model that Allows Voices to Mimic and Control the Generated Speech’s Speaker Identity",voic convers vc method use modifi speaker ident without alter linguist content non linguist inform vital natur human human commun chang non linguist inform ad emot speech vc make human machin commun sound natur thi allow peopl get inform speech thu social better human use sever languag commun often need machin translat speech speech convers prof akagi jaist explain convent monolingu vc model face challeng appli cross lingual vc clvc task exampl chang speaker ident led undesir modif linguist inform summari http www marktechpost com nmbr nmbr nmbr research jaist japan advanc institut scienc technolog propos model allow voic mimic control gener speech speaker ident http www marktechpost com nmbr nmbr nmbr research jaist japan advanc institut scienc technolog propos model allow voic mimic control gener speech speaker ident paper http ieeexplor ieee org document nmbr http ieeexplor ieee org document nmbr
jj4646,MachineLearning,1619072335.0,"[D] is the ""curse of dimensionality"" still as relevant as it was 20 years ago?",read good exampl explain layman term curs dimension exampl first consid circl insid squar nmbr dimens exampl nmbr consid sphere insid cube nmbr dimens exampl nmbr thi illustr fact cube exampl nmbr lot emptier ratio volum sphere cube compar squar exampl nmbr number dimens increas e g cube becom hypercub nmbr dimens mathemat shown ratio empti increas thi analog sphere repres data cube repres space data belong exampl show us higher dimens need exponenti data fill thi space thu higher dimens data becom spars thi sparsiti make harder fit machin learn algorithm understand thi intuit know mathemat explan behind whi sparsiti give machin learn algorithm hard time perhap sparsiti make matrix calcul harder calcul furthermor shown use chernhoff inequ higher dimens data probabilist like occupi extrem region space exacerb curs dimension thi said modern machin learn exampl e g deep neural network abl overcom curs dimension cnn convolut neural network deal pictur natur high dimension data thu like suffer curs dimension yet compani like googl microsoft constantli develop neural network abl success make predict pictur look would appear curs dimension dead rather affect us much onc modern neural network abl handl curs dimension wa read techniqu call manifold learn abl extract import inform data reduc number dimens therebi mitig curs dimension thought somewher within architectur hidden layer neural network form dimension reduct take place
Spotums,MachineLearning,1617791320.0,[D] Docos on ML like AlphaGo - The Movie,realli enjoy watch alphago movi youtub wa wonder ani similar documentari relat machin learn worth watch entertain infotain without dri
jfischer,MachineLearning,1617812523.0,[P] Datahut.ai: A directory of data science and data engineering projects,http datahut ai new free websit provid statist analysi popular data scienc data engin project wife creat thi site becaus spend lot time research project best fit given use case client person side project cover nmbr project scratch surfac love feedback topic cover addit content like see thank
soulslicer0,MachineLearning,1618352118.0,[D] Bayesian Machine Learning for KITTI Depth Estimation,thi code predict depth rgb imag instead produc depth alon produc multimod depth distribut pixel form categor distribut thi use weed uncertain nmbrd point downstream adapt depth sens task solv task monocular stereo lidar upsampl base depth estim use architectur core network architectur taken psm net neural rgbd note bayesian machin learn ha realli explor detail research especi look multi view stereo sensor fusion writeup http github com soulslic probabilist depth blob main pic explan pdf http github com soulslic probabilist depth blob main pic explan pdf code http github com soulslic probabilist depth http github com soulslic probabilist depth
harish-2306,MachineLearning,1616831163.0,[P] Looking for a teammate in implementing a neat algorithm in Python with C++ as the backend.,hi nmbr major field data scienc plan creat python librari neat c backend faster alreadi exist neat librari thi first time write librari veri well experienc python c dl thought write wrapper swig cloud dicuss chang technolog plan need fun person work interest join drop messag thank
Inevitable_Engineer5,MachineLearning,1617281572.0,[D] Genetic Algorithm: the chromosome representation for Sliding Puzzle Solver?,hello want solv game slide puzzl solver via genet algorithm ani idea chromosom represent problem exampl encod movement via bit nmbr nmbr nmbr right nmbr left ok recombin work thi chromosom represent becaus movement allow ani idea thank
ykilcher,MachineLearning,1620491472.0,[D] Paper Explained - Involution: Inverting the Inherence of Convolution for Visual Recognition (Full Video Analysis),http youtu phnmbrjzunnmbrmoy http youtu phnmbrjzunnmbrmoy convolut neural network cnn domin comput vision almost decad appli two fundament principl spatial agnostic channel specif comput involut aim invert principl present spatial specif comput also channel agnost result involut oper rednet architectur compromis classic convolut newer local self attent architectur perform favor term comput accuraci tradeoff compar either outlin nmbr nmbr intro overview nmbr nmbr principl convolut nmbr nmbr toward spatial specif comput nmbr nmbr involut oper nmbr nmbr comparison self attent nmbr nmbr experiment result nmbr nmbr comment conclus paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com linmbr involut http github com linmbr involut
emystats,MachineLearning,1616606233.0,"[P] Best way to calculate ""performance"" in a probability estimation task",thank advanc take time read thi long post work task particip estim probabl seri bead extract one two hidden jar bead extract one one replac two jar http stack imgur com nmbrfonmbrhm png contain bead two color yellow black differ proport jar contain nmbr yellow bead nmbr black bead jar b contain nmbr yellow bead nmbr black bead jar hidden particip awar differ therefor estim probabl sequenc bead extract specif one two jar exampl extract particip alway answer question probabl sequenc wa extract jar first bead extract yellow like bead wa extract jar second bead also yellow even like sequenc bead wa extract jar estim cours chang particip shown bead particip shown sequenc actual task event nmbr particip ask question befor see ani bead thi whi estim thi plot http imgur com xlnmbrqxlk png nmbr plot see red line estim one particip x axi see extract number event number axi probabl estim black see ideal observ estim correct probabl particip shown sequenc bead alreadi extract thi case nmbr yellow bead nmbr black bead http stack imgur com pnmbrztpm png whi thi point event nmbr sequenc like come jar particip shown bead extract one one happen black particip doe know thi beforehand cours whi probabl estim slowli decreas final sequenc http stack imgur com nrbbmm png problem would like defin perform profil particip base respond task would like abl correl thi profil psychometr result averag respons survey perform profil would like good idea much particip far ideal observ thought could calcul distanc pair point axi sum probabl absolut distanc squar distanc would better would also like retain sign similar task particip respons overestim underestim ideal observ estim use distanc could easili correl perform person data question doe thi make sens wa wonder better way perform thi type analysi way retain inform particip choic exampl thought could fit one curv particip respons one curv ideal observ estim evalu differ paramet defin curv sure go someon ha suggest instead perform time seri k mean cluster http drkeithmcnulti com nmbr nmbr nmbr cluster time seri data r group particip respons familiar thi analysi could idea perform cluster analysi could see cluster perform respect person criteria exampl peopl cluster particularli high x criterium also thought perform pca http www sthda com english articl nmbr princip compon method r practic guid nmbr pca princip compon analysi essenti see person criteria correl anoth analysi familiar question relat psychometr result perform way http stack imgur com bvmsq png see imag particip ani idea recommend onlin exampl tutori would realli appreci r code one particip librari ggplotnmbr librari scale particip probabl estim particip structur list event c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr prob_est c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr class data frame row name c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr ideal observ probabl estim ideal_observ structur list event c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr prob c nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr row name c na nmbrl class data frame plot ggplot data subset particip event nmbr ae x event prob_est col red geom_point cex nmbr geom_lin lwd nmbr lab x event number probabl scale_y_continu break pretty_break n nmbr limit c nmbr nmbr scale_x_continu break pretty_break n nmbr geom_lin data subset ideal_observ event nmbr ae x event prob col black lwd nmbr geom_point data subset ideal_observ event nmbr ae x event prob col black cex nmbr plot calcul discrep ideal perform differ sum particip nmbr ideal_observ nmbr differ nmbr nmbr sup creat nmbr nmbr nmbr reprex packag http reprex tidyvers org vnmbr nmbr sup
SQL_beginner,MachineLearning,1619536458.0,[D] Rules for Determining how much Data should he used in a Model,thi concept alway struggl statist data alway better suppos nmbr year data hospit visit interest supervis classif predictor age height weight blood type salari etc interest predict hospit stay less nmbr day nmbr day thi easili solv use random forest dilemma use nmbr year data might abl captur wide varieti pattern sinc interest predict futur inform mayb older data less relev might surpress current trend deal thi problem
Rina-Panigrahy,MachineLearning,1619364646.0,"[R] Google-Workshop: Conceptual Understanding of Deep Learning, May 17. Join Us.",pleas join us virtual googl workshop conceptu understand deep learn http site googl com view conceptualdlworkshop home may nmbrth nmbram nmbrpm pst live youtub http www youtub com watch v gnmbrdgbwjiulq goal doe brain mind perhap even artifici one work algorithm level deep learn ha produc tremend technolog stride recent decad unsettl feel lack conceptu understand whi work extent work current form goal workshop bring togeth theorist practition develop understand right algorithm view deep learn character class function learn come right learn architectur may provabl learn multipl function concept rememb time human theoret understand languag logic rl meta learn lifelong learn speaker panelist includ ture award winner geoffrey hinton lesli valiant godel prize winner christo papadimitri full detail http site googl com corp view conceptualdlworkshop home panel discuss also panel discuss fundament question mathemat model mind explor basic question provabl algorithm captur essenti capabl mind rememb complex phenomena knowledg graph creat automat learn new concept function action hierarchi time whi human decis seem interpret twitter conceptualdlworkshop http twitter com search q nmbrconceptualdlworkshop src recent_search_click pleas retweet http twitter com rinapi statu nmbr hope see rina panigrahi http theori stanford edu rinap http theori stanford edu rinap
wattnurt,MachineLearning,1620102631.0,"[D] Are there any ML algorithms that can learn a simple ""X+1"" problem?",thi idea veri simplist problem statement suppos n binari input n binari output simpl problem ani arbitrari input copi output set one output bit nmbr ani exampl input nmbr correct output would nmbr n cours larg enough exhaust learn input output set dure train interest side effect thi problem also ani input usual sever correct output mani nmbr input ani ml algorithm learn someth like thi note much interest heavili cater solut e g problem statement ha encod featur set model architectur gener learn power point view algorithm learn thi extrem simpl rule
Yuqing7,MachineLearning,1617727057.0,"[N] IBM, UMich & ShanghaiTech Papers Focus on Statistical Inference and Gradient-Boosting",team univers michigan mit ibm watson ai lab shanghaitech univers publish two paper individu fair ml model introduc scale free interpret statist principl approach assess individu fair method enforc individu fair gradient boost suitabl non smooth ml model quick read improv ml fair ibm umich shanghaitech paper focu statist infer gradient boost http syncedreview com nmbr nmbr nmbr improv ml fair ibm umich shanghaitech paper focu statist infer gradient boost paper statist infer individu fair http arxiv org pdf nmbr pdf individu fair gradient boost http arxiv org pdf nmbr pdf arxiv
ykilcher,MachineLearning,1618846736.0,[D] Paper Explained - NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (Full Video Analysis),http youtu crln cyfxtk http youtu crln cyfxtk view synthesi tricki problem especi onli given spars set imag input nerf emb entir scene weight feedforward neural network train backpropag differenti volum render procedur achiev state art view synthesi includ direct depend abl captur fine structur detail well reflect effect transpar outlin nmbr nmbr intro overview nmbr nmbr view synthesi task descript nmbr nmbr fundament differ classic deep learn nmbr nmbr nerf core concept nmbr nmbr train nerf spars view nmbr nmbr radianc field volum render nmbr nmbr result view depend nmbr nmbr posit encod nmbr nmbr hierarch volum sampl nmbr nmbr experiment result nmbr nmbr comment conclus paper http arxiv org ab nmbr http arxiv org ab nmbr websit code http www matthewtancik com nerf http www matthewtancik com nerf
jj4646,MachineLearning,1619155542.0,"[D] can someone please explain the ""representer theorem"" in simpler term?",http en wikipedia org wiki representer_theorem someon pleas tri explain represent theorem simpler term whi consid import realm machin learn thank
ClaudeCoulombe,MachineLearning,1619512223.0,"[D] Who first advanced the ""manifold hypothesis"" to explain the stunning generalization capacity of deep learning?",manifold hypothesi state natur data lie low dimension manifold kind local euclidian subspac within high dimension space data encod alreadi found clayton nmbr algorithm manifold learn http cseweb ucsd edu lcayton resexam pdf wa written befor term deep learn wa invent hinton nmbr brahma wu nmbr whi deep learn work manifold disentangl perspect http diginol lib fsu edu islandora object fsu nmbr datastream pdf view mention manifold hypothesi fact without ani citat
niels_vg,MachineLearning,1617358952.0,Predict Company Sales - Design choices; how to store incoming sales/which model to choose? [P],hi folk tri predict book stand comedian cafe lot featur use affect number sale e g day year weather averag sale last month day week averag sale specif day week etc goal creat model abl predict number sale given day onc everi hour start nmbr day nmbr hour befor show stop one hour befor deadlin show multipl predict variabl alway known chang avg _nmbr averag daili sale last nmbr day avg _nmbr averag daili sale last nmbr day vacat hot cold variabl indic whether vacat day longtermgrowth number day compani alreadi exist measur continu growth dayofyear day year min nmbr max nmbr weekday day week hot cold encod moday nmbr nmbr etc apart abov variabl one indic mayb import highli correl eventu sale tri predict thi combin two variabl currenthour number hour befor start show min nmbr max nmbr current sale number sale alreadi obtain question would best method store data abov way suffici train predict model currenthour currentsal doubt follow two method nmbr simpli use two column x data nmbr indic number hour befor deadlin nmbr indic number sale alreadi obtain howev thi provid us ani inform sale obtain nmbr creat column hour befor deadlin nmbr column total name hr _nmbr hr _nmbr valu hour would number sale yet obtain dure timestamp downsid thi solut would nmbr nmbr column onli hold thi data thi good idea thi like drastic increas comput time conclud follow two question nmbr would best two method describ abov store sale yet obtain better idea two scenario creat abov would glad hear furthermor nmbr type predict model would think result best perform current see high perform linear regress lasso ridg hardli believ thi would result best perform thank avanc
jacobgil,MachineLearning,1619376340.0,[Project] Recent Class Activation Map Methods for CNNs and Vision Transformers,http github com jacobgil pytorch grad cam http github com jacobgil pytorch grad cam cam base method famili pixel attribut method tri highlight part imag contribut model output method assign weight spatial nmbrd activ network sum get nmbrd salienc map thi project includ pytorch implement pip instal sever class activ map method includ veri recent one grad cam http arxiv org ab nmbr http arxiv org ab nmbr grad cam http arxiv org ab nmbr http arxiv org ab nmbr xgrad cam http arxiv org ab nmbr http arxiv org ab nmbr ablat cam http ieeexplor ieee org abstract document nmbr http ieeexplor ieee org abstract document nmbr score cam http arxiv org ab nmbr http arxiv org ab nmbr work vision transform test deit well cnn test torchvis model hope use conveni start point develop compar new method
TheCollaboratory,MachineLearning,1619194117.0,[P] Introducing The Collaboratory: A place to explore and discover research based on your interests,keep track new research increasingli time consum task mani field fast pace interdisciplinari domain like ml even harder stay top requir research self curat varieti sourc bookmark newslett arxiv review etc topic relev collaboratori webservic aim eas pain explor keep research relev platform automat sourc recommend latest research relev interest base paper seed read list recommend power larg languag model transform research descript semant embed b compar pre comput embed grow index nmbrm paper dataset model ensur recommend highli relev index effort ensur time inspir solv thi problem encount daili live check dozen sourc week stay top literatur differ field think thi tool realli use peopl spin new topic peopl whose interest lie field peopl need keep stream research move quickli pleas take look site let us know think thecollaboratori ai http thecollaboratori ai platform remain work progress want keep make better pleas let us know make better
kaia_1527,MachineLearning,1618075767.0,[D] Learning resources: multi-object localization,hey everyon learn multi object local wa wonder whether anyon could recommend learn resourc end end exampl went nmbr fast ai http fast ai lesson http www youtub com watch v nmbrfrkxr nmbrpbi object local use pascal dataset exampl date hope train multi object detector singl class found exampl surprisingli spars
swifty540,MachineLearning,1619081651.0,[D] How repetitive are the Ambient Sounds?,fan ambient sound featur appl homepod wa wonder repetit found thi thread r homepod comment dpunmbrm doe _anyon _els _feel _like _the _ambient _sound _are http www reddit com r homepod comment dpunmbrm does_anyone_else_feel_like_the_ambient_sounds_ar sure actual repetit describ thread wa wonder machin learn could use figur exactli repetit actual doe anyon insight tool detect repetit audio
mamrollahi,MachineLearning,1616864558.0,[D] Which similarity method has been used in WS353 dataset?,hello may know similar method ha use wsnmbr dataset http alfonseca org eng research wordsimnmbr html
KirillTheMunchKing,MachineLearning,1619540579.0,"[D] Main ideas from ""EigenGAN Layer-Wise Eigen-Learning for GANs"" explained!",eigengan layer wise eigen learn gan http casual_gan nmbr author propos novel gener architectur intrins learn interpret direct latent space unsupervis manner moreov direct control straightforward way strength coeffici directli influenc attribut gender smile pose etc gener imag sampl architectur overview http preview redd zdsnmbrxwsnmbrsqvnmbr png width nmbr format png auto webp nmbrfnmbrbanmbrenmbrenmbrcnmbrcenmbrbfbnmbrcnmbrdnmbrenmbrdnmbreefnmbranmbrf direct travers exampl http reddit com link mzsnmbrct video nmbrokqodsqvnmbr player check nmbr minut paper explan http casual_gan nmbr arxiv http arxiv org pdf nmbr pdf
Anomalix,MachineLearning,1619811263.0,[D] Any good enough DCGANs that work on low-end GPUs?,want experi bit dcgan nmbrgb vram enough someth like stylegan wa wonder anyth run lower end gpu good enough want abl nmbrxnmbr possibl nmbrxnmbr bet imposs low amount vram
blatant_variable,MachineLearning,1619388418.0,[R] Correcting Experience Replay for Multi-Agent Communication (ICLR 2021 Spotlight),hi first author thi paper rl agent learn commun gener thi quit challeng becaus agent learn polici chang make multi agent environ highli non stationari key insight orwellian one use present inform alter past messag improv futur learn thi involv relabel messag sampl replay buffer reflect current commun polici agent find thi greatli enhanc agent abil learn substanti improv perform multi agent rl algorithm across rang experi paper http openreview net forum id xvxpuckcnpo http openreview net forum id xvxpuckcnpo video http www youtub com watch v piinq fgdci http www youtub com watch v piinq fgdci pleas ask ani question may happi answer
minimaxir,MachineLearning,1619970229.0,[P] Create Your Own AI-Generated Magic: The Gathering Cards (2-cell Colab Notebook),http colab research googl com drive nmbrvotnmbruzvltobgmduzmunmbrvwhinmbrx nmbre_a coupl year ago train gpt nmbr magic gather card work extrem well howev wa overengin due limit around gpt nmbr time much better ai text gener tool train bespok tini gpt nmbr nmbrm paramet encod magic card data use aitextgen http github com minimaxir aitextgen schema capabl anecdot qualiti card gener much better rnn approach past card follow color pie wa abl make colab notebook surprisingli littl code unnest includ card decod model small enough run local cpu download notebook let know ani question
forsakenMule,MachineLearning,1617823068.0,[D] Regularly retraining a churn prediction model,tri build process aim predict custom churn hard time find good resourc tackl problem retrain model inde rel easi train model first time given right data struggl determin best strategi deal regular retrain inde let assum train model wich perform well compani decid use deriv action custom flag potenti churner face issu new data avail bias action taken due predict model product reinforc learn realli option feedback time count year concept drift due product chang competit pressur rather month ani idea link go tackl thi issu
nirmalya8,MachineLearning,1617254105.0,"""[D]"" Generating Medical Images using GANs",hey peopl medic dataset either less data dataset veri imbalanc deal thi imbal thought synthet gener medic imag class less exampl wa look paper gener medic imag help gener adversari network get recommend constraint nmbr dataset constraint prefer freeli avail nmbr either code paper detail architectur loss function activ function etc thank
6rubtub9,MachineLearning,1619011427.0,[D] Meaning of semantic in machine learning,hi thi may elementari question ask read sever comput vision paper come across phrase semant use featur semant strong featur deep semant featur tri look mean semant machin deep learn domain find ani satisfi answer anyon explain doe mean semant strong deep use thank
seuqaj114,MachineLearning,1618486921.0,[P] Nimbo: Run jobs on AWS with a single command,hey everyon friend launch nimbo http nimbo sh dead simpl cli wrap aw cli allow run code aw run local github http github com nimbo sh nimbo http github com nimbo sh nimbo doc http doc nimbo sh http doc nimbo sh decid build thi becaus frustrat cumbersom use aw wa want abl run job aw easili run local time want make use cheap spot instanc nimbo thi singl paramet like current user experi thi reason also provid mani use command make faster easier work aw easili check price log onto instanc sync data snmbr see use command http doc nimbo sh use command unlik similar servic sole client side mean code run ecnmbr instanc data store snmbr bucket server infrastructur orchestr happen nimbo packag ton idea nimbo one command jupyt notebook ecnmbr add docker support person favorit provid imag preload larg dataset like imagenet download store simpli spin instanc dataset avail dataset happi receiv ani feedback suggest
michaelaalcorn,MachineLearning,1620422300.0,"[R] DeepMind - Game Plan: What AI can do for Football, and What Football can do for AI",
khalilmeftah,MachineLearning,1616538667.0,[P] Generating CryptoPunks Images with GPT-2,gener cryptopunk gpt nmbr http preview redd nmbrkncstuonmbr png width nmbr format png auto webp bnmbrfcnmbrfnmbrccnmbrbnmbrcanmbrcnmbrcfanmbrfnmbrcnmbr
chimp73,MachineLearning,1619910179.0,"[D] How far can we get with one-shot learning, generalization and policy gradient?",openai research http arxiv org ab nmbr show mere scale simpl nn improv perform gener sampl effici notabl fine tune gpt nmbr converg onli one epoch http github com cabhijith gpt nmbr_doc blob master fine tune md thi rais question veri larg nn sampl effici one shot learn singl sdg updat reach human level infer gener abil beyond assum capabl wonder could actor model look like make use chiefli one could elimin larg time horizon use rnn transform instead continu one shot learn sensori transit within veri brief time window predict next second previou one one could dedic output neuron drive actuat train polici gradient long term near term recal would simpli gener one shot learn sensori transit similarli decis make would simpli gener one shot learn modul polici make clear mean one shot learn sdg recal gener let say dinner predict go pasta actual fish sdg updat make one shot learn ate even due predict error ask ate next day gener context yesterday context question know wa fish one could use predict sampl addit predict target model one shot learn predict thought occur gener reward modul thought becom goal driven allow agent ignor predict object increas reward e g ponder via inner monologu instead listen one would also need feed predict sampl addit sensori input time step model ha access thought predict consciou thought latent space sensori space thi match human mind thought beyond model data gener process sensori experi consciou thought would occur brief time slice also match human consciou thought skip one thought almost discret manner conscious henc onli exist briefli dure forward pass http karpathi github io nmbr nmbr nmbr forward pass realiti interpret second afresh tie togeth via one shot learn contextu inform previou step allow model learn imagin predict reward imit learn would simpl consequ gener name identifi agent self model natur emerg mere self model one predict thought learn predict one predict seem suffici thought get strateg condit previou thought goal direct reli gener e model may condit x one shot learn polici updat world knowledg know x onli work context establish subgoal model also know thought act predictor thu gener order achiev x gener thought model expect complet manner use get architectur detail may matter much ignor econom factor larg differ differ nn architectur far even though transform perform nmbrx better http arxiv org ab nmbr lstm fig nmbr left strong diverg e evid lstm abl achiev perform nmbrx resourc transform seem mostli trick get larg time horizon biolog implaus also necessari reli one shot learn tie togeth long term depend instead long time horizon gener would side step issu meticul backprop long term depend tempor unrol exhaust backprop valu inform throughout state space rl polici gradient extrem noisi human level higher gener abil might abl filter one shot learn noisi updat becaus common sens learn world work though predict task model conclud learn experi pain pleasur plausibl relat certain caus world
hiDDenthings63,MachineLearning,1616820874.0,[D] How do I make a model which takes a bedroom image as input give an output of different design of bedroom related to input image?,want make model project take interior design imag input provid output differ kind design relat input imag know start think would use cnn track make find anyth relat googl
KirillTheMunchKing,MachineLearning,1618595253.0,[R] Spatially-Adaptive Pixelwise Networks for Fast Image Translation (ASAPNet) by Shaham et al. - Explained,spatial adapt pixelwis network fast imag translat http casual_gan nmbr author propos а novel architectur effici high resolut imag imag translat core method pixel wise model spatial vari paramet predict convolut network low resolut version input reportedli nmbrx speedup achiev baselin method similar visual qualiti detail http casual_gan nmbr asapnet http preview redd ablptrdnmbrpktnmbr png width nmbr format png auto webp nmbrfednmbrdnmbrfbaanmbrdnmbranmbrcnmbrecec familiar paper check http casual_gan nmbr
bendee983,MachineLearning,1616616039.0,[D] Has anyone tried Newton's method for ML optimization?,ani scenario newton method would better sgd adam etc ye whi includ ml dl framework unless mistaken
deep-yearning,MachineLearning,1618494268.0,[D] What really makes neural networks generalizable?,usual employ regular techniqu dropout batch norm earli stop etc help prevent model overfit train set perform well valid set howev thi still doe usual help model perform better real data test data data consid distribut train valid set thi mean model generaliz thi clearli huge area research paper read lead direct usabl advic project instead focus theoret discuss generaliz pleas correct wrong point better paper question practic tip dure train develop get model actual perform well real test data distribut data obvious start train valid data match distribut expect test data great start alway predict guarante distribut test data
amirninja,MachineLearning,1617643791.0,[Discussion] Similarity between two datasets/matrices,hello dataset creat anoth dataset use tow differ method method method b would like find close newli creat dataset origin dataset metric would make sens thi case cosin similar euclidean distanc captur close differ singl number use frobeniu norm thi subredit http www reddit com r machinelearn comment rnmbrinmbr proper_method_for_calculating_similarity_between seem suggest mantel test howev sure right one ani thought help would appreci thank
thisisdhruvagarwal,MachineLearning,1620638455.0,Can we use PPO in a multi-action task? [D],use ppo multi action task like nmbr output layer first one specifi whether move left right second one specifi whether shoot layer nmbr output neuron softmax activ function use ppo thi task ye actor loss
JEUNGHWAN,MachineLearning,1620611903.0,[P] AI Kant is willing to be ghostwriter only for you,hi dream someon write philosophi essay place major philosophi came idea train gpt nmbr critiqu pure reason kant kant becom ghostwrit doe write kantian essay place student project call teachabl nlp http forum ainetwork ai teachabl nlp kant ghostwrit onli nmbr http forum ainetwork ai teachabl nlp kant ghostwrit onli nmbr program help fine tune natur languag process nlp model without complex code graphic process unit gpu easili train get nlp model use case want appreci ani feedback thought thank demo http reddit com link nnmbrtnmbrud video ognnmbrpttjnmbrynmbr player
broutonlab,MachineLearning,1620219389.0,[D] Have you ever faced attacks on deep learning model in your projects?,adversari attack blog post http broutonlab com blog adversari attack deep learn model seriou threat dl model attack intent creat malici input fool dl model get incorrect output thi lead seriou troubl e g bank applic user identif hi face citizen surveil system airport question nmbr develop deep learn model take account fact may come adversari attack product nmbr method protect employ nmbr ever tri attack dl model product
Yuqing7,MachineLearning,1619627967.0,[R] Google’s 1.3 MiB On-Device Model Brings High-Performance Disfluency Detection Down to Size,research team googl research propos small fast devic disfluenc detect model base bert architectur smallest model size onli nmbr mib repres size reduct two order magnitud infer latenc reduct factor eight compar state art bert base model quick read googl nmbr mib devic model bring high perform disfluenc detect size http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper disfluenc detect unlabel data small bert model arxiv http arxiv org pdf nmbr pdf
vaseline555,MachineLearning,1619268301.0,[D] Has anybody implemented FedAvg? I have a question,hello implement fedavg use pytorch even look github repositori still confus test model main question nmbr prepar test dataset client e client ha train test dataset use global ident test set client sinc finish fedavg client model weight detail descript deal mnist dataset nmbr client client ha onli one digit client nmbr ha digit nmbr client nmbr ha digit nmbr client nmbr ha digit nmbr simul non iid set local train client send paramet central server server aggreg final distribut averag model client test averag model perform test onli onc use test dataset digit former case abov question test nmbr time use local split test set onli one digit calcul mean report final perform veri confus latter true client final ha abil encod unobserv data e g client nmbr onli nmbr digit sampl final avail encod anoth digit nmbr nmbr fedavg right thank advanc
martin1285,MachineLearning,1618585781.0,[D] Serializing and using KNN for Predictions,hello work problem would like use k nearest neighbor regressor make predict work python use joblib serial model pickl format understand k nearest neighbor instanc base requir entir train set make predict run thi model pipelin etl train model serial model make predict abl make predict use pickl model understand python train data serial along algorithm doe requir load entir train data make predict result thi size pickl object get larger train data increas understand thi correct deploy perspect thi would first time deploy instanc base model thank advanc
wdanilo,MachineLearning,1618363356.0,"[News] [Project] Enso 2.0 is out! Visual programming language for Data Science. It lets you code in a visual way in Python, Java, R, and JavaScript. Written in Rust and running in WebGL.",hi wojciech one founder enso enso award win interact program languag dual visual textual represent tool span entir stack go high level visual commun nitti gritti backend servic singl languag enso also polyglot languag let import ani librari enso java javascript r python use function callback data type without ani wrapper enso compil underli graalvm jit compil compil instruct set unifi memori model check demo video http www youtub com watch v fqvwmoojmqk nmbr ab _channel enso http www youtub com watch v fqvwmoojmqk nmbr ab_channel enso websit http enso org http enso org github enso open sourc http github com enso org enso http github com enso org enso graalvm websit enso compil base http www graalvm org http www graalvm org
hardmaru,MachineLearning,1616464018.0,[N] NeurIPS2021 will be using openreview.net to manage submissions,accord program chair neurip nmbr use openreview manag submiss thi year review process public previou year submiss visibl onli assign program committe intern discuss remain privat dure review process notif deadlin accept opt reject paper made public togeth anonym review meta review unlik iclr review process still privat review would releas onli afterward reject submiss default would reveal unless author opt http openreview net group id neurip cc nmbr confer
techsucker,MachineLearning,1619392197.0,"[R] Scientists From The Max Planck Florida Institute For Neuroscience (MPFI) Have Developed ‘Gold Digger’, A Software Tool That Uses A Modified PIX2PIX Deep Learning Network",electron microscopi em method use high resolut imag biolog non biolog sampl requir precis time consum step sampl prepar imag acquisit produc clariti detail requir visual small cell structur high resolut addit extract biolog inform em creat imag veri labori time intens task thi becaus current em analysi softwar usual requir skill eye examin hundr pictur manual team scientist max planck florida institut neurosci mpfi ha appli neural network creat novel analysi softwar gold digger aim streamlin part lengthi process diego jerez eleanor stuart two high school data scienc student http techxplor com news nmbr nmbr gold digger neural network nexu html start work thi project curios later turn complex interdisciplinari project summari http www marktechpost com nmbr nmbr nmbr scientist max planck florida institut neurosci mpfi develop gold digger softwar tool use modifi pixnmbrpix deep learn network http www marktechpost com nmbr nmbr nmbr scientist max planck florida institut neurosci mpfi develop gold digger softwar tool use modifi pixnmbrpix deep learn network paper http www natur com articl snmbr nmbr nmbr nmbr http www natur com articl snmbr nmbr nmbr nmbr
moon-child-99,MachineLearning,1618115946.0,[P] How do I validate a subjective model?,cluster model classifi best worst essenti trade featur provid sinc class subject valid thi test case right answer
bendee983,MachineLearning,1616423246.0,[R] Adversarial training reduces safety of neural nets in robots,adversari train result drop pure accuraci dl model gener receiv accept tradeoff robust adversari attack use robot accuraci degrad caus safeti risk accord research paper http bdtechtalk com nmbr nmbr nmbr adversari train robot learn ist austria mit tu wien key point adversari train ha design static imag classif task infer task independ robot deal dynam environ infer done depend sequenc robot matter often error happen also error take place e happen consecut cycl result robot crash classic adversari train metric onli measur number misclassif error robot also import far predict error deviat correct label read coverag paper interview lead author http bdtechtalk com nmbr nmbr nmbr adversari train robot learn http bdtechtalk com nmbr nmbr nmbr adversari train robot learn read full paper http arxiv org ab nmbr http arxiv org ab nmbr
Rohit901,MachineLearning,1618904137.0,[D] When to use one-hot encoding of categorical variables?,hey nmbr continu input variabl nmbr categor variabl ha nmbr level use one hot dummi encod creat nmbr variabl input degrad model perform plan use simpl multi layer neural network mayb add lstm layer classif task help nmbr nmbr data point wa plan use creat dummi method panda encod categor variabl
Appaulingly,MachineLearning,1618063524.0,[P] A machine learning tool now exists to detect Photoshop face warping!,sheng yu wang et al http arxiv org ab nmbr develop ml tool identifi imag edit use adob photoshop face awar liquifi tool common tool utilis warp facial featur ml algorithm outperform human identifi edit imag even determin edit ha taken place imag highli recommend check work fascin creat subreddit r fakewarpbot scrape imag r instagramr r kimkardashianp use tool analys imag face warp r instagramr subreddit redditor post imag purport edit differ way lot time suggest edit subtl human determin fact edit ha taken place hope r fakewarpbot provid certain determin edit also post imag r fakewarpbot analysi would stress way thi machin earn tool final determin whether face warp ha occur credit goe sheng yu wang et al http arxiv org ab nmbr edit spell
_rusht,MachineLearning,1619974802.0,"[P] Onepanel - open source, extensible deep learning platform, now includes an Ubuntu based deep learning desktop, hyperparameter tuning and a Python DSL for defining pipelines and workflows",
aselsiriwardena,MachineLearning,1618556255.0,[P] Simple UI for deep learning model,hi look help project work simpl imag imag translat project want creat ui model project wa built use pytorch look veri simpl ui demonstr like select imag left side show result imag right side ani suggest ani broiler plate code
NahanTrogn,MachineLearning,1618195876.0,[Discussion] About pre-processing audio for Yamnet's input,hi commun ml thi first time post question forum read input yamnet http github com tensorflow model tree master research audioset yamnet input audio featur input audio featur previou releas vggish yamnet wa train audio featur comput follow audio resampl nmbr khz mono spectrogram comput use magnitud short time fourier transform window size nmbr ms window hop nmbr ms period hann window mel spectrogram comput map spectrogram nmbr mel bin cover rang nmbr nmbr hz stabil log mel spectrogram comput appli log mel spectrum nmbr offset use avoid take logarithm zero featur frame nmbr overlap exampl nmbr second exampl cover nmbr mel band nmbr frame nmbr ms question whi frame length nmbr ms exampl cover nmbr mel band nmbr frame nmbr ms nmbr ms think becaus nmbr ms length window stft nmbrm onli window hop thank advanc wish good day
ottawalanguages,MachineLearning,1619755336.0,[D] How sensitive are statistical models to the richness of information within the data?,spent last hour think creat exampl illustr question http imgur com nmbrgunmbrpb question indirectli relat exploratori data analyt featur select statist model suppos variabl let assum categor variabl thi exampl make histogram variabl appear extrem skew first glanc would want includ heavili skew variabl input statist model e g nmbr variabl singl valu inform use could statist model know heavili skew variabl contain veri use inform nmbr might realli help make futur predict sometim use context problem e g work biolog problem consult biologist might abl gain insight time tri use logic figur heavili skew variabl fact use model big complex data possibl post exampl abov illustr thi problem http imgur com nmbrgunmbrpb would curiou know ani dealt similar problem past thank
dgheere,MachineLearning,1619432105.0,[R] Survey on evaluation of algorithmically generated music. Can you tell the difference?,dear utrecht univers conduct scientif studi evalu algorithm gener music test see whether peopl identifi whether piec music made comput johann sebastian bach specif doe matter whether familiar style bach would veri much appreci could take nmbr nmbr minut time fill thi survey would greatli help write bachelor thesi respons cours complet anonym treat confidenti thank time http survey uu nl jfe form sv_nmbruclrbbcuhubnmbr
Professional-Bag392,MachineLearning,1617261893.0,[D] Is there a way to evaluate model during training?,work machin learn project set ml pipelin variou stage project pipelin goe like data extract data valid preprocess train model evalu model evalu concern current happen train complet base evalu model approv reject want model evalu take place dure train ani point say nmbr train complet train stop model evalu base model approv resum train abov scenario implement
johndoe709,MachineLearning,1616437000.0,[D] Gender Bias in Persian to English Google Translate,third person pronoun mani languag neutral call epicen translat text languag languag third person pronoun neutral english translat usual either determin gender pronoun gener assum use evid see translat text persian english done googl translat gender bia persian english translat http preview redd nmbrxsnmbrqtlnmbrbmonmbr png width nmbr format png auto webp cnmbrcnmbranmbranmbrcnmbrfnmbrdenmbr point googl translat lot better wa year ago help write thi text curiou solut avoid bia languag model solut becaus model train text human produc thi post inspir follow post http www reddit com r europ comment mnmbruphb hungarian _ha _no _gender _pronoun _so _googl utm _sourc share utm _medium webnmbrx context nmbr http www reddit com r europ comment mnmbruphb hungarian_has_no_gendered_pronouns_so_googl utm_sourc share utm_medium webnmbrx context nmbr
Stanford_Online,MachineLearning,1619652145.0,[N] Free webinar - Hacking AI: Security & Privacy of Machine Learning Models,regist upcom webinar stanford professor dan boneh discuss recent work intersect cybersecur machin learn emphasi adversari machin learn http learn stanford edu secur privaci machin learn model webinar html http learn stanford edu secur privaci machin learn model webinar html
papajan18,MachineLearning,1619619546.0,"[R] ""Understanding Human Intelligence through Human Limitations"" - A Great Article that Highlights How to Think of the Relationship Between the Study of Human and Machine Intelligence",http www sciencedirect com scienc articl pii snmbr highlight articl human intellig aris optim three main constraint limit time lifespan limit comput must fit insid singl brain commun must abl transfer solut brain sustain humankind space problem human intellig solv subset potenti problem want artifici intellig solv machin face constraint human necessarili use solut use case machin intellig one ha limit time bandwidth high latenc commun case understand human optim around constraint provid valuabl insight
qudcjf7928,MachineLearning,1618165059.0,"[D] Has anyone looked at ""LSPE"" algorithm as portfolio rebalancing method?",http proceed mlr press vnmbr uzielnmbra uzielnmbra pdf http proceed mlr press vnmbr uzielnmbra uzielnmbra pdf thi long short term forecast portfolio select transact cost paper claim produc posit return even dure market time typic problem classic method portfolio rebalanc wa commiss fee oblivi model result quit realist ever sinc ha numer way found incorpor said commiss fee etc came across thi lspe paper problem idea talk get long term portfolio get rebalanc everi day short term portfolio mod nmbr agent choos updat short term portfolio idea transit path part transit path purpos serv dimens use
ykilcher,MachineLearning,1619899473.0,[D] Paper Explained - DINO: Emerging Properties in Self-Supervised Vision Transformers (Full Video Analysis),http youtu hnmbrijnmbrfnmbrcpik http youtu hnmbrijnmbrfnmbrcpik self supervis learn final frontier represent learn get use featur without ani label facebook ai new system dino combin advanc self supervis learn comput vision new vision transform vit architectur achiev impress result without ani label attent map directli interpret segment map obtain represent use imag retriev zero shot k nearest neighbor classifi knn outlin nmbr nmbr intro overview nmbr nmbr vision transform nmbr nmbr self supervis learn imag nmbr nmbr self distil nmbr nmbr build teacher student move averag nmbr nmbr dino pseudocod nmbr nmbr whi cross entropi loss nmbr nmbr experiment result nmbr nmbr hypothesi whi thi work nmbr nmbr conclus comment paper http arxiv org ab nmbr http arxiv org ab nmbr blog http ai facebook com blog dino paw comput vision self supervis transform nmbrx effici train http ai facebook com blog dino paw comput vision self supervis transform nmbrx effici train code http github com facebookresearch dino http github com facebookresearch dino
Difficult_Parsnip876,MachineLearning,1620376445.0,[N] The Pastry A.I. That Learned to Fight Cancer,pastri learn fight cancer new yorker http www newyork com tech annal technolog pastri ai learn fight cancer seem like bread shop countri adopt thi technolog well
MaJhole007,MachineLearning,1618824980.0,[D] BERT Finetuning/Domain Adaptation,usual bert finetun downstream task task adapt onli small dataset nmbr sampl requir wonder much data need finetun specif domain like financ domain adapt expect result model outperform origin bert downstream task financi domain thank advanc
dojoteef,MachineLearning,1619234019.0,[R] Wordcraft: a Human-AI Collaborative Editor for Story Writing,
thunder_jaxx,MachineLearning,1616698147.0,[R] Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification,abstract standard markov decis process formal user specifi task write reward function howev mani scenario user unabl describ task word number readili provid exampl world would look like task solv motiv thi observ deriv control algorithm first principl aim visit state high probabl lead success outcom given onli exampl success outcom state prior work ha approach similar problem set two stage process first learn auxiliari reward function optim thi reward function use anoth reinforc learn algorithm contrast deriv method base recurs classif eschew auxiliari reward function instead directli learn valu function transit success outcom method therefor requir fewer hyperparamet tune line code debug show method satisfi new data driven bellman equat exampl take place typic reward function term experi show approach outperform prior method learn explicit reward function arxiv url http arxiv org ab nmbr http arxiv org ab nmbr thi wonder direct rl excit paper written thi direct
jikkii,MachineLearning,1618864223.0,"[N] HuggingFace releases accelerate: A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-precision",huggingfac releas new pytorch librari acceler http github com huggingfac acceler user want use multi gpu tpu without use abstract class control tweak easili nmbr line code ad raw pytorch train loop script run local well ani distribut setup releas accompani blog post detail api introduc acceler http huggingfac co blog acceler librari exampl look like practic huggingfac acceler practic http preview redd menmbrgnmbrrtmwnmbrunmbr png width nmbr format png auto webp nmbrefdfnmbrbfacnmbrenmbrenmbrcnmbrdfnmbrfnmbrafnmbrenmbr librari fulli open sourc avail pypi github learn check document http huggingfac co doc acceler
fabien-campagne,MachineLearning,1618632546.0,[P] Multi-modality Perceiver implementation for Pytorch,fork phil wang repo implement perceiv pytorch fix two problem implement nmbr figur preprint text indic cross attent block follow latent transform text indic latent transform ha nmbr block train imagenet thi repo fair implement seen kera jax make mistak use singl latent block latent transform made sever block nmbr signatur forward method thi implement support train multi modal input multi modal want train video audio imag instanc input model signatur doe support multi modal becaus modal ha differ number dimens posit encod must appli modal independ thi possibl accept singl tensor input forward posit encod done forward method repo also offer experiment contribut help text one input modal implement fix two issu thi fork http github com facnmbr perceiv multi modal pytorch http github com facnmbr perceiv multi modal pytorch packag avail pypi pip instal perceiv multi modal pytorch http github com facnmbr perceiv multi modal pytorch
bayonetworking123,MachineLearning,1619155102.0,[P] Imputing values to training/testing data after model selection,develop model multipli imput miss valu covari data experi ran expect select model train train data base test set fit run risk leakag use thi model predict miss valu combin train test data thi somewhat differ scenario typic experienc tri predict miss valu current data without overfit rather predict data see futur could use bootstrap dataset cross valid instead test set avoid ani issu sure issu first place
squidwardstrousers,MachineLearning,1616373467.0,[D] Why does computer vision get more attention than speech recognition?,see lot tutori dataset gear toward comput vision speech recognit whi
MonitorIndividual341,MachineLearning,1618801306.0,Prospects of Machine Learning and AI [Discussion],want opinion futur ml ai major role play futur job also someon start learn topic
jwestonhughes,MachineLearning,1616338331.0,[D] Explicitly modelling inter-operator variability in segmentation,medic imag segment dataset exampl segment exactli one twelv differ segment order thousand segment want understand segment differ systemat exampl doe one segment usual draw tighter segment usual cut piec segment often doe anyon know ani exist comput vision method look thi could swear saw public recent build model predict everi segment segment find wonder dream
dlisfyn,MachineLearning,1619647752.0,[D] Need advice on how to generate HD point clouds visuals for a presentation,hi show point cloud data part present want seek idea render high definit point cloud visual till wa take screenshot meshlab look good also someon awar gener rotat shape visual nmbr nmbr http www youtub com watch v nmbriulxjmqiinmbr thank
whyhateverything,MachineLearning,1617194894.0,[D] Good algorithm for clustering big data (sentences represented as embeddings)?,hi lot sentenc nmbr repres embed sentenc transform want cluster group number sentenc larger well result googl point kmean like sinc use cosin similar scalabl veri slow time interest find good algorithm help cluster thi amount embed without lose qualiti time friendli also struggl use solut sinc also ask cluster number advanc cannit determin obviou reason must point profession machin learn engin even though understand use implement disadvantag advantag rewrit optim often see thi happen research world pro data scienc ml ai help veri valuabl welcom take care wish good health everyon
spiritualParkour,MachineLearning,1619002088.0,[P] Coral Dev board vs coral Dev board mini,hope thi right sub ask went site understand differ wa http coral ai product dev board mini http coral ai product dev board mini http coral ai product dev board http coral ai product dev board great someon point thank
tdls_to,MachineLearning,1617115495.0,"[P] ML Product Challenge (free to participate, sponsored by a few startups)",hey peopl host machin learn product challeng http ai scienc _m deep learn product challeng cohort nmbr utm_sourc rdt work small team bring team meet peer team solv interest busi problem use ml project sponsor startup well opportun work project nmbr nmbr prize build web app automat detect bia risk ml model nmbr nmbr prize tbc build recommend system web app nmbr nmbr prize build api mine relationship busi use case technic concept nmbr prize whatev want build ani question thi pleas ping join info session http www eventbrit ca e ml product challeng info session xai ticket nmbr aff newslett ps thi challeng free join everyon need submit propos invit particip templat propos instruct video seri provid
RyanAI100,MachineLearning,1619981364.0,[D] CrossWeigh: Training NER with Imperfect Annotations | Research Papers Summary 016,
mennasiam,MachineLearning,1616527200.0,Video Class Agnostic Segmentation Benchmark in Autonomous Driving [R],check work video class agnost segment autonom drive identifi unknown object jointli semant panopt segment paper http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf code http github com msiam video _class _agnost _segment http github com msiam video_class_agnostic_segment demo http www youtub com watch v cnmbrhmfhdtsnmbrm http www youtub com watch v cnmbrhmfhdtsnmbrm
Green_ninjas,MachineLearning,1620350367.0,[R] Easier machine learning conferences,know neurip deadlin come ani easier peer review journal confer student think paper decent qualiti sure standard neurip without faculti mentor
remymess,MachineLearning,1619896317.0,[N] Hybrid seminar platform,hey friend hope great alain remi phd mathemat statist togeth friend build hybrid onlin physic platform sculpt academ seminar realli miss physic seminar find onlin seminar amaz myriad reason time cost ecolog network want perk stop envis futur seminar consist hybrid mixtur person onlin audienc build platform around thi vision aspir leverag modern technolog academia make life seminar organis easi possibl allow everi academ open door ani academ seminar coupl click talk public requir registr need review organis offer place onlin seminar particip socialis befor event virtual cafeteria form dynam gather town provid way physic onlin seminar particip interact give everi commun everi institut equal chanc shine worldwid onli qualiti event matter vision reson pleas look websit http agora stream http agora stream wit exponenti increas traffic sinc releas research group univers societi oxford ucl stanford world publish content regular basi platform evolut driven feedback feel free reach us ani question suggest would like meet inform chat http calendli com remi mess e coffe http calendli com remi mess e coffe special thank mani engag us last time post nmbr love meet hear experi idea see veri soon alain remi nbnmbr moment platform complet free want money barrier knowledg veri soon deploy premium account user would want enjoy luxuri featur e g abil host seminar nmbr particip simpli support us nbnmbr miss hottest seminar moment hear new featur follow us twitter link http twitter com agorastream http twitter com agorastream http www linkedin com compani agorastream http www linkedin com compani agorastream nbnmbr appet small select fun featur got onlin seminar particip socialis befor event dynam gather town integr applic form potenti futur speaker everi commun page abil clap end seminar smash space bar fulli work dev environ releas soon mobil app allow physic onlin audienc interact fulli work dev environ releas soon
apatus,MachineLearning,1617707302.0,Multi-Task learning for unbalanced classes [P],current work project assign four class input exampl target could nmbr nmbr nmbr nmbr problem class differ amount nmbr nmbr data first class nmbr nmbr nmbr nmbr problem model alway decid favor repres class thi mean class nmbr alway guess number close nmbr find solut thi problem read littl bit oversampl realli hard get distribut right sinc everi item ani number class realli sure approach thi problem doe anyon idea could solv thi
danparker276,MachineLearning,1616348052.0,"[D] Should I build my own AI bot for sms with azure ml studio, or use a 3rd party that say they understand speech better",first cost much issu part ip better look build concierg type bot take respons nurtur lead live agent product like vers offer solut alreadi send logic need api build thi ourself good ai ml dev nmbrmillion row data either way feed system guess whatev nmbrrd parti languag process top azur cognit servic lui text process aw googl nlp probabl data process make differ nmbrrd parti ha would anyway nmbrrd parti work top limit text sm logic go make much differ say year experi convers make better either way say need live train well bot know realli wonder nmbrrd parti blackbox make much differ
bloodcarter,MachineLearning,1619885051.0,[D] Black Box Interpretations,hi folk wrote overview interpret problem ani method cover think would love advic http dasha ai en us blog black box interpret ml http dasha ai en us blog black box interpret ml
ottawalanguages,MachineLearning,1618956370.0,[D] Why do polynomials have a bad reputation for overfitting?,must heard start learn statist model overfit data first exampl often given polynomi function e g see pictur http ardianumam wordpress com nmbr nmbr nmbr deriv polynomi regress regular avoid overfit warn although higher degre polynomi fit train data quit well sure overfit gener poorli test data question whi doe thi happen ani mathemat justif whi higher degre polynomi function overfit data closest explan could find onlin wa someth call rung phenomenon http en wikipedia org wiki rung nmbrs_phenomenon suggest higher order polynomi tend oscil lot doe thi explain whi polynomi function known overfit data understand whole field regular tri fix overfit problem e g penal prevent statist model hug data close use mathemat intuit whi polynomi known overfit data gener function e g respons variabl tri predict use machin learn algorithm approxim use older method like fourier seri taylor seri newer method like neural network believ theorem guarante taylor seri polynomi neural network arbitrarili approxim ani function perhap neural network promis smaller error simpler complex doe anyon know whi polynomi said bad habit overfit extent neural network larg replac interest paper http www nber org system file working_pap wnmbr wnmbr pdf
jakedageek127,MachineLearning,1616442294.0,[P] Mars 2020 Images Sorted by Content Diversity,hi spun thi quick project weekend main outreach site http mar nasa gov marsnmbr multimedia raw imag raw imag mar nmbr persever rover great onli sort chronolog order mission natur take multipl pictur target galleri page get bit repetit made new veri simpl webdev passion galleri site use demud algorithm unsupervis novelti detect priorit novel interest imag result veri content dens content divers collect imag skim easili http jakehle com mnmbr content divers doe thi work button explain methodolog past tri updat result onc morn onc even sinc imag roll throughout day also comment answer ani question becaus persever take mani imag object design calibr target sort chronolog galleri result mani page similar content find differ object content galleri flip hundr page thousand imag demud algorithm solv thi problem priorit set imag divers novel content quickli identifi one everi item rank look give demud massiv orchard return one everi fruit thi veri use quickli find interest thing larg dataset demud algorithm also capabl explain whi thought item wa interest enough bring attent implement check step nmbr extract featur imag resnet nmbr last fulli connect layer prior softmax nmbr find interest imag demud nmbr display top nmbr order priorit resourc demud github repositori http github com wkiri demud guid scientif discoveri explan use demud wagstaff et al aaai nmbr paper link http wkiri com research paper wagstaff demud nmbr pdf unusu chemcam target disocv automat curios first nineti sol gale crater mar wagstaff et al lpsc nmbr paper link http www hou usra edu meet lpscnmbr pdf nmbr pdf interpret discoveri larg imag data set wagstaff lee icml whi nmbr paper link http wkiri com research paper wagstaff interp nmbr pdf visual imag content explain novel imag discoveri lee wagstaff dmkd nmbr paper site http jakehle github io visual img disc
Alternative_Detail31,MachineLearning,1617110460.0,[D] How effective is explainable AI in getting rid of biases?,wa go combin compani recruit manpow sector came across thi compani http www hiresweet com http www hiresweet com accord land page advertis could streamlin recruit process use explain ai order get rid bias would setup possibl look like someth like assign influenc percentag paramet someth like blog post addit read materi effect bia reduct xai welcom
techsucker,MachineLearning,1617164953.0,[N] Researchers at MIT and Amazon Study Pervasive Label Errors in Test Sets that Destabilize Machine Learning Benchmarks,larg label data set crucial success supervis machin learn ml across sever domain imag classif sentiment analysi audio classif howev machin learn ml dataset perfectli label process use develop dataset often involv automat label crowdsourc inher error prone techniqu prior work ha majorli focus nois train set ml dataset mani studi concentr label error test set yet divers potenti consequ studi ha look systemat error across cite ml test set benchmark test dataset use evalu ml model valid theoret find label error occur extens could potenti undermin framework measur machin learn progress label error test set could mislead practition incorrect conclus model perform summari http www marktechpost com nmbr nmbr nmbr research mit amazon studi pervas label error test set destabil machin learn benchmark http www marktechpost com nmbr nmbr nmbr research mit amazon studi pervas label error test set destabil machin learn benchmark paper http labelerror com paper pdf demo http labelerror com
GrettaGrove,MachineLearning,1619573475.0,[R] Self-Tuning Deep Reinforcement Learning,http arxiv org ab nmbrvnmbr http arxiv org ab nmbrvnmbr
GabrieleValvano,MachineLearning,1618841919.0,[R] Interested in GAN and Attention? Take a look at Adversarial Attention Gates!,find adversari condit attent gate improv object segment last least tri new weakli annot dataset project page http vio github io multiscal adversari attent gate http co uwnmbrbxkynmbrqnmbr amp nmbr paper http arxiv org ab nmbr http co nmbrnglbxhpqnmbr amp nmbr code http github com gvalvano multiscal adversari attent gate http co sfnmbrxcgxqci amp nmbr dataset http vio github io multiscal adversari attent gate data http co nkavtnmbrugd amp nmbr http preview redd cagmlnmbrgqnmbrunmbr png width nmbr format png auto webp nmbranmbrdnmbrcnmbrfnmbradnmbrdnmbrdnmbrbdanmbranmbraanmbrbnmbr abstract larg fine grain imag segment dataset annot pixel level difficult obtain particularli medic imag annot also requir expert knowledg weakli supervis learn train model reli weaker form annot scribbl learn segment use scribbl annot adversari game unpair segment mask train multi scale gan gener realist segment mask multipl resolut use scribbl learn correct posit imag central model success novel attent gate mechan condit adversari signal act shape prior result better object local multipl scale subject adversari condit segmentor learn attent map semant suppress noisi activ outsid object reduc vanish gradient problem deeper layer segmentor evalu model sever medic acdc lvsc chao non medic ppss dataset report perform level match achiev model train fulli annot segment mask also demonstr extens varieti set semi supervis learn combin multipl scribbl sourc crowdsourc scenario multi task learn combin scribbl mask supervis releas expert made scribbl annot acdc dataset code use experi http vio github io multiscal adversari attent gate http vio github io multiscal adversari attent gate
sk81k,MachineLearning,1620485171.0,How big of a deal are scale free networks? [D],sure thi right subreddit post thi sinc network analysi ha come machin learn thought thi might right place recent read broido clauset scale free network rare paper wa wonder much differ model degre distribut scale free vs non scale free actual matter need non scale free algorithm
rarboot,MachineLearning,1617027809.0,[D] Andrew Ng's data-centric vs model-centric Machine Learning,regard http youtu nmbr azxmwhjo nmbr http youtu nmbr azxmwhjo nmbr timestamp wa choic mine actual referenc thi video mlop http www reddit com r machinelearn comment mfcanmbrp d_whats_the_simplest_most_lightweight_but post deeper comment thread felt deserv discuss abridg analysi machin learn data scienc current model centric project orient team without back product would actual rephras experi centric sens workflow someth line problem specif sota literatur review data collect model estim mvp ng advoc data centric approach allevi problem underspecif issu shift focu often fruitless model fiddl actual deliv valu qualiti data feel like actual mlop talk sens actual project pattern tool present given last point qa felt andrew ng comment http youtu nmbr azxmwhjo nmbr matur mlop tool internet tutori vertic approach advocaci actual veil critisc current mlop landscap wa underwhelm first given andrew ng mlop hot topic afterward realli bug bad data manag especi project orient scenario ani thought
hou_yz,MachineLearning,1620040910.0,[R] Visualizing Adapted Knowledge in Domain Transfer,http arxiv org ab nmbr http arxiv org ab nmbr thi paper first attempt visual model learn dure domain adapt specif found sourc target network make similar predict compens knowledg differ target imag forc translat complet unseen sourc style result also indic reli model rather imag style transfer http preview redd hgnmbrnnmbrhmtnmbrwwnmbr png width nmbr format png auto webp nmbraeaebnmbrbnmbrfnmbraanmbrebnmbrfnmbrenmbrebnmbr
techsucker,MachineLearning,1619285060.0,"[N] MLCommons, AI Industry’s Performance Benchmark, Releases MLPerf™ Inference v1.0 Results To Understand The Power Usage of Machine Learning (ML) Models",machin learn area incorpor almost everi industri ha call standard machin learn benchmark similar spec benchmark creat primarili cpu benchmark would prove pivot compar rel machin learn solut avail marketplac mlcommon http mlcommon org en open engin consortium ha work direct creat machin learn benchmark train infer platform mlperf mlcommon usual list industri academ partnership aim advanc develop access latest ai machin learn dataset benchmark creat discuss disclos time make peopl awar refin take place along way recent compani unveil platform infer vnmbr also releas nmbr result http mlcommon org en news mlperf infer vnmbr databas onli thi compani also disclos new power measur techniqu platform would look provid addit metadata result full read http www marktechpost com nmbr nmbr nmbr mlcommon ai industri perform benchmark releas mlperf infer vnmbr nmbr result understand power usag machin learn ml model http www marktechpost com nmbr nmbr nmbr mlcommon ai industri perform benchmark releas mlperf infer vnmbr nmbr result understand power usag machin learn ml model
GiuPaolo,MachineLearning,1618052104.0,[R] Last CFP for the Evolutionary RL workshop at GECCO 2021.,onli nmbr day befor deadlin nmbrst evolutionari reinforc learn workshop gecco nmbr premier confer evolutionari comput thi year held virtual lill franc juli nmbr nmbr nmbr recent year reinforc learn rl ha receiv lot attent thank perform abil address complex task time evolutionari algorithm ea proven competit standard rl algorithm certain problem simpler scalabl recent advanc ea led develop algorithm like novelti search qualiti divers capabl effici address complex explor problem find wealth differ polici result develop spark strong renew interest popul base comput approach nevertheless even ea perform well hard explor problem still suffer low sampl effici thi limit less present rl method notabl becaus sampl reus contrari struggl hard explor set complementari characterist rl algorithm ea push research explor new approach merg two order har respect strength avoid shortcom goal workshop foster collabor share perspect spread best practic within grow commun intersect rl ea topic heart workshop includ evolutionari reinforc learn evolut strategi popul base method polici search neuroevolut hard explor spars reward problem decept reward novelti divers search method diverg search sampl effici direct polici search intrins motiv curios build design behaviour character meta learn hierarch learn evolutionari automl open end learn autor invit submit new origin work new perspect recent publish work topic top submiss select oral present present alongsid keynot speaker jeff clune ex team leader uberai lab current research team leader openai import date submiss deadlin april nmbr nmbr notif april nmbr nmbr camera readi may nmbr nmbr find info workshop websit http site googl com view evorl
CopperGenie,MachineLearning,1620269184.0,[D] What is the most human-like chatbot available to the public?,necessarili talk comprehens bot discuss wise bot appear consist human like respons
ykilcher,MachineLearning,1620314786.0,[D] Paper Explained - MLP-Mixer: An all-MLP Architecture for Vision (Full Video Analysis),http youtu nmbrknmbrznmbrrqjwik http youtu nmbrknmbrznmbrrqjwik convolut neural network domin comput vision nearli nmbr year might final come end first vision transform vit shown remark perform even simpl mlp base model reach competit accuraci long suffici data use pre train thi paper present mlp mixer use mlp particular weight share arrang achiev competit high throughput model rais interest question natur learn induct bias interact scale futur research outlin nmbr nmbr intro overview nmbr nmbr mlp mixer architectur nmbr nmbr experiment result nmbr nmbr effect scale nmbr nmbr learn weight visual nmbr nmbr comment conclus paper http arxiv org ab nmbr http arxiv org ab nmbr
vadimdotme,MachineLearning,1619763832.0,[R] Eindhoven Reinforcement Learning Seminar,hi r machinelearn run biweekli onlin obviou reason seminar reinforc learn tu eindhoven http einreis tilda ws discuss advanc topic like bayesian method curios multi agent rl think rl theori seminar http site googl com view rltheoryseminar practic bent everi topic tri invit best expert guest speaker deepmind openai uber lyft uva inria yandex etc check record youtub http www youtub com channel ucnmbrwcvhgsstonmbrtbbfnmbrpjcsnmbrw feel free join us event today nmbr nmbr cet distribut machin learn registr requir click join http meet jit si eindhovenreinforcementlearningseminar
SQL_beginner,MachineLearning,1619534991.0,"[D] appeal of ""occam's razor"" in statistics and machine learning",peopl often refer occam razor statist simpler model prefer complex model provid model similar perform whi prefer simpler model doe thi varianc bia tradeoff
Advanced_Treat_7986,MachineLearning,1617701673.0,[Project] How I trained Spotify Podcast Speech Synthesis using Tacotron2,project thi project speech synthesi voic wa train spotifi podcast text speech deep learn model tacotronnmbr paper googl implement nvidia thi medium articl contain train wa done step usabl data pipelin make scalabl appli ml project code paper thi project found metdium articl
hardmaru,MachineLearning,1617069336.0,[R] ViViT: A Video Vision Transformer,
shinysamurzl,MachineLearning,1616671416.0,[D] Human Error Function,human error function thing like model creat result human give score learn repeat would go implement someth like thi
AdelSexy,MachineLearning,1617816916.0,[D] Data imbalance and noisy labels,cv classif task nmbr class dataset imbalanc toward class nmbr also know label noisi class nmbr nmbr mess nmbr case observ got better result test set suppos clean use default random sampler case weight random sampler sampl imag batch respect weight opposit class presenc dataset thi unexpect noisi label sourc also use mixup affect bad train becaus noisi label
MaxRek,MachineLearning,1620342257.0,"[Project], [Discussion] Do you know any time series annotation platform?",last mani month engag gener studi signal valu time seri built data electron document flow electron document interchang larg compani contractor indic signific drop indic compani learn produc coupl type signal thi data one problem frequent fals posit combat thi featur want add markup train classifi mark purpos time seri data need near futur annot mechan work project requir function mani class label plot label label index valu threshold larg number time seri abil maintain fill sever markup session onc edit mark valu abil work sub seri last n valu time seri tag data statist thi new area therefor crossroad implement thi function look readi made solut tri implement project exist someth cover requir
JosephLChu,MachineLearning,1619818568.0,[R] Work In Progress: A Drop In Replacement For Softmax With Uncertainty Calibrated Scores,work activ function could work drop replac softmax main origin intent appli principl maximum entropi prior would allow activ function output better calibr confid score probabl term uncertainti use formula came convert correl score nmbr nmbr probabl nmbr nmbr idea certainti measur nmbr certain nmbr fulli unknown nmbr certainli way convert thi nmbr nmbr probabl set nmbr correl scale nmbr n probabl scale thi relev neural net sens pre activ signal nmbr given node basic mean everyth cancel thi map maximum uncertainti anyway want give away mani detail given unpublish lot time effort theoriz experi mani variant formula think someth work train network thi new activ function output layer instanc mnist test notmnist result output seem much less overconfid equival network train softmax sigmoid howev accuraci mnist chang much fact task new activ function get veri similar result softmax use output layer sure use actual one place might affect perform though thi point test thi larger sota model tri use place softmax attent head transform network languag model result seem promis know scale work across task toy problem wa abl run singl gpu like know experienc research whether thi project worth tri make paper publish think may someth sure bia want time effort spent wast anoth problem find cours time work thi project accumul mani variant activ function determin one actual best task scale prove tricki wa concern sever version work situat perform better reliabl sens famili activ function simpler eleg doe one deal thi kind uncertainti
cdancette,MachineLearning,1617104591.0,[P] multimodal: a library for VQA / vision and language research,hi everyon current build librari vision languag research http github com cdancett multimod focus onli visual question answer vqa dataset vqa vnmbr vnmbr vqa cp dataset provid pretrain visual featur bottom top attent evalu metric featur dataset hassl implement start work vqa figur would nice refer implement work also implement model bottom model vqa exampl use librari plan add vqa dataset gqa clevr model task like caption edit ad clevr dataset let know think would like thi librari like pretrain model task dataset
UBIAI,MachineLearning,1618595730.0,[D] Tutorial on how to train entity relation extraction classifier with transformers & use cases,recent publish articl http walidamam medium com train joint entiti relat extract classifi use bert transform spaci nmbrebnmbrdnmbrbnmbrc joint ner relat extract transform eager hear use case pleas checkout articl http walidamam medium com train joint entiti relat extract classifi use bert transform spaci nmbrebnmbrdnmbrbnmbrc share use case ani question simpli dm get back asap
hardmaru,MachineLearning,1617852612.0,[R] SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network,
bebbo203,MachineLearning,1616746707.0,[D] Random Network Distillation (RND) applied to robotic manipulators,work applic thi network manipul seem like thi algorithm appli robot anywher search googl scholar variou search engin thank
louloucha,MachineLearning,1618846331.0,[D] Explanation System on Time-Series Data,part final year research project univers laboratori work design agnost e black box explan system base data mine techniqu recommend system also right onli focus sequenti data e sequenti purchas behavior user sequenti dynam etc evalu part sequenti pattern mine algorithm base numer target search competitor could compar afaik ani purpos ask guy know ani algorithm baselin work identifi explan pattern time seri data found bunch paper link slowli work found bunch paper link slowli work http link springer com chapter nmbr nmbrfnmbr nmbr nmbr nmbr nmbr _nmbr http link springer com chapter nmbr nmbrfnmbr nmbr nmbr nmbr nmbr_nmbr http ieeexplor ieee org document nmbr http ieeexplor ieee org document nmbr http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf http arxiv org ftp arxiv paper nmbr nmbr pdf http arxiv org ftp arxiv paper nmbr nmbr pdf ani help would appreci
Brahimce,MachineLearning,1618447831.0,[R][P] How to deal particle swarm optimization with equality constraints?,face problem want creat pso system particl consist nmbr variabl real variabl sum variabl equal one gener initi popul gener new popul initi popul particl gener popul equal one
Math_wizard369,MachineLearning,1620590419.0,[D] Annotated Research paper Walkthroughs using Jupyter Notebooks,hi went annot transform http nlp sea harvard edu nmbr nmbr nmbr attent html harvard nlp post walk attent need paper line line also clone post googl colab read along run code learn lot go thi notebook wa wonder anyon knew anymor type notebook rememb websit found back thi abl find ani help would greatli appreci thank
Gletta,MachineLearning,1620281236.0,[N] Computer Vision News (with research and code!) - May 2021,dear peek comput vision new may mani articl ai deep learn htmlnmbr version recommend http www rsipvis com computervisionnew nmbrmay pdf version http www rsipvis com comput vision news nmbr may pdf dilbert page nmbr free subscript page nmbr enjoy http preview redd nmbrinmbrlnmbrxayfxnmbr jpg width nmbr format pjpg auto webp fnmbrcnmbrbffnmbrdcfdnmbrfnmbrcfnmbrenmbranmbrcnmbrfnmbr
Yuqing7,MachineLearning,1619026057.0,[R] Pieter Abbeel Team Proposes Task-Agnostic RL Method to Auto-Tune Simulations to the Real World,research team uc berkeley carnegi mellon univers propos task agnost reinforc learn method reduc task specif engin requir domain random visual dynam paramet quick read pieter abbeel team propos task agnost rl method auto tune simul real world http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper auto tune sim real transfer arxiv http arxiv org pdf nmbr pdf
ennanco,MachineLearning,1617956035.0,"[N] Call for Papers: Special Issue ""Applied Machine Learning in NIR Technology""",host special issu appli scienc jcr nmbr submiss diffus highli appreci http www mdpi com journal applsci special _issu nir _technolog http www mdpi com journal applsci special_issu nir_technolog special issu inform sinc nmbr near infrar reflect nir scanner common companion laboratori thi technolog allow analysi electromagnet spectrum band close visibl spectrum result larg amount inform analyz order make predict factor qualiti sampl thi advantag abl quickli analyz materi without destroy sampl made recent time thi kind equip ha move laboratori portabl devic case small credit card therefor numer applic develop umbrella thi technolog analysi sewer water determin food safeti diagnosi construct materi support medic vet diagnosi number applic near endless howev thi blossom applic usual goe along requir model identifi use inform captur spectra relationship factor usual non linear complex necessari use machin learn techniqu obtain although ha usual perform analyt process current applic machin learn ha step forward term precis adjust result nir machin learn multidisciplinari technolog mani field scienc industri could benefit use especi focu featur select band spectra contain inform requir solv problem applic machin learn need process adjust optim perform aim thi special issu present latest advanc made thi field combin techniqu well show remain challeng futur thi area research whi thi special issu solicit submiss limit follow area select featur band nir spectra special interest applic use nano scale nir scanner due limit oper rang studi differ preprocess techniqu comparison automat featur extract process pca lda evolutionari comput develop combin cloud comput fog comput edg comput process nir spectra differ industri process applic compar latest approach machin learn techniqu deep learn ensembl model work particular interest cover explain artifici intellig frame decis make use nir data machin learn keyword signal process near infrar machin learn artifici neural network support vector machin k nearest neighbour naïv bay random forest ensembl model evolutionari comput explain artifici intellig ensembl method deep learn featur extract princip compon analysi pca food secur materi analysi drug identif medic diagnosi vet diagnosi internet thing iot
ml_abler,MachineLearning,1620639883.0,[D] ML and Quantum Computing,hi reddit entir sure thi right place ask thi go recent got opportun work quantum comput team entir purpos team find applic quantum comput firm sound like amaz opportun lot reserv would love appreci insight come cs engin background master ai ml full time posit moment data scientist work cluster model quantum comput opportun avail due format new team ha lot vacanc moment although prospect quantum ai ml sound hella interest although veri nich quantum comput seem like extrem departur formal educ heavi emphasi physic thi make anxiou viabl thi opportun career job prospect domain someon background would help creat nich data scienc admit shamelessli like career pay big buck time keep interest enough would love opinion
MrAcurite,MachineLearning,1617202567.0,[D] Does anyone care about the quality of the prose in academic papers?,read lot great literari work late go back read academ paper veri notic downgrad qualiti languag employ guess make sens want commun technic inform lot room reason employ metaphor color languag still seem like ha way make work better make legitim enjoy read instead linguist equival shove stale bread throat obvious often lot beauti found appreci clever new idea present appreci typic spite rather due actual qualiti write thi someth anybodi els care
olegvol,MachineLearning,1617562096.0,[P] QSMM for building algorithmic neural nets,work qsmm framework build algorithm neural net principl produc qualiti adapt behavior requir excess comput resourc train oper suffer problem explain gener behavior core method oper random select next state algorithm neural net accord probabl possibl state calcul basi cycl occur neural net current framework ha exampl demonstr possibl use case number shall increas futur one exampl util framework adapt pars token sequenc hope peopl make use implement idea transform approach behind concept artifici intellig http qsmm org http qsmm org
vajra_,MachineLearning,1616699791.0,[D] Model Size calculation for sparse neural networks,gener calcul model size spars neural network much weight nmbr non zero weight nmbr byte
deama15,MachineLearning,1616545017.0,[Project] Remastering old anime using machine learning,remast use ai algorithm old anim hajim ippo box anim finish type remast wa enhanc resolut clean artifact nois frame interpol made subreddit got info well faq sampl check http www reddit com r interpolateandenh screenshot comparison first one old second one new http doc googl com present nmbrbtnmbrpzizbdnmbrhovyxbnnmbrijlficmlqlnmbrbhqq_lnmbronnmbrpnmbrha edit usp share anim next seri old hunter x hunter point want tri live action content specif action stuff like martial art movi straight action interpol algorithm quit good enough well actual kinda least high end one good luck tri interpol anyth anyth rtx nmbr
machinemask,MachineLearning,1617699100.0,[D] Best system load monitoring tool?,hello look tool monitor display inform cpu gpu usag time envis someth like htop togeth interact dashboard filter data e g time user like instal compani gpu server get better understand use mostli use server train comput vision model interest featur think would interest cpu usag block vs non block gpu util memori usag ram usag disk read write support multipl machin display save data dashboard filter display data e g user process time found project similar thing permon http github com bminixhof permon gpu monitor http github com msalvari gpu_monitor nvtop http github com syllo nvtop weight bias http wandb ai site articl monitor improv gpu usag model train think good idea set system softwar miss ani experi suggest welcom
jhanytime,MachineLearning,1618156460.0,[D] Video - Introduction to graph neural networks (made easy!),phd student studi machin learn applic transport system autonom system think rl robot sever gcn made easi video youtub feel like video often miss forest tree especi sinc gcn nmbr algorithm wa develop nmbr video often cover broader histor context gnn develop cover differ variat model allow model new type system thi second video seri make graph graph neural network applic area potenti make big impact pleas let know think video learn anyth new http youtu ckanmbrfanmbrttinmbr
rish-16,MachineLearning,1620547959.0,[P] PyTorch Involution layer wrapper,hello everyon current process learn implement paper scratch implement newli introduc involut layer paper involut invert inher convolut visual recognit li et al present cvpr nmbr wrapper http github com rish nmbr involut _pytorch http github com rish nmbr involution_pytorch forgiv ani implement error ani pr issu welcom note releas tensorflow wrapper soon time permit like would greatli appreci motiv continu build easi use ml wrapper thank
sim_inf,MachineLearning,1617905410.0,[D] Student Travel Grant for ACL/NAACL/EMNLP,ani student travel grant award acl confer mean onli acl naacl emnlp one appli confer commun typic thi receiv applic variou form contact chair follow websit twitter account post thi hear nlp person know thi perhap ha first hand experi thank
ka-wei,MachineLearning,1618776983.0,[P] Cinemate - Movie Recommender System made with Tensorflow Rust,last coupl month work movi recommend system use tensorflow rust model use collabor filter neural network recommend movi base movi input unlik model find internet thi model also take rate popular trade coeffici input prefer popular movi thi coeffici set nmbr valu high averag rate coeffici set nmbr optim number probabl two default valu nmbr big goal thi websit fast recommend get recommend matter second due perform highli optim predict rust visit websit http cinem http cinem
NoAnalyst4,MachineLearning,1620067314.0,[D] Does the ICML acceptance rate curtailment impact 2021 submissions?,new icml accept rule appli thi year paper next year submiss thi first ever submiss icml worri chanc chang announc http www reddit com r machinelearn comment nnmbrqw _icml _confer _we _plan _to _reduc _the _number _of http www reddit com r machinelearn comment nnmbrqw d_icml_conference_we_plan_to_reduce_the_number_of bias seem realli unfair chang polici middl decis process
Yuqing7,MachineLearning,1619109567.0,[R] Are Multilingual Language Models Fragile? IBM Adversarial Attack Strategies Cut MBERT QA Performance by 85%,ibm research team propos four multilingu adversari attack strategi attack seven languag zero shot set larg multilingu pretrain languag model e g mbert reduc averag perform nmbr percent quick read multilingu languag model fragil ibm adversari attack strategi cut mbert qa perform nmbr http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper multilingu bert model robust case studi adversari attack multilingu question answer arxiv http arxiv org pdf nmbr pdf
hardmaru,MachineLearning,1617623139.0,[R] Towards General Purpose Vision Systems,
Superb-Drawer5214,MachineLearning,1617340770.0,[D] How important is the prestige of undergraduate school in getting into top ML PhD programs?,look cv resum phd student cmu berkeley stanford univers washington mit got bachelor degre berkeley stanford mit cmu harvard princeton iit student graduat famou ivi leagu school univers washington peke tsinghua could view cv resum becaus upload cv consid attend umd onli three student graduat umd phd school
byronbae,MachineLearning,1616680571.0,[P] Sound pollution mapping from GeoJSON,undertak data scienc project within job subject veri unfamiliar alreadi big problem extrem data scarciti asid wonder anyon could help start point put simpli possibl geojson file contain sound measur specif coordin throughout citi would like build model tri predict noisiest point eventu goal would includ type relat data real time traffic etc etc found thi seem closest problem http omdena com heatmap machin learn go ani concept actual appli technolog etc idea type data outcom veri similar goal play around data bit alreadi notebook leaflet arcqgi bit issu wrap head around entir workflow thi project could work sinc want go map raw data point map key point identifi analysi point ani insight would greatli appreci
Ekkolo,MachineLearning,1620631488.0,[D] NER for Resume Parsing,hello need resum pars french resum use prodigi prodi gy http prodi gy annot dataset make model question better annot full resum annot line line posit text full document inform mayb spaci care thank
Acrobatic-Egg-,MachineLearning,1619433901.0,[D] The Journey Of Problem-Solving Using Analytics,nmbr year work analyt domain fortun nmbr client across geographi one thing realiz peopl may solv busi problem use analyt journey lost somewher risk sound clich enjoy journey destin attempt creat problem solv journey experienc learn fail framework problem solv use analyt nmbr step process go nmbr break busi problem analyt problem let start thi anoth clich hour solv problem spend nmbr minut think problem nmbr minut think solut thi lot analyst consult fail soon busi problem fall ear straightaway get solut ing without even bare attempt understand problem hand tackl thi team follow call cs fs framework extra mark come better name cs fs framework stand current state futur state framework cs fs framework first step identifi current state client current problem follow next step identifi desir futur state want solut provid insight behavior driven insight final outcom driven behavior final import step cs fs framework identifi gap prevent client move current state desir futur state thi becom analyt problem thu input next step nmbr find analyt solut analyt problem busi problem convert analyt problem let look data shall big start form hypothes around problem without bias data stress thi point enough process form hypothes independ data avail correct method thi form possibl hypothes look avail data elimin hypothes data hypothes form start look data usual analyt solut follow understand data eda test hypothes ml problem requir yada yada yada thi part analyst good exampl problem revolv around custom churn thi step go ahead classif model let remind output thi step analyt solut classif model custom churn problem time peopl solv problem would technic gift understand confus matrix output classif model output auc roc curv want talk languag understand thi take final road journey problem solv final step nmbr convert analyt solut busi solut analyt solut comput busi solut human less deal human want understand mani week worth effort ha produc may creat effici accur ml model world ha ever seen final stakehold unabl interpret mean whole exercis wa useless thi use stori board experi actual tell stori would start current state problem step taken reach desir futur state thi visual skill dashboard creation insight gener creation deck come pictur creat dashboard report keep mind tell stori lay beauti color chart power bi tableau dashboard chart number report action orient part larger stori onli someon understand stori like go purchas anoth book onli make journey beauti meaning fellow passeng stakehold travel said reach destin hope total open critic suggest improv make thi journey look forward input commun
SimlaBurcu,MachineLearning,1619032775.0,[P] ColTraIn Hybrid Block Floating-Point (HBFP) Training Emulator,excit announc releas coltrain hbfp train emul http github com parsa epfl hbfpemul hbfp http paper nip cc paper nmbr file nmbranmbraeddfcnmbrcnmbrdnmbrenmbrbnmbrcccnmbrabnmbrbcnmbr paper pdf offer accuraci nmbr bit float point numer silicon densiti nmbr bit fix point wide varieti model resnet wideresnet densenet alexnet lstm bert forese hbfp lay foundat accur train algorithm run acceler order magnitud denser arithmet convent novel float point base platform coltrain emul repositori includ sever exampl dnn model includ cnn lstm bert hbfp refer fpnmbr baselin check coltrain emul http github com parsa epfl hbfpemul http github com parsa epfl hbfpemul visit websit http parsa epfl ch coltrain http parsa epfl ch coltrain inform
hardmaru,MachineLearning,1618498632.0,[R] Meta-Learning Bidirectional Update Rules. A new type of generalized neural net where neurons and synapses maintain multiple states. They show that backprop in classical neural nets can be seen as a special case of a two-state net where one state is used for activations and another for gradients.,
Svito-zar,MachineLearning,1617024327.0,[D] Is anyone using Automatic Bug Fixing Tools for Python?,mani us make bug often one fix bug wa sever month screw mani experi wonder ml find bug quick search thi topic result mani paper even tool http analyticsindiamag com nmbr python bug fix tool essenti develop http analyticsindiamag com nmbr python bug fix tool essenti develop wonder anyon use tool actual work fix copi past error
mrgemy95,MachineLearning,1620443257.0,[D] JAX vs Pytorch gpu performance.,doe anyon know benchmark compar jax api pytorch speed gpu awar thi comparison http dzone com articl acceler automat differenti jax http dzone com articl acceler automat differenti jax compar desn lay wa look someth benchmark complic architectur
projekt_treadstone,MachineLearning,1619738644.0,[D] Prototypical network in the medical domain,ani exist project work implement prototyp network base meta learn medic imag medic imag heavier load comput imagenet would like know handl larg pixel medic data resiz larg medic imag per standard prototyp architectur larg drop accuraci larg resiz valu fit gpu train
hardmaru,MachineLearning,1616865606.0,[R] Out of Distribution Generalization in Machine Learning (Martin Arjovsky's PhD Thesis),
PebbleWrestler9000,MachineLearning,1617831182.0,[D] Issues with using LSTM networks to classify raw EMG signal data,unsur thi correct subreddit post thi current issu ml undergradu research project wa hope potenti get guidanc current task take emg signal data time domain electr signal data gather user classifi finger person engag ani moment thi multi class label classif problem nmbr total label possibl thi exampl emg signal look like plot python http preview redd ggednmbrotfgtrnmbr png width nmbr format png auto webp fafnmbrdnmbrfnmbrdnmbrdcbddnmbrddnmbrfnmbrenmbrcenmbrb tell graph normal amplitud rang rang nmbr nmbr ensur time seri equal length append nmbr front end seri match length longest sequenc data set result time seri approxim length nmbr nmbr total seri distribut label approxim equal result tensor shape nmbr nmbr nmbr nmbr row nmbr length sequenc nmbr valu store time step current use follow kera model http preview redd frrnmbrcnbygtrnmbr png width nmbr format png auto webp anmbrenmbrfnmbrefeadenmbrbcnmbrabbnmbranmbrdcnmbrc use lstm network length sequenc number neuron follow dropout follow dens layer anoth dropout layer final classif dens layer use adam optim algorithm learn rate nmbre nmbr nmbre nmbr also tweak lnmbr kernel regular valu default rang nmbre nmbr nmbre nmbr issu unusu terribl perform exampl thi http preview redd nmbresbnmbrphtrnmbr png width nmbr format png auto webp cfnmbrfnmbrcanmbrenmbrcnmbranmbrecaanmbranmbrfcnmbra valid accuraci consist zero valid loss continu increas fit train accuraci plateau around valu nmbr run thi model nmbr epoch befor valid accuraci nonetheless remain nmbr loss increas train accuraci loss continu plateau even nmbr epoch initi suspect overfit could issu deal dropout layer believ thi case would anyon chat help figur go model simpli learn thank
hardmaru,MachineLearning,1617937116.0,[P] Neuralink's Monkey Mindpong,blog post http neuralink com blog decod presum train machin learn take neural activ data monkey calibr enabl monkey play pong directli thought
Jack_Hackerman,MachineLearning,1618764770.0,[D] How to normalize and merge two different datasets with similar deltas for Keras?,hi get enough attent stackoverflow ask two dataset train model first dataset valu within rang nmbr nmbr anoth one ha nmbr nmbr rang essenti dataset veri similar sens percentag data chang nmbr data chang rownmbr valuenmbr nmbr rownmbr valuenmbr nmbr first dataset anoth dataset someth like rownmbr valuenmbr nmbr rownmbr valuenmbr nmbr raw valu rang target differ similar percentag chang nmbr normal make similar combin break network nmbr thi possibl nmbr normal target normal data feed predict function tri predict stock someth data financi data need job make regress bond paramet updat realiz normal first second dataset separ use set mean set std lol target one target nmbr anoth target nmbr
Yuqing7,MachineLearning,1617896959.0,[N] ContinualAI Releases Avalanche: An End-to-End Library for Continual Learning,research develop team continualai includ larg group research ku leuven byted ai lab univers california new york univers institut propos avalanch end end librari continu learn base pytorch quick read continualai releas avalanch end end librari continu learn http syncedreview com nmbr nmbr nmbr continualai releas avalanch end end librari continu learn paper avalanch end end librari continu learn arxiv http arxiv org pdf nmbr pdf
thedeepreader,MachineLearning,1620224443.0,[D] (Paper Overview) MLP-Mixer: An all-MLP Architecture for Vision,video http youtu nmbrfhmzebnzro http youtu nmbrfhmzebnzro paper http arxiv org ab nmbr http arxiv org ab nmbr code soon avail author http github com googl research vision _transform http github com googl research vision_transform abstract convolut neural network cnn go model comput vision recent attent base network vision transform also becom popular thi paper show convolut attent suffici good perform neither necessari present mlp mixer architectur base exclus multi layer perceptron mlp mlp mixer contain two type layer one mlp appli independ imag patch e mix per locat featur one mlp appli across patch e mix spatial inform train larg dataset modern regular scheme mlp mixer attain competit score imag classif benchmark pre train infer cost compar state art model hope result spark research beyond realm well establish cnn transform
niujin,MachineLearning,1620380538.0,[D] Predictive model for the shape of an entire histogram,work project market research survey respond repli survey nmbr point scale nmbr dislik nmbr indiffer nmbr like respons shown histogram would like develop ml model predict shape histogram survey befor survey run wild databas past survey countri industri etc straightforward predict singl valu mean histogram train machin learn model predict entir histogram far approach consid train nmbr separ independ model train model mean one stdev assum normal bad assumpt know histogram mani differ shape design custom machin learn architectur nmbr output train model predict mean histogram onli best perform come ensembl model random forest use auto ml azur ml ha anybodi tri someth similar new market research data scienc sever year
michaelaalcorn,MachineLearning,1619522727.0,[R] baller2vec++: A Look-Ahead Multi-Entity Transformer For Modeling Coordinated Agents,
hardmaru,MachineLearning,1619579460.0,[R] Why AI is Harder Than We Think,
donkey_strom16001,MachineLearning,1619388491.0,[D] The Rants of an experienced engineer who glimpsed into AI Academia (Briefly),background recent graduat master degre wa fortun unfortun glimps whole academ side ml took thesi track degre becaus immigr harder get good research lab without authorship coupl good paper delud work full stack swe startup nmbr year befor come us master degre focus ml ai everyth year project manag build fulli polish w product devop even dabbl ml batchelor degre univers whose name even worth mention univers master degre top nmbr ai space know much ml curios drove univers come uni focus learn ml ai one nmbr nmbr year found advisor thesi topic thi fun start amaz advisor entir peer review system way assess ml scienc tick thi rant begin rant nmbr acadmia follow gate institut narr let say ph world top ai institut work best prof way higher likelihood get good postdoc huge research lab vs someon poor countri ph well known advisor publish well known paper come develop nation see thi mani time countri academ get fund colleg us one reason thi colleg huge endow mani academ wealthi research sponsor brand name prestig carri massiv weight help get fund us academ circl thi prestig money percol student research work student top colleg get huge advantag circl top research keep set institut noth top research top institut due natur citat way money flow base viciou cycl creat best institut keep get better rest get much notic rant nmbr peer review without code review ml ai shadi comput scientist wa appal heard need code review research paper comput scientist someon actual shit ton actual ml past year find absolut garbag code review part thi system say everi scientist read paper review code least one person ani paper code submiss least ml ai space thi basic get whi peopl call themselv comput scientist want read fuck code make grad student collect scienc need thi core problem lie fact peer review free better solut thi end creat git chang mani live academ research need someth similar rant nmbr idea novel see someon els paper volum scientif research grow exponenti inform creat faster digest expect peopl know everyth amount overlap ai ml field requir way better search engin googl scholar side effect larg volum research everi paper someth novel make harder filter fuck wa novel mani experi code someth came realiz someon els ha done someth symbol similar work seem like small variant fuck head novel fuck novel stitch transform ani problem fanci embed tidi research paper novel make transform bigger novel new rl algorithm test nmbr seed fanci fuck prior esoter reason success novel use parameter model get nmbr accuraci nmbr sampl test set novel appli self supervis learn new dataset novel keep list question novelti probabl write novel ask fuck novel rant nmbr citat base optim promot self growth collect growth whatev peopl may say collabor academia intrins promot right incent structur harbor collabor let explain write paper posit name matter ph student first author paper great nth author great appar thi veri touchi thing academ lot ego clash around number order name distinctli rememb onc attend seminar lab approach student research project idea first thing came phd student mouth wa posit authorship engin work team past thi wa never someth thought especi becaus work industri alway group person academia revers academia applaud celebr individu achiev thi understand someth like thi make phd stick lane way citat research focu calibr hire abil complet ph thesi metric peopl incentiv think themselv instead think collabor make someth better conclus ph idealist sens pursuit hard idea poetic way situat like publish perish word paper get pass scienc without even see code run extrem discourag go rout rant diss scientist becaus commun need better way address problem p never expect mani peopl express opinion thi rant u take thi serious mani peopl state outsid tini experi give full pictur realiz post come someth tri dichotom academia industri tri want highlight problem saw one person blame issu opinion byproduct econom creat thi system thank gold stranger
RSchaeffer,MachineLearning,1619728964.0,[R] Help understanding NeurIPS 2013 Dirichlet Process Mixture Model paper,hi struggl understand certain part nmbr neurip paper onlin learn nonparametr mixtur model via sequenti variat approxim http proceed neurip cc paper nmbr hash nmbrcnmbrfnmbrenmbrenmbrcbnmbrddnmbrfnmbrdnmbrecf abstract html http proceed neurip cc paper nmbr hash nmbrcnmbrfnmbrenmbrenmbrcbnmbrddnmbrfnmbrdnmbrecf abstract html anyon thi subreddit familiar bayesian nonparametr ha five minut would realli appreci answer question post math stackexchang http math stackexchang com question nmbr onlin stochast variat infer dirichlet process mixtur model http math stackexchang com question nmbr onlin stochast variat infer dirichlet process mixtur model base paper review review nmbr question think author intend add answer supplement supplement start thi document provid proof theorem present paper never actual got around ad proof answer email sole author yet hear back
answersareallyouneed,MachineLearning,1617655429.0,[D] Questions on mathematical maturity for PhD/R&D ML,current job mostli involv implement paper adapt model fit need compani math realli issu understand implement paper far believ lack mathemat matur competit posit go back phd work research past specif interest domain adapt synthet data gener question nmbr common peopl come thi work gener understand concept slowli build matur lot mentor math physic major later came machin learn perhap idea take bit skew nmbr nmbr year befor want appli start phd plan work full time year effect way use thi time studi first colleagu recommend go real analysi also seem like good portion thi subreddit gone bishop element statist learn veri least tldr interest field would like mediocr mid level profession ani advic
ML_WAYR_bot,MachineLearning,1618171211.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 110,thi place share machin learn research paper journal articl read thi week relat research mean elabor give us insight otherwis could interest paper read pleas tri provid insight understand pleas post thing present wiki prefer link arxiv page pdf easili access pdf summari page way around ani pertin link previou week nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr week nmbr http www reddit com nmbrqyjiq week nmbr http www reddit com nmbrxwnmbr week nmbr http www reddit com nmbrildf week nmbr http www reddit com nmbrsnmbrknmbru week nmbr http www reddit com nmbrtnnmbrax week nmbr http reddit com nmbrsnmbrelnmbr week nmbr http reddit com bfsxnmbrz week nmbr http reddit com dnmbrvnonmbr week nmbr http reddit com fnmbrfnmbriq week nmbr http reddit com hltnmbro week nmbr http reddit com knmbrywb week nmbr http www reddit com nmbrsnmbrxqm week nmbr http www reddit com nmbracbnmbrt week nmbr http www reddit com nmbrjwde week nmbr http www reddit com nmbrabnmbri week nmbr http www reddit com nmbrwvjfk week nmbr http reddit com anmbropot week nmbr http reddit com blnmbrov week nmbr http reddit com denmbrhnmbr week nmbr http reddit com fnmbrfsnmbrz week nmbr http reddit com hunmbrzqnmbr week nmbr http reddit com khnmbrnx week nmbr http www reddit com nmbrtnmbrmqm week nmbr http www reddit com nmbrcwfbnmbr week nmbr http www reddit com nmbr week nmbr http www reddit com nmbrd week nmbr http www reddit com nmbrexnmbr week nmbr http reddit com anmbryaro week nmbr http reddit com bqlbnmbrv week nmbr http reddit com dkoxnmbr week nmbr http reddit com ffinmbrb week nmbr http reddit com iaznmbr week nmbr http reddit com kpsxtc week nmbr http www reddit com nmbrubnmbrkw week nmbr http www reddit com nmbrfcnmbrmh week nmbr http www reddit com nmbrhhhb week nmbr http www reddit com nmbrjsnmbr week nmbr http reddit com nmbraluh week nmbr http reddit com adnmbrssz week nmbr http reddit com bwnmbrjmnmbr week nmbr http reddit com drnmbrnca week nmbr http reddit com fnnmbrrnmbr week nmbr http reddit com ijjcep week nmbr http reddit com kzevku week nmbr http www reddit com nmbrxomfnmbr week nmbr http www reddit com nmbrhynmbrur week nmbr http www reddit com nmbrteiz week nmbr http www reddit com nmbrbnmbravnmbr week nmbr http reddit com nmbrtnnez week nmbr http reddit com ainmbrgi week nmbr http reddit com cnmbritkk week nmbr http reddit com dxshkg week nmbr http reddit com fvknmbrjnmbr week nmbr http reddit com isnmbrhjnmbr week nmbr http reddit com lnmbrlvg week nmbr http www reddit com nmbrzcyvk week nmbr http www reddit com nmbrkdnmbrvd week nmbr http www reddit com nmbrdnmbrnbnmbr week nmbr http www reddit com nmbrenmbrfxnmbr week nmbr http reddit com nmbrxnmbroj week nmbr http reddit com apnmbrctk week nmbr http reddit com cdnmbrgko week nmbr http reddit com enmbrnmyk week nmbr http reddit com gnmbreavg week nmbr http reddit com jnmbrxrnmbr week nmbr http reddit com ljxnmbrn week nmbr http www reddit com nmbrtnmbrmo week nmbr http www reddit com nmbrobnmbrdx week nmbr http www reddit com nmbrgngwc week nmbr http www reddit com nmbrhccnmbrc week nmbr http reddit com nmbrjmh week nmbr http reddit com aucinmbrc week nmbr http reddit com cjnmbrkyc week nmbr http reddit com ebnmbrlxk week nmbr http reddit com gcxnmbruf week nmbr http reddit com jnmbrcbf week nmbr http reddit com luqbxl week nmbr http www reddit com nmbrheol week nmbr http www reddit com nmbrrnmbryd week nmbr http www reddit com nmbrjgdva week nmbr http www reddit com nmbrkgcqr week nmbr http reddit com nmbrupnmbrg week nmbr http reddit com azjoht week nmbr http reddit com cpnmbrjex week nmbr http reddit com ehbfst week nmbr http reddit com glmnmbrsv week nmbr http reddit com jhzznmbrv week nmbr http reddit com mnmbrunmbrz week nmbr http www reddit com nmbrkvsu week nmbr http www reddit com nmbrttnmbrcz week nmbr http www reddit com nmbrmnmbrlnmbrv week nmbr http www reddit com nmbrnayri week nmbr http reddit com nmbrnnmbrrt week nmbr http reddit com bnmbrrnmbri week nmbr http reddit com cvdenmbra week nmbr http reddit com entcxi week nmbr http reddit com gunmbrtnmbrd week nmbr http reddit com jqjgonmbr week nmbr http reddit com mfnmbrmnmbru week nmbr http www reddit com nmbrsnmbroa week nmbr http www reddit com nmbrwhnmbrwb week nmbr http www reddit com nmbrpnmbrhanmbr week nmbr http www reddit com nmbrqelnmbrp week nmbr http reddit com nmbrcfnmbr week nmbr http reddit com bakewnmbr week nmbr http reddit com dnmbrgnmbrknmbr week nmbr http reddit com euctyw week nmbr http reddit com hddfnmbrj week nmbr http reddit com jznmbrevt upvot paper two week ago u rtrxnmbr machin learn team share reus featur http www tecton ai blog machin learn team share reus featur u justdi effici explor chemic space dock deep learn http chemrxiv org articl preprint efficient_exploration_of_chemical_space_with_docking_and_deep learn nmbr u kirillthemunchk styleclip text driven manipul stylegan imageri sota stylegan imag edit http casual_gan nmbr besid rule fun
Farconion,MachineLearning,1620063831.0,[D] Effectively summarizing projects & research on a resume?,doe anyon ani tip effect summar ml project research resum find sinc project research usual pretti nich tri convey uphil battl becaus peopl read resum go ani idea talk enough space cover appropri background knowledg get part thi job appli sinc bank get ml posit colleg good chunk work ml relat like make background approach unfamiliar field subfield relat work
mistermysterioyster,MachineLearning,1619897023.0,"[D] Paper Reading Group #018 - MP3: A Unified Model to Map, Perceive, Predict and Plan. (Link to full slides in comments!)",
hallavar,MachineLearning,1617297476.0,[Discussion] Any metric for evaluating non-image synthetic data ?,hello evalu gener data obtain ae gan etc alway tricki question imag paper read use incept score evolut fid howev metric base well gener imag classifi pretrain network thi summari need detail gener data imag relat like text sequenc graph evalu gener model good metric evalu plausibl synthet data ie realism gener given train distribut also divers ensur train distribut well understood model know evalu first criterium realism idea evalu second anyon ha ever work someth like glad talk hi work thank advanc
vijish_madhavan,MachineLearning,1618161739.0,"[P] SkinDeep, Remove Tattoos using Deep Learning. GitHub Link in comments.",
SolitaryPenman,MachineLearning,1619269805.0,[D] Looking for datasets for video time-series segmentation/labeling,look video dataset time seri segment note look dataset semant segment video label time step one k categori exampl video would person perform differ action one action singl video unfortun dataset could find onli singl action perform video eg weizmann human action dataset thu singl label per video would great someon could point video dataset time step differ label
hardmaru,MachineLearning,1617245208.0,[R] Going deeper with Image Transformers,
rarboot,MachineLearning,1618235282.0,[N] Microsoft buys AI speech tech company Nuance for $19.7 billion,verg http www theverg com nmbr nmbr nmbr nmbr microsoft buy nuanc ai speech tech may wrong thi afaik ha sinc microsoft made huge acquisit compani arguabl heavili convolut intern ecosystem feel like ms data acquisit process product portfolio imo cannib ani thought
mikegartrell,MachineLearning,1617282048.0,[N] Upcoming talks for Laplace’s Demon: A Seminar Series about Bayesian Machine Learning at Scale,two upcom talk april ongo onlin seminar seri bayesian machin learn scale intend audienc includ machin learn practition statistician academia industri upcom talk zoom registr link thi come wednesday nmbr april mont carlo integr repuls point process rémi bardenet http criteo zoom us webinar regist wn_i_vilnmbryttpafshnmbrdo_hdyg mont carlo integr workhors bayesian infer mean squar error mont carlo estim decreas slowli typic nmbr n n number integrand evalu thi becom bottleneck bayesian applic evalu integrand take ten second like life scienc evalu likelihood often requir solv larg system differenti equat present two approach faster mont carlo rate use interact particl system first show result random matrix theori lead stochast version gaussian quadratur ani dimens mean squar error decreas nmbr n nmbr nmbr thi quadratur base determinant point process argu kernel machin point process second show take thi error rate assum integrand smooth particular give tight error bound integrand belong ani arbitrari reproduc kernel hilbert space use mixtur determinant point process tailor space thi mixtur reminisc volum sampl random experiment design use linear regress joint work ayoub belhadji pierr chainai adrien hardi nmbr april automat backward filter forward guid markov process graphic model frank van der meulen http criteo zoom us webinar regist wn_nmbrszkmhlfqhklnmbrkpalfmnmbrgq discuss structur way effici infer probabilist graphic model build block consist markovian stochast process start point gener model forward descript probabilist dynam inform provid observ backpropag model transform gener forward model condit model guid data approxim actual condit model known likelihood ratio two backward filter forward chang measur suitabl incorpor probabilist program context becaus formul set transform rule guid gener model combin differ approach effici sampl latent state paramet condit observ applic set includ markov chain discret state space interact particl system state space model branch diffus gamma process past talk found http ailab criteo com laplac demon bayesian machin learn scale
strngelet,MachineLearning,1616679026.0,[P] boost T5 models speed up to 5x & reduce the model size by 3x using fastT5.,want share thi new librari work open sourc quick link github repositori http github com kinmbran fasttnmbr pypi project http pypi org project fasttnmbr fasttnmbr logo http preview redd knonmbrbmnmbrsenmbrpnmbr png width nmbr format png auto webp nmbrfenmbrbnmbrfanmbrfnmbrbanmbranmbrbnmbr titl suggest increas infer speed ani pretrain tnmbr model also decreas model size singl line code librari instal pip instal fasttnmbr thi code snippet repositori readm give concis overview fasttnmbr usag http preview redd glranmbrhevenmbrpnmbr png width nmbr format png auto webp eanmbrbnmbrcbnmbrfcnmbrenmbrabnmbrcnmbranmbrfnmbrenmbrdacnmbrbnmbr fasttnmbr librari export tnmbr model onnx past_key_valu quantiz run onnxruntim export onnx model support gener method huggingfac transform inferenc inform project refer repositori http github com kinmbran fasttnmbr reduc tnmbr model size nmbrx increas infer speed nmbrx
MudlarkJack,MachineLearning,1617972696.0,[Discussion] is it possible to cross train a pre-existing model with a higher resolution data set than was used to train the original network?,use case indic titl thi gan question exampl previous train network say nmbrxnmbr imag want cross train complet new data set contain nmbrxnmbr imag benefit normal time save cross train work smaller resolut origin data set somehow preclud thi
sideonion,MachineLearning,1619650542.0,[P] Are there non-profits who work on ML for social cause (fairness etc.) where I can work for a project and contribute?,geographi bar okay volunt ani geograph locat want volunt work part time non profit work research ml thing like fair account good tech background abl find place contribut possibl research social caus pleas recommend allen ai becaus onli look full time peopl move usa
regalalgorithm,MachineLearning,1620420803.0,[D] Invitation to help address AI misrepresentation and misconceptions,tldr run site debunk misconcept ai news pl posit respons hope bring could use help fine post befor nmbr year run thi thing call skynet today http www skynettoday com name meant iron news mission put ai new perspect word debunk inaccur portray ai research media also put articl put thing perspect mani peopl research feel annoy hype misconcept ai wonder ani might want join effort basic coupl grad student thi spare time put ani new articl due busi much help write lot work interest pleas consid take look contribut survey http www skynettoday com contribut messag thank exampl articl put includ deepmind alphafold nmbr impress advanc hyperbol coverag http www skynettoday com brief alphafoldnmbr state deepfak nmbr http www skynettoday com overview state deepfak nmbr gpt nmbr ai breakthrough come job http www skynettoday com brief gptnmbr ibm microsoft amazon halt sale facial recognit polic call regul http www skynettoday com brief face recog polic boston dynam robot impress far termin http www skynettoday com brief boston dynam tldr run site debunk mispercept ai pl join http www skynettoday com contribut wan na help
git-commit-bt7274,MachineLearning,1617721034.0,[P] Corgi: Rust neural network/dynamic automatic differentiation library I have been working on,hello work rust automat differenti crate call corgi level crate thought would worth share github http github com patricksongzi corgi http github com patricksongzi corgi crate http crate io crate corgi http crate io crate corgi edit fix exampl edit nmbr ad support custom layer model exampl http github com patricksongzi corgi blob main exampl custom rs http github com patricksongzi corgi blob main exampl custom rs exampl dynam comput graph let arr nmbr let b arr nmbr let mut c arr nmbr _ nmbr nmbr c c b c nmbr nmbr c c c backward none assert_eq c arr nmbr assert_eq c gradient arr nmbr assert_eq b gradient arr nmbr assert_eq gradient arr nmbr fulli connect neural network http github com patricksongzi corgi blob main src dens rs http github com patricksongzi corgi blob main src dens rs custom oper thi need work readm project still need lot work includ improv ergonom arr macro implement fulli connect layer effici improv use bla
WavyShapes,MachineLearning,1616431656.0,[P] Backprop: a library to easily finetune and use state-of-the-art models,hi everybodi like share backprop http github com backprop ai backprop python librari co author last month goal make finetun use model easi possibl even without extens ml experi current got support text imag base task wrapper around model like googl tnmbr openai clip facebook bart among onc got train data import model task finetun singl line code also got featur make deploy product easi full transpar deploy paid platform develop mean necessari use librari decid check doc http backprop readthedoc io en latest got exampl notebook repo exampl http github com backprop ai backprop tree main exampl folder happi progress made still earli day realli appreci ani thought feedback get make backprop featur easier use futur
ad1tyawagh,MachineLearning,1619612972.0,[Discussion] Why doesn't Google's Live Captioning feature generate punctuation marks?,post sinc someth relat nlp understand dure data clean peopl usual remov punctuat whi might ani punctuat consid punctuat hold semant mean understand whi remov gener practic someon shed light thi
ilikepancakez,MachineLearning,1616419675.0,[R] Combinatorial optimization and reasoning with graph neural networks,
Red-Portal,MachineLearning,1616337731.0,[D] How many of you explicitly ask the reviewer to raise their score?,hi given icml review period would like ask experi explicitli ask review rais score saw peopl thi got posit result curiou thi effect neg gener thing might somewhat rude score total review polit phrase ask thing also mani write someth privat feedback metareview box even outright unjust conduct review
bendee983,MachineLearning,1618507723.0,[D] Microsoft's ML acquisition strategy,thi week microsoft announc nmbr billion acquisit nuanc compani use deep learn transcrib clinic appoint stuff interest deal evolut microsoft relat nuanc http bdtechtalk com nmbr nmbr nmbr microsoft nuanc acquisit go cloud provid partner owner thi success strategi onli microsoft mayb amazon posit implement step nmbr microsoft start invest ml compani give azur credit lure ml platform thi allow microsoft help compani develop also learn possibl replic product worth multipl small invest oppos one larg acquisit smart move becaus mani compani tri new thing ml dl success small invest microsoft cast wider net make sure good posit make next move step nmbr microsoft enter partnership compani success product thi allow microsoft integr ml product enterpris solut e g nuanc dragon dl wa integr microsoft cloud healthcar solut sinc compani build ml tool top azur stack integr much easier compani step nmbr acquir realli success compani nuanc ha great reach ai healthcar sector thi allow microsoft gain exclus access compani data talent technolog client acquisit nuanc microsoft total address market healthcar ha reach nmbrb integr ml technolog enterpris tool nuanc one exampl microsoft ml acquisit strategi compani similar path openai http bdtechtalk com nmbr nmbr nmbr microsoft openai gpt nmbr licens carri similar strategi self drive car industri http bdtechtalk com nmbr nmbr nmbr microsoft self drive car strategi
pinter69,MachineLearning,1616346925.0,[R] Compositional Zero-Shot Learning - Dr. Massimiliano Mancini (CVPR 2021) - Link to free zoom lecture by the author in comments,
Jemsdaan,MachineLearning,1617052129.0,[D] RTX 3080 cuda 10.0,hi guy uni project need replic project use tensorflow gpu nmbr cuda nmbr onli gpu dispos rtx nmbr understand rtx nmbr support cuda nmbr onli cuda nmbr order use cuda nmbr tensorflow need updat nmbr nmbr thi break alot code quesiton dead water seem like onli solut either train model cpu ha terribl perfom upgrad code compat tensorflow nmbr nmbr thi scope project sure thi correct place ask someon ha suggest get thi run gpu pleas let know
TheInsaneApp,MachineLearning,1619861540.0,[D] Types of Machine Learning Papers,
SPAMinaCanCan,MachineLearning,1618438536.0,[D] What are you thoughts on how the amount of classes can affect model accuracy,thi hope veri basic question struggl find good paper explain amount differ class affect differ model exampl say build semant segment classifi jpg imag contain soft drink object find contain within imag better construct train data use gener soft drink class better construct train data use differ colour soft drink seper class e red orang green etc wonder class name convent affect overal accuraci classifi everi thought thi also want comment extend thing car cloth etc
AuspiciousApple,MachineLearning,1620578926.0,[D] What's the SOTA/best practice for finetuning pre-trained CNNs on smaller datasets (~10k images)? Any principled approaches? Any papers comparing different schedules?,basic two way approach transfer learn treat pretrain weight particularli effici weight initialis method train model like normal focuss hyperparam especi data augment b use special protocol finetun b francoi chollet recommend freez lower convolut layer onli train ad head option second step also finetun part lower convolut layer veri low learn rate http kera io guid transfer _learn introduct http kera io guid transfer_learn introduct http blog kera io build power imag classif model use veri littl data html http blog kera io build power imag classif model use veri littl data html also rememb read idea like appli lnmbr penalti magnitud weight deviat pre train weight special schedul worth ani research also happi ani suggest finetun
hyunwoongko,MachineLearning,1617857667.0,[P] Try to talk with GPT3 (GPT-Neo),http preview redd nmbrnphdngxrvrnmbr png width nmbr format png auto webp nmbrenmbrdfnmbrddcnmbrcnmbranmbrdnmbrdnmbracnmbrbaeb gpt neo model wa releas eleutherai gpt neo http github com eleutherai gpt neo repositori sid black stella biderman leo gao phil wang connor leahi gptnmbr like causal languag model train pile http pile eleuth ai dataset today deploy prompt base convers option use gpt neo openchat tri convers gpt neo use onli line code check http github com hyunwoongko openchat http github com hyunwoongko openchat want detail inform thank
fromnighttilldawn,MachineLearning,1617599998.0,[D] How do you improve your model after obtaining the test error?,veri basic question train neural network ml model see address literatur consid follow scenario chop data train valid test someth like nmbr nmbr nmbr ratio train perform valid feel pretti confid model perform well run model test set obtain high error someth fall expect yike cours thi stage would anyth improv model tri anyth effect use test set train set question whether exist best correct practic improv model obtain test error know literatur lot hyperparamet tune obtain test set wish follow footstep techniqu allow prevent thi scenario happen thank advanc
hobogalaxy,MachineLearning,1620042624.0,"[P] General and feature-rich PyTorch/Hydra template for rapid and scalable ML research/experimentation, with a list of best practices",hi look way make research effici scalabl iter coupl differ framework structur converg follow templat http github com ashlev lightn hydra templat http github com ashlev lightn hydra templat get feel might use take look superpow http github com ashlev lightn hydra templat superpow section readm base pytorch lightn hydra plugin develop research team also meant start point anyon would like learn thi technolog stack find thi combin simpl use veri power time believ veri conveni small team research reproduc paper gener project need maintain mani curat configur experi find use allow us painlessli scale small experi hiperparamet search multi gpu slurm comput cluster framework like optuna ax hyperparamet optim requir minim setup onli need declar config hyperparamet rang hydra take care whole iter job logic possibl use experi track framework like neptun wandb mlflow csv file easi configur manag command line superpow need argpars thank hydra advanc train debug featur pytorch lightn e g gradient accumual deepspe integr etc encapsul dataset lightn datamodul give us veri conveni way understand reus dataset across project feel like ml peopl use tool becaus simpli realiz advantag especi hydra seem like veri use addit ani deep learn project focus structur readm way hope give quick overview hope help spread word framework broad commun incorpor best practic http github com ashlev lightn hydra templat best practic trick gather last coupl month play around typic workflow follow nmbr write lightningdatamodul found intuit way encapsul ani dataset lightningdatamodul simpl abstract provid method data download split transform expos dataload would love see research tri thi concept even project use pytorch lightn read lightningdatamodul make immediet see dataset prepar seem like data scienc project throw around data logic across differ part pipelin make hard understand go see exampl datamodul http github com ashlev lightn hydra templat blob main src datamodul mnist_datamodul py nmbr write lightningmodul thi basic encapsul pytorch model code nmbr add new experi config specifi path lightningdatamodul lightningmodul train launch experi tracker attach like csv logger tensorboard python run py http run py experi simple_mnist logger tensorboard btw structur partli base data scienc cooki cutter project templat hear recommend check found great sourc use concept project organ http drivendata github io cookiecutt data scienc http drivendata github io cookiecutt data scienc love hear thought let know see limit room improv
seuadr,MachineLearning,1617201468.0,Machine Learning and HVAC [D],hi work hvac control deploy fault detect platform product current rule base find mani thing great determin long term perform drift start data scienc boot camp learn machin learn eye toward appli thi build hvac system like use dataset predict thing rang gener expect energi use near futur period time like next hour perform drift sensor equip like heat coil perform meet expect current condit think thi abl seem area discuss openli internet googl fu weak sure start instanc collect larg dataset thi equip year pretti confid gain use insight autom process feed execut model kind interv consid execut short time interv like say nmbr min write kind comput power would need thi current vm nmbr core nmbrgb would expect poni get job done know big open question look guidanc start see might awar exist commun could help thank advanc time assist jare
ai_painter,MachineLearning,1619460955.0,[D] Lambda GPU Cloud launches world's first RTX A6000 instances,lambda launch rtx anmbr gpu cloud instanc http lambdalab com blog introduc nvidia rtx anmbr gpu instanc lambda cloud nvidia rtx anmbr instanc nmbrx faster nvidia rtx nmbr instanc rtx anmbr nmbr gib vram per gpu disclaim engin lambda
Yuqing7,MachineLearning,1619192608.0,"[R] Facebook AI, McGill U & Mila Promote 'Translationese' to Boost NMT System Faithfulness",research team mcgill univers mila quebec ai institut facebook ai propos novel metric perturb function detect quantifi compar trade robust faith nmt system corpu level particular exampl quick read facebook ai mcgill u mila promot translationes boost nmt system faith http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper sometim want translationes arxiv http arxiv org pdf nmbr pdf
jeromeharper,MachineLearning,1618965208.0,[D] Cov-19 binary classification dataset.,hi guy look binari classif covid nmbr dataset predict label posit neg thi label could whether one infect far found dataset kaggl consist medic imag xray scan chest look imag data featur found one kaggl featur age gender hypertens etc label posit neg pleas help thank advanc cheer
JasonTodd550,MachineLearning,1619729450.0,[R] I’m building the interface for our product. I’d love some feedback and insights.,hey folk frontend develop design work build interfac product platform ml model host sandbox ran api current mvp run interfac user use look commun ml focus tri get industri target user particip research nmbr nmbr valid better look sub dedic link test http app useberri com mknmbrywphn also super happi get one one feedback interest send thought directli even interview partner dm
tstanislawek,MachineLearning,1617815710.0,[P] Curated List of Document Understanding (DU) Papers & Resources.,hi everybodi last year spent lot time work autom busi process big compani see rise interest du topic especi key inform extract field therefor creat list http github com tstanislawek awesom document understand http github com tstanislawek awesom document understand resourc make easier track paper relev thi topic
Yogi_DMT,MachineLearning,1618847448.0,[P] StoRM: Mutation-based hyperparameter tuner,struggl find decent hyperparamet tuner nn tune exampl design tuner attempt remedi lot issu associ thi type paramet space nest categor condit etc runnabl script exampl folder demonstr storm perform compar random tune pleas feel free post ani feedback let know use http github com ben arnao storm http github com ben arnao storm
gabegabe6,MachineLearning,1618579597.0,[D] What tools can you recommend for GPU resource alocation?,problem given team gpu server nmbr gpu best way signal use gpu long e g think simpl tool say nmbr day later need nmbr gpu alloc time cours everyon team could see thi wa plan creat simpl cli tool first want get feedback use thi purpos realli want use excel sheet thi
CauchySchwartzDaddy,MachineLearning,1619584963.0,[D] Are there light(-er) installs of pytorch for model deployment that aren't nearly a whole gb of space and just support loading a model and forward pass?,deploy model docker flask find kind tediou instal nmbr mb pytorch need load model forward pass consid contain deploy method pretti light term space allot realli afford huge instal
Equivalent-Choice-75,MachineLearning,1619383564.0,[D] Academia to Industry. How to deal with Research FOMO?,master student top nmbr us univers spend almost work hour ml research go industri day fomo miss cut edg research due natur job product face rather pure research sure mani phd student would face deal thi still read latest paper post join ani suggest
CaptainMcThorn,MachineLearning,1617880707.0,[R] Hollow-tree Super: a directional and scalable approach for feature importance in boosted tree models,
numpee,MachineLearning,1617769571.0,[Discussion] Suggestions for well-written papers,recent encount post regard qualiti prose http www reddit com r machinelearn comment mhnmbrvrt d_does_anyone_care_about_the_quality_of_the_pros utm_sourc share utm_medium webnmbrx context nmbr academ paper seem like peopl gener differ view consid well written exampl prefer clear concis languag without ani color languag vice versa question suggest paper consid veri well written would nice gave quick explan prefer write style well
Headz0r,MachineLearning,1617960110.0,[D] Objective of openAIs Microscope,regard microscop applic openai http microscop openai com model contrastive_nmbrx image_block_nmbr_nmbr_add_nmbr_nmbr nmbr question one see two set imag gener featur visual one channel optim object result repeat pattern neuron optim object show spatial prefer optim techniqu refer doe gener imag differ respect class
binaryfor,MachineLearning,1617468530.0,[P] Deep Daze - A simple command line tool for text to image generation using OpenAI's CLIP and Siren,
1846bdksy,MachineLearning,1617602310.0,[D] Top 4 CS PhD AI+Healthcare Research Topic Worries,veri grate accept top nmbr cs phd program mit stanford cmu berkeley thi year research interest list ai healthcar phd applic faculti school assum pursu area howev recent start hesit make ai healthcar specif comput vision healthcar phd research topic main reason worri post phd career outcom topic like thi realli like opportun work googl brain fair potenti even quant trade compani futur hand think ai healthcar promis field may potenti also startup relat curiou think ai healthcar phd thesi topic thi assum still make fundament advanc ai e g publish cvpr iccv eccv slightli lower frequenc pure ai student due addit paper healthcar relat journal think thi hinder career possibl overthink thi thank veri much way altern would tri pursu pure ai research without applic healthcar
ProbablyCloseEnough,MachineLearning,1616960156.0,[R] Slurm Interface Prototype Evaluation Survey (2 minutes),use slurm schedul comput job share comput resourc pleas evalu propos interfac complet survey follow link http peersurvey cc gatech edu nmbrbnmbrenmbrcnmbrbenmbranmbrdnmbrafbfanmbr http peersurvey cc gatech edu nmbrbnmbrenmbrcnmbrbenmbranmbrdnmbrafbfanmbr thi continu investig previou post http www reddit com r machinelearn comment lfnnmbrdnmbr r_slurm_interface_survey_nmbr_minut utm_sourc share utm_medium webnmbrx context nmbr thi coursework human comput interact cours thank particip
mrwafflezzz,MachineLearning,1619708471.0,[R] Question regarding sampling negative examples for supervised learning,ask thi question thi sub becaus rather difficult question bear let say match predictor thi predictor use nmbr set featur one set content c one set user u match user content u c repres vector spatial meaning term distanc user u distanc content c let say onli posit match u c label nmbr ani combin posit match ambigu mean would make sens approach thi semi supervis manner assum ani combin u c sampl inher neg exampl label nmbr could fact nmbr nmbr could give sampl combin u c label look similar vector u vector user consum content c idea user similar user consum content c likelihood consum content c becom higher ani feedback welcom
fiddlerlabs,MachineLearning,1616372511.0,[R] A Practical Guide To Adversarial Robustness,adversari machin learn still veri young field less nmbr year old explos paper work around attack model find vulner turn verit arm race defend attack brief summari field http blog fiddler ai nmbr nmbr practic guid adversari robust http blog fiddler ai nmbr nmbr practic guid adversari robust
windy-city-wizard,MachineLearning,1618899153.0,[R] Two questions: computing class weights and large confusion matrix?,nmbr algorithm comput class weight address imbalanc dataset multi class classif nmbr class nmbr way make larg confus matrix nmbrxnmbr easier see initi obviou class get lot fals posit bad guess onc address class lot harder extract meaning insight veri larg confus matrix http preview redd nmbrgaobryqsnmbrunmbr png width nmbr format png auto webp enmbrfadnmbrdnmbraenmbrfnmbrbnmbrfnmbrccnmbrdnmbrenmbr
minimaxir,MachineLearning,1619798940.0,[P] Easily Transform Portraits of People into AI Aberrations Using StyleCLIP,lot experi use styleclip http github com orpatashnik styleclip creat fun imag written blog post reproduc input _fun_ experi involv mark zuckerberg releas streamlin colab notebook get run http minimaxir com nmbr nmbr styleclip colab notebook http colab research googl com drive nmbrejnmbratvtnenmbrnnmbrinmbrullvrstanmbrjnmbrhdnubi usp share tl dr styleclip essenti photoshop driven text good bad chao entail
zecharias99,MachineLearning,1617968121.0,[P] Chai: Open source framework for deploying chat AIs,chai open sourc platform allow develop deploy chat ai check websit http chai ml doc http chai ml doc includ support huggingfac bot use chai _pi http pypi org project chaipi speak ai line code http preview redd ucabdgnmbrqvnmbrsnmbr png width nmbr format png auto webp bnmbrenmbrdenmbrbaanmbrenmbrfnmbrfanmbrenmbrfnmbrd http preview redd gkxnmbrtesnmbrwnmbrsnmbr png width nmbr format png auto webp nmbrcaaanmbrdnmbrbnmbrcnmbrdnmbrbnmbracnmbr check tri deploy facebook blenderbot http huggingfac co facebook blenderbot_smal nmbrm chai chat mobil app
RandomForests92,MachineLearning,1616527472.0,[P] I just published first version of my metrics library for ML projects,hope well releas new open sourc librari onemetr use evalu comput vision project hope becom default benchmark librari ml relat project would veri grate could take look potenti suggest metric outsid comput vision might use http github com skalskip onemetr http github com skalskip onemetr one metric librari rule
bionet271,MachineLearning,1618480565.0,"[P] I implemented DeepMind's ""Perceiver"" in PyTorch",deepmind publish thi paper http arxiv org pdf nmbr pdf find ani sourc code implement complet faith posit encod exampl paper also everi detail pretti close thought share case anyon want use help make better let know miss anyth still veri much learn http github com louislva deepmind perceiv http github com louislva deepmind perceiv
mroc_lak,MachineLearning,1616578491.0,[D] What tools do you use for testing your computer vision systems?,hi interest best practic develop comput vision applic product tool would recommend test system requir base test unit test integr test etc write infra hous
faridrashidi,MachineLearning,1619327497.0,[P] Collection of Kaggle Past Solutions (to learn ideas and techniques),collect nmbr nmbr almost avail solut idea code share top perform past kaggl competit thi list get updat soon new competit finish allow search kaggl past competit solut idea nmbr http github com faridrashidi kaggl solut http github com faridrashidi kaggl solut nmbr http farid one kaggl solut http farid one kaggl solut
bert4QA,MachineLearning,1616667982.0,[R] Hurdles to Progress in Long-form Question Answering,
CKL-IT,MachineLearning,1620223941.0,"[N] 200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support - John Snow Labs NLU 3.0.0",nmbr state art medic model ner entiti resolut relat extract assert spark nmbr python nmbr support nlu nmbr releas much incred excit announc releas nlu nmbr nmbr make john snow lab medic healthcar model avail nmbr line code nlu model accur domain highli scalabl spark cluster addit spark nmbr x spark nmbr x support togeth pythonnmbr thi enabl amaz spark nlpnmbr nmbr http nlp johnsnowlab com doc en release_not nmbr spark nlp healthcar nmbr nmbr http nlp johnsnowlab com doc en licensed_release_not nmbr releas new featur nmbr new model healthcar domain nmbr new class model assert sentenc chunk resolv relat extractor medic ner model de identif model spark nmbr x nmbr x support python nmbr support new output level relat nmbr line instal nlu run wget http raw githubusercont com johnsnowlab nlu master script colab_setup sh bash variou new emr databrick version support http github com johnsnowlab spark nlp releas tag nmbr nmbr gpu mode nmbr speedup enabl gpu mode author mode licens featur new document nlu healthcar exampl http nlu johnsnowlab com doc en examples_hc usag exampl nluload instrunct author environ use licens featur http nlu johnsnowlab com doc en examples_hc author access licens featur instal healthcar depend new notebook medic name entiti extract ner notebook http github com johnsnowlab nlu blob master exampl colab healthcar medical_named_entity_recognit overview_medical_entity_recogn ipynb relat extract notebook http github com johnsnowlab nlu blob master exampl colab healthcar relation_extract overview_rel ipynb entiti resolut overview notebook http github com johnsnowlab nlu blob master exampl colab healthcar entity_resolut entity_resolvers_overview ipynb assert overview notebook http github com johnsnowlab nlu blob master exampl colab healthcar assert assertion_overview ipynb de identif overview notebook http github com johnsnowlab nlu blob master exampl colab healthcar de_identif deidentification_model_overview ipynb graph nlu tutori http github com johnsnowlab nlu blob nmbrrcnmbr exampl webinars_conferences_etc graph_ai_summit healthcare_graph_nlu_covid_tigergraph ipynb assertiondlmodel languag nlu load refer spark nlp model refer english assert http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_en html assertion_dl http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_en html english assert biobert http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_biobert_en html assertion_dl_biobert http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_biobert_en html english assert healthcar http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_healthcare_en html assertion_dl_healthcar http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_healthcare_en html english assert larg http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_large_en html assertion_dl_larg http nlp johnsnowlab com nmbr nmbr nmbr assertion_dl_large_en html new word embed languag nlu load refer spark nlp model refer english emb glove clinic http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_en html embeddings_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_en html english emb glove biovec http nlp johnsnowlab com nmbr nmbr nmbr embeddings_biovec_en html embeddings_biovec http nlp johnsnowlab com nmbr nmbr nmbr embeddings_biovec_en html english emb glove healthcar http nlp johnsnowlab com nmbr nmbr nmbr embeddings_healthcare_en html embeddings_healthcar http nlp johnsnowlab com nmbr nmbr nmbr embeddings_healthcare_en html english emb glove healthcare_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_healthcare_nmbrd_en html embeddings_healthcare_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_healthcare_nmbrd_en html english en emb glove icdoem embeddings_icdoem english en emb glove icdoem_nmbrng embeddings_icdoem_nmbrng sentenc entiti resolv languag nlu load refer spark nlp model refer english embed_sent biobert mli sbiobert_base_cased_mli english resolv sbiobertresolve_cpt english resolv cpt sbiobertresolve_cpt english resolv cpt augment sbiobertresolve_cpt_aug english resolv cpt procedures_aug sbiobertresolve_cpt_procedures_aug english resolv hcc augment sbiobertresolve_hcc_aug english resolv icdnmbrcm http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_en html sbiobertresolve_icdnmbrcm http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_en html english resolv icdnmbrcm augment http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_augmented_en html sbiobertresolve_icdnmbrcm_aug http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_augmented_en html english resolv icdnmbrcm augmented_bil http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_augmented_billable_hcc_en html sbiobertresolve_icdnmbrcm_augmented_billable_hcc http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrcm_augmented_billable_hcc_en html english resolv icdnmbrpc http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrpcs_en html sbiobertresolve_icdnmbrpc http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdnmbrpcs_en html english resolv icdo http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdo_en html sbiobertresolve_icdo http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_icdo_en html english resolv rxcui http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_rxcui_en html sbiobertresolve_rxcui http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_rxcui_en html english resolv rxnorm http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_rxnorm_en html sbiobertresolve_rxnorm http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_rxnorm_en html english resolv snome http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_en html sbiobertresolve_snomed_auxconcept http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_en html english resolv snome aux_concept http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_en html sbiobertresolve_snomed_auxconcept http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_en html english resolv snome aux_concepts_int http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_int_en html sbiobertresolve_snomed_auxconcepts_int http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_auxconcepts_int_en html english resolv snome find http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_findings_en html sbiobertresolve_snomed_find http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_findings_en html english resolv snome findings_int http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_findings_int_en html sbiobertresolve_snomed_findings_int http nlp johnsnowlab com nmbr nmbr nmbr sbiobertresolve_snomed_findings_int_en html relationextractionmodel languag nlu load refer spark nlp model refer english relat posolog posology_r english relat http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_direction_biobert_en html redl_bodypart_direction_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_direction_biobert_en html english relat bodypart direct http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_direction_biobert_en html redl_bodypart_direction_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_direction_biobert_en html english relat bodypart problem http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_problem_biobert_en html redl_bodypart_problem_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_problem_biobert_en html english relat bodypart procedur http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_procedure_test_biobert_en html redl_bodypart_procedure_test_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_bodypart_procedure_test_biobert_en html english relat chemprot http nlp johnsnowlab com nmbr nmbr nmbr redl_chemprot_biobert_en html redl_chemprot_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_chemprot_biobert_en html english relat clinic http nlp johnsnowlab com nmbr nmbr nmbr redl_clinical_biobert_en html redl_clinical_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_clinical_biobert_en html english relat date http nlp johnsnowlab com nmbr nmbr nmbr redl_date_clinical_biobert_en html redl_date_clinical_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_date_clinical_biobert_en html english relat drug_drug_interact http nlp johnsnowlab com nmbr nmbr nmbr redl_drug_drug_interaction_biobert_en html redl_drug_drug_interaction_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_drug_drug_interaction_biobert_en html english relat humen_phenotype_gen http nlp johnsnowlab com nmbr nmbr nmbr redl_human_phenotype_gene_biobert_en html redl_human_phenotype_gene_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_human_phenotype_gene_biobert_en html english relat temporal_ev http nlp johnsnowlab com nmbr nmbr nmbr redl_temporal_events_biobert_en html redl_temporal_events_biobert http nlp johnsnowlab com nmbr nmbr nmbr redl_temporal_events_biobert_en html nerdlmodel languag nlu load refer spark nlp model refer english med_ner ade clinic http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_clinical_en html ner_ade_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_clinical_en html english med_ner ade clinical_bert http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_clinicalbert_en html ner_ade_clinicalbert http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_clinicalbert_en html english med_ner ade ade_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_healthcare_en html ner_ade_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_ade_healthcare_en html english med_ner anatomi http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_en html ner_anatomi http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_en html english med_ner anatomi biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_biobert_en html ner_anatomy_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_biobert_en html english med_ner anatomi coars http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_en html ner_anatomy_coars http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_en html english med_ner anatomi coarse_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_biobert_en html ner_anatomy_coarse_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_anatomy_coarse_biobert_en html english med_ner aspect_senti http nlp johnsnowlab com nmbr nmbr nmbr ner_aspect_based_sentiment_en html ner_aspect_based_senti http nlp johnsnowlab com nmbr nmbr nmbr ner_aspect_based_sentiment_en html english med_ner bacterial_speci http nlp johnsnowlab com nmbr nmbr nmbr ner_bacterial_species_en html ner_bacterial_speci http nlp johnsnowlab com nmbr nmbr nmbr ner_bacterial_species_en html english med_ner bionlp http nlp johnsnowlab com nmbr nmbr nmbr ner_bionlp_en html ner_bionlp http nlp johnsnowlab com nmbr nmbr nmbr ner_bionlp_en html english med_ner bionlp biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_bionlp_biobert_en html ner_bionlp_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_bionlp_biobert_en html english med_ner cancer http nlp johnsnowlab com nmbr nmbr nmbr ner_cancer_genetics_en html ner_cancer_genet http nlp johnsnowlab com nmbr nmbr nmbr ner_cancer_genetics_en html english med_ner cellular http nlp johnsnowlab com nmbr nmbr nmbr ner_cellular_en html ner_cellular http nlp johnsnowlab com nmbr nmbr nmbr ner_cellular_en html english med_ner cellular biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_cellular_biobert_en html ner_cellular_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_cellular_biobert_en html english med_ner chemic http nlp johnsnowlab com nmbr nmbr nmbr ner_chemicals_en html ner_chem http nlp johnsnowlab com nmbr nmbr nmbr ner_chemicals_en html english med_ner chemprot http nlp johnsnowlab com nmbr nmbr nmbr ner_chemprot_biobert_en html ner_chemprot_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_chemprot_biobert_en html english med_ner chemprot clinic http nlp johnsnowlab com nmbr nmbr nmbr ner_chemprot_clinical_en html ner_chemprot_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_chemprot_clinical_en html english med_ner clinic http nlp johnsnowlab com nmbr nmbr nmbr ner_clinical_en html ner_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_clinical_en html english med_ner clinic biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_clinical_biobert_en html ner_clinical_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_clinical_biobert_en html english med_ner clinic noncontrib ner_clinical_noncontrib english med_ner diseas http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_en html ner_diseas http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_en html english med_ner diseas biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_biobert_en html ner_diseases_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_biobert_en html english med_ner diseas larg http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_large_en html ner_diseases_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_diseases_large_en html english med_ner drug http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_en html ner_drug http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_en html english med_ner drugsgreedi http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_greedy_en html ner_drugs_greedi http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_greedy_en html english med_ner drug larg http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_large_en html ner_drugs_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_drugs_large_en html english med_ner events_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_events_biobert_en html ner_events_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_events_biobert_en html english med_ner events_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_events_clinical_en html ner_events_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_events_clinical_en html english med_ner events_healthcr http nlp johnsnowlab com nmbr nmbr nmbr ner_events_healthcare_en html ner_events_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_events_healthcare_en html english med_ner financial_contract http nlp johnsnowlab com nmbr nmbr nmbr ner_financial_contract_en html ner_financial_contract http nlp johnsnowlab com nmbr nmbr nmbr ner_financial_contract_en html english med_ner healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_healthcare_d html ner_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_healthcare_d html english med_ner human_phenotyp gene_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_gene_biobert_en html ner_human_phenotype_gene_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_gene_biobert_en html english med_ner human_phenotyp gene_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_gene_clinical_en html ner_human_phenotype_gene_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_gene_clinical_en html english med_ner human_phenotyp go_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_go_biobert_en html ner_human_phenotype_go_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_go_biobert_en html english med_ner human_phenotyp go_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_go_clinical_en html ner_human_phenotype_go_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_human_phenotype_go_clinical_en html english med_ner jsl http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_en html ner_jsl http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_en html english med_ner jsl biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_biobert_en html ner_jsl_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_biobert_en html english med_ner jsl enrich http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_enriched_en html ner_jsl_enrich http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_enriched_en html english med_ner jsl enriched_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_enriched_biobert_en html ner_jsl_enriched_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_jsl_enriched_biobert_en html english med_ner measur http nlp johnsnowlab com nmbr nmbr nmbr ner_measurements_clinical_en html ner_measurements_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_measurements_clinical_en html english med_ner medment http nlp johnsnowlab com nmbr nmbr nmbr ner_medmentions_coarse_en html ner_medmentions_coars http nlp johnsnowlab com nmbr nmbr nmbr ner_medmentions_coarse_en html english med_ner posolog http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_en html ner_posolog http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_en html english med_ner posolog biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_biobert_en html ner_posology_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_biobert_en html english med_ner posolog greedi http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_greedy_en html ner_posology_greedi http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_greedy_en html english med_ner posolog healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_healthcare_en html ner_posology_healthcar http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_healthcare_en html english med_ner posolog larg http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_large_en html ner_posology_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_large_en html english med_ner posolog large_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_large_biobert_en html ner_posology_large_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_large_biobert_en html english med_ner posolog small http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_small_en html ner_posology_smal http nlp johnsnowlab com nmbr nmbr nmbr ner_posology_small_en html english med_ner radiolog http nlp johnsnowlab com nmbr nmbr nmbr ner_radiology_en html ner_radiolog http nlp johnsnowlab com nmbr nmbr nmbr ner_radiology_en html english med_ner radiolog wip_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_radiology_wip_clinical_en html ner_radiology_wip_clin http nlp johnsnowlab com nmbr nmbr nmbr ner_radiology_wip_clinical_en html english med_ner risk_factor http nlp johnsnowlab com nmbr nmbr nmbr ner_risk_factors_en html ner_risk_factor http nlp johnsnowlab com nmbr nmbr nmbr ner_risk_factors_en html english med_ner risk_factor biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_risk_factors_biobert_en html ner_risk_factors_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_risk_factors_biobert_en html english med_ner inmbrbnmbr nerdl_inmbrbnmbr english med_ner tumour http nlp johnsnowlab com nmbr nmbr nmbr nerdl_tumour_demo_en html nerdl_tumour_demo http nlp johnsnowlab com nmbr nmbr nmbr nerdl_tumour_demo_en html english med_ner jsl wip clinic jsl_ner_wip_clin english med_ner jsl wip clinic greedi http nlp johnsnowlab com nmbr nmbr nmbr jsl_ner_wip_clinical_en html jsl_ner_wip_greedy_clin http nlp johnsnowlab com nmbr nmbr nmbr jsl_ner_wip_clinical_en html english med_ner jsl wip clinic modifi http nlp johnsnowlab com nmbr nmbr nmbr jsl_ner_wip_modifier_clinical_en html jsl_ner_wip_modifier_clin http nlp johnsnowlab com nmbr nmbr nmbr jsl_ner_wip_modifier_clinical_en html english med_ner jsl wip clinic rd http nlp johnsnowlab com nmbr nmbr nmbr jsl_rd_ner_wip_greedy_clinical_en html jsl_rd_ner_wip_greedy_clin http nlp johnsnowlab com nmbr nmbr nmbr jsl_rd_ner_wip_greedy_clinical_en html de identif model languag nlu load refer spark nlp model refer english med_ner deid augment http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_augmented_en html ner_deid_aug http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_augmented_en html english med_ner deid biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_biobert_en html ner_deid_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_biobert_en html english med_ner deid enrich http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_enriched_en html ner_deid_enrich http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_enriched_en html english med_ner deid enriched_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_enriched_biobert_en html ner_deid_enriched_biobert http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_enriched_biobert_en html english med_ner deid larg http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_large_en html ner_deid_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_large_en html english med_ner deid sd http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_sd_en html ner_deid_sd http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_sd_en html english med_ner deid sd_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_sd_large_en html ner_deid_sd_larg http nlp johnsnowlab com nmbr nmbr nmbr ner_deid_sd_large_en html english med_ner deid nerdl_deid english med_ner deid synthet ner_deid_synthet english med_ner deid dl http nlp johnsnowlab com nmbr nmbr nmbr ner_deidentify_dl_en html ner_deidentify_dl http nlp johnsnowlab com nmbr nmbr nmbr ner_deidentify_dl_en html english en de_identifi http nlp johnsnowlab com nmbr nmbr nmbr deidentify_rb_en html deidentify_rb http nlp johnsnowlab com nmbr nmbr nmbr deidentify_rb_en html english de_identifi rule deid_rul english de_identifi clinic http nlp johnsnowlab com nmbr nmbr nmbr deidentify_enriched_clinical_en html deidentify_enriched_clin http nlp johnsnowlab com nmbr nmbr nmbr deidentify_enriched_clinical_en html english de_identifi larg http nlp johnsnowlab com nmbr nmbr nmbr deidentify_large_en html deidentify_larg http nlp johnsnowlab com nmbr nmbr nmbr deidentify_large_en html english de_identifi rb http nlp johnsnowlab com nmbr nmbr nmbr deidentify_rb_en html deidentify_rb http nlp johnsnowlab com nmbr nmbr nmbr deidentify_rb_en html english de_identifi rb_no_regex deidentify_rb_no_regex chunk resolv languag nlu load refer spark nlp model refer english resolve_chunk athena_condit http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_athena_conditions_healthcare_en html chunkresolve_athena_conditions_healthcar http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_athena_conditions_healthcare_en html english resolve_chunk cpt_clinic http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_cpt_clinical_en html chunkresolve_cpt_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_cpt_clinical_en html english resolve_chunk icdnmbrcm clinic http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_clinical_en html chunkresolve_icdnmbrcm_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_clinical_en html english resolve_chunk icdnmbrcm diseases_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_diseases_clinical_en html chunkresolve_icdnmbrcm_diseases_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_diseases_clinical_en html english resolve_chunk icdnmbrcm hcc_clinic chunkresolve_icdnmbrcm_hcc_clin english resolve_chunk icdnmbrcm hcc_healthcar chunkresolve_icdnmbrcm_hcc_healthcar english resolve_chunk icdnmbrcm injuri http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_injuries_clinical_en html chunkresolve_icdnmbrcm_injuries_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_injuries_clinical_en html english resolve_chunk icdnmbrcm musculoskelet http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_musculoskeletal_clinical_en html chunkresolve_icdnmbrcm_musculoskeletal_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_musculoskeletal_clinical_en html english resolve_chunk icdnmbrcm neoplasm http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_neoplasms_clinical_en html chunkresolve_icdnmbrcm_neoplasms_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_neoplasms_clinical_en html english resolve_chunk icdnmbrcm poison http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_poison_ext_clinical_en html chunkresolve_icdnmbrcm_poison_ext_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_poison_ext_clinical_en html english resolve_chunk icdnmbrcm pueril http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_puerile_clinical_en html chunkresolve_icdnmbrcm_puerile_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrcm_puerile_clinical_en html english resolve_chunk icdnmbrpc clinic chunkresolve_icdnmbrpcs_clin english resolve_chunk icdo clinic http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrpcs_clinical_en html chunkresolve_icdo_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_icdnmbrpcs_clinical_en html english resolve_chunk loinc http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_loinc_clinical_en html chunkresolve_loinc_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_loinc_clinical_en html english resolve_chunk rxnorm cd http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_cd_clinical_en html chunkresolve_rxnorm_cd_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_cd_clinical_en html english resolve_chunk rxnorm chunkresolve_rxnorm_in_clin english resolve_chunk rxnorm in_healthcar chunkresolve_rxnorm_in_healthcar english resolve_chunk rxnorm sbd http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_sbd_clinical_en html chunkresolve_rxnorm_sbd_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_sbd_clinical_en html english resolve_chunk rxnorm scd http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_scd_clinical_en html chunkresolve_rxnorm_scd_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_scd_clinical_en html english resolve_chunk rxnorm scdc chunkresolve_rxnorm_scdc_clin english resolve_chunk rxnorm scdc_healthcar chunkresolve_rxnorm_scdc_healthcar english resolve_chunk rxnorm xsmall clinic http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_xsmall_clinical_en html chunkresolve_rxnorm_xsmall_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_rxnorm_xsmall_clinical_en html english resolve_chunk snome find http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_snomed_findings_clinical_en html chunkresolve_snomed_findings_clin http nlp johnsnowlab com nmbr nmbr nmbr chunkresolve_snomed_findings_clinical_en html new classifi languag nlu load refer spark nlp model refer english classifi icdnmbr clinic classifier_icdnmbrcm_hcc_clin english classifi icdnmbr healthcar classifier_icdnmbrcm_hcc_healthcar english classifi ade biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_biobert_en html classifierdl_ade_biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_biobert_en html english classifi ade clinic http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_clinicalbert_en html classifierdl_ade_clinicalbert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_clinicalbert_en html english classifi ade convers http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_conversational_biobert_en html classifierdl_ade_conversational_biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_ade_conversational_biobert_en html english classifi gender biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_gender_biobert_en html classifierdl_gender_biobert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_gender_biobert_en html english classifi gender sbert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_gender_sbert_en html classifierdl_gender_sbert http nlp johnsnowlab com nmbr nmbr nmbr classifierdl_gender_sbert_en html english classifi pico classifierdl_pico_biobert german medic model nlu load refer spark nlp model refer emb wnmbrv_cc_nmbrd emb wnmbrv wnmbrv_cc_nmbrd resolve_chunk chunkresolve_icdnmbrgm resolve_chunk icdnmbrgm chunkresolve_icdnmbrgm resolve_chunk icdnmbrgm nmbr chunkresolve_icdnmbrgm_nmbr med_ner legal ner_leg med_ner ner_healthcar med_ner healthcar ner_healthcar med_ner healthcare_slim ner_healthcare_slim med_ner traffic ner_traff spanish medic model nlu load refer spark nlp model refer emb scielo nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html embeddings_scielo_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html emb scielo nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html embeddings_scielo_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html emb scielo nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html embeddings_scielo_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielo_nmbrd_ html emb scielowiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html embeddings_scielowiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html emb scielowiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html embeddings_scielowiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html emb scielowiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html embeddings_scielowiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_scielowiki_nmbrd_ html emb sciwiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html embeddings_sciwiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html emb sciwiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html embeddings_sciwiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html emb sciwiki nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html embeddings_sciwiki_nmbrd http nlp johnsnowlab com nmbr nmbr nmbr embeddings_sciwiki_nmbrd_ html med_ner http nlp johnsnowlab com nmbr nmbr nmbr ner_diag_proc_ html ner_diag_proc http nlp johnsnowlab com nmbr nmbr nmbr ner_diag_proc_ html med_ner neoplasm http nlp johnsnowlab com nmbr nmbr nmbr ner_neoplasms_ html ner_neoplasm http nlp johnsnowlab com nmbr nmbr nmbr ner_neoplasms_ html med_ner diag_proc http nlp johnsnowlab com nmbr nmbr nmbr ner_diag_proc_ html ner_diag_proc http nlp johnsnowlab com nmbr nmbr nmbr ner_diag_proc_ html gpu mode enabl nlu gpu mode set gpu true load model e nlu load train sentiment gpu true must resart kernel alreadi load nlu pipelin withouth gpu mode output level relat thi new output level use relat extractor give nmbr row per relat extract bug fix fix bug caus load nlu model offlin mode work occas nmbr line instal nlu wget http raw githubusercont com johnsnowlab nlu master script colab_setup sh bash instal via pip pip instal nlu pyspark nmbr nmbr addit nlu ressourc nlu websit http nlu johnsnowlab com nlu tutori notebook http nlu johnsnowlab com doc en notebook nlu video blogpost nlu http nlp johnsnowlab com learn python nlu librari nlu github http github com johnsnowlab nlu suggest question contact us slack http join slack com spark nlp shared_invit zt lutctnmbrgm kuuazcyfkhugynmbr_nmbramkxqa
sci-genie,MachineLearning,1619920075.0,[D] The Topics I Would Choose From If I Ever Did A Ph.D. in AI/ML Within the Next 2 Years. What would be Yours?,
cathie_burry,MachineLearning,1617639889.0,Why are correct AI medical diagnoses seemingly so hard to achieve? [D],lot peopl work thi lot project invest thi lot realli smart peopl tri solv thi problem studi read fit problem peopl work run lot regulatori issu end day seem like would less complic deal aspect medicin thing peopl built ai like alphazero roadblock hear add impass see whi go ai clinic
windy-city-wizard,MachineLearning,1619974865.0,[D] [R] Evaluation set for large number of imbalanced classes?,work classif problem upward nmbr class hundr observ class top nmbr common class ten thousand observ bottom nmbr dozen observ evalu set current ha nmbr observ class cap arbitrarili nmbr seem like sensibl setup metric interest top nmbr accuraci better way evalu model
shreyansh26,MachineLearning,1619962439.0,[P] GPT-1 - Annotated Paper + Paper Summary,gpt nmbr recent gpt nmbr creat lot hype launch howev start improv languag understand gener pre train paper introduc idea gpt nmbr part paper note seri gone paper creat brief yet inform summari paper take take minut understand gpt nmbr well check link happi read paper summari improv languag understand gener pre train http shreyanshnmbr github io post nmbr nmbr nmbr_language_understanding_generative_pretrain annot paper http github com shreyanshnmbr annot ml paper blob main gptnmbr pdf http github com shreyanshnmbr annot ml paper blob main gptnmbr pdf
hwbs20,MachineLearning,1619257344.0,An RTX 3070 for protoyping [D],rtx nmbr inmbr processor nmbr gb ram enough prototyp deep learn model area work gener model use case nmbr check model code actual run mayb run tini dataset make sure thing correct onc thi done put cluster scale experi nmbr mayb reproduc model demand much comput even thi case check code work push cluster nmbr train basic gan vae etc understand main thing get result veri fast wait like hour wait go rtx nmbr similar spec main problem nmbr bit budget avail august one avail right way budget wherea want someth thi week thank advanc
thunder_jaxx,MachineLearning,1619812725.0,[D] Unpopular Opinion: Conferences Should Mandate a Limitations Section For Any Paper Introducing some New Model / Method / Variant,titl say mean specif limit section research convey solid limit new method propos feel inform veri crucial dissemin good scienc age ai ml limit problem depend help ground claim research paper review process help make thi section better whi reason nmbr explicitli state go look insid paper may found mani time hidden footnot conclud remark requir cognit load read process state reduc cognit load think stuff becaus cover part good scienc nmbr make us stick good scienc paper becom sourc benchmark porn nmbr keep clickbaiti titl check ai ml research brought advert model clickbaiti titl clickbaiti titl mani time titl ha actual realli good spot http arxiv org ab nmbr least fair scienc limit ensur boundari scienc salesmanship veri awar put lot load research seldom peopl like healthi cozi make us care learn research sell research thought
Signal-Ad-8598,MachineLearning,1620398804.0,[D] How is tfjs-node performance in comparison with Python version?,hi come across post show tfj node faster python tensorflow multi thread howev post nmbr year ago still true whi tfj node popular train model node js familiar js syntax python
__Julia,MachineLearning,1616942750.0,[D] Is it valuable to have a patent in our industry?,hello work research engin r heard polar opinion work patent small circl would like hear opinion peopl industri valuabl patent someon resum compar paper ml confer gener public percept patent differ realiti mani case harder write paper make top tier confer write patent howev show author abl think box enhanc exist product design system solut anoth argument heard gate keep scienc seen blocker well opinion thi commun
Yuqing7,MachineLearning,1619541221.0,"[R] Microsoft & Peking U Researchers Identify 'Knowledge Neurons' in Pretrained Transformers, Enabling Fact Editing",research team microsoft research peke univers peep pretrain transform investig factual knowledg store propos method identifi knowledg neuron util explicitli updat eras fact quick read microsoft peke u research identifi knowledg neuron pretrain transform enabl fact edit http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper knowledg neuron pretrain transform arxiv http arxiv org pdf nmbr pdf
dojoteef,MachineLearning,1617280471.0,[N] John Carmack solves AGI!,short year solitari research ai legendari programm john carmack ha recent unveil agi name rick creat combin flexibl gan express power predict minim knew penchant physic build machin result qualiti facial express smooth motion uncanni help record video nmbrk nmbrfp check http www youtub com watch v bxqlsrlakknmbr
rockwilly,MachineLearning,1619313536.0,[Project] - I made a fun little political leaning predictor for Reddit comments for my dissertation project,
NeedMoreTime4Things,MachineLearning,1617309596.0,[D] Keeping up with research - Poll,hi talk peopl realiz us differ way keep current develop ml tri dive new field befor phd like know manag stay top research thank advanc view poll http www reddit com poll minmbrhrm
KirillTheMunchKing,MachineLearning,1620229627.0,[D] StyleGAN2 Distillation for Feed-forward Image Manipulation. How to gender swap Harry-Potter and edit other images explained!,stylegannmbr distil feed forward imag manipul http casual_gan nmbr thi paper octob nmbr author propos pipelin discov semant edit direct stylegan unsupervis way gather pair synthet dataset use direct use train light imagenmbrimag model perform one specif edit add smile chang hair color etc ani new imag singl forward pass familiar thi paper check nmbr minut summari http casual_gan nmbr sampl model http preview redd nmbrcohkadiobxnmbr png width nmbr format png auto webp nmbranmbrfnmbrcnmbrenmbranmbrbnmbrdnmbrccnmbrcnmbrabccnmbrabaaanmbrad arxiv http arxiv org ab nmbr paper explanain nmbr minut http casual_gan nmbr
KirillTheMunchKing,MachineLearning,1619016127.0,[R] Training Generative Adversarial Networks with Limited Data,train gener adversari network limit data http casual_gan nmbr author propos а novel method train stylegan small dataset thousand imag without overfit achiev high visual qualiti gener imag introduc set adapt discrimin augment stabil train limit data detail http casual_gan nmbr stylegan ada http preview redd nmbrtunmbrtenmbrgjunmbr png width nmbr format png auto webp nmbrdfnmbrdenmbrenmbrfnmbrbbnmbrdnmbrccnmbrfnmbrbnmbra case familiar paper read http casual_gan nmbr
ancientmooner,MachineLearning,1618412945.0,[P] Code and pretrained models for Swin Transformer are released (SOTA models on COCO and ADE20K),imag classif pretrain model http github com microsoft swin transform http github com microsoft swin transform object detect coco http github com swintransform swin transform object detect http github com swintransform swin transform object detect semant segment adenmbrk http github com swintransform swin transform semant segment http github com swintransform swin transform semant segment
Exotic-Photograph-37,MachineLearning,1617994173.0,[P] Low Computation GAN? (Noobie to GAN),hello research studi gan content want find differ way manipul someon face map action e danc sing seem like deepfak librari use requir lot comput time ani librari low comput time think someth like wombo ai http wombo ai take long though know becaus super power server connect use wombo ai http wombo ai directli becaus would privaci issu would requir commun third parti doe anyon ani tip librari could use thank
brainggear,MachineLearning,1617276285.0,[R] On the Origin of Species of Self-Supervised Learning,
Realistic_Sea_3634,MachineLearning,1620485299.0,"[D] Why has machine learning become such a toxic field, know-it-all field?",work mani scientist mani differ field background none come close obnoxi pompos outright unpalat know vibe machin learn commun sure case small rotten bunch smear whole field thi behaviour rife nmbr place cesspit known twitter reddit somewhat industri much less rampant compar academia experi clear googl brain deepmind fair academia observ think domin field littl involv sme often see machin learn group group swarm problem throw ml data call problem solv veri littl ani sme involv importantli follow except thi gener far dl encourag habit learn basic encount thi often especi appar dl peopl jump straight e g cv nlp bother learn anyth foundat seen spoken numer peopl publish cv paper prestigi confer even know whi colour space use even pixel becaus sure fuck small squar imag may claim need know thi delusion talk absolut limit comput cnn transform need foundat know improv real work goe vast major paper dl problem thi ha cite mani past howev must articul also understand mani contribut factor thi inde problem often slight architectur chang increment improv real thought gone paper thi sometim result seen numer time varieti set includ team phd good engin less product research msc experi hi belt whole point phd come ml team use r alway case much expect insol arrog fair ethic crowd thi crowd current oper simpli serv cancer tumour ml world alway point problem never real solut act like gatekeep god gift world bring massiv toxic virtual ml commun prohibit free speech commun without fear repercuss thi crowd could overhaul leader vitriol yobo claim academ appli field veri littl focu applic often excus put forward field like math veri applic straight away firstli ml like math like straight engin especi dl primarili appli thu much focus applic slight architectur chang nmbr improv imagenet pythagoreon theorem wait happen lazi want get phd sure phd actual want make real contribut field stand behind field like physic stat often appli make real world impact applic fair ml also doe nowher near much especi averag compani industri fix world problem state abil ml sure delus pr combin cite lot befor edit nmbr know whi peopl focus definit pixel reiter small squar model help use enough work applic great use claim help model definit becaus understand whi downvot thi thank discuss want understand reddit ml commun view origin content thi post minu pixel editnmbr realis would better put thi comment regard ethic crowd see mani peopl comment requir clarifi posit feel intent tri make mountain molehil often least onlin perspect want engag civil discours debat present instead want blame live echo chamber act like saviour pretenti god work purpos ethic fair tri chang thing ethic fair commun perpetu live littl echo chamber tri cancel disagre utter toxic never mind fact mani popular research space preach toxic larg tech compani ceo unfair practic top univers compani etc first work place like googl deepmind microsoft attend univers like stanford cmu realli want make differ plight poc tech whi work deepmind go work consult littl random african start empow fuck hypocrit whatev conveni easi simpli popular contest found vent quit fervent thi howev often appar display self entitl superior grant thi simpli observ mostli onlin also somewhat person
rsree123,MachineLearning,1617678542.0,How to overcome Impostor Syndrome [D],even work appli ml close nmbr year sometim get feel know anyth would abl recal thing top mind quick look help would even rememb detail fundament concept thi case everyon abl retain everyth mind peopl look profil high expect ani tip overcom thi
aselsiriwardena,MachineLearning,1619173423.0,[P] Pytorch Load Balance and Scalability,need idea execut test pytorch imag gener model load balanc scalabl ani specif tool need execut parallel process
hardmaru,MachineLearning,1620428651.0,[R] Computer-Aided Design as Language,
__data_science__,MachineLearning,1616513807.0,[D] Advanced Takeaways from fast.ai book,recent read fast ai deep learn book http www goodread com book show nmbr deep learn coder fastai pytorch want summaris mani advanc takeaway trick got go leav basic thing becaus enough post focus found new special book also put insight deck http saveal ai share deck nmbr nmbr nmbrknmbruxpazkgnmbr save help rememb long term would massiv recommend use space repetit app video explan http youtu adnmbrafdrcskq like anki save http saveal ai thing learn otherwis forget much import takeaway neural network train fundament alway start ml project produc simpl baselin binari classif could even simpl predict common class train dataset baselin linear regress random forest boost etc use baselin clean data look datapoint get incorrect check see actual classifi correctli data gener also leverag baselin help debug model e g make neural network nmbr layer abl match perform linear regress baselin bug e g ad featur improv perform linear regress probabl also improv perform neural net unless bug hyperparamet optimis help bit especi learn rate gener default hyperparamet quit well close optimis hyperparamet one last thing tri rather first know someth problem tri inject induct bia train process e g featur relat sequenti way incorpor train separ use rnn e g know output onli nmbr nmbr use sigmoid design final layer forc output network thi rang transfer learn alway use transfer learn find model pre train similar task fine tune model particular task e g see huggingfac http huggingfac co help thi nlp gradual unfreez discrimin learn rate work well fine tune transfer learn model gradual unfreez freez earlier layer train later layer onli gradual unfreez earlier layer one one discrimin learn rate differ learn rate per layer network usual earlier layer smaller learn rate later layer trick deal overfit best way deal overfit get data exhaust thi first befor start regularis method data augment realli power possibl text well imag imag data augment crop pad squish resiz imag text data augment negat word replac word simil perturb word embed nice github repo http github com qdata textattack thi mixup regularis creat new data averag togeth train datapoint backward train nlp onli train addit separ model fed text backward averag output two model get final predict trick improv perform test time augment test time use averag predict mani augment version input predict rather predict true input nmbr cycl train increas reduc learn rate throughout train circular fashion usual make huge differ learn rate finder algorithm algorithm fast ai provid help automat discov roughli best learn rate never use one hot encod use embed instead even tabular data use adamw instead adam help littl bit lower precis train help pytorch lightn http github com pytorchlightn pytorch lightn simpl flag set regress problem know output within rang good use sigmoid forc neural net output within thi rang e make network output min _valu sigmoid output max _valu min _valu cluster featur help identifi one redund remov help perform label smooth use nmbr nmbr instead nmbr nmbr label target smoothen train dichotomis data output continu better train network predict continu valu rather turn classif problem progress resiz train model smaller resolut imag first increas resolut gradual speed train lot strateg use bottleneck layer forc network form compact represent data differ point help tri use skip connect help smooth loss surfac pleas let know found thi help ani train trick use also know
Yuqing7,MachineLearning,1620061055.0,"[R] CMU, UT Austin & Facebook’s CNN Layer Width Optimization Strategies Achieve 320x Overhead Reduction",research carnegi mellon univers univers texa austin facebook ai propos novel paradigm optim width cnn layer method compat across variou width optim algorithm network achiev nmbrx reduct width optim overhead without compromis top nmbr accuraci imagenet quick read cmu ut austin facebook cnn layer width optim strategi achiev nmbrx overhead reduct http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper width transfer varianc width optim arxiv http arxiv org pdf nmbr pdf
dontreallyknowmuch,MachineLearning,1618540777.0,[R] GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds,new work nvidia recent showcas gtc nmbr keynot convert user creat minecraft block world view consist realist look world method learn perform thi translat absenc pair minecraft real data use gan pretrain network gener pseudo ground truth tweet http twitter com arunmallya statu nmbr http twitter com arunmallya statu nmbr arxiv http arxiv org ab nmbr http arxiv org ab nmbr webpag http nvlab github io gancraft http nvlab github io gancraft sampl output http reddit com link mrunmbrh video inmbrarzkyfktnmbr player http reddit com link mrunmbrh video njqlnmbrgcnmbrgktnmbr player http reddit com link mrunmbrh video nmbrrqenmbrgenmbrgktnmbr player even chang style output world http reddit com link mrunmbrh video srgnmbrqwnmbrgktnmbr player
mroc_lak,MachineLearning,1616427593.0,[D] How do you test your machine learning models for healthcare to gain confidence before embarking on a clinical trial?,hi look ml applic healthcar interest understand compani prepar clinic trial metric correl well clinic trial perform import pitfal avoid
timscarfe,MachineLearning,1616537282.0,[D] Meta-Gradients in Reinforcement Learning with Tomas Zahavy (DeepMind) and Robert Lange (Video),dr tom zahavi research scientist deepmind think reinforc learn gener learn framework today hi opinion could lead artifici gener intellig think task could solv simpli maximis reward back nmbr tom wa undergradu befor deep learn revolut attend onlin lectur cnn automat discov represent thi wa epiphani tom decid veri moment wa go becom ml research tom view abil recognis pattern discov structur import aspect intellig thi ha hi quest ever sinc particularli focus use divers preserv metagradi discov thi structur thi discuss dive deep meta gradient reinforc learn video http youtu hfazwgk _isnmbr http youtu hfazwgk_isnmbr pod http anchor fm machinelearningstreettalk episod nmbr meta gradient rl dr toma zahavi deepmind etbcrnmbr http anchor fm machinelearningstreettalk episod nmbr meta gradient rl dr toma zahavi deepmind etbcrnmbr
freshprinceofuk,MachineLearning,1619968135.0,[D] Best CPU real time pose estimation model available?,hi look quit pose estim model cpu gpu nmbrd nmbrd seen anyth impress kemtai kemtai com browser cpu real time anyon suggest model thi may
Rat-a-ouchie,MachineLearning,1619213594.0,"[D] PhD Applied Maths - Machine Learning, supervisor selection should be one you get along with or something else is more important?",hey guy phd appli mathemat love machin learn want specialis machin learn base thesi amd wa wonder anyon ani advic phd supervisor select sure thi right place ask ani advic appreci summari look supervisor find right research topic
jj4646,MachineLearning,1619155260.0,"[D] is this the equivalent of the ""what came first, the chicken or the egg"" in machine learning?",http en wikipedia org wiki probably_approximately_correct_learn learn thi concept statist learn call probabl approxim correct pac although word thi seem complic technic understand correctli essenc pac show target concept e g set possibl input point correspond certain output error machin learn algorithm probabilist bound certain rang think thi intend show machin learn algorithm use make predict instead base predictor color sock neighbor wear nmbr pac framework wa develop nmbr yet prior thi mani statist model use make predict e g regress model onc pac wa develop research examin statist model use prior thi confirm model compat pac framework nmbr question modern model newer machin learn model develop e g lstm model develop long pac framework wa establish new algorithm test make sure compat pac framework nmbr someon pleas confirm understand pac framework correct sourc http stat stackexchang com question nmbr doe pac learn theori mean http machinelearningmasteri com hypothesi machin learn hypothesi context pac seem gener term machin learn algorithm hypothesi space space possibl algorithm e g linear regress model specif beta paramet individu hypothesi possibl linear regress model hypothesi space distribut data concept class im still confus differ target concept concept class someon pleas clarifi thi
__data_science__,MachineLearning,1617707256.0,[D] Training strategy given Double Descent phenomenon,doe doubl descent http openai com blog deep doubl descent chang ideal train strategi befor use follow thi broad train strategi nmbr make network big enough overfit train data nmbr regularis reduc overfit possibl doubl descent mean thi might correct anymor wa wonder guy think
anianruoss,MachineLearning,1617294131.0,[R] Robustness Certification for Point Cloud Models,present first robust certifi semant transform e g rotat shear nmbrd point cloud model object classif part segment task paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com eth sri nmbrdcertifi http github com eth sri nmbrdcertifi abstract use deep nmbrd point cloud model safeti critic applic autonom drive dictat need certifi robust model semant transform thi technic challeng requir scalabl verifi tailor point cloud model handl wide rang semant nmbrd transform thi work address thi challeng introduc nmbrdcertifi first verifi abl certifi robust point cloud model nmbrdcertifi base two key insight gener relax base first order taylor approxim applic ani differenti transform ii precis relax global featur pool complex pointwis activ e g relu sigmoid commonli employ point cloud model demonstr effect nmbrdcertifi perform extens evalu wide rang nmbrd transform e g rotat twist classif part segment task exampl certifi robust rotat nmbr nmbr point cloud max pool relax increas certif nmbr
adammathias,MachineLearning,1619016230.0,"[N] Aim 2.3.0 is out with system resource monitoring, ""reverse grouping"" and more",highlight comment system resourc monitor option automat track gpu cpu memori curiou much thi cover disk network revers group thi aim call option divid everyth one param typic seed look like pick variabl ui experi clear set variabl default indivis via api line chart smooth thi self explanatori mayb somewhat automat default base number point scale standard error standard deviat new built aggreg mode addit min max support infinit valu nan full list releas issu featur request http github com aimhubio aim mileston nmbr close nmbr announc http medium com aimstack aim vnmbr nmbr nmbr system resourc usag revers group nmbrddnmbranmbrff gev
CanadianTuero,MachineLearning,1617011308.0,[P] Differentiable Optimizers with Perturbations in PyTorch,read thi http www reddit com r machinelearn comment mcdox p_torchsort_fast_differentiable_sorting_and post day learn use perturb creat differenti optim http arxiv org ab nmbr http arxiv org ab nmbr offici implement http github com googl research googl research tree master perturb tensorflow sinc primarili use pytorch tool someth want play around research reimplement use nativ pytorch figur would share case find use well http github com tuero perturb differenti pytorch http github com tuero perturb differenti pytorch
BotPoetsSociety,MachineLearning,1618053966.0,[P] AI Poetry,creat poem combin ai model poem gener gptnmbr model fine tune poetri choos edit gener poetri think fun read raw poetri come machin even obviou flaw photo http unsplash com voic text speech aw azur http reddit com link monmbrxrk video qfmfynmbrfbzbsnmbr player youtub channel http www youtub com channel uchydklnmbrlnmbrwnmbrvebsakswnmbrsdw http www youtub com channel uchydklnmbrlnmbrwnmbrvebsakswnmbrsdw twitter http twitter com botpoetssocieti http twitter com botpoetssocieti
JoshN1986,MachineLearning,1616957813.0,[P] scite: a smart citation index that displays the context of citations and classifies their intent using deep learning,
bendee983,MachineLearning,1617897743.0,[D] Waymo now has a machine learning PhD as its co-CEO,nmbr googl hire john krafcik veteran automot industri lead self drive car effort later spun waymo last week krafcik step cede hi role dimitri dolgov comput scienc phd veteran ml research tekedra mawakana doctor law whi thi import time krafcik join googl gener belief wa deep learn wa matur enough sdc reach product level sdc wa matter scale road test gather enough train data train dl model ha becom evid current state dl readi tackl mani challeng open road mani gap need fill legal infrastructur sdc also readi mani question remain unansw thi whi make sens put ml engin lawyer helm compani deep learn ha come long way push sdc forward bumpi road still lie ahead read full analysi http bdtechtalk com nmbr nmbr nmbr waymo ceo reshuffl self drive car industri http bdtechtalk com nmbr nmbr nmbr waymo ceo reshuffl self drive car industri
bryant1410,MachineLearning,1619129609.0,[N] Competition on classifying tweets as jokes + more,comput humor task tweet nmbr subtask binari classif intend humor non intend humor funni score humor mechan classif humor target classif http competit codalab org competit nmbr http competit codalab org competit nmbr spanish think big blocker speak paper team describ system publish iberlef workshop sepln nmbr málaga spain virtual
VinayUPrabhu,MachineLearning,1617308083.0,[P] A small dataset of mis-parsed citations from Google scholar,tl dr googl scholar parser aggress index public sometim index high school cafeteria restaur menu paper nice aspect lot agro journal global south meet fate well nmbr dataset http github com vinayprabhu reveng _of _the _pith _sigboviknmbr tree main data http github com vinayprabhu revenge_of_the_pith_sigboviknmbr tree main data nmbr awar rais paper author sigbovik humor style http github com vinayprabhu reveng _of _the _pith _sigboviknmbr blob main sigbovik _plant _nmbr _camera _readyish pdf http github com vinayprabhu revenge_of_the_pith_sigboviknmbr blob main sigbovik_plants_nmbr_camera_readyish pdf http preview redd vzunmbriqpdmqnmbr jpg width nmbr format pjpg auto webp nmbrabaenmbrenmbrdnmbrenmbr
Symbiot10000,MachineLearning,1616967325.0,"[D] Papers on intelligent agents for search (not voice, Alexa, etc.)",look write someth intellig agent use search internet resourc regular platform e mobil desktop headless platform like alexa ai voic assist specif topic without user directli interact search engin variou reason incred difficult googl drill ani paper subject ani signal nois ratio ha beaten think gpt nmbr style gener oracl infinit scope abstract great deal hide sourc ai project scrape replac googl perhap rather machin learn system ha task specif domain blastoma research compress ha specif audienc mind ha greater level discern judgement regard qualiti sourc averag search engin anyon ha link two would point right direct grate
jj4646,MachineLearning,1619580096.0,[D] do machine learning models handle multicollinearity better than traditional models (e.g. linear regression)?,come older tradit model like linear regress ensur variabl multicollinear wa veri import multicollinear greatli harm predict abil model howev older tradit model meant use smaller dataset fewer row fewer colum compar modern big data intuit easier identifi correct multicollinear smaller dataset e g variabl transform remov variabl stepwis select etc machin learn model big data multicollinear big problem e g model like randon forest known sustain strong perform presenc multicollinear make random forest immun multicollinear neural network deep neural network abk deal multicollinear make neural network immun multicollinear thank
jj4646,MachineLearning,1619072556.0,"[D] Competetive ""Rule Based"" Machine Learning Models",http en wikipedia org wiki association_rule_learn ha anyon ever seen advanc associ rule model involv machin learn architectur advanc machin learn model provid complet set rule interpret make predict doe someth like thi exist
kpang0,MachineLearning,1617823197.0,[P] Vald: a highly scalable distributed fast approximate nearest neighbour dense vector search engine.,hi recent releas vnmbr vald cloud nativ distribut fast approxim nearest neighbour dens vector search engin run kubernet oss project apachenmbr licenc alreadi run behind yahoo japan imag search recommend engin also run behind japanes nation digit librari digit archiv retriev engin use machin learn convert unstructur data audio imag video user characterist etc vector use vald perform vector search vector possibl oper faster complex search engin vald still veri new project look lot feedback mani user pleas come visit site web http vald vdaa org http vald vdaa org github http github com vdaa vald http github com vdaa vald
SQL_beginner,MachineLearning,1620156717.0,"[D] ""Classifier Technology and the Illusion of Progress"" (2006, Hand)",http arxiv org ab math nmbr found thi interest paper author argu complex algorithm e g deep neural network alway signific advantag simpler algorithm real world henc illus author bring mani reason whi thi happen reason relat mathemat relat experiment design note author bring point sure whi thi true convers two class case although real data set exactli linear decis surfac common find centroid predictor variabl distribut class differ simpl linear surfac surprisingli well estim true decis surfac whi common find centroid predictor variabl distribut differ whi doe thi allow linear surfac estim true surfac well thought read thi paper thi wa paper wa publish nmbr befor deep learn revolut e g nmbr convolut neural network clearli outperform human imagenet competit possibl result thi paper somewhat irrelev outdat research univers compani e g googl facebook microsoft probabl spent billion dollar sinc nmbr develop complex machin learn model use common sens mani model perform well enough research done futur agre certain problem perhap simpler model e g linear regress decis tree perform well deep learn model sure mani problem real world requir complex model argument made whi complex model requir use concept vc dimens http en wikipedia org wiki vapnik enmbr nmbr nmbrchervonenkis_dimens relat problem initi x perceptron problem could say big data data mani column mani row less like linearli sepper e harder shatter shatter classifi perfectli compar smaller dataset could say data point exist configur data point arrang make less probabl analyz use simpler model vc dimens simpler model lower vc dimens complex model doe thi fact alon somewhat justifi need develop complex model
l34df4rm3r,MachineLearning,1618580410.0,[D] Graph Convolution and GraphSAGE: why don't people use these together?,deep learn graph peopl graph convolut graph sage seen combin two intuit combin transduct induct framework ani drawback use dgl quit easi stack layer get output question whi see thi use work involv graph neural network gcn variant
othotr,MachineLearning,1616740968.0,[R] Stanford HAI Spring Conference - Intelligence Augmentation: AI Empowering People to Solve Global Challenges,stanford institut human center ai host spring confer today interest convers ai best support human healthcar art educ address global challeng detail event record avail hai confer site http hai stanford edu event intellig augment ai empow peopl solv global challeng quick outlin video section welcom introduct http crossmind ai video stanford hai nmbr spring confer intellig augment ai empow peopl solv global challeng nmbrdnmbrabfnmbrcnmbrbnmbr timecod nmbr hai director fei fei li john etchemendi russ altman jame landay session healthcar http crossmind ai video stanford hai nmbr spring confer intellig augment ai empow peopl solv global challeng nmbrdnmbrabfnmbrcnmbrbnmbr timecod nmbr immers technolog caregiv innov opportun ecosystem challeng deborah estrin cornel tech student lightn talk complement extend human intellect principl direct eric horvitz microsoft mobil ai achiev healthi child develop worldwid denni wall stanford safer proactiv care ai suchi saria john hopkin univers session ii art http crossmind ai video stanford hai nmbr spring confer intellig augment ai empow peopl solv global challeng nmbrdnmbrabfnmbrcnmbrbnmbr timecod nmbr intellig exotic ai ken goldberg uc berkeley student lightn talk art intellig exotic ai michel elam stanford digit griot reimagin archiv rashaad newsom stanford amplifi human artist ai hilari hahn carol reiley deepmus ai session iii educ http crossmind ai video stanford hai nmbr spring confer intellig augment ai empow peopl solv global challeng nmbrdnmbrabfnmbrcnmbrbnmbr timecod nmbr escap autom legaci bad instruct daniel schwartz stanford student lightn talk ai super power teacher chri piech stanford push boundari educ technolog ami ogan carnegi mellon univers ai acceler workplac learn scale candac thill amazon http preview redd pnmbrqgnmbreutibpnmbr png width nmbr format png auto webp nmbrccnmbrddnmbrcnmbrcnmbrdanmbrdnmbrcanmbrfnmbrdnmbrcnmbr
dadasenior,MachineLearning,1619096232.0,"[Discussion] I own a 16"" macbook pro with max specs. But how can I make it fast for Keras?",train convolut neural network huge dataset use tensorflow kera far notebook kaggl veri slow gpu acceler seem work also mani user befor make expens pc build ml wonder could exploit expens macbook pro nmbr instead macbook pro nmbr nmbr nmbr ghz intel core inmbr nmbr core nmbr gb nmbr mhz ddrnmbr amd radeon pro nmbrm nmbr gb best option plaidml could exploit discret amd gpu macbook b use acceler tensorflow specif tailor mac avail http github com appl tensorflow_maco c also egpu power amd radeon rx nmbrxt nmbrgb cuda compat someth like plaidml call ani help experi appreci thank advanc
bert4QA,MachineLearning,1617439649.0,[R] FeTaQA: Free-form Table Question Answering,
EinsteiniumArmour,MachineLearning,1620342778.0,"[P] Last year, I built a multilingual text simplifier for my undergraduate thesis. This year, I made it work with multilingual BERT!",english simplif made mile http preview redd kympalubnmbrlxnmbr png width nmbr format png auto webp anmbrdnmbreaeanmbrcfnmbrffnmbrfenmbrbnmbranmbrcednmbrf mile http github com kvasir mile multilingu text simplifi inspir lsbert http arxiv org ab nmbr bert base lexic simplif approach propos nmbr unlik lsbert mile use bert base multilingu uncas model well simpl languag agnost approach complex word identif cwi candid rank although test mile support least nmbr languag arab bulgarian catalan czech danish dutch english finnish french german hungarian indonesian italian norwegian polish portugues romanian russian spanish swedish turkish ukrainian pleas note result use ani languag specif resourc mile doe alway offer synonym substitut complex word although almost alway simpler origin select substitut may alter mean text pleas keep thi mind feel free use tailor mile languag choos github repo mile found http github com kvasir mile
FirstTimeResearcher,MachineLearning,1620101406.0,[D] Petition to the Neurips 2021 conference to extend the deadline,origin tweet hi neuripsconf sincer request mani friend collabor importantli student affect covid pleas extend deadlin mani student know work experi covid close famili member hospit grow number neuripsconf paper submit indian research student person know mani scrambl write paper experi thi situat pleas consid extend least week two person know two student hospit current work hard submit paper thi time talk indian collabor almost everi student similar situat extra week two would help tremend thank much pl amplifi http twitter com rishiy statu nmbr
weifz,MachineLearning,1620391383.0,[D]Why is it impossible to do causal discovery from observational data?,hi say shall see thi problem statist imposs despit larg number paper topic http www stat cmu edu larri sml causat pdf http www stat cmu edu larri sml causat pdf sec nmbr could explain sinc read lot paper causal discoveri observ data thank
SeaworthinessOk834,MachineLearning,1619396009.0,[D] Is Anaconda Worth the Trouble?,hi everyon get readi work pytorch struggl whether reinstal anaconda issu past kind screw path old laptop wa care got new comput wa go along fine uninstal month back would realli like use seem definit guid avoid recur issu wa hope mayb somebodi might resourc advic make work must realli suck hur hur get platform thank advanc edit strang reassur know onli window user ha problem anaconda given plenti consid thank respons feedback
thisisdhruvagarwal,MachineLearning,1618056732.0,Which Policy Gradient Method was used by Google's Deep Mind to teach AI to walk? [D],saw thi http www youtub com watch v gnnmbrnrccnmbrtwq video youtub polici gradient method wa use train ai walk wa ddpg dnmbrpg
mimeticaware,MachineLearning,1617515924.0,[D] Hashing techniques to compare large datasets?,implement research paper hash fingerprint techniqu larg dataset greater nmbr gb want implement librari gener hash fingerprint larg dataset easili compar sure start ani exist implement research paper would realli help
Rishit-dagli,MachineLearning,1618399521.0,[P] Implementing Perceiver: General perception with Iterative Attention in TensorFlow,today glad present implement perceiv gener percept iter attent model build top transform solv quadrat scale problem without make ani assumpt data like previou approach tensorflow thi mean use model imag audio video etc thi model also achiev state art task ps thi made readi use python packag get start veri easili project http github com rishit dagli perceiv http github com rishit dagli perceiv
VinayUPrabhu,MachineLearning,1618166994.0,[P] On the extreme compressibility of Dall-E encoding tensors,brief abstract saw bunch artsi folk experi interest downstream applic dall e encod thought share thi observ turn one could potenti use much lower effect vocab size nmbr instead nmbr without suffer much visual qualiti loss word intrins dimension vocabulari space unearth tucker decomposit like tensor compress techniqu nmbr use much lower dimension encod vector nmbr compress rather raw nmbr x nmbr xnmbr vector post encod regress classif linear algebra twiddl pipelin ps notic nice space fill artifact gif travel upward nmbrd nmbrd colab http github com vinayprabhu colabarama blob master dall _e _low _d ipynb http github com vinayprabhu colabarama blob master dall_e_low_d ipynb http preview redd wnmbrdqnmbrinmbrlsnmbr png width nmbr format png auto webp nmbrbnmbrdnmbrcnmbrdnmbrcnmbrfnmbrbnmbrefnmbrdnmbranmbranmbrb obligatori cat gif http redd khmdlenmbralsnmbr gif
sideonion,MachineLearning,1620432525.0,[D] What DL algorithm to use to track target when I know target coordinates first frame - single target only?,set imag defin first frame hu target detect track subsequ frame deep learn model pre train data imag want detect one specif target know human detect model exist use want detect particular human subsequ frame may multipl human frame want focu onli one tri detect ani method help pleas let know thank
TheCockatoo,MachineLearning,1616836263.0,[D] What's your experience with ML conference rebuttals / letters to area chairs?,ever written area chair due review incompet review e g review ha veri obvious spent nmbr minut paper yet reject high confid comment reveal understand basic machin learn happen
stivi2000,MachineLearning,1617832590.0,[P] Language Independent Sentiment Analysis,train sentiment model use english dataset use german sentenc work surprisingli well see detail whi actual work http github com aok plu sentimentanalysi
WFHFAWAY,MachineLearning,1617552633.0,[D] Is A Failure Ever Worth Publishing?,formal research part ms architectur idea find ani exampl literatur went research process applic integr idea wa exhaust due time constraint net result research wa integr approach exist backbon lower valid perform slightli appl appl basi anyon tri thi befor mayb work could find refer anyon tri experi alway lead big improv never worth publish feel like onli make progress know ha tri befor
SkyLordOmega,MachineLearning,1618722171.0,[D] Wav2Vec2 training for Hindi language,wa part datasprint huggingfac wavnmbrvecnmbr fine tune task train three dataset hindi languag nmbr commonvoic nmbr indic tt iitm nmbr iiith indic dataset train model give good perform longer audio nmbr nmbr wer nmbr perform commonvoic veri bad wer nmbr commonvoic ha audio smaller length attach imag exampl predict test set could reason thi drastic degrad qualiti could improv model resum train onli commonvoic dataset http preview redd nmbrwqzwchonmbrvtnmbr png width nmbr format png auto webp bnmbranmbraecnmbrfacnmbrdenmbrednmbrbnmbrafnmbrbnmbr
PaganPasta,MachineLearning,1620454345.0,[D] ICML 2021 Results,icml result due today gather around anxiou author fare relev content last week http www reddit com r machinelearn comment nnmbrqw d_icml_conference_we_plan_to_reduce_the_number_of good luck
Seankala,MachineLearning,1618462099.0,"[D] Regarding BERT-based models (BERT, RoBERTa, etc.) do we absolutely have to include the [CLS] and [SEP] special tokens in the input data?",thought occur wa process data use cl token classif would obvious make sens includ use token includ
Gullible_Dance,MachineLearning,1619642170.0,[D] New paper shows that federated learning is broken?,titl see gradient imag batch recoveri via gradinvers http arxiv org ab nmbr http arxiv org ab nmbr author recov individu train exampl accumul gradient doe thi mean data privaci law
ravode,MachineLearning,1617294699.0,[D] Dask on App Engine or Cloud Run?,hello wonder run dask app engin cloud run thing use case thi etl job run sk learn model part argo workflow precis execut done unparallel respect node like parallel sk learn stuff move dask obviou approach argo knmbr base would integr dask knmbr cluster coupl reason whi wonder whether app engin cloud run might also viabl option case skip horizont scale instead fire strong instanc parallel dask avail core instead
jj4646,MachineLearning,1620015148.0,[D] stochastic block model vs. standard community detection algorithms,ha anyon ever come across stochast block model http en wikipedia org wiki stochastic_block_model thi seem like commun detect algorithm graph e network cluster doe anyon know circumst would make sens use stochast block model compar commun detect algorithm louvain cluster thank
xiikjuy,MachineLearning,1619972031.0,[D] How to visualize the features of encoder output of an encoder-decoder Transformer model?,hello wonder visual encod output featur encod decod model like bart tnmbr base bart model max posit nmbr model dimens nmbr featur dimens would nmbr nmbr nmbrk experi use sne befor still reason choic featur dimens thi order ani suggest good practic thank
blazejd,MachineLearning,1617211645.0,[Discussion] How was this paper titled?,thi littl desper coupl week ago stumbl upon interest paper rememb titl lot search find explain use gradient could identifi easi difficult classifi exampl data afterward wa shown use nmbr exampl chosen properli achiev similar perform use whole dataset train wa figur show imag two dimens someth like anyon rememb base thi vagu descript titl would realli appreci share http preview redd cnmbramgnmbrlaeeqnmbr png width nmbr format png auto webp nmbrbdcdnmbrfnmbrccnmbreenmbrecnmbrdnmbranmbrc
ccrbltscm,MachineLearning,1618792131.0,[P] Research paper graph for NeRF: foundational work & latest advancements - Link to the interactive graph and paper collection in comments,
meldiwin,MachineLearning,1619994622.0,"[N] Living Robots ""Computationally Designed Organisms""",
innerlee,MachineLearning,1617966854.0,"[N] MMOCR: A Toolbox for Text Detection, Recognition, and Understanding Based on PyTorch",releas http github com open mmlab mmocr http github com open mmlab mmocr new member openmmlab http openmmlab com http openmmlab com thi first releas support text detect http redd hoyxnmbrffgnmbrsnmbr gif text detect psenet panet dbnet textsnak maskrcnn text recognit http redd ppnmbrtpyrjgnmbrsnmbr gif text recognit crnn sar robustscann segocr nrtr key inform extract http redd huzucxylgnmbrsnmbr gif key inform extract sdmg r longer post see http medium com openmmlab mmocr comprehens toolbox text detect recognit understand nmbrbefanmbrbnmbr http medium com openmmlab mmocr comprehens toolbox text detect recognit understand nmbrbefanmbrbnmbr
inigomlap,MachineLearning,1619161977.0,[D] What methodology do you use in data science projects?,data scientist project methodolog team use data scienc check methodolog use poll thi articl http www sciencedirect com scienc articl ab pii snmbr http www sciencedirect com scienc articl ab pii snmbr view poll http www reddit com poll mwponm
vanstorm9,MachineLearning,1618251549.0,[D] How do you visualize and compare image distributions of datasets?,situat handl multipl imag dataset want determin similar two imag dataset distribut thi help determin thing whether suitabl combin two dataset one debug whi valid accuraci high test low straight discov inform compar imag dataset would aid import decis done gener pixel intens histogram one multipl imag two dataset compar accordingli anyth els visual compar imag distribut among dataset also ani metric also visual calcul compar certain properti imag dataset
lsmith1988,MachineLearning,1618030770.0,Search engine used to seek details of videos/images [r],caption paper project underway ml extract inform given video imag search exact locat thi may internet exclud revers imag search googl instanc search color wheel frame video speech etc return locat interest learn thi type technolog whether ha someth ha done alreadi
cgnorthcutt,MachineLearning,1617033396.0,[R] Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks,hi reddit excit share latest research label error pervas nmbr commonli use benchmark test set use machin learn research investig implic label error particular affect stabil ml model benchmark rank exampl label error categori imag dataset figur show given label cl guess altern human valid correct label also second label multi class data point browser label error across nmbr dataset avail http labelerror com error text audio dataset also includ websit http preview redd nmbruhmppnmbrozpnmbr png width nmbr format png auto webp bcnmbrenmbrcnmbranmbrcnmbranmbrbdnmbranmbrfnmbrbnmbranmbrdcnmbrd demo http labelerror com http labelerror com blog post http lnmbr curtisnorthcutt com label error http lnmbr curtisnorthcutt com label error abstract identifi label error test set nmbr commonli use comput vision natur languag audio dataset subsequ studi potenti label error affect benchmark result error test set numer widespread estim averag nmbr error across nmbr dataset exampl nmbr label error compris nmbr imagenet valid set put label error identifi use confid learn algorithm human valid via crowdsourc nmbr algorithm flag candid inde erron label tradit machin learn practition choos model deploy base test accuraci find advis caution propos judg model correctli label test set may use especi noisi real world dataset surprisingli find lower capac model may practic use higher capac model real world dataset high proport erron label data exampl imagenet correct label resnet nmbr outperform resnet nmbr preval origin mislabel test exampl increas nmbr cifar nmbr correct label vgg nmbr outperform vgg nmbr preval origin mislabel test exampl increas nmbr paper http arxiv org ab nmbr http arxiv org ab nmbr code http github com cgnorthcutt cleanlab http github com cgnorthcutt cleanlab joint work anish athaly jona mueller
,MachineLearning,1616615314.0,[N] Hype GTC 2021,get glimps futur comput dure nvidia ceo jensen huang gtcnmbr keynot nmbr nmbr nmbr nmbr pdt save date http bit ly nmbrrlvfwz http bit ly nmbrrlvfwz think across ai ml commun extrem import push boundari thi keynot free listen even need regist confer heard nvidia ceo jensen huang speak sincer impress thing use ai ml data scienc inform tip tomorrow thought push thi mass today
CauchySchwartzDaddy,MachineLearning,1617076262.0,[D] Advice on getting grants/funding for a college ML research club to cover GPU costs,basic help run ml club campu want abl get sort fund cover gpu cost cloud one friend said googl give gpu find ani info thi realli need whole ton run whole oper wa wonder ani good way go thi
blissfox-red,MachineLearning,1617171438.0,[D] Nvidia Data Science of the Day posts,subsequ bump post whose author disappear emb sql queri python code let rip gpu http forum develop nvidia com emb sql queri python code let rip gpu nmbr http www reddit com r machinelearn comment mnmbrbnmbr p _emb _your _sql _queri _into _your _python _code _and utm _sourc share utm _medium webnmbrx context nmbr http www reddit com r machinelearn comment mnmbrbnmbr p_embed_your_sql_query_into_your_python_code_and utm_sourc share utm_medium webnmbrx context nmbr gpu k nearest neighbor algorithm cross finish line start block http forum develop nvidia com gpu k nearest neighbor algorithm cross finish line start block nmbr http www reddit com r machinelearn comment mnmbrzvenmbr p _with _gpu _knearest _neighbor _algorithm _cross utm _sourc share utm _medium webnmbrx context nmbr http www reddit com r machinelearn comment mnmbrzvenmbr p_with_gpus_knearest_neighbor_algorithm_cross utm_sourc share utm_medium webnmbrx context nmbr arriv part far miss nvidia webpag might alreadi know data scienc day page propos post one day averag seem encapsul usual link blog post articl technic news data scienc everi post might relev ml practition believ least might like miss want give look link http forum develop nvidia com c ai data scienc data scienc day nmbr none http forum develop nvidia com c ai data scienc data scienc day nmbr none
tranhp129,MachineLearning,1620591990.0,[D] Non Strongly-convex loss is strongly convex in expectation,seen sever paper mention loss strongli convex themselv strongli convex expect eg logit loss squar loss take deriv loss show loss strongli convex understand whi expect strongli convex exampl hessian squar loss would rank nmbr matrix outer product vector thu squar loss strongli convex whi take expect thi make ani differ ani help appreci
gta141,MachineLearning,1620337216.0,[Research] DeepPlastic: A Novel Approach to Detecting Epipelagic Bound Plastic Using Deep Visual Models,goal thi paper quantifi marin plastic use deep learn check paper http arxiv org ab nmbr http arxiv org ab nmbr predict use model http reddit com link nnmbrihmnmbr video dzdhwqfikkxnmbr player
RussellEsby,MachineLearning,1618479575.0,[P] Voice Conversion VAE-Cycle-GAN on Melspectrograms,hi follow thi great work ehab albadawi http ebadawi github io post speech _style _transfer http ebadawi github io post speech_style_transf demonstr result incred realli stand approach qualiti feasibl work open sourc implement past month link found http github com russellsb voic convers gan http github com russellsb voic convers gan sinc struggl load mode collaps model output blurri spectrogram quit captur initi structur architectur chang make abl execut model one ad conv layer encod decod get right dimens paper descript design residu block either use convolut layer tri mani modif experi better stabil train close replic paper feel replic much current might anyon abl point may issu keen lean right direct
paulcjh,MachineLearning,1616435921.0,[P] Silero NLP streaming on serverless GPUs (~300ms latency),hey everyon coupl week ago put post deepspeech run serverless setup neuro http getneuro ai http getneuro ai got silero run well found thi model lot faster ds way accur see around nmbrm per request moment hope closer nmbrm soon thi pretti decent speed thi applic alreadi code listen mic local machin stream silero model return convers result find sourc http github com neuro ai dev npu _exampl tree main silero python http github com neuro ai dev npu_exampl tree main silero python cours thi run serverless hammer theori hard want silero http github com snakersnmbr silero model http github com snakersnmbr silero model audio text convers model pretti heavi ani q want see thi let know think next play around spade http github com nvlab spade http github com nvlab spade set bulki vision model cheer
idg101,MachineLearning,1619555928.0,[D] Unpopular Opinion: I hate the tensorboard Smoothing algorithm and always set the slider to 0.,look code smooth slider bar tensorboard implement exponenti move averag use major ml task seem someth much simpl like move averag filter would much better make slider window length
Drakshh,MachineLearning,1619710277.0,[Project] Model to evaluate audio clips similarly,post multipl subreddit got respons henc post sorri thi belong dear rel new nlp ml current work project compar score two audio clip origin clip singl sentenc movi charact anim real second clip human tri mimic come model determin similarli score human clip nmbr factor consid use nmbr get text speech compar origin nmbr evalu similarli audio spectrogram spectral centroid zero cross rate nmbr identif emot speech use emot embed assum avail internet measur similarli probabl use cosin similarli come factor pleas help come new comparison factor suggest approach thi problem better way thank anticip
cloud_weather,MachineLearning,1619254999.0,[D] StyleGAN2 + CLIP = StyleCLIP: You Describe & AI Photoshops Faces For You,
skeering,MachineLearning,1619970192.0,[R][D] Starting a Post-Doc and Looking for Advice on Research Area,start post doc within next nmbr nmbr month look around opportun supervisor advis post doc area phd instead branch two main field diversifi phd wa xai veri happi last nmbr year went go forward wa look hot research area asid thi person like find interest correct wrong seem big question ai go forward nmbr generalis better e g take learn mnist appli fashionmnist nmbr make system immun adversari attack nmbr get explan opaqu model e g medic radiolog nmbr learn fewer exampl one shot learn semi supervis learn ultim goal unsupervis learn work well real world sure miss anyth probabl interest asid xai number nmbr abov would correct assum ani four area import next gener ai technolog ani area miss lastli would agre number nmbr good area get second research interest next nmbr nmbr year thank great day
Jason_s0214,MachineLearning,1619216428.0,[R][D] Our new ICLR'21 work clarifies a misconception regarding distillation and label smoothing in a previous NeurIPS'19 study,label smooth truli incompat knowledg distil empir studi http arxiv org ab nmbr project page http zhiqiangshen com project ls _and _kd index html http zhiqiangshen com project ls_and_kd index html ani comment discuss welcom
Zethsc2,MachineLearning,1618571357.0,[R] mlf-core: a framework for deterministic machine learning,
aspcraft,MachineLearning,1620306117.0,Noise-reduction techniques and evaluation for timeseries data [Discussion],common practic deal noisi data common nois reduct techniqu non stationari time seri also sort formula compar differ method nois reduct exampl one produc two differ timeseri origin noisi data way compar two new timeseri evalu better exampl linear regress best line typic chosen minimis mean squar error someth similar thi anyon ani idea criterion could adapt formula minimis maximis get best noic reduc timeseri interest hear thought gener idea
ottawalanguages,MachineLearning,1618866478.0,[D] Effective Ways of Choosing the Number of Layers/Neurons in a Neural Network,read theoret background neural network e g univers approxim theorem seen sever author demonstr even simpl layer mani neuron neural network theoret approxim variabl interest e respons variabl decent level precis howev implic use simpl neural network order achiev good result thi would requir veri larg number neuron therefor deeper neural network develop year attempt provid good result layer fewer number neuron thi bring situat never abl success fit neural network ani real world data use alway gotten realli bad result neural network tri sort combin number neuron number layer learn rate activ function drop regular etc thi seem hyperparamet grid search problem iron model like cart decis tree good result data supervis binari classif random forest ha produc even better thi data small ani mean contain around nmbr column nmbr nmbr row data doe anyon know routin written e g tensorflow kera assist thi problem decid number layer number neuron ground rule decid mani layer mani neuron begin someth around intellig point right direct mani neuron layer choos
Unreasonable_Energy,MachineLearning,1618961433.0,Do we already have the ML technology to make eye contact work better in video chat? [D],problem video chat make eye contact imag convers partner eye appear screen eye point camera thu appear partner make eye contact appear look offset direct relev xkcd http xkcd com nmbr solut principl multipl camera array edg screen say nmbr nmbr webcam around edg screen instead nmbr seem like possibl machin learn magic combin multipl camera feed come slightli differ vantag point singl feed virtual vantag point within convex hull physic camera point somewher middl screen need abl automat locat imag convers partner eye within screen basic solv problem understand set virtual vantag point one eye imag point voila make eye contact screen imag actual see screen imag appear make eye contact thi would easi whi alreadi exist machin learn technolog alreadi make thi realiti somebodi alreadi potenti hurdl immedi come mind nmbr learn virtual vantag point transform would hard mayb pretti sure alreadi seen impress demonstr vantag point shift thi would requir certainli enough understand thi specialti know though mayb hard nmbr take long appli vantag point transform real time induc unaccept lag ye process need happen real time happen local machin virtual vantag point feed ani costli transmit network standard video feed imagin appli local could pretti fast alreadi seem superfici impress video transform appli real time face contour etc nmbr requir non standard hardwar setup sure like realli expens difficult one coupl extra webcam could work mobil everyth nmbr nobodi care thi problem enough work suspect surprisingli larg gain make video chat littl less uncanni mayb thi gain small worth effort appreci ani thought feasibl scheme machin learn perspect
triplehelix_,MachineLearning,1618407205.0,[D] [R] AI/ML colorisation versus actual color photos from between 1909 and 1915,
mate_classic,MachineLearning,1617894376.0,[D] State of Deep Learning outside CV and NLP,comput vision natur languag process get limelight deep learn world right someon work anoth field fell deep learn hype often see problem direct equival cv nlp nevertheless peopl tri adopt success method field thi sometim lead result meaning becaus research take time adapt method properli field often dataset much smaller sampl part group e g step time seri enough paper one part time seri put train part test set wrote blog post http krokotsch eu research nmbr nmbr nmbr one eye data scientist html one problem field predict mainten lead whole line research astray question would state dl field cv nlp doe suffer blindli copi approach
vulnerablebeast,MachineLearning,1618978908.0,[P] Is it possible to use a loss function involving one input and multiple ground truths,instead optim say f x _groundtruth _i _predict _i take averag ground truth say f x _groundtruth _i nmbr _predict _i _groundtruth _i _predict _i nmbr ha thi done befor thank
bert4QA,MachineLearning,1618589144.0,[R] Privacy-Adaptive BERT for Natural Language Understanding,
hardmaru,MachineLearning,1617713905.0,[R] MobileDets: Searching for Object Detection Architectures for Mobile Accelerators.,
mihirkarkare,MachineLearning,1617327641.0,[D] Churn prediction using ML,would good way defin churn analys behavior custom use revolv credit credit card compani want retain revolv credit custom would good strategi attack thi problem use ml thi situat term churn littl difficult defin use revolv month two complet natur indic custom ha made hi mind stop use revolv credit
Caffeinated-Scholar,MachineLearning,1619202533.0,[R] FIERY: Future Instance Prediction in Bird's-Eye View from Surround Monocular Cameras,
sl2085,MachineLearning,1616794332.0,[D] What type of machine learning can be used to solve timetable optimisation problems?,onli realli think tradit oper research relat techniqu linear program ani success techniqu peopl use solv timet optimis problem
Competitive-Net-5306,MachineLearning,1617836999.0,[P] About a ML agent for the game Slay the Spire that I've been making,hi recent work make setup would abl train test machin learn agent tcg roguelik game call slay spire like share process current statu project receiv feedback improv mayb help face problem similar went thi project solv follow problem nmbr establish connect game process least mimic someth similar nmbr find way design model capabl make differ type decis differ format input depend game state model must abl handl differ task rang select card reward choos whether throw potion particular enemi would benefici nmbr find way properli reward model nmbr run much game possibl parallel ani given moment time first problem prove lot easier expect wa alreadi mod call commun mod practic solv problem moment discov allow connect commun game process ani arbitrari extern python script stdin stdout fiddl make work afterward wa good go second problem wa bit tricki quit happi solv divid game distinct situat requir distinct format input make distinct type decis made neural network everi singl one shake feel might effici way still noob way solv second problem made solv third problem bit difficult train one singl net collect net togeth play game tri predict benefici play action situat would wa howev abl solv follow process nmbr add one extra net collect net whose purpos predict much score thi ai would get end game base perfect snapshot current situat nmbr agent play game creat snapshot set moment game record everi decis made snapshot nmbr game assign label everi snapshot creat dure game score equal got game wa nmbr train snapshot net label nmbr label everi decis point snapshot _score snapshot _score befor nmbr train net label fourth problem wa tricki enjoy one solv know data usual better machin learn data wa gener dure train agent actual play game could make agent play game simultan would get data howev abl launch run multipl game onc wa abl achiev use virtual machin basic would creat virtual machin worker node actual run game make game commun local python script would establish socket connect main machin actual run agent one catch enough comput resourc larg scale solut wa googl comput engin cloud platform instanc wa virtual machin connect internet wa almost perfect use howev put gpu instanc wa practic due cost without game run abysm slow due render issu solv make small mod game appli bytepatch code disabl render call main loop wa surprisingli easi due game written java howev still run game cli becaus requir window manag want autom process without open desktop worker node manual travers gui launch game solut problem prove decept simpl attach command gnome session properti start automat fire game use ssh connect open new gnome session done cli bash script thing requir reset could close gnome session also done via cli start back
cvpy,MachineLearning,1616342349.0,"[P] Face make up powerd by deep learning | change color of lips, eyes and eyeglasses",
StandardDull3128,MachineLearning,1617116497.0,[Discussion] Can I use CNNs to solve this problem?,doe intuit experi expertis tell would abl train cnn solv binari classif problem describ expect high accuraci let say nmbr problem predict whether imag contain one type textur class nmbr contain sever textur clear border among class nmbr data data high resolut nmbr centimet pixel agricultur imageri obtain via remot sens drone imag pictur depict differ crop weed road soil bush etc would feed model squar imag nmbrxnmbrpx nmbrxnmbrpx exampl imag neg class nmbr po class nmbr http imgur com gnkbnca http imgur com gnkbnca
xiikjuy,MachineLearning,1618403267.0,[D] Is captioning a reasonable way towards explainable AI?,take video classif exampl someon may visual spatial tempor attent mask way explain ai focus see add video captain function top video classif model thu test video onli class predict associ sentenc check sentenc gener sens ai mind make predict doe make sens ani relat publish work thi kind idea
mfilion,MachineLearning,1618933040.0,[Project] Continuous 3D Hand Pose Tracking using Machine Learning & Monado OpenXR,part project back invest ai program manag ivado lab collabora ha develop multi stage neural network base solut accur locat track hand despit complex background nois occlus hand system estim nmbrd nmbrd joint locat without ani depth inform collabora also current work integr monado xr codebas use box differ devic http www collabora com news blog blog nmbr nmbr nmbr continu nmbrd hand pose track use machin learn monado openxr http www collabora com news blog blog nmbr nmbr nmbr continu nmbrd hand pose track use machin learn monado openxr
bjourne-ml,MachineLearning,1617774303.0,[P] Music generation using tracker music in MOD format,link http modmusicgen com hi work project gener music use neural network train tracker music mod format tracker music convert simpl intern format make amend train convert midi sound like piano music tracker music would veri much appreci time fill prefer survey also ani question project tri answer thi thread
techsucker,MachineLearning,1617636798.0,[R] Researchers From the University of Toronto and LG AI Research Develop ‘Explainable’ Artificial Intelligence (AI) Algorithm,team research univers toronto lg ai research develop explain artifici intellig xai algorithm algorithm help identifi elimin defect display screen algorithm outperform compar approach industri benchmark wa develop ongo ai research collabor lg univers toronto accord research xai algorithm could appli field primarili requir detail machin learn make decis includ data interpret medic scan summari http www marktechpost com nmbr nmbr nmbr research univers toronto lg ai research develop explain artifici intellig ai algorithm http www marktechpost com nmbr nmbr nmbr research univers toronto lg ai research develop explain artifici intellig ai algorithm paper http arxiv org pdf nmbr pdf
koolaidman123,MachineLearning,1619518931.0,Visformer: The Vision-friendly Transformer,
yusuf-bengio,MachineLearning,1620636756.0,[D] Recent MLP-only architectures plagiarize Jürgen Schmidhuber,hi group wa first show simpl mlp architectur achiev state art perform comput vision benchmark given strong enough data augment nmbr nmbr moreov hi work pioneer use committe e techniqu popular term mixtur expert howev recent fuzz mlp onli architectur hi fundament contribut even worth singl sentenc simpli cancel nmbr better digit recognit committe simpl neural net meier cire gambardella schmidhub nmbr pdf http peopl idsia ch juergen icdarnmbrb pdf nmbr handwritten digit recognit committe deepneur net gpu cire san meier gambardella schmidhub nmbr pdf http arxiv org pdf nmbr pdf
NeitherBandicoot,MachineLearning,1616955264.0,[D] Why some major papers in ML aren't peer-reviewed?,littl bit outsid come life scienc field notic major public field ml peer review strike veri unusu given field paper peer review good blog post understand need publish asap becaus research field move fast preprint exist reason whi could somebodi explain whi peer review appear priorit ml research tri critic way work puzzl confus becaus use see edit took exampl becaus repres question comment suggest
upulbandara,MachineLearning,1619204466.0,[D] How to extend a text classification ML model to work with more than one language?,use product ml text classif train model use custom english text corpu current model work accept level accuraci purpos want extend handl french languag well plan investig follow two approach nmbr french languag corpu therefor would like train new model handl french text nmbr use model train english corpu use third parti languag translat servic googl translat translat french text english befor input ml model would like know thought regard two approach
MediocreMinimum,MachineLearning,1617017494.0,[D] What will the major ML research trends be in the 2020s?,enter new decad hurrah think next nmbr year bring ml research convent accept trend think happen e g deep learn continu eat everyth multi task multi domain learn make shot learn avail domain deep learn slow end sigmoid curv safe ethic explain ai rise hogwash advanc decoupl comput power gari marcu judea pearl win symbol structur causal war deep learn still major breakthrough languag finetun gpt nmbr make big breakthrough theori fundament ml thi decad applic healthcar final deploy model beat logist regress
PhYsIcS-GUY227,MachineLearning,1619445711.0,"[P] Integrating Git, DVC, and MLflow into one",hey r machinelearn one creator dagshub http dagshub com want share someth cool work dvc dvc org http dvc org mlflow mlflow org http mlflow org two open sourc project veri wide adopt specialti dvc excel data version mlflow use mani thing actual multipl tool combin one mainli experi track capabl tool built tradeoff sinc open sourc set storag dvc central track server mlflow pain requir creat cloud account add permiss dagshub alreadi integr dvc sens whenev creat project come free built dvc remot sinc last week also get free mlflow server mean log experi directli dagshub share team colleagu http redd edvlunmbrxivnmbr gif whi think thi awesom nmbr zero setup add mlflow remot server uri log experi nmbr access control built team peopl need access onli view experi log new one easili control nmbr better ui comparison one complaint mlflow user wa inabl compar run across experi mlflow dagshub easili possibl run appear singl list filter fit onli singl experi nmbr integr mlflow dvc lot peopl work system build ad hoc system integr thi integr creat project wa built thi type work integr tool need detail blog post http dagshub com blog launch dagshub integr databrick mlflow engin built thi love hear thought
mildlyoverfitted,MachineLearning,1618130003.0,[P] Growing Neural Cellular Automata - Implementation and explanation,hey made video tri explain implement articl grow neural cellular automata nich topic howev find fascin hope could find use origin articl http distil pub nmbr grow ca http distil pub nmbr grow ca video http youtu nmbracbwofnmbroo http youtu nmbracbwofnmbroo
temakone,MachineLearning,1617020121.0,[R] Swin Transformer: New SOTA backbone for Computer Vision🔥,swin transform new sota backbon comput vision ms research asia new vision transform architectur call swin transform serv backbon comput vision instead cnn whi two main problem usag transform comput vision nmbr exist transform base model token fix scale howev contrast word token visual element differ scale e g object vari size scene nmbr regular self attent requir quadrat imag size number oper limit applic comput vision high resolut necessari e g instanc segment main idea swin transform nmbr hierarch featur map level hierarchi self attent appli within local non overlap window size window progress increas network depth inspir cnn thi enabl build architectur similar featur pyramid network fpn u net dens pixel level task nmbr window base self attent reduc comput overhead overal architectur consist repeat follow block split rgb imag non overlap patch token appli mlp translat raw featur arbitrari dimens appli nmbr consecut swin transform block window self attent block window size second block use shift patch _size nmbr window allow inform flow non overlap window downsampl layer reduc number token merg neighbor patch nmbrxnmbr window doubl featur depth http preview redd xtjhyflalypnmbr png width nmbr format png auto webp bnmbrfnmbrbnmbrenmbrbanmbrenmbrffnmbrcnmbrd http preview redd znmbrznmbrycclypnmbr png width nmbr format png auto webp nmbrenmbrbnmbrbnmbrfbnmbrdanmbrbenmbrbnmbrdanmbrbacdnmbrbnmbrdcnmbr result outperform sota signific margin coco segment detect task adenmbrk segment compar accuraci efficientnet famili imagenet nmbrk classif faster http preview redd giwnmbrnznmbrdlypnmbr jpg width nmbr format pjpg auto webp dnmbrebnmbrenmbrddnmbreenmbrenmbrcnmbrdnmbrfbnmbrdnmbrbnmbra conclus transform super flexibl research start inject transform induct bias similar cnn e g local connect featur hierarchi thi seem help tremend paper http arxiv org ab nmbr http arxiv org ab nmbr code promiss soon http github com microsoft swin transform http github com microsoft swin transform tl dr blogpost http xzcode github io post paper review swin transform http xzcode github io post paper review swin transform join telegram channel gradient dude http gradientdud miss latest post like thi http gradientdud http gradientdud
Kaleidophon,MachineLearning,1616769467.0,[P] deep-significance: Easy and Better Significance Testing for Deep Neural Networks (link below),hey recent becom somewhat frustrat ml dl paper highlight score onli stem singl run result tabl claim approach superior onli outperform margin thi whi implement test packag statist signific test propos dror et al nmbr specif tailor toward neural network also ad inform statist signific test appli mention test common scenario face ml practition http github com kaleidophon deep signific http github com kaleidophon deep signific veri happi receiv feedback commun improv thi help move field forward
cloud-native,MachineLearning,1616368252.0,[D] How would you migrate a DS team from HPC cluster to the cloud,want ask could point resourc success move ds team cloud could share experi team compani work team nmbr old school analysi folk stat natur scienc background need move prem setup microsoft azur research team ml research domain specif research use hpc ssh connect vscode easili use dask run distribut process via slurm unix filesystem etc best cloud setup team peopl research organ big tech compani give ds team member freedom run ani comput instanc want run pool comput instanc ds team ssh run kubernet cluster use ak use azur ml offer even though much ml someth els reli heavili cli tool vscode jupyt onli solut option us ani pointer would greatli appreci
yusuf-bengio,MachineLearning,1616767299.0,[D] Dilemma: Mathematically wrong ICML submission got extremely good reviews,tangenti involv icml submiss research group differ institut initi review realiz main theorem work base mathemat object wrong anyon work thi subfield find counterexampl violat theorem pretti straightforward howev none review found error theori even prais paper high score definit accept wa involv thi work onli veri begin e g lay idea roadmap never thoroughli read theoret part paper befor submiss proof exploit subtl differ two definit concept older vs newer literatur moreov final paper use grandios mathemat notat make error harder spot opinion even appear choic mathemat write style use conflict definit made deliber problem though interven pi read beyond abstract phd student respons proof known narcissist tendenc piss want risk career becaus pi quit bigshot field student extrem well connect fang compani best friend top nmbr research wa think quit worst thing happen research realiz error publish counter paper disprov furthermor feel onli one thi particular kind dilemma doe anyon experi situat like mine updat thank feedback situat mani suggest wrote discuss counterexampl co author dure discuss realiz three thing nmbr come counterexampl see violat main claim straightforward origin thought took even student wrote proof quit realiz might issu nmbr student pi still convinc correct main theoret result cite good review addit evid claim correct main argument proof use primarili exist theorem literatur correct reformul mathemat express thu someth wrong claim must come theorem proven literatur alreadi wrong nmbr submiss withdrawn icml co author intend chang paper
Rokossowsky,MachineLearning,1618739918.0,[D] In what order should one read self-driving related papers?,hi read book dl self drive like delv paper found thi list http paperswithcod com task autonom drive http paperswithcod com task autonom drive go top rate first would guy suggest logic order understand thing thank rokossowski
kakushka123,MachineLearning,1618324760.0,[D] How is Tesla autopilot trained?,listen thi podcast howev sure understood correctli understand big nn doe anyon know architectur train scratch befor everi releas set milion imag handchosen human evolv time e g imag taken taken base interact model fleet car like human correct etc correct
Sirisian,MachineLearning,1619820302.0,[R] DINO and PAWS: Advancing the state of the art in computer vision with self-supervised Transformers,http ai facebook com blog dino paw comput vision self supervis transform nmbrx effici train http arxiv org ab nmbr http github com facebookresearch dino http arxiv org ab nmbr http github com facebookresearch suncet dino research show model automat learn class specif featur lead unsupervis object segment paw method semi supervis learn build principl self supervis distanc metric learn paw pre train model minim consist loss ensur differ view unlabel imag assign similar pseudo label
TheHentaiSama,MachineLearning,1620115041.0,[Discussion] Model to predict a class for a signal based on simpler signals,hello everyon work someth struggl find good solut make simpl let say origin signal compos simpler signal make predict simpler signal use model random forest classifi need make predict origin signal problem signal compos ani number simpler signal impact final result tri simpl method consist major vote make predict simpl signal decid class origin signal major vote result bad question doe anyon know model handl task know litteratur could help thank advanc
schienal,MachineLearning,1618586669.0,[N] Probabilistic ML @ Tübingen is restarting!,http www youtub com watch v ubavgdnmbrlfi list plnmbrumpnmbrrnmbrijnmbrthaofynmbrmnmbruxnmbrjnmbranmbrynd http www youtub com watch v ubavgdnmbrlfi list plnmbrumpnmbrrnmbrijnmbrthaofynmbrmnmbruxnmbrjnmbranmbrynd anyon think start discord server studi along cours pace
NominalNom,MachineLearning,1619809526.0,[D] A recent history of my pointless stare down with Nvidia which I lost,quick comic summari experi tri get gpu sinc prior launch amper card work film post product prior deep learn code experi want gpu lot memori process high imageri exist tensorflow base open sourc toolset could figur use small amount python experi secur titan rtx amazon retail price decid return found immin releas amper card becaus nmbr sound lot better nmbr cours nmbr go around price nmbrk rrp paid rtx titan wa veri naiv exact moment fact crypto mine wa go go back full swing although wa warn someon thi veri sub expect eth proof stake cancel yet besid avail issu wa also size nmbr nvidia seem intentionali made huge fit typic deep learn rig graphic workstat problem get third parti blower card find one stock whoop nvidia kill alright look one rinki dink third parti rgb gamer card suffici low profil onli need one card nmbrgb vram okay sold forev get one may expens previou titan mayb best get anmbr anmbr becaus tbh seem like go rrp make huge step inflat nmbr price better support linux imo found lhr card though ship soon also may nmbr lhr seem like suppli necessarili improv proprietari gui base toolset develop use pytorch back end still recommend nmbrgb realli want memori wise without need slice input imag much thi issu go anywher manag get nmbr super nmbrgb interim card realli bare minimum also comic much card go glad snag one last one best buy nmbr rrp last year
vishnu_subramaniann,MachineLearning,1616496654.0,"[P] Jarvislabs.ai - An Affordable GPU Cloud with Fast launch, Pause and Resume. Scale GPUs post creation. A100/RTX6K/RTX5K",last year learn practic deep learn particip sever kaggl competit medal dure year tri sever cloud platform premis system offer simplic flexibl afford veri none offer one platform struggl differ platform know would need dl research gave birth jarvislab ai http jarvislab ai aim simpl afford along friend start work thi project year back due covid execut project becam challeng first time entrepreneur underestim complex problem hand persist abl launch beta version product decemb nmbr amaz feedback earli adopt abl make product smoother would love invit come tri platform featur nmbr nmbr click jupyt lab nmbr second nmbr paus instanc resum left nmbr ssh instanc nmbr scale gpu storag chang gpu type resum nmbr auto paus use jarviscloud paus code catch good night sleep model train nmbr pay per usag minut bill first nmbr minut nmbr competit price lowest knowledg price gpu type gpu ram price hr rtx nmbr nmbr gb nmbr rtx nmbr nmbr gb nmbr anmbr nmbr gb nmbr talk us happi assist spin first instanc mani use one platform reach us nmbr chat option cloud jarvislab ai nmbr email us hello jarvislab ai mailto hello jarvislab ai nmbr comment come long way understand lot ha done list upcom product featur http github com jarvislabsai jarviscloud chitchat discuss deep learn ai evolv would use cloud platform could evolv come year understand thi develop open constantli keep touch user pleas help us shape jarvislab ai http jarvislab ai ani valuabl suggest feedback
olegranmo,MachineLearning,1618557871.0,[Research] Tsetlin Machine Interpretability and Accuracy in NLP Significantly Boosted Using GloVe Synonyms,tsetlin machin boolean bag word boost glove synonym http preview redd nmbrjsnmbrwbbnmbrlhtnmbr png width nmbr format png auto webp nmbrdnmbrfnmbrbfenmbrabaadnmbrafnmbrbcnmbrfnmbrcnmbrdnmbrfnmbrcnmbr use glove obtain synonym enhanc boolean bag word use tsetlin machin nlp ad synonym help tsetlin machin produc fewer semant power rule boost accuraci nmbr thi make transpar interpret rule competit deep learn base nlp model http arxiv org ab nmbr http arxiv org ab nmbr
cents_less,MachineLearning,1618511530.0,[P] Announcing Feast 0.10: The simplest way to serve features in production,hey folk last two year work open sourc featur store call feast idea behind feast help operation featur mean help build train dataset offlin featur help load featur onlin store structur way provid low latenc access featur product origin design feast wa heavi weight need run big stack kubernet spark chat bunch user one thing kept hear wa saw valu feast production data wa heavi weight put lot energi toward realli simplifi feast made easi pip instal run feast local get start develop test also deploy cloud provid like gcp want someth scalabl love download tri project got slack workspac join get involv ask question also hate star github either announc http feast dev blog feast nmbr nmbr announc http feast dev blog feast nmbr nmbr announc web site http feast dev http feast dev github http github com feast dev feast http github com feast dev feast slack http slack feast dev http slack feast dev
ottawalanguages,MachineLearning,1618970325.0,"[D] ""no free lunch"" vs neural networks",read theorem call free lunch theorem state singl algorithm better algorithm thi somewhat obviou complex algorithm perform better complex problem simpler algorithm perform better simpler problem thi said whi neural network base algorithm accept main type algorithm solv complex real world problem apart simpl answer observ simpli perform better problem look neural network e g mlp lstm cnn reffer mathemat properti neural network could attribut success whi use neural network instead regress model certain prespect neural network defi free lunch theorem
Andrew_the_giant,MachineLearning,1618067692.0,[D] SARIMAX - Achieving Stationarity first?,newbi forecast havn abl find answer thi question yet thi question relat arima type model onli use hyper paramet grid search find best pdq pdq paramet need differ dataset first use paramet model achiev stationar assum use correct paramet
pcaversaccio,MachineLearning,1617613213.0,[R] Dodrio: Exploring Transformer Models with Interactive Visualization,
DaBeastGeek,MachineLearning,1616594581.0,"[D] What are some non transformer based, NLP models?",curiou ani well regard model reli transform look someth prefer small paramet wise test edg devic lot state art thing see huge even smallest model albert ha someth like nmbr million param ani help veri much appreci
PM_ME_UR_FAV_THINGS,MachineLearning,1619476926.0,"[D] Open Source Nudity/NSFW Classification Review, any suggestions?",hello review open sourc model nuditi nsfw content classif label doe anyon recommend project worth check googl alreadi wa hope might know nich
othotr,MachineLearning,1616651494.0,[R] Minimum-Distortion Embedding,
du_dt,MachineLearning,1618371964.0,[D] Internship at Huawei - your experience?,internship huawei particular ml research posit wa experi would recommend friend huawei activ expand late particular canada top nmbr r spend link http www newswir ca news releas huawei canada rank nmbrth overal corpor r amp spend canada nmbr html seen lot intern posit activ hire experi huawei cheer
ykilcher,MachineLearning,1617114145.0,"[D] Machine Learning PhD Survival Guide 2021 (Video) | Advice on Topic Selection, Papers, Conferences & more! - by Yannic Kilcher",http youtu rhqpbqmulxo http youtu rhqpbqmulxo hi everyon let know think thi thi video advic new phd student field machin learn nmbr field ha shift dramat last year navig grad school veri hard especi clueless wa start video person recount mistak learn alreadi sever publish paper know thi video howev even sure start select topic goe paper might benefit thi video becaus exactli felt main takeaway select nich topic rather hype topic write paper reject discourag bad review take review teach serious keep focu confer network internship great opportun team complementari skill work hard outlin nmbr nmbr intro overview nmbr nmbr thesi topic select nmbr nmbr publish paper nmbr nmbr deal review nmbr nmbr review nmbr nmbr take teach serious nmbr nmbr maintain focu nmbr nmbr navig confer nmbr nmbr internship nmbr nmbr collabor nmbr nmbr forget enjoy transcript http www notion yannic kilcher phd surviv guid transcript cnmbrabnmbrenmbrenmbrfbbnmbrcdfdbnmbrdnmbra http www notion yannic kilcher phd surviv guid transcript cnmbrabnmbrenmbrenmbrfbbnmbrcdfdbnmbrdnmbra
sobe86,MachineLearning,1617750723.0,[D] Samy Bengio resigns from Google,sourc bloomberg http www bloomberg com news articl nmbr nmbr nmbr googl ai research manag sami bengio resign email staff archiv fo link http archiv fo yynmbrai n b sami yoshua bengio brother co found googl brain co author origin torch librari wa timnit gebru manag dure drama end last year directli refer thi hi email today time voic hi support http www facebook com stori php story_fbid nmbr id nmbr shock happen februari ethic ai group wa reshuffl cut sami respons http twitter com alexhanna statu nmbr reuter report http www reuter com articl us alphabet googl research bengio googl ai scientist bengio resign colleagu fire email iduskbnnmbrbtnmbrjt though mention fire hi farewel note influenc hi decis resign peopl familiar matter said speak condit anonym
KirillTheMunchKing,MachineLearning,1619877241.0,[D] An Image Is Worth 16X16 Words: Transformers For Image Recognition At Scale - Vision Transformers explained!,imag worth nmbrxnmbr word transform imag recognit scale http casual_gan nmbr thi paper late nmbr author propos novel architectur success appli transform imag classif task model transform encod oper flatten imag patch pretrain veri larg imag dataset author abl show great result number smaller dataset finetun classifi top transform model detail http casual_gan nmbr vit model architectur overview http preview redd nmbrknmbryszkiwnmbr png width nmbr format png auto webp nmbrenmbranmbrcnmbrfanmbrdnmbrdnmbrbnmbracnmbrfbenmbr nmbr minut paper explan http casual_gan nmbr arxiv http arxiv org ab nmbr
mippie_moe,MachineLearning,1618432999.0,[D] Lambda GPU Benchmark Center for Deep Learning,gpu benchmark machin learn http lambdalab com gpu benchmark thi ongo project lambda continu add new gpu popular model releas suggest new model ani feedback would much appreci
hotpot_ai,MachineLearning,1617318941.0,[R][D] CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation,
ancientmooner,MachineLearning,1616904933.0,[R] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,transform make previous satur coco adenmbrk benchmark unblock creat new sota coco adenmbrk coco det http paperswithcod com sota object detect coco nmbr map nmbr map coco inst http paperswithcod com sota instanc segment coco nmbr map nmbr map ade seg http paperswithcod com sota semant segment adenmbrk val nmbr miou nmbr miou thi paper present new vision transform call swin transform capabl serv gener purpos backbon comput vision challeng adapt transform languag vision aris differ two domain larg variat scale visual entiti high resolut pixel imag compar word text address differ propos hierarch transform whose represent comput shift window shift window scheme bring greater effici limit self attent comput non overlap local window also allow cross window connect thi hierarch architectur ha flexibl model variou scale ha linear comput complex respect imag size qualiti swin transform make compat broad rang vision task includ imag classif nmbr top nmbr accuraci imagenet nmbrk dens predict task object detect nmbr box ap nmbr mask ap coco test dev semant segment nmbr miou adenmbrk val perform surpass previou state art larg margin nmbr box ap nmbr mask ap coco nmbr miou adenmbrk demonstr potenti transform base model vision backbon arxiv http arxiv org pdf nmbr pdf code http github com microsoft swin transform
clint9smith,MachineLearning,1616875481.0,[Discussion] How to create a team recommender when team sizes can change,tri use user item rate tripl svd recommend model user phase project item team rate team rate issu tri solv recommend team team size chang phase phase could recommend role team separ user item rate tripl role person person _rate best team necessarili best person role put togeth
broutonlab,MachineLearning,1619605595.0,[D] How do you manage Data Science experiments?,prepar overview http broutonlab com blog data scienc experi manag weight bias platform practic exampl googl colab http colab research googl com drive nmbrefnmbrynmbremyjelxlnmbrqnmbrrgwfpnmbrrsiaqykt usp share use w b platform manag experi techniqu tool use manag data scienc experi work
petersonsass,MachineLearning,1618921963.0,[D] Why solving the vanishing gradients problem?,often said recurr neural net vanish gradient problem understand right current hidden state less depend distant hidden state wrong thi argument realli want hidden state depend equal
legoonest,MachineLearning,1617351719.0,[P] VinDr Lab - an open-source annotation platform for Medical AI,depart medic imag vinbigdata ha decid releas dicom annot tool open sourc call vindr lab web base tool allow multipl annot work time remot thi softwar use build dataset kaggl competit http www kaggl com c vinbigdata chest xray abnorm detect follow releas larg scale dataset vindr cxr thi next contribut data share well tool ai develop encourag commun promot data share tool drive ai research develop hope somebodi find use enjoy send feedback tool publicli avail http github com vinbigdata medic vindr lab http github com vinbigdata medic vindr lab vindr lab dicom viewer http preview redd gyenmbrbnmbrvpqnmbr png width nmbr format png auto webp nmbrenmbrenmbrfnmbrfcnmbrfdnmbrfnmbrbnmbranmbradbanmbranmbrcnmbref
retro_var,MachineLearning,1619635905.0,[D] Books or Articles in Tree Based Methods with Formal Mathematics?,hi search book articl explain tree base method random forest gradient boost etc extens mathemat theori background onli similar book found wa classif regress tree brieman friedman nmbr http www amazon com es leo breiman dp nmbr glad could recommend new inform thank
muzammal-naseer,MachineLearning,1617009271.0,[R] On Generating Transferable Targeted Perturbations,studi strengthen target perturb otherwis featur neural network context transfer pattern one model anoth broaden definit black box inform avail attack analyz transfer unknow target model unknow train mechan unknown decis space unknown input process http arxiv org ab nmbr http arxiv org ab nmbr pretrain gener avail http github com muzamm naseer ttp http github com muzamm naseer ttp also track progress transfer target attack within easi follow set result updat within day http github com muzamm naseer ttp track sota target transfer http github com muzamm naseer ttp track sota target transfer
Yuqing7,MachineLearning,1620402702.0,[R] MIT & IBM 'Curiosity' Framework Explores Embodied Environments to Learn Task-Agnostic Visual Representations,research team mit mit ibm watson ai lab propos curiou represent learn crl framework learn understand surround environ train reinforc learn rl agent maxim error represent learner gain incent explor environ quick read mit ibm curios framework explor embodi environ learn task agnost visual represent http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper curiou represent learn embodi intellig arxiv http arxiv org pdf nmbr pdf
pcaversaccio,MachineLearning,1617532776.0,[R] Labels4Free: Unsupervised Segmentation using StyleGAN,
TheRealMarqupe,MachineLearning,1620562851.0,CNNs Color Invariance [Discussion],want detect specif object ani color exampl car train model imag contain onli black gray car perform model predict wors imag contain car differ color one use train exampl model fail classifi correctli car present imag imag contain yellow car best way achiev color invari explan exampl credibl sourc refer would much appreci thank
prathameshpck,MachineLearning,1619130146.0,Is fine tuning twice a viable thing to do?? [D],know thi right place ask thi goe say dataset veri sampl manag find anoth dataset someth similar larger would make sens finetun twice e first second larger dataset fine tune smaller one
dDW5ia5j,MachineLearning,1617178321.0,"[P] Generic template to bootstrap your PyTorch project with PyTorch Lightning, Hydra, W&B, DVC, and Streamlit",link http github com lucmo nn templat gener opinion templat bootstrap pytorch project avoid write boilerpl code pytorch lightn lightweight pytorch wrapper high perform ai research hydra framework elegantli configur complex applic dvc track larg file directori ml model think git data weight bias organ analyz machin learn experi streamlit turn data script shareabl web app minut
NumiAI,MachineLearning,1616346275.0,[D] Barlow Twins: SSL via Redundancy Reduction,paper http arxiv org pdf nmbrvnmbr pdf http arxiv org pdf nmbrvnmbr pdf author jure zbontar li jing ishan misra yann lecun stéphane deni thi recent publish work self supervis learn base simpl idea yet yield amaz result like read paper got interest read barlow redund concept neurosci interest fact came across barlow public back nmbr revisit hi opinion redund reduct http preview redd sueixtaiweonmbr jpg width nmbr format pjpg auto webp nmbrdfcenmbrcnmbrbfdnmbrcanmbranmbrcnmbrfnmbranmbrfcnmbrc http preview redd tcnmbrjnmbrxpvweonmbr jpg width nmbr format pjpg auto webp nmbrfenmbrabnmbrenmbrabnmbrbcnmbrfnmbrdbnmbrdnmbr author paper actual support idea redund reduct understand barlow paper redund increas decreas would like hear opinion thi appar conflict understand thank
l_atze_l,MachineLearning,1620032568.0,[P] MoViNet in PyTorch,tl dr implement movinet pytorch http github com atzenmbr movinet pytorch http github com atzenmbr movinet pytorch current work video recognit found movinet http arxiv org ab nmbr quit interest paper decid implement pytorch sinc code releas tf author use thi architectur onc code weight tf releas bug report comment veri use let know find incoher paper implement well hope thi use someon
jj4646,MachineLearning,1619062368.0,"[D] decline of traditional ""state space models""",seem recurr neural network overtaken tradit state space model time seri model thi becaus tradit state space model requir analyst make certain assumpt system transit differ state wherea recurr neural network consid wide combin state hidden layer deep architectur
igorsusmelj,MachineLearning,1616493351.0,[P] Release of lightly 1.1.3 - A python library for self-supervised learning,releas new version lightli http github com lightli ai lightli valuabl feedback thi subreddit thought might interest updat lightli support model addit simclr moco ad simsiam barlow twin big thank open sourc contributor model byol swav pipelin benchmark http doc lightli ai getting_start benchmark html cifarnmbr show variou framework action use differ train epoch batch size model run well multi gpu setup use pytorch lightn distribut data parallel set curiou hear feedback
chasep255,MachineLearning,1617563283.0,[D] Why not use momentum based optimizer with WGAN?,keep read use ani momentum optim wgan noth read offer explan whi whi use momentum base optim anyon know reason
EscapedLaughter,MachineLearning,1620289418.0,[N] Music Demixing (Audio Source Separation) Competition by Sony | ISMIR 2021,competit http www aicrowd com challeng music demix challeng ismir nmbr utm_sourc reddit utm_medium ml utm_campaign soni featur nmbr baselin open unmix code http github com sigsep open unmix pytorch paper http www theoj org joss paper joss nmbr nmbr joss nmbr pdf http www theoj org joss paper joss nmbr nmbr joss nmbr pdf crossnet umx code http github com soni ai research code tree master x umx paper http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf competit hope serv benchmark variou sourc separ model particip get togeth dure ismir workshop share learn soni also offer nmbr nmbr chf cash prize top particip leaderboard exampl http dnmbrcowzsnmbrinmbrn cloudfront net music demix http reddit com link nnmbrhli video tnmbrorzhnmbrrmgxnmbr player ps thi first post subreddit transgress ani norm apolog
Hi_I_am_Desmond,MachineLearning,1620404887.0,"[D] In Quantum NNs, are the hybrid optimization methods run on classical hardware?",read mani resourc sinc know anyon field start research hope find someon work quantum machin learn mani approach consid common base quantum circuit learn mitarai et al suppos use hybrid hardwar optim comput classic hardwar exampl onli quantum hardwar link paper make clear distinct hardwar run qnn
PK_thundr,MachineLearning,1619199060.0,[D] How to develop a compelling argument for a paper submission?,work certain loss function train dnn unfortun result mediocr sota match sota go process develop compel argument paper simpl set experi accuraci result increment progress alreadi done field realiz thi depend greatli actual work ani kind gener guid principl
CoolThingsOnTop,MachineLearning,1617471222.0,[D][R] Blog Post: Why Are Kronecker Products So Effective?,thi week list iclr nmbr outstand paper wa announc one award paper wa beyond fulli connect layer quaternion parameter hypercomplex multipl nmbr nnmbr n paramet http openreview net forum id rcqdyclnmbrzyk make use kroneck product build new kind nn layer look kroneck product wa pleasant surpris find thi paper list winner decid write blog post point interest connect previou work let know think blog post http santiagnmbrm github io blog nmbr nmbr nmbr whi kroneck product effect html http santiagnmbrm github io blog nmbr nmbr nmbr whi kroneck product effect html
antiquark2,MachineLearning,1618348607.0,"[D] Could this network be used to generate the most attractive image possible? What would it look like... -""ComboLoss for Facial Attractiveness Analysis with Squeeze-and-Excitation Networks""",
No_Effective7572,MachineLearning,1619626129.0,[P] Semi Supervised Segmentation on Graphs using Eikonal Equation with PyOpenCl backend.,hey guy would like share thi project http github com agitoz semi supervis segment graph http github com agitoz semi supervis segment graph doe segment graph applic imag pointcloud run time depend eikon equat graph eikon equat use creat gener distanc manifold classic equat solv use fast march method time depend eikon equat steadi coincid fast march solut basic creat knn graph gpu backend use pyopencl run pde gpu backend hope find interest
shuvob4,MachineLearning,1618401627.0,[R] Drug Target Interaction research using Machine Learning,comput scienc graduat aim pursu master machin learn thesi undergradu would like know inform research hope find guidanc thi post highli interest healthcar machin learn scour internet found drug target interact topic interest dig littl deeper found middl sea view land read paper found understand thing describ field domain knowledg seek anoth topic someon guid topic look read paper understand topic better thank advanc nice day
hardmaru,MachineLearning,1617802883.0,[R] Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences,recent paper fair publish pna http www pna org content nmbr nmbr enmbr find biolog structur function emerg represent languag model train massiv databas protein sequenc summari learn biolog properti sequenc data logic step toward gener predict artifici intellig biolog propos scale deep contextu languag model unsupervis learn sequenc span evolutionari divers find without prior knowledg inform emerg learn represent fundament properti protein secondari structur contact biolog activ show learn represent use across benchmark remot homolog detect predict secondari structur long rang residu residu contact mutat effect unsupervis represent learn enabl state art supervis predict mutat effect secondari structur improv state art featur long rang contact predict abstract field artifici intellig combin scale data model capac enabl unsupervis learn ha led major advanc represent learn statist gener life scienc anticip growth sequenc promis unpreced data natur sequenc divers protein languag model scale evolut logic step toward predict gener artifici intellig biolog thi end use unsupervis learn train deep contextu languag model nmbr billion amino acid across nmbr million protein sequenc span evolutionari divers result model contain inform biolog properti represent represent learn sequenc data alon learn represent space ha multiscal organ reflect structur level biochem properti amino acid remot homolog protein inform secondari tertiari structur encod represent identifi linear project represent learn produc featur gener across rang applic enabl state art supervis predict mutat effect secondari structur improv state art featur long rang contact predict paper http www pna org content nmbr nmbr enmbr
Artistic-Mushroom974,MachineLearning,1617240597.0,[d] Robotics/ AI PhD Salary Expectations for T1.5 School,junior first year phd student robot ai gtech cs rank ai robot put gtech nmbr us http csrank org index ai vision mlmine nlp ir robot us http csrank org index ai vision mlmine nlp ir robot us seen post nmbr nmbrk total comp post ml ai phd big tech fintech also seen caveat like onli top nmbr mit stanford cmu berkeley school phd http www reddit com r machinelearn comment bwwmhnmbr _do _a _phd _i _not _worth _it _unless _except http www reddit com r machinelearn comment bwwmhnmbr d_doing_a_phd_is_not_worth_it_unless_except question realist salari expect next coupl school top nmbr much wors top nmbr still good prospect nmbr nmbrk offer would low mid high rang also prospect take master rather finish full degre context mani lab school fair outstand amount top confer public iclr neurip icml corl icra money onli reason chose thi rout lot curios possibl ai demand difficult work
_Arsenie_Boca_,MachineLearning,1620455301.0,[D] Worth learning JAX?,recent popular paper vit start use jax implement model mainli use pytorch past wa play thought learn tensorflow alway felt like tensorflow ha lot legaci code convent make kinda unneccessarili complic compar pytorch nmbr googl seem shift jax intern think jax replac tensorflow nmbr regardless worth learn jax nmbr would learn jax higher level api compar torch nn would use like stax flax haiku
memgamemotron,MachineLearning,1617048073.0,[P] Need help figuring out how to print out the sentence and sentence predictions from my google trax neural network model.,begin thi project help school gain experi taken plenti deeplearn ai http deeplearn ai cours help build thi code foundat data chat bot provid chat text angri label happi label go feed model http preview redd iyonmbrsgfgonmbrqnmbr png width nmbr format png auto webp nmbrdnmbrafnmbrbnmbrbeenmbrefnmbrfnmbr next data preprocess includ split data nmbr nmbr train evalu http preview redd qknmbrdnmbrinmbrwonmbrqnmbr png width nmbr format png auto webp nmbrbnmbrenmbrcnmbrcbanmbrbnmbrfnmbrfnmbraacnmbr preprocess text remov special charact space stop word token text like http preview redd kynmbrfnmbrnruqnmbrqnmbr png width nmbr format png auto webp fnmbrfanmbrbacnmbranmbracdnmbrenmbrenmbrfnmbrc next build vocab list like http preview redd qnmbrfnxnmbrbnmbrrnmbrqnmbr png width nmbr format png auto webp nmbraddenmbrddnmbrfdnmbrfanmbrenmbrbnmbrabnmbrcnmbr creat pad tensor sentenc http preview redd nmbrmnmbrvanmbrvrnmbrqnmbr png width nmbr format png auto webp dnmbrbnmbrfenmbrdanmbrenmbrdenmbrdcnmbrfbbnmbrdanmbrdnmbrc afterward creat data gener appli train evalu http preview redd nmbrmzlnmbrytisnmbrqnmbr png width nmbr format png auto webp nmbrbnmbrfnmbranmbrcnmbrdnmbrenmbrfnmbreenmbr http preview redd nmbrfnmbrmnmbrksnmbrqnmbr png width nmbr format png auto webp nmbranmbraanmbrenmbrenmbrenmbreaenmbrfcnmbrdenmbrdnmbrcnmbr http preview redd xknmbrunmbrrrlsnmbrqnmbr png width nmbr format png auto webp dnmbrbnmbrcnmbrfnmbrbfnmbrenmbrfnmbrfnmbrfnmbranmbr http preview redd thqavnmbritsnmbrqnmbr png width nmbr format png auto webp nmbrfnmbreanmbrfafdnmbrdeanmbrednmbranmbrbdnmbr http preview redd wnmbrdnmbryxsnmbrqnmbr png width nmbr format png auto webp nmbrcdbnmbrdbfdfnmbrfnmbradfnmbranmbrcnmbraenmbrf start creat layer forward propag one layer next neigh relu activ function http preview redd hbnmbrczcgftnmbrqnmbr png width nmbr format png auto webp nmbredfbnmbranmbrbnmbrfenmbrcanmbrenmbrcanmbrdbnmbrenmbrenmbrecbf defin dens layer http preview redd rfysjtnmbrptnmbrqnmbr png width nmbr format png auto webp nmbrfnmbrcnmbraefdeanmbrbecnmbrcfnmbrbnmbrfbd http preview redd mmkspnmbrqtnmbrqnmbr png width nmbr format png auto webp nmbrcnmbrfnmbrdnmbrdbnmbrbnmbrenmbraenmbrbaenmbrfnmbr next step defin model use trax combin layer http preview redd nmbrgnmbrcnmbracunmbrqnmbr png width nmbr format png auto webp anmbrbnmbraecefnmbrenmbrdenmbrafnmbrbnmbref http preview redd nmbrswtlcnmbrdunmbrqnmbr png width nmbr format png auto webp nmbrfnmbrcnmbrfnmbrbnmbrdcfenmbrfacnmbrbdnmbrbdefebnmbrab creat train evalu loop help us understand model perform http preview redd pnmbrpnmbrghyiunmbrqnmbr png width nmbr format png auto webp nmbrfenmbranmbrcnmbrdnmbrbfnmbrdnmbrabdnmbranmbrcadnmbrdnmbrfenmbrcnmbr next check model accuraci know pretti low current learn student look improv excit feedback help improv thi model http preview redd nmbrxcgvnmbrgnmbrvnmbrqnmbr png width nmbr format png auto webp nmbrenmbrabnmbrfbnmbranmbrenmbrfnmbrbfnmbranmbrbnmbrbnmbrenmbrednmbr http preview redd gnmbrhqesznmbrvnmbrqnmbr png width nmbr format png auto webp nmbreanmbranmbrbnmbrcfnmbranmbrenmbrfnmbrcnmbrdbnmbrdnmbr see thi model perform nmbr follow code need help tri print observ sentenc follow predict tri get nmbr output predict angri happi label purpos help understand custom either angri happi bot custom experi also identifi interfer need agent http preview redd kajgcwtwvnmbrqnmbr png width nmbr format png auto webp anmbrbnmbrcdnmbrdaanmbrcnmbrenmbrcnmbrcnmbrbbnmbr instead get nmbr predict label thi output look like would greatli appreci ani help welcom ani ml mentor thi project thank look everyon wait hear
weifz,MachineLearning,1617781633.0,[D] How to define Pearl's causality in time series ?,hi recent studi granger causal pearl causal wonder way defin pearl causal time seri relationship granger pearl differ thank lot
PytonRzeczny,MachineLearning,1616604232.0,[D] Wasserstein GAN math,hi could recommend resourc learn math includ wgan paper becaus read think understand titl thi paper want implement thi without know go loss function quit useless
AerysSk,MachineLearning,1619271507.0,"[D] ML researchers of Reddit, what qualifications do you seek in a research applicant that you have not met?",third year undergradu cs student recent appli research train role similar googl brain ai resid compani requir strong math program skill adequ english commun skill countri major languag english surpris interview postdoc research top us univers disclos doe seem like work compani nmbr hour interview schedul next week met real life dear ml research qualif seek applic question ask expect answer
bendee983,MachineLearning,1620405956.0,[R] AttendSeg: super-compact NN for semantic segmentation for edge devices,new neural network develop research darwinai univers waterloo make possibl run semant segment resourc constrain edg devic key highlight model ha nmbr million param comparison refinenet ha nmbrm param precis ha reduc nmbr bit without signific compromis accuraci reduc size model nmbrmb refinenet nmbrmb attendseg use attent condens provid compact self attent model wa gener use gener synthesi ml techniqu explor constraint space provid engin accuraci model size etc creat best model attendseg present cvpr june read stori interview u waterloo professor co author alex wong http bdtechtalk com nmbr nmbr nmbr attendseg deep learn edg semant segment http bdtechtalk com nmbr nmbr nmbr attendseg deep learn edg semant segment full paper http arxiv org ab nmbr http arxiv org ab nmbr
AleksanderPet,MachineLearning,1616496675.0,[R] MDMMT: Multidomain Multimodal Transformer for Video Retrieval,research team lomonosov moscow state univers cooper intellig system data scienc lab moscow huawei r center develop novel multi modal multi domain textnmbrvideo system outperform current state art result e g googl facebook wide use public dataset msr vtt lsmdc video retriev task paper http arxiv org ab nmbr http arxiv org ab nmbr comparison paperwithcod msr vtt http paperswithcod com sota video retriev msr vtt msr vtt nmbrka split http paperswithcod com sota video retriev msr vtt nmbrka lsmdc http paperswithcod com sota video retriev lsmdc updat nmbrth fo april nmbr share model test script provid number paper refin list remov train test intersect scientif commun pleas refer github http github com papermsucod mdmmt
vector_machines,MachineLearning,1617491149.0,[D] Resources for crowdsourcing MCQ based dataset,want crowdsourc dataset mcq format given sentenc user requir pick right option nmbr explor mechan turk seem templat nlp one gener requir hardcod label thi mean creat custom one last emnlp recal crowdaq bit close form want learn cost effici crowdsourc option know ani want spend lot time read doc api ani suggest advic experi appreci
argh_usernametaken,MachineLearning,1618393674.0,[Discussion] which NN architecture is best suitable for analysing the structural data of biomolecules,tri extract mean structur data biomolecul like protein ml method appli thi type data
WigglyHypersurface,MachineLearning,1620230052.0,[D] Making sense of this autoencoder archetecture,look implement architectur thi paper http arxiv org pdf nmbr pdf imput miss data confus coupl point choic made rather encod decod setup thi autoencod add extra gener network troubl pars whi thi necessari desir though also confus input gener input nois mask also input encod handl miss e replac na zero understand correctli miss data imput case mask use loss function zero log likelihood valu data miss correct seem like would simpler standard encod decod setup initi fill miss data random valu resampl predict miss valu end epoch keep train log likelihood miss valu mask way need mask addit input encod gener
techsucker,MachineLearning,1617727196.0,[N] Facebook AI Introduces A New Self-Supervised Learning Framework For Model Selection And Hyperparameter Tuning For Large-Scale Forecasting,research facebook ai recent releas new self supervis learn framework model select ssl ms hyperparamet tune ssl hpt provid accur forecast less comput time resourc ssl hpt algorithm estim hyperparamet nmbr nmbrx faster compar baselin search base algorithm produc accur forecast result numer applic present forecast one signific data scienc machin learn task perform therefor crucial fast reliabl accur forecast result larg amount time seri data manag variou busi time seri analysi use find trend forecast futur valu slight differ hyperparamet thi type analysi could lead veri differ forecast result given model seriou consequ therefor essenti select optim hyperparamet valu summari http www marktechpost com nmbr nmbr nmbr facebook ai introduc new self supervis learn framework model select hyperparamet tune larg scale forecast http www marktechpost com nmbr nmbr nmbr facebook ai introduc new self supervis learn framework model select hyperparamet tune larg scale forecast paper http arxiv org ab nmbr http arxiv org ab nmbr facebook sourc http ai facebook com blog larg scale forecast self supervis learn framework hyper paramet tune http ai facebook com blog larg scale forecast self supervis learn framework hyper paramet tune
Lunavahid,MachineLearning,1620639107.0,[Vault] [Discussion] Is Human in the Loop the New Thing?,recent discuss around ai ethic goe way one concept need human ai pipelin loop even ceo declar worri fact ai push peopl percept judgment eventu make bias ultim question need human loop need surpris algorithm analys outcom result check hidden bias find potenti pitfal even find pattern might use anoth ai system new frontier ai need data perform better data better algorithm recip success sever new achiev let look one applic familiar annot tag imag annot ha never thi access billion imag text audio video annot tag provid solid learn background aia system learn nmbr year ago challeng wa recogn appl number nmbr letter z new challeng identifi spanish hous sunni day next lake sophist need form user mean sophist annot tag learn purpos sophist mean label annot reason need human loop increas
BrettNMartensen,MachineLearning,1618610104.0,[D] Recency versus Frequency in Prediction,neural net built keep track recent next input symbol sequenc use predict next symbol might given familiar sequenc expect happen last time could built keep track frequent next symbol occur build probabl distribut next stimuli base count experienc use highest probabl next stimulu predict doe anyon know ani paper publish compar success rate two approach e recenc versu frequenc predict purpos
janimezzz,MachineLearning,1617183219.0,[N] Deep learning method for generating proteins will speed up drug development,research chalmer univers technolog sweden present way gener synthet protein use gener deep learn new approach ha huge potenti develop effici industri enzym well new protein base medicin antibodi vaccin read http news cision com chalmer r uniqu ai method gener protein speed drug develop cnmbr http news cision com chalmer r uniqu ai method gener protein speed drug develop cnmbr read articl expand function protein sequenc space use gener adversari network http doi org nmbr snmbr nmbr nmbr nmbr natur machin intellig
Candid-Wishbone-692,MachineLearning,1619708153.0,[N] Call for Teachable NLP Challenge,hi found thi excit teachabl nlp challeng look peopl want particip anyon want particip level nlp welcom teachabl nlp challeng free open everyon interest train ai need prepar good idea dataset nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr edt need submit ai model link explan ai good exampl http forum ainetwork ai c ai showcas nmbr http forum ainetwork ai c ai showcas nmbr prize appl store gift card winner interview broadcast ai network youtub channel nmbrk subscrib particip submit info via http form gle xfuunssnmbrheannmbrjthnmbr http form gle xfuunssnmbrheannmbrjthnmbr receiv invit email check teachabl nlp work http forum ainetwork ai teachabl nlp use teachabl nlp nmbr http forum ainetwork ai teachabl nlp use teachabl nlp nmbr watch nmbr minut tutori video http youtu hzujzotnmbrqznmbr http youtu hzujzotnmbrqznmbr
fernauata,MachineLearning,1620097391.0,[R] House-GAN++: A breakthrough in automated floorplan design via Relational Refinement GAN,hous gan breakthrough autom floorplan design via relat refin gan w convolut messag pass joint work autodesk research appear cvprnmbr http www facebook com hashtag cvprnmbr __eep__ nmbr __cft__ nmbr azwymnmbrnnmbrkjnmbrspnmbrqgofqgtldlnmbrdsnnnmbrznmbrungeswnmbrqhjiikhfkkbnchxnmbrefusrxjsmjibaxsjnlpumzgnmbrkupnmbrsunmbrjcohsfxnmbrguvayxjslkcqdyvnhpivzplqitwpcurvxcoopnmbrkrzqusjwdxaedyvr __tn__ nk r video show interact browser demo http reddit com link nnmbrejlo video znmbrenmbrwwnmbrrnmbrxnmbr player arxiv http arxiv org ab nmbr http arxiv org ab nmbr play around http www houseganpp com http www houseganpp com fbclid iwarnmbrynbszda ssrl_awsuofnmbrlljhnmbrnnmbrugggnmbrg unmbrs_xbvnmbrtzeqgbqnmbrcwanmbrznmbr project websit http ennauata github io houseganpp page html http ennauata github io houseganpp page html fbclid iwarnmbrsnmbrcysrvwxnnmbrcgganmbrtnmbrgrlbsrybtbtnmbrvlinmbrmbqa nmbrexnxnmbrxnmbrtxauijua
ykilcher,MachineLearning,1618408423.0,[P] Video: I built a Neural Network in Minecraft | Analog Redstone Network w/ Backprop & Optimizer (NO MODS),http youtu nmbrodhtaipfwi http youtu nmbrodhtaipfwi built analog neural network vanilla minecraft without ani mod command block network use redston wire power strength carri signal one hidden layer includ nonlinear automat backpropag even weight updat outlin nmbr nmbr intro overview nmbr nmbr redston compon explain nmbr nmbr analog multipl redston nmbr nmbr gradient descent squar root comput nmbr nmbr neural network demonstr nmbr nmbr network schema explain nmbr nmbr network learn datapoint nmbr nmbr outro conclus built thi dure seri live stream want thank everyon help cheer chat world save http github com yk minecraft neural network http github com yk minecraft neural network game http www minecraft net http www minecraft net multipli inspir http www youtub com channel uclmzknmbrtlnlxcxchcjujenmbrag http www youtub com channel uclmzknmbrtlnlxcxchcjujenmbrag
human_treadstone,MachineLearning,1616807524.0,[D] Choosing correct baseline model for Metric learning,use match prototyp network perform singl shot learn ssd dataset befor thi want implement baselin keep track improv think nmbr nearest neighbour baselin thi good baselin could find ani github implement nmbr nn ssd case alreadi baselin implemet pleas point resourc
Yuqing7,MachineLearning,1619711797.0,[R] Toward a New Generation of Neuromorphic Computing: IBM & ETH Zurich's Biologically Inspired Optimizer Boosts FCNN and SNN Training,ibm eth zurich research make progress reconcil neurophysiolog insight machin intellig propos novel biolog inspir optim artifici ann spike neural network snn incorpor synapt integr principl biolog grape group respons adjust propag error signal lead improv train time converg accuraci scalabl ann snn quick read toward new gener neuromorph comput ibm eth zurich biolog inspir optim boost fcnn snn train http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper learn deep neural network use biolog inspir optim arxiv http arxiv org pdf nmbr pdf
SuperFX,MachineLearning,1618524699.0,[D] A100 vs. A6000 for sequence learning tasks?,doe anyon first hand experi perform differ nvidia anmbr anmbr gpu larg sequenc task e g use transform awar benchmark lambda ha post wa wonder research group hand experi use real model done benchmark lambda number suggest someth order nmbr speed gain price differenti nmbrx think peopl data wholesal price would use great deal terribl wonder thi hold practic like assembl gpu server use one gpu
_sshin_,MachineLearning,1617440536.0,[D] Short blogpost about EfficientNetV2,http mlpaper com nmbr nmbr nmbr review efficientnetvnmbr smaller model faster train http mlpaper com nmbr nmbr nmbr review efficientnetvnmbr smaller model faster train
Transit-Strike,MachineLearning,1619093209.0,[D] Are we underestimating how important studying theory is?,hear lot discuss peopl essenti say employ univers onli care good project prove know learn cours mean noth go kaggl find cool project work technic true realli undersel import theori could open kaggl repo see everyon use leakyrelu batch norm adam would tempt look youtub video kaggl submiss recreat output doe realli hold weight think tri someth similar manag build decent solut would later github repo logic realli fail tri build someth bigger better though stylegan exampl understand optimis process like need know peopl use batch norm etc etc imposs understand code otherwis even veri similar project found abl apprach nmbrx time better simpl deeplearn ai http deeplearn ai cours sure could cheat way project sound sexi novic know noth ml learn anyth use tf nn everywher find usabl result sure realli
OverLordGoldDragon,MachineLearning,1620238337.0,[P] Fastest wavelet transforms in Python + synchrosqueezing,ssqueezepi nmbr nmbr http github com overlordgolddragon ssqueezepi releas w benchmark cwt xnmbr faster pywavelet cpu xnmbr gpu correct stft also cpu gpu acceler synchrosqueez also see kymatio http github com kymatio kymatio sota timeseri limit data fast differenti nice lectur http youtu nmbreyureyipxg
nivter,MachineLearning,1619874458.0,[P] I created a series of YouTube videos on normalizing flows - mostly inspired from UCB's Unsupervised DL code,
dcpyro,MachineLearning,1616358255.0,[D] Is my idea of a Feature Store wrong?,featur store part enterpris data catalog featur store seem highli nich data catalog miss lot benefit enterpris data catalog data discoveri tool need gener featur discover search data exampl dataset b use gener featur set ab would want know inform search ever come across dataset b data catalog along would benefici code git commit gener featur miss someth
fripperML,MachineLearning,1616589984.0,"[P] New library for performing nested cross validation, optimizing, calibrating and reporting quality of binary classification models",titl say everyth check http github com jaimearboleda nestedcvtrain http github com jaimearboleda nestedcvtrain first python packag sure mani thing could improv find interest pleas let know appreci lot
gtgski,MachineLearning,1619394734.0,[D] VAE but every neuron models a distribution,variat autoencod model ha distinct middl layer neuron activ model unit gaussian ani experi everi neuron model unit gaussian rest layer middl layer
proximauri,MachineLearning,1617872991.0,[D] Model does not learn with more classes.,hi everyon tri train vggnmbr model dataset use transfer learn task face recognit classif softmax first tri onli train nmbr class everyth fine model converg accuraci nmbr howev train model like nmbr class includ first nmbr ident well network doe learn accuraci reach nmbr percent onli could reason thank
ML_WAYR_bot,MachineLearning,1620590405.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 112,thi place share machin learn research paper journal articl read thi week relat research mean elabor give us insight otherwis could interest paper read pleas tri provid insight understand pleas post thing present wiki prefer link arxiv page pdf easili access pdf summari page way around ani pertin link previou week nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr week nmbr http www reddit com nmbrqyjiq week nmbr http www reddit com nmbrxwnmbr week nmbr http www reddit com nmbrildf week nmbr http www reddit com nmbrsnmbrknmbru week nmbr http www reddit com nmbrtnnmbrax week nmbr http reddit com nmbrsnmbrelnmbr week nmbr http reddit com bfsxnmbrz week nmbr http reddit com dnmbrvnonmbr week nmbr http reddit com fnmbrfnmbriq week nmbr http reddit com hltnmbro week nmbr http reddit com knmbrywb week nmbr http reddit com mygnmbrsm week nmbr http www reddit com nmbrsnmbrxqm week nmbr http www reddit com nmbracbnmbrt week nmbr http www reddit com nmbrjwde week nmbr http www reddit com nmbrabnmbri week nmbr http www reddit com nmbrwvjfk week nmbr http reddit com anmbropot week nmbr http reddit com blnmbrov week nmbr http reddit com denmbrhnmbr week nmbr http reddit com fnmbrfsnmbrz week nmbr http reddit com hunmbrzqnmbr week nmbr http reddit com khnmbrnx week nmbr http www reddit com nmbrtnmbrmqm week nmbr http www reddit com nmbrcwfbnmbr week nmbr http www reddit com nmbr week nmbr http www reddit com nmbrd week nmbr http www reddit com nmbrexnmbr week nmbr http reddit com anmbryaro week nmbr http reddit com bqlbnmbrv week nmbr http reddit com dkoxnmbr week nmbr http reddit com ffinmbrb week nmbr http reddit com iaznmbr week nmbr http reddit com kpsxtc week nmbr http www reddit com nmbrubnmbrkw week nmbr http www reddit com nmbrfcnmbrmh week nmbr http www reddit com nmbrhhhb week nmbr http www reddit com nmbrjsnmbr week nmbr http reddit com nmbraluh week nmbr http reddit com adnmbrssz week nmbr http reddit com bwnmbrjmnmbr week nmbr http reddit com drnmbrnca week nmbr http reddit com fnnmbrrnmbr week nmbr http reddit com ijjcep week nmbr http reddit com kzevku week nmbr http www reddit com nmbrxomfnmbr week nmbr http www reddit com nmbrhynmbrur week nmbr http www reddit com nmbrteiz week nmbr http www reddit com nmbrbnmbravnmbr week nmbr http reddit com nmbrtnnez week nmbr http reddit com ainmbrgi week nmbr http reddit com cnmbritkk week nmbr http reddit com dxshkg week nmbr http reddit com fvknmbrjnmbr week nmbr http reddit com isnmbrhjnmbr week nmbr http reddit com lnmbrlvg week nmbr http www reddit com nmbrzcyvk week nmbr http www reddit com nmbrkdnmbrvd week nmbr http www reddit com nmbrdnmbrnbnmbr week nmbr http www reddit com nmbrenmbrfxnmbr week nmbr http reddit com nmbrxnmbroj week nmbr http reddit com apnmbrctk week nmbr http reddit com cdnmbrgko week nmbr http reddit com enmbrnmyk week nmbr http reddit com gnmbreavg week nmbr http reddit com jnmbrxrnmbr week nmbr http reddit com ljxnmbrn week nmbr http www reddit com nmbrtnmbrmo week nmbr http www reddit com nmbrobnmbrdx week nmbr http www reddit com nmbrgngwc week nmbr http www reddit com nmbrhccnmbrc week nmbr http reddit com nmbrjmh week nmbr http reddit com aucinmbrc week nmbr http reddit com cjnmbrkyc week nmbr http reddit com ebnmbrlxk week nmbr http reddit com gcxnmbruf week nmbr http reddit com jnmbrcbf week nmbr http reddit com luqbxl week nmbr http www reddit com nmbrheol week nmbr http www reddit com nmbrrnmbryd week nmbr http www reddit com nmbrjgdva week nmbr http www reddit com nmbrkgcqr week nmbr http reddit com nmbrupnmbrg week nmbr http reddit com azjoht week nmbr http reddit com cpnmbrjex week nmbr http reddit com ehbfst week nmbr http reddit com glmnmbrsv week nmbr http reddit com jhzznmbrv week nmbr http reddit com mnmbrunmbrz week nmbr http www reddit com nmbrkvsu week nmbr http www reddit com nmbrttnmbrcz week nmbr http www reddit com nmbrmnmbrlnmbrv week nmbr http www reddit com nmbrnayri week nmbr http reddit com nmbrnnmbrrt week nmbr http reddit com bnmbrrnmbri week nmbr http reddit com cvdenmbra week nmbr http reddit com entcxi week nmbr http reddit com gunmbrtnmbrd week nmbr http reddit com jqjgonmbr week nmbr http reddit com mfnmbrmnmbru week nmbr http www reddit com nmbrsnmbroa week nmbr http www reddit com nmbrwhnmbrwb week nmbr http www reddit com nmbrpnmbrhanmbr week nmbr http www reddit com nmbrqelnmbrp week nmbr http reddit com nmbrcfnmbr week nmbr http reddit com bakewnmbr week nmbr http reddit com dnmbrgnmbrknmbr week nmbr http reddit com euctyw week nmbr http reddit com hddfnmbrj week nmbr http reddit com jznmbrevt week nmbr http reddit com moynmbrm upvot paper two week ago u kadisonsing http arxiv org ab nmbr http arxiv org ab nmbr u znmbrgnmbrd http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf u fakespotanalysisbot link fakespot analysi http fakespot com product make art artifici intellig make sell art ai blockchain nft awesom ai besid rule fun
cbsudux,MachineLearning,1617622290.0,[D] Anyone deploy DL models with AWS Lambda? Trying to estimate costs,ha anyon deploy dl model aw lambda gpu look find minimum would cost deploy serverless aw lambda mid level gpu tnmbr pnmbr equival http www fixmyphoto ai http www fixmyphoto ai ha deploy serverless react applic aw lambda function handl infer accord github page http github com mathiasgrub pconv kera
WavyShapes,MachineLearning,1618930996.0,[P] Backprop Model Hub: a curated list of state-of-the-art models,hey everyon want share thi model hub http backprop co hub work curat list state art text vision model includ perform benchmark notabl dataset goal make thi conveni space find product readi model fast easi use real world scenario tri keep select focus qualiti quantiti also got open sourc librari http github com backprop ai backprop make use finetun model possibl line code want enabl peopl take advantag latest ml research without need massiv dataset deep learn expertis thi help like see task model let us know love hear peopl thought
Seankala,MachineLearning,1616906465.0,[D] Not able to reproduce SoTA baseline results due to (assumed) package mismatch. How should I go about this?,hi student work research project sota baselin model manag run unfortun perform quit bit lower report paper search around close issu github ha led believ may probabl due packag version mismatch unfortun packag origin implement use rel older version order instal believ downgrad mani driver server current use run experi would advic someon shoe thi first actual project sure proceed use result disclaim whatev achiev origin perform first thank
jnforcer,MachineLearning,1620072239.0,[R] XGBoost works best for intelligent Deep Brain Stimulation,http www biorxiv org content nmbr nmbr nmbrvnmbr smart brain implant revolution neurotechnolog improv qualiti life patient brain disord treatment parkinson diseas pd neural implant deep brain stimul present avenu develop machin learn base individu treatment refin human motor control develop optim movement decod approach predict grip forc base sensorimotor electrocorticographi subthalam local field potenti pd demonstr electrocorticographi combin bayesian optim extrem gradient boost decis tree outperform machin learn approach elucid link dopamin movement code capac pd show neg correl decod perform motor symptom sever medic state final introduc approach leverag wholebrain connectom predict machin learn base decod perform invas neurophysiolog studi provid framework aid develop intellig adapt deep brain stimul
FirstTimeResearcher,MachineLearning,1619818763.0,"[D] ICML Conference: ""we plan to reduce the number of accepted papers. Please work with your SAC to raise the bar. AC/SAC do not have to accept a paper only because there is nothing wrong in it.""",icml confer ha decid lower accept rate nmbr http twitter com tomgoldsteinc statu nmbr accord current meta review statist need rais accept bar pleas coordin ac reduc nmbr accept submiss http twitter com ryan_p_adam statu nmbr
Yuqing7,MachineLearning,1616607343.0,"[N] CMU, Oxford & Facebook Cross-Lingual Vision-Language Model Achieves New SOTA in Zero-Shot Setting",research team cmu oxford facebook ai propos vision languag model train sourc languag appli differ languag without addit annot train data quick read cmu oxford facebook cross lingual vision languag model achiev new sota zero shot set http syncedreview com nmbr nmbr nmbr cmu oxford facebook cross lingual vision languag model achiev new sota zero shot set paper multilingu multimod pretrain zero shot cross lingual transfer vision languag model arxiv http arxiv org pdf nmbr pdf
StellaAthena,MachineLearning,1616370695.0,[P] EleutherAI releases 1.3B and 2.7B GPT-3-style models trained on the Pile,gpt neo http github com eleutherai gpt neo project eleutherai http www eleuth ai ha releas nmbrb nmbrb paramet gpt nmbr style model model train pile http pile eleuth ai nmbr gb curat dataset eleutherai releas januari releas includ nmbr full model code written mesh tensorflow design run tpu nmbr train model weight nmbr optim state allow continu train model eai left nmbr googl colab notebook http colab research googl com github eleutherai gptneo blob master gptneo_example_notebook ipynb show use code base train fine tune sampl model befor peopl inevit get confus thi size gpt nmbr nmbrb model littl smaller gpt nmbr nmbrb model twice big gpt nmbr come varieti size includ nmbrb nmbrb whi chose valu full gpt nmbr model nmbrb paramet edit gotten coupl question thi discord want share follow well best knowledg thi complet list announc autoregress non moe transform model consid public anyon download train model weight free typo say facebook ha train megatron lm model find weight http github com pytorch fairseq tree master exampl megatron_nmbrb amp xnmbrb model size creator public gpt neo small nmbrb eleutherai ye gpt nmbr nmbrb openai ye meena nmbrb googl gpt nmbr nmbrb nmbrb openai gpt neo mid nmbrb eleutherai ye gpt nmbr nmbrb nmbrb openai megatron lm nmbrb nvidia megatron lm nmbrb facebook ye gpt nmbr nmbrb nmbrb openai ture nlg nmbrb microsoft gpt nmbr nmbrb nmbrb openai
,MachineLearning,1617032593.0,[P] NeMo Getting Started. Prototyping Conversational AI Application,hey hope everyon great monday know want let everyon know nvidia ai platform piec use daili nemo nvidia nemo http github com nvidia nemo toolkit build new state art convers ai model nemo ha separ collect automat speech recognit asr natur languag process nlp text speech tt model collect consist prebuilt modul includ everyth need train data everi modul easili custom extend compos creat new convers ai model architectur convers ai architectur typic larg requir lot data comput train nemo use pytorch lightn easi perform multi gpu multi node mix precis train cool collab notebook get start nemo http colab research googl com github nvidia nemo blob rnmbr nmbrrcnmbr tutori nemo_getting_start ipynb show construct toy demo show abil translat russian audio file english neat nemo pipelin divers translat audio file english want use bert nlp task translat english well anyway hope enjoy thi collab book poke around nemo afterward
marcos_pereira,MachineLearning,1620577183.0,[D] Machine Learning Collective is hosting OpenClubHouse: a live discussion open to all featuring researchers from Google Brain and Uber AI Labs. Starts in 40 minutes!,
programmerChilli,MachineLearning,1619010169.0,[R] Rotary Positional Embeddings - a new relative positional embedding for Transformers that significantly improves convergence (20-30%) and works for both regular and efficient attention,thi wa origin discov chines research circul onlin time befor publish preprint http arxiv org ab nmbr meantim eleutherai ha play around found extrem effect across divers rang set size http blog eleuth ai rotari embed none author arxiv paper part eleutherai eleuth interest pure thi work realli well surpris see thi posit embed becom default
chilled_87,MachineLearning,1620064529.0,[P] Reproducible research: Machine learning for credit card fraud detection,ml credit card fraud detect one field publish research unfortun reproduc real world transact data share confidenti reason also believ author make enough effort provid code make result reproduc releas five first chapter book topic aim make first step toward improv reproduc research thi domain http fraud detect handbook github io fraud detect handbook http fraud detect handbook github io fraud detect handbook thi preliminari releas jupyt book format make experi result reproduc open sourc licens publish chapter cover background motiv baselin methodolog forthcom chapter address advanc topic class imbal featur engin deep learn interpret feedback welcom
ispeakdatruf,MachineLearning,1619311145.0,[D] Looking for interesting classification datasets,new techniqu want tri small cardin classif problem sota still ha headroom exampl mnist sinc sota alreadi nmbr xx imagenet number class larg ideal dataset would nmbr class sota nmbr ani interest dataset thank advanc
ilikepancakez,MachineLearning,1618773529.0,[D] Neural Nets (1994),http www teamten com lawrenc write plannmbr html http www teamten com lawrenc write plannmbr html wa colleg interest neural net thi wa written happen later graduat work author thi post academia time believ neural net seen fade trend someth wa cute idea destin work becaus work well enough even comput anyth use person wa fascin know sever peopl kept hope well one quit well known ai neural net research pursu neural net person keep use relat genet algorithm artifici evolut think wa view mix skeptic gener pocket enthusiast gate stori wa probabl share hear academ lawrenc author post incred smart person doubt wa abl see past mani research say btw recent happen across paper nmbr http pageperso lif univ mr fr edouard thiel rech nmbr blum pdf nmbr year ago mention neural network pass wa popular idea time origin paper medial axi transform scroll nmbrnd page nmbr near top consid continu isotrop plane ideal activ granular materi rudimentari neural net ha follow properti point
IborkedyourGPU,MachineLearning,1618497148.0,[D] MLFlow vs ClearML vs Gradient Paperspace,mlop tool scene slightli overcrowd want limit comparison three tool subject requir run prem got hardwar need want cloud easili launch experi experi databas log metric creat plot compar differ experi visual track model perform time easi instal use set experi tracker requir level devop savvi mani data scienc team nice deploy model api endpoint use docker thi thi realli crucial nice hyperparamet tune fine hyperparamet tune reli third parti plugin long open sourc exampl mlflow hydra ax plugin abl handl hyperparamet tune bayesian optim fine open sourc afaik mlflow clearml open sourc gradient mlflow clearml gradient compar respect especi interest comparison mlflow clearml point view outsid seem pretti similar could wrong ofc
darkmabler,MachineLearning,1617811607.0,[D] Models in production - what architecture do you use?,hi new commun ml space time wa curiou everyon around use serv model product right implement project util aw ek nvidia triton infer server project implement thi need handl nmbr thousand concurr request chose ek due scalabl thought done anyon ever use nvidia triton infer server like tensorflow serv
DeepML42,MachineLearning,1618953886.0,[D] Marginal Likelihood vs. Likelihood for Variational Autoencoder,thi discuss http www reddit com r machinelearn comment nmbrqmnmbrag d_how_to_calculate_variational_autoencoder_log comput likelihood vae discuss talk likelihood p x margin likelihood differ margin likelihood likelihood vae comput vae
Megixist,MachineLearning,1619071095.0,[P] Implementation of MADGRAD optimization algorithm for Tensorflow,pleas present tensorflow implement madgrad optim algorithm wa publish facebook ai paper adapt without compromis momentum adapt dual averag gradient method stochast optim http arxiv org pdf nmbrvnmbr pdf aaron defazio sami jelassi nmbr thi algorithm wa first introduc sever peopl request implement tf kera decid thi implement main featur includ nmbr simpl integr everi tf kera model sinc madgrad subclass deriv optimizervnmbr superclass use way ani tf kera optim nmbr built weight decay support nmbr full learn rate schedul support nmbr complet support spars vector backpropag nmbr avail pypi instal import directli ani question concern implement paper welcom check repositori http github com darshandeshpand tf madgrad exampl test case like work consid give star
xEdwin23x,MachineLearning,1619117403.0,"[D] In a scale of 1 to 10 how much importance or thought do you guys put into the SWE and quality of the code in general you're writing when doing experiments? I feel its important but at the same time there's lots of pressure to move fast, so how do you strike a balance in this aspect?",read lot write better code onli becom better swe better ml research person feel realli import write good clear modular reusabl code time fast move natur ml academia least dunno industri push get mvp minimum viabl product thi case model result fast possibl make hard think thing done advanc see even big research group put code look ugli need quit tweak keep chang im curiou opinion thi topic approach thi problem
hardmaru,MachineLearning,1620565245.0,[R] Barlow Twins: Self-Supervised Learning via Redundancy Reduction,
Fun_Huckleberry_8991,MachineLearning,1619411818.0,[P] Reinforcement Learning with multiple simultaneous actions?,hi current work project relat use reinforc learn agent ha larg set possibl discret action exampl given graph n node possibl action choos nmbr n node check stop criteria actual solv dqn howev bottl neck agent onli pick one node step larg n may make runtim increas doe anyon know ani possibl rl method agent pick multipl node one node step thank lot
AugustFR,MachineLearning,1619210772.0,College student created AI artists - the future is here - miragegallery.ai [N],
donjuan1337,MachineLearning,1617368020.0,[D] Modeling class errors,work project post process predict system use ml real valu rank variabl predict thi predict system strategi model system error real valu variabl differ target predict trivial problem regard rank variabl e g nmbr nmbr nmbr nmbr rank seen class unsur model error class variabl ani suggest reason model error make data time invari good sinc data set limit
Equivalent-Choice-75,MachineLearning,1620009742.0,[D] Does Pytorch/TF/Jax work well with M1 GPU?,thi inform surprisingli difficult find onlin sever conflict sourc inform simpl question doe ani pytorch tf jax work mnmbr gpu well nvidia gpu even compar
SomeParanoidAndroid,MachineLearning,1617702239.0,[D] Choosing ML + numerical computations workstation/server,start phd machin learn newli establish lab mainli focus wireless commun task find server workstat get offic budget around nmbr nmbr cours util gpu train model part work involv run numer simul optim algorithm physic model thi sort stuff rest nmbr nmbr peopl deal latter stuff exclus also write code python use numba tensorflow use matlab final constraint base europ supervisor skeptic order us abroad gener due deliveri time extra complex would ideal like someth gener avail supplier anywher lambdalab system nmbr unfortun consid probabl need server concurr code usual take sever hour part priorit especi think get rtx nmbr seem one best vfm gpu dl inmbr ryzen xeon supposedli xeon abl handl multipl job better stay without problem longer look way slower see support ecc memori know ha ani relev field also code could use good cpu thi import dilemma would nmbrgb ram enough would like get nmbrgb may budget think priorit thi liquid cool need server place offic doe dual gpu setup make sens e g nmbrx nmbr seem ridicul spend huge portion budget account everyon plu gener question discuss point game pc workstat opt inmbr alienwar configur hit spec spot avoid would appreci opinion thi workstat solut deep learn compani like ibm lenovo hp e c thi price rang touch realiti offer setup nmbrgb ram pnmbr nmbrgb vram rtx nmbr closest nmbr seri find budget could dream setup lambda lab someth equival linux vs window feel way comfort former kind fear window get way unnecessarili matlab doe support run code remot right
bendee983,MachineLearning,1617032735.0,[D] Algorithms Are Not Enough,algorithm enough provid fresh perspect shortcom current ai system main idea discuss aan current ai system heavili depend represent human engin must discov problem simplifi solut distinct step set input data expect outcom set reward action onli ai algorithm design solv problem lack algorithm solv complic problem algorithm seek discov new problem develop solut without help human review book discuss author herbert roitblat http bdtechtalk com nmbr nmbr nmbr ai algorithm represent herbert roitblat http bdtechtalk com nmbr nmbr nmbr ai algorithm represent herbert roitblat
jayalammar,MachineLearning,1619708819.0,[P] Explainable AI Cheat Sheet (Image + Video),hi r machinelearn creat high level map major categori ml explain method explain ai cheat sheet http ex pegg io http ex pegg io video go http www youtub com watch v ygnmbrqnmbrxnmbrydem http www youtub com watch v ygnmbrqnmbrxnmbrydem larg field thi non exhaust list help orient peopl come domain think improv feedback appreci
Advanced-Hedgehog-95,MachineLearning,1616961935.0,[D] Motivation to use 768 dimensional embeddings from Transformers?,scientif reason transform model nmbr dimension embed even wavnmbrvecnmbr mockingjay model audio nmbr dimension embed
HashRocketSyntax,MachineLearning,1618613481.0,Why do practitioners still use regular tensorflow? [D],look nmbr nn class ha hand loss mix hidden layer optim look tensorflow optim tensorflow loss either point tf kera tf compat vnmbr understand lot practition use tensorflow kera whi thi case use vnmbr vnmbr abl low level fanci footwork layer tri faceti truli seek understand edit takeaway comment custom batch epoch oper perform legaci code embed devic
latticeprep,MachineLearning,1617339115.0,[D] How does stripe use GBT's to find edge similarity?,read stripe blog post find similar account flag fraudul activ http stripe com blog similar cluster make ani sens wonder anyon ha ani idea gbt use adjac list like thi post year risk underwrit team manual compil mani exampl exist cluster fraudul account investig fraud ring use refer cluster train data learn similar function sampl edg group obtain dataset consist pair account along label pair indic whether two account belong cluster use intra cluster edg posit train exampl inter cluster edg neg train exampl edg denot pair account becaus wide varieti featur construct given pair account decid use gradient boost decis tree http en wikipedia org wiki gradient_boost gbdt repres similar model practic found gbdt strike right balanc easi train strong predict power robust despit variat data start thi project want get someth door quickli wa effect well understood properti wa straightforward fine tune variant use xgboost http xgboost readthedoc io en latest one best perform shelf model case structur also known tabular data well develop infrastructur train serv read infrastructur use train machin learn model http stripe com en ca blog railyard train model stripe previou post train model use predict fraudul activ sinc thi model oper pair stripe account feasibl feed possibl pair account comput score across pair instead first gener candid set edg score thi take recent creat stripe account creat edg account share certain attribut although thi exhaust approach thi heurist work well practic prune set candid edg reason number onc candid edg score filter edg select similar score abov threshold comput connect compon result graph final output set high fidel account cluster analyz process manual inspect togeth unit particular fraud analyst may want examin cluster contain known fraudul account investig remain account cluster thi iter process individu cluster grow quickli identifi increas similar fake account fraudster oper creat fraud ring detect shutdown stripe accur cluster model becom identifi new cluster futur found thi baffl realiz gbt could use effect find cliqu graph ha anyon tri thi understand work better realli understand edg candid score past known fraudul edg sens featur space thi
fool126,MachineLearning,1616478880.0,[D] Recent (2021-03) review papers of different areas in the field,motiv recent post share review paper deep gener model compar review vae gan normal flow energi base autoregress model http arxiv org ab nmbr want crowdsourc compil list review paper area thi especi help look catch specif area ever quickli expand field
zeando,MachineLearning,1619902307.0,[R] RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models ( GPT and CTRL Models ),
Lairv,MachineLearning,1618660227.0,[D] How to handle big datasets in computer vision ?,current tri use scannet http www scan net org dataset thi dataset contain lot thing nmbrd model depth imag semant segment etc weight total nmbrtb purpos onli need rgb color imag someth like nmbrgb thi still quit huge moment even download dataset machin seen sever project e g atla http github com magicleap atla make use thi dataset train model possibl download dataset cloud platform edit seem debat whether thi realli big data least scale requir work simpli train mnist although sure thi noth compar train gptnmbr
n31415926535,MachineLearning,1619809245.0,[P] AdapterHub v2: Lightweight Transfer Learning with Transformers and Adapters,hi r machinelearn yesterday releas vnmbr adapterhub http adapterhub ml http adapterhub ml framework make adapt access nlp integr huggingfac transform librari adapt lightweight altern full fine tune pre train transform model par perform onli updat nmbr model weight train adapt modul mb size extract share plug model flexibl composit adapt train differ task e g via stack fuse split adapterhub adapt transform drop replac huggingfac transform adapt support hub nmbr pre train readi use adapt nlp task similar huggingfac model hub minim chang nmbr nmbr line code switch exist transform script adapt train easi load compos train save share adapt support variou transform model bert roberta gpt nmbr bart github http github com adapt hub adapt transform http github com adapt hub adapt transform document http doc adapterhub ml http doc adapterhub ml pre train adapt http adapterhub ml explor http adapterhub ml explor http preview redd fsnmbrbenmnmbrycwnmbr png width nmbr format png auto webp nmbrbanmbrebnmbranmbrfnmbrdnmbranmbrenmbreebdnmbr
eparlan,MachineLearning,1616950375.0,[P] Implementation of DenStream,would like showcas someth work back python implement denstream algorithm http archiv siam org meet sdmnmbr proceed nmbrcaof pdf http archiv siam org meet sdmnmbr proceed nmbrcaof pdf algorithm base dbscan stream data e acquir data onc dure train iter implement found http github com mrparosk pydenstream http github com mrparosk pydenstream ani feedback pleas let know
pianomano8,MachineLearning,1619197053.0,[R] MLC@Home and MLDS: A Dataset for Weight-Space Analysis of Neural Networks,announc mlc home mld tl dr project websit http www mlcathom org http www mlcathom org paper http arxiv org ab nmbr http arxiv org ab nmbr mlc home mlc home volunt base distribut comput project dedic understand explain machin learn model specif neural network collabor project host umbc http www umbc edu sinc juli nmbr thousand volunt train neural network home comput otherwis idl use boinc http boinc berkeley edu framework seti home project less chase sota understand network encod data via inspect mlc home also first ml focuss project use boinc framework mld machin learn dataset gener sinc juli nmbr volunt crunch away creat mld dataset hundr thousand way nmbr million neural network small select shape leav onli weight space variabl releas http www mlcathom org mld html earli version thi dataset public commit make entir dataset avail complet thi past week post preliminari find base thi dataset arxiv http arxiv org ab nmbr summari preliminari find paper given enough sampl ident shape neural network train differ train data show cluster behavior weight space classifi network train dataset high accuraci abl differenti network train backdoor adversari data versu train clean data believ thi largest publicli avail dataset dedic weight space analysi least order magnitud still grow dataset lead sort interest question possibl evalu network via direct inspect weight structur network oppos indirect measur perform observ loss test data mld also captur meta inform train process loss histori hardwar network wa train window llinux amdnmbr armnmbr armnmbr cpu cuda rocm time inform allow even opportun comparison next step mld continu expand mld dataset current dataset consist small rnn nmbr nmbr paramet less ad support cnn current plan support transform arbitrarili size network mld continu grow use resourc commun mlc home ha even larger goal leverag volunt comput capabl multipli mani line research mlc home support multipl project onc mld first mlc home like never outperform tightli coupl cluster train singl larg network forese mlc home use dataset gener mld reproduc robust studi architectur hyperparamet search neuro evolut name commun ha contribut nmbr comput join everi day interest want help mlc home activ see collabor individu contributor comput help mlc home instruct instal client join avail websit research mlc home activ look research collabor interest weight space meta analysi want talk mld improv new project idea could benefit generos mlc home volunt pleas us via email twitter discord love collabor develop data scienc engin run project ha support cut edg legaci hardwar multipl platform easi softwar develop data scienc engin would like help pleas let us know client open sourc written c use pytorch c api comput specif need osx develop port client mac platform mani enhanc make overal websit could also use updat summari veri excit possibl mlc home past nmbr month made real use grow resourc love commun feedback collabor make grow new fun way alway thank volunt make possibl without never would gotten ground mlc home admin websit http www mlcathom org http www mlcathom org forum http www mlcathom org mlcathom forum _index php http www mlcathom org mlcathom forum_index php e mail mlcathomenmbr gmail com mailto mlcathomenmbr gmail com twitter http twitter com mlchomenmbr http twitter com mlchomenmbr gitlab http gitlab com mlcathom http gitlab com mlcathom
giakou4,MachineLearning,1619505394.0,[P] Carotid plaque dataset,recent work thesi applic machin learn techniqu carotid plaqu classifi symptomat asymptomat howev dateset wa provid consist nmbr imag would like possibl better model train howev abl find ani free dateset ha anyon work someth similar
kvfrans,MachineLearning,1617836706.0,[R] StampCA: Growing Emoji with Conditional Neural Cellular Automata,visual http imgur com losnmbrnkv mpnmbr blog post http kvfran com stampca condit neural cellular automata twitter thread http twitter com kvfran statu nmbr basic idea neural ca defin local interact togeth grow global design instead one system one design defin gener system grow mani design thi let us condit neural ca give differ design specif seed stampca model encod design specif inform cell state gener inform network paramet thi mean nmbr grow mani design without retrain nmbr grow design world mani emoji grow one world http imgur com rggxhi mpnmbr stamp emoji circl http video twimg com ext_tw_video nmbr pu vid nmbrxnmbr tnmbrlimifaklyhmnmbri mpnmbr also train gan base stampca thi model use random valu seed grow variou mnist like digit grow fake mnist digit http video twimg com ext_tw_video nmbr pu vid nmbrxnmbr nmbriemnkdnmbriynmbrzhg mpnmbr tag nmbr code replic experi play model thi colab notebook emoji http colab research googl com drive nmbrfbeurymdpgqidplnmbralprmdpvizumnmbrxpg usp share scrollto nmbr_qze_cnmbruphf thi colab notebook mnist http colab research googl com drive nmbrkgyynmbrjebulnmbrbpbvlybwtholvnmbrhrclnmbr
bzlister,MachineLearning,1618695659.0,[P] GAN for text generation,look model train text particular genr produc new text transform exist text style genr use common word phrase awar gan limit success appli text gener due non differenti natur textual data compar imag hope nonetheless someth use thi
Yuqing7,MachineLearning,1620313621.0,[R] Facebook AI Conducts Large-Scale Study on Unsupervised Spatiotemporal Representation Learning,research team facebook ai conduct larg scale studi unsupervis spatiotempor represent learn video work take unifi perspect four recent imag base framework moco simclr byol swav investig simpl object easili gener unsupervis represent learn methodolog space time quick read facebook ai conduct larg scale studi unsupervis spatiotempor represent learn http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper larg scale studi unsupervis spatiotempor represent learn arxiv http arxiv org pdf nmbr pdf
ZeroHour999,MachineLearning,1620499138.0,[R] Emotion Recognition of the Singing Voice: Toward a Real-Time Analysis Tool for Singers,http arxiv org ab nmbr http arxiv org ab nmbr
MushiML,MachineLearning,1620243275.0,[D] Shuffling Batch Normalization in MoCo - Self Supervised Learning Method,hi author mention paper shuffl bn encod fq fk batch normal bn nmbr standard resnet nmbr experi found use bn prevent model learn good represent similarli report nmbr avoid use bn model appear cheat pretext task easili find low loss solut thi possibl becaus intra batch commun among sampl caus bn leak inform resolv thi problem shuffl bn train multipl gpu perform bn sampl independ gpu done common practic key encod fk shuffl sampl order current mini batch befor distribut among gpu shuffl back encod sampl order mini batch queri encod fq alter thi ensur batch statist use comput queri posit key come two differ subset thi effect tackl cheat issu allow train benefit bn use shuffl bn method end end ablat counterpart figur nmbra irrelev memori bank counterpart figur nmbrb doe suffer thi issu becaus posit key differ mini batch past wa unabl understand type inform leak due intra batch commun pleas someon help understand thi point refer sourc thank
ykilcher,MachineLearning,1619799059.0,[D] Paper Explained - Why AI is Harder Than We Think (Full Video Analysis),http youtu uwfvxckuqnmbr http youtu uwfvxckuqnmbr ai commun ha gone regular cycl ai spring rapid progress gave rise massiv overconfid high fund overpromis follow promis unfulfil subsequ dive period disenfranchis underfund call ai winter thi paper examin reason repeat period overconfid identifi four fallaci peopl make see rapid progress ai outlin nmbr nmbr intro overview nmbr nmbr ai spring ai winter nmbr nmbr current ai boom overhyp nmbr nmbr fallaci nmbr narrow intellig vs gener intellig nmbr nmbr fallaci nmbr hard human mean hard comput nmbr nmbr fallaci nmbr call thing matter nmbr nmbr fallaci nmbr embodi cognit nmbr nmbr conclus comment paper http arxiv org ab nmbr http arxiv org ab nmbr
thunder_jaxx,MachineLearning,1619841163.0,[R] Rip van Winkle's Razor: A Simple Estimate of Overfit to Test Data,
Aurora_HF,MachineLearning,1617526327.0,How to handle 2D geo-spatial grid like data samples in ML [D],look problem wherein whole geograph area divid number bin pixel get nxn matrix cover whole region bin pixel ha number paramet featur associ e g number build bin number peopl live bin poverti level bin crime level bin etc thi whole inform repres one sampl train dataset e thi matrix like data differ geograph region correspond label best handl thi kind dataset machin learn task e g ml train nxn grid differ area like thi classifi label unseen test nxn grid think term cnn may repres term channel channel repres associ featur bin suggest http stack imgur com nmbrilhnmbr png http stack imgur com nmbrgaej png
VinayUPrabhu,MachineLearning,1617472489.0,[P] What do you mean when you say X-is-all-you-need? The landscape and the dataset of all the 80 odd ML papers that have made these claims either in their title or in the body of the paper,github http github com vinayprabhu x need http github com vinayprabhu x need thi part paper titl spice survey paper interact cheatsheet embed got accept upcom rethink ml paper iclr nmbr workshop http preview redd qnmbrcwxksnmbryzqnmbr png width nmbr format png auto webp nmbrenmbrdnmbrdnmbrfnmbrbcnmbrdnmbrfebabnmbranmbrbnmbrccdnmbr
Ingvariuss,MachineLearning,1620406896.0,[D] Data Collection Crowdsourcing - How to animate people?,hello start work ambiti ai project would advanc specif field psycholog thing thi project need much data would take around nmbr year collect consist basi idea wa commun quit aliv help collect data wrote thorough document project descript rule data format collect even made littl websit doe work basic need copi past stuff check box gave document two friend read see everyth sound get green light share document around variou social media channel big chunk peopl ran away becaus document wa long fear start attack idea use ai convers conclud idea ai model work goe hood fine background color teach ai work whi need data format option ignor question ha anyon ran someth like thi overcom anim find data collector mind peopl need psycholog knowledg order collect thi data reason intellig tl dr need peopl help collect data scare ai effect crowdsourc project
badge,MachineLearning,1617268644.0,[D] Generalized Additive Models… with trees?,look implement gener addit model work speedili possibl entir end end process start look use c ml net http doc microsoft com en us dotnet api microsoft ml treeextens gam use c sinc nmbr read code bit difficult part fasttre librari clearli tree base implement test simpl sin x model wa dread fastforest regressor much better doe anyon ani insight use refer subject use gam r python never seen non spline base implement befor
thunder_jaxx,MachineLearning,1619753760.0,[R] Sharpness-Aware Minimization for Efficiently Improving Generalization,
ottawalanguages,MachineLearning,1620111466.0,[D] Inevitable Manual Work Required in Machine Learning Projects,feel mani peopl admit ultim signific part mani data mine project e g check data qualiti pars data etc still done manual exampl exampl made relat supervis nlp natur languag process classif suppos nmbr medic report patient contain unstructur text made doctor dure hospit visit given patient report contain text note doctor made patient visit nmbr nmbr report make mention patient bio data e g age gender medic histori etc detail symptom patient experienc long period time e g let say report nmbr word averag problem differ doctor differ style write nmbr report differ anoth human read report human could figur happen patient patient seriou condit let call thi class nmbr non seriou condit let call thi class nmbr thi interest predict futur patient base limit medic note made doctor futur patient problem clear fast way know take nmbr medic report avail label report class nmbr class nmbr exampl class nmbr one doctor could clearli write end report medic test conduct result neg anoth doctor could end report say patient serious consid chang lifestyl eat healthier food benign thi exampl would someon assign label nmbr case without manual read decid inform report correspond seriou condit non seriou condit wa think use someth like sentiment analysi captur mood report use sentiment analysi method inform gaug tone report dark seriou condit light non seriou condit sure thi best way approach thi problem way thi without read report manual decid label end thi interest suppos new patient come first visit doctor make quick note e g patient male nmbr year old nmbr cm nmbr kg non smoker frequent complain chest pain high blood pressur work construct worker take daili medicin acid reflex base quick note nmbr report avail note tri illustr point medic note new patient nmbr report format research predict supervis classif e g decis tree thi patient seriou non seriou condit ps suppos doctor veri detail medic encyclopedia comput thi medic encyclopedia use alongsid nmbr medic report improv predict result
Ingvariuss,MachineLearning,1619513497.0,[P][D] NLP question - Question Answering AI,hey peopl work person project quit challeng one featur user interact open domain question answer chatbot train data provid want model resembl specif person group fed everyth person group wrote said etc mind model answer question nmbr nmbr sentenc need base pure fact thi mean user ask model question like capit franc someth along line existenti question mean life question dabbl nlp world ai nmbr ani pre train prebuilt model could use thi found open sourc pavlov ai librari ha interest one nmbr model would suit thi task best nmbr ani featur watch provid inform biggest part job collect relev data group want model resembl would best practic make data inform also want nmbr group model resembl need train nmbr model filter model learn nmbr categori thank repli question advanc interest project feel free send dm could even collabor thi part project make model great
SQL_beginner,MachineLearning,1620420157.0,"[D] has anyone ever worked on a machine learning model for ""queues""?",ha anyon ever work machin learn model queue suppos bakeri bakeri ha ha n peopl work peopl line q order current work bakeri interest make machin learn model predict long custom wait befor custom order readi long next custom wait befor place order ha anyon ever come across machin learn model predict wait process time seen exampl onlin peopl tri fit exponenti distribut histor wait time see well fit well tri differ k combin ha anyon ever come across instanc machin learn algorithm e g random forest neural network use predict wait time saw someth like thi http arxiv org ab nmbr wa python r code thi paper anyon recommend sourc blog github websit book youtub lectur etc show provid comput code analyz queue use machin learn model thank
aseigo,MachineLearning,1618740258.0,[P] Livebook: Jupyter-style environment for machine learning and scientific computing with Elixir,
_Arsenie_Boca_,MachineLearning,1620480658.0,[D] Multiple fine-tuning steps order,tri maxim perform target task transfer learn onli appli fine tune pretrain model thi task one might also want incorpor sever fine tune step special model target task thi call domain adapt behavori fine tune terminolog see http ruder io recent advanc lm fine tune depend whether data share domain task set target task thi probabl especi help set amount label data specif target task limit domain significantli differ pretrain data e g http www aclweb org antholog nmbr acl main nmbr pdf relat adapt via languag model fine tune step might contain domain adapt via languag model task adapt via task set target task differ domain task adapt via task set target task similar domain target task appli sever fine tune adapt step would one choos order empir test possibl order might feasibl wrong order might make model forget valuabl skill knowledg intuit would roughli order list abov reason order ascendingli similar target task lead best model rule thumb ani literatur investig thi least appli briefli discuss
savoga,MachineLearning,1618414525.0,[D] Advantages of ML approaches for anomaly detection?,advantag ml approach anomali detect isol forest autoencod dbscan etc tradit approach find point situat extrem part distribut
blkpingu,MachineLearning,1616784241.0,[D] Looking for Deep Learning Workstation / Server vendor in Europe / Germany,want buy workstat far onli found lambdawork bizon locat us doe anyon know compani sell workstat server germani least eu
KaleidoscopeBest1569,MachineLearning,1620233329.0,[R] Hierarchical Cross-Modal Agent for Robotics Vision-and-Language Navigation,project webpag http zubair irshad github io project robo vln html http zubair irshad github io project robo vln html pytorch code dataset http github com gt ripl robo vln http github com gt ripl robo vln arxiv paper http arxiv org ab nmbr http arxiv org ab nmbr abstract deep learn ha revolution abil solv complex problem vision languag navig vln thi task requir agent navig goal pure base visual sensori input given natur languag instruct howev prior work formul problem navig graph discret action space thi work lift agent navig graph propos complex vln set continu nmbrd reconstruct environ propos set robo vln close mimic challeng real world navig robo vln task longer trajectori length continu action space challeng obstacl provid suit baselin inspir state art work discret vln show less effect thi task propos decompos task special high low level polici effect tackl thi task extens experi show use layer decis make modular train decoupl reason imit propos hierarch cross modal hcm agent outperform exist baselin key metric set new benchmark robo vln
whyhateverything,MachineLearning,1617030324.0,[P] Passing embeddings to faiss for clustering,hi everyon hard time faiss document cluster embed creat sentenc transform want use faiss cluster part get final list show document belong cluster idea thi faiss precis pass embed would endlessli grate help thank advanc
lifeonahilltop,MachineLearning,1620348179.0,[D] How do companies typically develop ML models for different customers?,work fraud protect industri compani ship fraud protect solut basic binari classifi wrap ui compani e commerc healthcar sector get custom day decid whether want build singl ml model custom ml model engin mlop point view singl model scalabl howev combin data multipl custom train take perform tradeoff differ custom seem straightforward anyon inform thi typic done industri peopl use techniqu like domain adapt assumpt brittl realiti imagin thi common challeng industri ani pointer relev materi case studi etc would greatli appreci
lukasus,MachineLearning,1617900076.0,[P] Mask2Face: How We Built AI That Shows the Face Beneath the Mask,virtual remov face mask see person look like underneath strv machin learn team prove possibl via imag inpaint base ml solut exactli approach problem precondit implement result futur improv masknmbrfac built ai show face beneath mask http www strv com blog masknmbrfac built ai show face beneath mask engin link project github http github com strvcom strv ml masknmbrfac http github com strvcom strv ml masknmbrfac
atif_hassan,MachineLearning,1618641825.0,[P] PyImpetus - A Markov Blanket based new SOTA feature selection algorithm for python,pyimpetu markov blanket base featur select algorithm select subset featur consid perform individu well group thi allow algorithm onli select best set featur also select best set featur play well exampl best perform featur might play well remain featur taken togeth could perform best featur pyimpetu take thi account produc best possibl combin thu algorithm provid minim featur subset decid mani featur take pyimpetu select optim set pyimpetu ha complet revamp support binari classif multi class classif regress task ha test nmbr dataset outperform state art markov blanket learn algorithm along tradit featur select algorithm forward featur select backward featur elimin recurs featur elimin perform comparison classif task accuraci metric higher score better ha use regress task mean squar error metric lower score better ha use final model use comparison task decis tree score report nmbr fold cross valid dataset sampl featur task type score use featur score use pyimpetu featur select featur select ionospher nmbr nmbr classif nmbr nmbr nmbr nmbr arcen nmbr nmbr classif nmbr nmbr nmbr nmbr alondsnmbr nmbr nmbr classif nmbr nmbr nmbr nmbr slice _local _data nmbr nmbr regress nmbr nmbr nmbr nmbr link github repo http github com atif hassan pyimpetu link pypi http pypi org project pyimpetu pyimpetu alreadi ha nmbrk download check pleas let know work machin learn project forget pen feedback doubt comment section cours forget star github repo thank amaz day
Quantum_Stat,MachineLearning,1619531012.0,"The NLP Index: 3,000+ code repos for hackers and researchers. [Project]",want introduc nlp index new asset nlp code discoveri free open public hous nmbr nmbr code repositori one search includ side bar import topic nlp today engin search type typo toler crazi fast index includ arxiv research paper pdf connectedpap link github repo http index quantumstat com
RyanAI100,MachineLearning,1618772283.0,[D] A Rigorous Study on Pretrained Model for NER | Research Papers Summary 014,
pinter69,MachineLearning,1619975673.0,[R] Few-Shot Patch-Based Training (Siggraph 2020) - Dr. Ondřej Texler - Link to free zoom lecture by the author in comments,
NeoDio_02,MachineLearning,1619551730.0,[D] Question on ROUGE scores for evaluating summaries,project text summar want run roug benchmark test summar model one thing confus larg differ score see differ sourc exampl http github com andersjo pyroug http github com andersjo pyroug get roug nmbr f score nmbr thi paper http ieeexplor ieee org stamp stamp jsp tp arnumb nmbr http ieeexplor ieee org stamp stamp jsp tp arnumb nmbr show roug nmbr f score like nmbr someon explain discrep roug score work thank
bert4QA,MachineLearning,1618242156.0,[R] KILT: a Benchmark for Knowledge Intensive Language Tasks,
Yuqing7,MachineLearning,1617673931.0,[N] Yann LeCun Team Uses Dictionary Learning To Peek Into Transformers' Black Boxes,yann lecun team propos dictionari learn provid detail visual transform represent insight semant structur word level disambigu sentenc level pattern format long rang depend captur transform quick read yann lecun team use dictionari learn peek transform black box http syncedreview com nmbr nmbr nmbr yann lecun team use dictionari learn peek transform black box paper transform visual via dictionari learn contextu embed linear superposit transform factor arxiv http arxiv org pdf nmbr pdf
SZenne_,MachineLearning,1617887636.0,What cloud computing setup should I get for my Deepfakes [R],hi graduat project research creation deepfak small budget nmbr would want spend thi nmbr week op cloud comput becaus comput right requir run deepfak softwar want nmbr second basic deepfak test softwar doe anybodi ani recommend onlin cloud comput server could use look
chasep255,MachineLearning,1620298405.0,[D] Learning a discrete encoding for raw audio.,work variou way gener music use neural net start wgan use nmbrd conv produc best result would realli like use rnn gener audio like would gener text sampl output feed sampl back input next time step sinc audio use sampl nmbrhz thi method practic decid first use auto encod gumbel softmax thi way could compress audio data learn discret encod onc thi encod plan train rnn encod like would text use decod convert thi sound current best architectur follow encod compress audio nmbrx discret represent nmbr differ valu hard gumbel softmax encod expand expand expand discret represent back length origin raw audio decod use rnn predict next sampl base prior sampl input expand tri wavenet instead rnn far rnn produc better result care qualiti speed encod nmbr mu law encod input _audio kera input none dtype intnmbr x layer embed nmbr nmbr input _audio x layer convnmbrd nmbr nmbr stride nmbr pad x x layer leakyrelu x x layer convnmbrd nmbr nmbr stride nmbr pad x x layer leakyrelu x x layer convnmbrd nmbr nmbr pad x x layer leakyrelu x x layer convnmbrd nmbr nmbr pad x x layer leakyrelu x x layer convnmbrd nmbr nmbr pad x expand input _data kera input none nmbr e layer convnmbrd nmbr nmbr pad kernel _initi random _normal use _bia fals input _data x layer convnmbrd nmbr nmbr pad e x layer leakyrelu x x layer convnmbrd nmbr nmbr pad e x layer leakyrelu x x layer convnmbrdtranspos nmbr nmbr stride nmbr pad x x layer leakyrelu x x layer convnmbrdtranspos nmbr nmbr stride nmbr pad x x layer leakyrelu x decod prior _audio _input kera input none batch _size nmbr state els none dtype intnmbr expand _input kera input none nmbr batch _size nmbr state els none x layer embed nmbr nmbr prior _audio _input x layer concaten axi nmbr expand _input x x layer timedistribut layer dens nmbr x x layer leakyrelu x x layer gru nmbr return _sequenc true state state x x layer gru nmbr return _sequenc true state state x add expand _input help gradient x layer concaten axi nmbr expand _input x x layer dropout nmbr x x layer timedistribut layer dens nmbr x x layer leakyrelu x x layer timedistribut layer dens nmbr x x layer leakyrelu x x layer timedistribut layer dens nmbr x train r mu law encod audio sampl r _prior r nmbr r r nmbr e encod r train train e _sm tf nn softmax e enc _loss tf reduc _mean e _sm tf math log e _sm nmbre nmbr tf math log nmbr tf cast tf shape e _sm nmbr tf floatnmbr e model gumbel _softmax e nmbr convert e one hot represent e tf stop _gradient model argmaxnmbronehot e e e e expand e train train take random chunk expand output sequenc long also add nois r _prior g decod r _prior e train train sound _loss tf reduc _mean tf kera loss spars _categor _crossentropi r g _logit true total _loss sound _loss enc _loss would like ask thing nmbr think way use gumbel softmax make sens nmbr sinc use hard version gumbel softmax stop _graident still need use temperatur paramet anneal nmbr doe loss function make sens ad enc _loss term output encod add penalti deviat flat distribut figur thi like second term elbo loss function use vae found help model learn use encod nmbr use gumbel softmax mayb make sens use normal softmax alway take argmax figur random add help explor possibl encod nmbr ani thought
glampiggy,MachineLearning,1620164503.0,Is it common for Transfer Learning to decrease the accuracy of a model? [Project],train pspnet deeplab scratch also use pre train backbon veri specif urban scene dataset pre train backbon use wa resnet weight download imagenet dataset train model without freez ani layer accuraci model scratch prove higher model pre train backbon dataset rel small onli nmbr imag could thi happen becaus imagenet dataset gener compar specif dataset work ha thu limit learn abil like done someth wrong
deadmanscurve,MachineLearning,1617728458.0,[Research] How do you train on and evaluate GLUE STS-B?,hello experi multi task learn read literatur around tri benchmark glue task figur peopl train evalu st b http huggingfac co dataset viewer dataset glue label similar score two sentenc rang nmbr nmbr spearman correl use evalu label discret could train classif model comput thi float read train regress model sigmoid activ normal label rang nmbr nmbr thi done lnmbr loss use spearman correl comput exactli thi inform ha surprisingli difficult find standard benchmark dataset ani info gladli appreci
miladink,MachineLearning,1618988935.0,[D]Is im2latex considered solved?,hope know imnmbrlatex dataset openai need infer equat gener latex imag imag found littl surpris actual littl work done read equat imag consid solv problem
minimaxir,MachineLearning,1620230683.0,[N] Wired: It Began As an AI-Fueled Dungeon Game. It Got Much Darker (AI Dungeon + GPT-3),http www wire com stori ai fuel dungeon game got much darker follow drama around ai dungeon thi good summari good discuss filter algo difficulti
IglooAustralia88,MachineLearning,1617224051.0,[P] How Bad is a Bad Classifier: Is there any signal here?,text classif problem classifi song lyric perform artist right small dataset nmbr lyric two line nmbr differ artist train dev test set balanc artist baselin encod lyric observ use bert perform logist regress got nmbr top nmbr nmbr top nmbr held test set sure phrase thi thi classifi anyth worth tri improv origin idea wa compar word level vs subword level nn classifi task like obvious nmbr artist random classifi would nmbr thi nmbrx seemingli ha found signal howev hard look nmbr score think anyth guess question hope find signal thi small amount data thi text classif text thi baselin implement tri tell data veri noisi thu experi hard get signific result thank
Separate_Run2806,MachineLearning,1620376282.0,[D] Tool to help ML Engineering follow code best practices.,hello data scienc team wa involv increas amount ml engin task small knowledg code qualiti best practic made thi vs code extens help python develop build unit test quickli effici ai make suggest input gener test file would love hear feedback give tri avail www ponicod com http www ponicod com unit test implement model ever test code pre process evalu stage
idg101,MachineLearning,1617314266.0,[D] Hyper-parameter tuning takes the majority of my time!,nmbrth year phd student paper publish alreadi come end phd find spend major time hyper paramet tune get best perform possibl thi take forev dual gpu machin doe anyon ani shortcut thi tri tune best nmbr nmbr epoch find thi good proxi long term valid loss converg lifecycl research seem come idea tune network show perform better benchmark thi time seem like complet wast research cycl spent ha better way
Superb-Drawer5214,MachineLearning,1617108593.0,"[D] If the number of machine learning PhD graduate is increasing rapidly, wouldn't it get exponentially harder to be hired at machine learning related jobs without PhD?",seem everyon want machin learn day phd machin learn increas rapidli get harder harder employ machin learn relat job without phd
Yuqing7,MachineLearning,1620141876.0,[R] Huawei & Tsinghua U Method Boosts Task-Agnostic BERT Distillation Efficiency by Reusing Teacher Model Parameters,research team huawei noah ark lab tsinghua univers propos extract distil etd gener flexibl strategi reus teacher model paramet effici effect task agnost distil appli student model ani size quick read huawei tsinghua u method boost task agnost bert distil effici reus teacher model paramet http syncedreview com nmbr nmbr nmbr deepmind podrac tpu base rl framework deliv except perform low cost nmbr paper extract distil effici effect task agnost bert distil arxiv http arxiv org pdf nmbr pdf
opensourcecolumbus,MachineLearning,1617938253.0,[P] BERT-based Financial Question Answering System,built thi product readi project use jina pytorch hug face transform adapt passag rerank approach first retriev top nmbr candid answer rerank candid answer use finbert qa bert base model fine tune fiqa dataset achiev state art result github repo http github com yuanbit jina financi qa search look feedback question would need make use easi use use case
mridal,MachineLearning,1620289195.0,[D] ACL-IJCNLP 2021 Acceptances are out,everyon mine wa accept acl find score nmbr nmbr nmbr
minidiable,MachineLearning,1619767355.0,[D] Object detection - useful resources,hi work new compani drone expert knowledg comput vision main expertis control state estim robot one main macro task new job revolv around topic object detect onboard aircraft small medium larg size know could divid field object detect two main stream data driven approach e g machin learn deep learn base classic approach use classic comput vision howev never implement object detector would realli like know histori main tool use achiev thi could point use resourc like book onlin cours best coursera link mileston paper youtub video channel etc thank
bendee983,MachineLearning,1618849898.0,[D] The challenges of applied machine learning,set data infrastructur break silo creat data lake etc collect clean train data set scalabl network comput cluster deal busi object ethic issu appli machin learn real world applic pose challeng absent academ research set four key challeng appli machin learn includ follow defin problem solv right problem doe align busi object desir accuraci model address special problem ha anyon els solv befor solv pre train model need develop model collect train data public dataset imagenet mscoco etc enough train model probabl buy data alreadi collect alreadi data consolid store silo need clean label data maintain model much model affect decay frequent need retrain model pipelin continu collect maintain data futur gather right team talent hous subject matter expert weigh model perform product manag defin assess busi object machin learn strategi process get input feedback end user system softwar engin integr model exist product staff provid reliabl scalabl infrastructur train infer challeng discuss latest articl challeng appli machin learn http bdtechtalk com nmbr nmbr nmbr appli machin learn challeng http bdtechtalk com nmbr nmbr nmbr appli machin learn challeng find lot real world ai practic guid respons machin learn http appen com real world ai alyssa simpson rochwerg wilson pang
Bitmore11,MachineLearning,1617281029.0,[D][P] Raven Protocol,look ani input raven protocol project raven decentr network comput node util idl comput power ai train speed key thi protocol could benefit besid ad librari anyth thi protocol miss solut problem tri solv experienc machin learn would like input stand benefit raven protocol websit http www ravenprotocol com github http github com raven protocol
Yuqing7,MachineLearning,1617249392.0,[N] Google Research’s Novel High Efficient Neural Volumetric Representation Enables Real-Time View Synthesis,googl research team acceler neural radianc field render procedur view synthesi task enabl work real time retain abil repres fine geometr detail convinc view depend effect quick read googl research novel high effici neural volumetr represent enabl real time view synthesi http syncedreview com nmbr nmbr nmbr googl research novel high effici neural volumetr represent enabl real time view synthesi paper bake neural radianc field real time view synthesi arxiv http arxiv org pdf nmbr pdf
montebicyclelo,MachineLearning,1620460319.0,[P] Patchless MLP-Mixer,http github com sradc patchless_mlp_mix thi preliminari explor even simpler mlp mixer style architectur
Tolstoyevskiy,MachineLearning,1617215508.0,[D] Comparison of experiment tracking tools,hey r machinelearn back publish post compar data version tool http dagshub com blog data version control tool peopl seem find use wrote anoth one compar experi track tool mani option choos make sens consid pro con option http dagshub com blog compar ml experi track tool fit data scienc workflow http dagshub com blog compar ml experi track tool fit data scienc workflow criteria mainli around nmbr want track nmbr data save nmbr visual capabl nmbr easi set nmbr stabl nmbr doe support larg scale experiment usual summari tabl form though articl cours contain detail tabular comparison ml experi track tool http preview redd bnmbrrlshkcqdqnmbr png width nmbr format png auto webp cnmbradeenmbrbeenmbrfnmbrbnmbrfnmbranmbrcbnmbrabnmbr
haipinglu,MachineLearning,1619300697.0,"[P] An introduction to PyKale https://github.com/pykale/pykale​, a PyTorch library that provides a unified pipeline-based API for knowledge-aware multimodal learning and transfer learning on graphs, images, texts, and videos to accelerate interdisciplinary research. Welcome feedback/contribution!",
stupidMZ,MachineLearning,1617940296.0,"[R]Group-Free 3D Object Detector: New SOTA on ScanNet V2(69.1 mAP@0.25, 52.8@mAP@0.5) and SUN RGB-D(62.8 mAP@0.25 and 42.3 mAP@0.5)🔥",group free nmbrd object detect via transform anoth work msra visual comput group paper link nmbr group free nmbrd object detect via transform arxiv org http arxiv org ab nmbr code link zeliunmbr group free nmbrd group free nmbrd object detect via transform github com http github com zeliunmbr group free nmbrd simpl yet effect method directli detect nmbrd object nmbrd point cloud without handcraft heurist point group mechan whi mainstream point base object detector base heurist point group step complex divers object real scene may lead wrong point assign degrad nmbrd object detect perform shown fig nmbr fig nmbr heurist point group step point blue box roi pool blue ball vote assign aggreg deriv object featur result wrong assign group free base approach automat learn contribut point object ha abil allevi drawback hand craft group http preview redd mnmbrrbtnmbrfnmbrlnmbrsnmbr png width nmbr format png auto webp nmbrcnmbrbnmbrbnmbranmbrfnmbrdnmbrcnmbradnmbrenmbrfcnmbranmbrbnmbr main idea nmbr use transform decod model relationship point object point use form featur object weight point automat learn dure train nmbr multi stage iter box predict framework adopt spatial encod refin iter stage nmbr free lunch multi stage ensembl mechan use improv perform overal architectur pointnet use backbon detect head multi stage transform decod shown fig nmbr fig nmbr thi figur illustr simpl architectur approach includ three major compon backbon network extract featur represent point point cloud sampl method gener initi object candid stack attent modul extract refin object represent point http preview redd nmbrqadvidlnmbrsnmbr png width nmbr format png auto webp nmbranmbranmbrbnmbrcccnmbrdnmbrdfnmbrbnmbrdnmbrfbdcnmbrc result veri high perform wa achiev scannet vnmbr sun rgb tabl nmbr result scannet vnmbr http preview redd gahnurnglnmbrsnmbr png width nmbr format png auto webp nmbrafnmbrdnmbrdfefnmbrcnmbranmbrfnmbrdnmbr tabl nmbr result sun rgb http preview redd lsnmbrkckilnmbrsnmbr png width nmbr format png auto webp nmbrabnmbrbnmbranmbrbfafnmbrefddnmbrefnmbrenmbr
giangblackk,MachineLearning,1618393121.0,[R] Time Series Forecasting Survey,find ani thorough survey time seri forecast method benchmark doe anyon suggest
sgevorg,MachineLearning,1616600557.0,[N] Aim 2.2.0 is out! Hugging Face integration and advanced params table management ...,hi r machinelearn commun excit launch aim http aimstack io vnmbr nmbr build open sourc self host tool ai train run comparison handl nmbr experi onc ha simpl straightforward api super easi get start thank incred support help us democrat ai dev tool check new featur play aimstack io http play aimstack io nmbr explor search eyjjagfydcinmbreyjzzxrnmbrawnmbrncyinmbreyjwzxjzaxnnmbrzwnmbrijpnmbrimrpcnmbrbsyxlpdxrsawvycyinmbrzmfscnmbrusinpvbnmbriomnmbrbgwsimludgvycgnmbrsyxrlijpmywxzzswiawnmbrkawnhdgnmbryijpmywxzzswieefsawdubwvudcinmbrinnnmbrzxailcjwbnmbrludhndbnmbrvudcinmbrntbnmbrfswizmnmbrjdxnlzcinmbreyjjaxjjbguionsiywnnmbraxzlijpmywxzzswicnvusgfzacinmbrbnvsbcwibwvnmbrcmljtmftzsinmbrbnvsbcwidhjhynmbrvdbnmbrzxhnmbrijpudwxslcjzdgvwijpudwxsfxnmbrlcjzzwfyynmbrgionsicxvlcnkioijsbnmbrnzlcbibgvnmbriglmighwyxjhbxmubgvhcmnmbrpbmdfcmfnmbrzsahpsawljawmdaxigfuzcbjbnmbrzxhnmbrlnnnmbrynnldcbpbiaodgvzdcwgdmfsksisinyiojfnmbrlcjjbnmbrzxhnmbrrmlsdgvyijpnmbrimdybnmbrvwqnldbnmbrxvciinmbrwyjwyxjhbxmuahbhcmftcynmbrtyxhfayjdlcjncmnmbrcejnmbrunmbrrnmbrbguioltdlcjncmnmbrcejnmbrqnmbrhhcnqiolsibwvnmbrcmljilnmbrsimfnznmbrjlznmbrfnmbrzwqionrydwusimfnznmbrjlznmbrfnmbrzwrbcmvhijoibwluxnmbrhecisimfnznmbrjlznmbrfnmbrzwrmawnmbrlijoibwfnmbriiwicnmbrvlzcinmbreyjjbnmbrxvciinmbrmtasinnnmbrewxlijoxmhnmbrsinblcnnpcnmbrqionsiynmbrsbnmbriiomzhbhnllcjzdhlszsinmbrzmfscnmbrvnmbrfxnmbr highlight thi releas check full releas post http medium com aimstack aim vnmbr nmbr nmbr hug face integr nmbrefanmbreecnmbr nmbr huggingfac integr aim hug face http preview redd wnanmbruqnmbrsvzonmbr png width nmbr format png auto webp bnmbrcnmbrcdenmbrddbanmbrecbnmbrcaanmbrenmbranmbr nmbr metric visibl control hide metric still search hide individu metric well collect http redd nmbrnxdnewiwzonmbr gif nmbr column resiz control screen real estat super long param drag column edg back forth resiz http redd xwnkknmbrikwzonmbr gif yet drop us star support come say hi aim slack commun http slack aimstack io check thi version let us know improv
doyougitme,MachineLearning,1618477849.0,"""[Discussion]"" Should I be using DVC (Data Version Control) in my day-to-day work?",follow dvc org http dvc org yet fulli sold use everyday work dev work ml doe seem unduli clumsi becaus experiment natur work guess sure whether data version problem whether dvc solut freelanc sure stack ml dev look like day curiou know whether dvc form popular part data ml engin stack work individu team uniqu advantag provid ha made life better use whi shortcom made give
questions2067,MachineLearning,1619731841.0,[D] Does anyone here have a career in machine learning that they applied to the medical field?,realli look ask career like learn current undergrad sure want thi topic interest
htahir1,MachineLearning,1617206594.0,[D] Why ML should be written as pipelines from the get-go,thought id share idea whi multi step fragment approach production ml flaw rather creat abstract gear toward data scientist incentiv write product readi code day nmbr happi hear thought commun http towardsdatasci com whi ml written pipelin get go bnmbrdnmbrfnmbr http towardsdatasci com whi ml written pipelin get go bnmbrdnmbrfnmbr
DNA1987,MachineLearning,1619196786.0,[D] 3D CNN how to deal with empty space,hello work nmbrd cnn use voxel repres protein one channel amino acid total nmbr channel lot empti space voxel nmbr channel encod one type amino acid channel even empti like rgb imag channel ha integ gradient posit x current network onli work coupl sampl need much train somehow think could like unbal class problem nmbrd space convolut thing confus
Inferrd_F,MachineLearning,1618153944.0,[P] How to make your Models available ?,creat tool make model avail peopl inferrd com http inferrd com creat api model second put model use right train wast time creat monitor infrastructur creat engag demo show user model real condit whi interest drag drop deploy model simpl afterward call jupyt notebook ani ide whole process registr deploy take nmbr minut know pay hidden fee charg littl bit price ram want nmbrmb ram box nmbr per month infrastructur engin built thi becaus want everyon abl make model usual see model sleep shelf somewher forev wait deploy someon els thi time shine lastli whi use inferrd com http inferrd com use aw gcp think aw gcp azur becom expens onc captiv want build tool allow migrat easili make depend ama
Grid_AI,MachineLearning,1617751199.0,[N] Latest Innovations with Grid.ai and PyTorch Lightning,join us april nmbrth nmbr et hear grid ai pytorch lightn latest innov ceo founder william falcon thoma chaton research engin manag thi discuss excel ai research machin learn engin data scientist look new way acceler improv current ai model train process leav tangibl strategi new tool great idea regist submit ani question william thoma http zoom us webinar regist nmbr wn _ywnmbrhnmbrhsz mxwngaunmbroog http zoom us webinar regist nmbr wn_ywnmbrhnmbrhsz mxwngaunmbroog
Evening-Use-7142,MachineLearning,1617874115.0,[D] Pytorch (geometric) over neo4j,hi ani good guidelin best practic cookbook exampl code run pytorch gnn larg cloud base databas neonmbrj data go store aw use neonmbrj current small db expect grow ani good guidelin work data way know neonmbrj ha ds librari allow run algorithm directli data wish design goal current standard one link predict node classif thank
soulslicer0,MachineLearning,1616883606.0,[D] PSA: IEEE PDF Express stores passwords in Plaintext,cvpr nmbr use ieee pdf express pdf check servic ask creat account forc password rule capit letter etc foolishli decid use person bank email password get email say creat account etc print password right email plain text absolut bullshit
radjeep,MachineLearning,1620015489.0,[Discussion] A very rudimentary solution to the XOR problem with a single layer (excluding output) neural network.,two input x nmbr x nmbr binari valu nmbr nmbr two weight w nmbr w nmbr bia unit b output neuron z henc equat z w nmbr x nmbr w nmbr x nmbr b let say set bia unit nmbr w nmbr nmbr w nmbr nmbr thi way output nmbr input combin nmbr nmbr nmbr nmbr requir output nmbr input nmbr nmbr onli except case would output nmbr input nmbr nmbr mitig thi use addit condit result nmbr onli output nmbr nmbr output ani valu nmbr thought
keepthepace,MachineLearning,1619525246.0,[P] I am writing a copyleft license for machine learning models. I'd love some comments and criticism,hello softwar develop robot lot love open sourc recent event made ponder one could releas train model order keep realli open free think would love prove otherwis licens applic right train weight veri differ beast sourc code execut binari tri write one modifi affero gpl licens someth fsf explicitli allow faq post http github com yquemen mlmpl thi actual old subject saw discuss debian legal mail list nmbr http list debian org debian legal nmbr nmbr msgnmbr html also crop http list debian org debian devel nmbr nmbr msgnmbr html occasion debian devel http list debian org debian devel nmbr nmbr msgnmbr html wa discuss nmbr debconf http saimei ftp acc umu se pub debian meet nmbr debconfnmbr high nmbr_machine_learning_threats_and_opportunities_for_debian_and_free_softwar ogv wa also discuss ffmpeg team http ffmpeg org pipermail ffmpeg devel nmbr juli nmbr html read mani case opinion think necessari new licens open sourc train weight necessarili difficult task think thank previou free softwar effort alreadi nmbr done need adapt exist licens bit explicit model tri shoehorn licens design compil softwar machin learn world formal train copyright law realli appreci someon background poke hole proposit everybodi construct critic welcom
P4TR10T_TR41T0R,MachineLearning,1619775478.0,[P] A review of recent research on transformers in vision,hey folk recent publish releas review transform vision focus last month research rememb discuss around vision transform particular would like highlight fact often seen intellectu curios onli googl train recent deriv model enjoy signific effici outperform efficientnetvnmbr allow deit like hard label distil efficientnetvnmbr normal free network allow hard label distil imagenet transform base model also advantag larg data regim e g imagenet nmbrk googl intern jft nmbrm dataset due reduc induct bia post discuss discuss thi includ interact perform visual consid check http iaml github io post nmbr nmbr nmbr transform vision http iaml github io post nmbr nmbr nmbr transform vision one last thing first time write blog post ani feedback format content deepli appreci
DAL59,MachineLearning,1619555922.0,[D] Whats the point of CLIP opposed to Dalle?,clip gener veri weird imag artifact massiv distort often tile screen request object dall hand creat complet normal look pictur time whi would anyon use clip
mlconvergence,MachineLearning,1619949450.0,[R] Generative Minimization Networks: Training GANs Without Competition,
cosapocha,MachineLearning,1619473464.0,[P] How would you measure uncertainty in a classification task?,hello everybodi use dropout deep ensembl evid bay backprop gener sampl measur uncertainti sampl comput mean varianc per class see bar overlap sum varianc see big number see two mean high say model reliabl mean think lot method wa wonder standard ani guy good idea measur uncertainti model classif thank veri much
hardmaru,MachineLearning,1620619558.0,[R] Learning Controllable Content Generators,
KirillTheMunchKing,MachineLearning,1617126474.0,[D] Are there any other GAN based image editing projects with an encoder-generator architecture that actually work in real time?,mostli see gan imag edit project reli pixnmbrpix distil work realtim author use latent space regress analyz leverag composition gan claim encod gener setup work realtim tri demo github doe work pretti fast small edit kinda strang hang larger edit case familiar paper want learn explain main idea telegram channel http casual_gan nmbr
thedeepreader,MachineLearning,1618683213.0,[P] Demo of Swin Transformer for Object Detection,
Zweiter,MachineLearning,1619199699.0,[R] Sim-to-Real Learning of All Common Bipedal Gaits,
bjourne-ml,MachineLearning,1616320233.0,[D] Thoughts on unlikelihood training/antitraining?,sub thought unlikelihood train antitrain idea dirt simpl model doe want reward likelihood slap unlikelihood say languag model predict next word model tend say cheat confus guess word ha alreadi seen exampl suppos sentenc particular standard likelihood train decod model given word except last ask predict next word like assign high probabl preced word well known problem lead continu like particular standard likelihood train particular standard likelihood train particular particular standard likelihood train standard particular standard likelihood train train thi lead repetit text unlikelihood train antitrain attempt solv thi penal model assign probabl mass preced incorrect word suppos part probabl distribut produc model look like p particular standard likelihood train nmbr p particular particular standard likelihood train nmbr p standard particular standard likelihood train nmbr p standard particular standard likelihood train nmbr calcul unlikelihood penalti alpha log nmbr nmbr log nmbr nmbr log nmbr nmbr nmbr nmbr alpha weight hyper paramet backprop next time model make predict assign less probabl mass preced word increas divers reduc repetit one use case unlikelihood suppos sentenc recent larg scale languag model target word model predict penal becaus grammat incorrect perplex accuraci reward model penal wa paper explain concept much better author claim achiev veri impress result neural text gener unlikelihood train http arxiv org ab nmbr say make inconsist dialogu unlik unlikelihood train http arxiv org ab nmbr
Present-Percentage88,MachineLearning,1619541186.0,[R] Online study: predicting COVID-19 misinformation in Twitter data using AI,hi everyon conduct user studi master thesi regard explain ai xai solut predict covid nmbr misinform twitter misinform ha import topic dure pandem explain ai solut help us detect misinform simultan explain predict key understand work particip benefici toward battl misinform pursuit toward transpar respons ai dure onlin studi label covid nmbr relat tweet answer set questionnair requir particip least nmbr year old run studi laptop desktop comput particip autonom use follow link http userstudi thesi herokuapp com en groupnmbr http userstudi thesi herokuapp com en groupnmbr thank advanc stay safe
fedetask,MachineLearning,1618071318.0,[R] Applications of Graph Neural Networks to Reinforcement Learning,could point paper appli graph neural network reinforc learn task
luisgasco,MachineLearning,1619167986.0,"[R] - Call For Participants MESINESP2 (BioASQ / CLEF2021 shared task) on semantic indexing of heterogenous health content: literature, clinical trials and patents",cfpnmbr mesinespnmbr track medic semant index bioasq clef nmbr http temu bsc es mesinespnmbr http temu bsc es mesinespnmbr mesinespnmbr award bsc plan tl nmbr nmbr test set addit data avail press need advanc multilingu semant search strategi health relat content like literatur patent clinic trial cross genr use semant search techniqu combin structur vocabulari critic sophist search content analysi need healthcar profession research pharmaceut industri patient group privat citizen follow impact past bioasq track benchmark studi e g biobert organ initi like biocr iberlef propos three semant label subtrack use wide use dec vocabulari similar mesh term mesinesp l scientif literatur automat label medic literatur abstract spanish includ recent covid nmbr literatur mesinesp clinic trial automat label clinic trial summari mesinesp p patent automat label health relat patent spanish improv patent intellig key inform web http temu bsc es mesinespnmbr http temu bsc es mesinespnmbr registr http clefnmbr lab registr dei unipd http clefnmbr lab registr dei unipd bioasq task nmbr mesinesp data http doi org nmbr zenodo nmbr http doi org nmbr zenodo nmbr mesinespnmbr organ close collabor wide use multilingu medic literatur databas birem isciii spain express direct need advanc technolog acceler manual index effort content spanish spoken global nmbr million peopl face challeng keep increas number publish medic paper use pure manual index larg manual index collect train document provid document alreadi automat annot nmbr million entiti mention medic entiti diseas medic procedur drug symptom facilit use complementari strategi like multi label classif multilingu transform graph match text similar advanc term match name entiti recognit compon particip system directli use ongo medic literatur index effort thu improv competit intellig prior art search enabl complex search queri need evid base medicin clinic decis make elabor clinic practic guidelin serv base futur task semant index medic record content languag import date april nmbr updat train valid test set releas april nmbr addit dataset releas medic entiti present document april nmbr bioasqnmbr lab u clef nmbr registr deadlin may nmbr start evalu period may nmbr end evalu period may nmbr submiss particip paper clefnmbr juli nmbr camera readi paper submiss sep nmbr nmbr clef nmbr confer public bioasq clefnmbr workshop team particip mesinespnmbr invit contribut system descript paper bioasq clef nmbr work note proceed short present approach bioasq nmbr workshop main track organ martin kralling barcelona supercomput center bsc spain lui gascó barcelona supercomput center bsc spain anastasio nentidi nation center scientif research demokrito greec elena primo peña biblioteca nacion de ciencia de salud instituto de salud carlo iii spain cristina bojo canal biblioteca nacion de ciencia de la salud instituto de salud carlo iii spain georg palioura nation center scientif research demokrito greec anastasia krithara nation center scientif research demokrito greec renato murasaki birem organización panamericana de la salud brasil scientif committe tristan naumann microsoft research usa prof xavier tannier sorbonn université limic franc luci lu wang allen institut ai ainmbr usa prof david camacho appli intellig data analysi research group universidad politécnica de madrid spain prof oscar corcho ontolog engin group universidad politécnica de madrid spain parmind batia amazon health ai usa prof irena spasic school comput scienc informat co director data innov research institut cardiff univers uk jose lui redondo garcía amazon alexa amazon uk carlo baden olmedo ontolog engin group universidad politécnica de madrid spain prof allan hanburi e commerc research unit faculti informat tu wien austria prof alfonso valencia barcelona supercomput center spain prof stefan j darmoni depart biomed informat rouen univers hospit franc limic franc rezarta islamaj nation center biotechnolog inform usa prof rafael berlanga llavori universidad jaum spain prof hen müller univers appli scienc western switzerland valai switzerland prof gareth j f jone school comput dublin citi univers ireland georg rehm deutsch forschungszentrum für künstlich intelligenz germani petr knoth research studio austria forschungsgesellschaft mbh austria natalia manola ceo openair amk greec prof jesú tramulla departamento de ciencia de la documentación e historia de la ciencia universidad de zaragoza spain
Intelligent-Fun-5311,MachineLearning,1619703113.0,[P] Real-time Object Detection on Jetson Nano,hi everyon need help real time object detect jetson nano train yolovnmbr model back pretti accur give veri low fp nmbr nano tri convert model tflite give even lower fp nmbr pleas tell achiev real time infer without ani loss accuraci thank advanc
lkncy,MachineLearning,1619314378.0,[P] ESL Solution,found realli good websit contain solut exercis esl element statist learn http yuhangzhounmbr github io esl_solut
ML_WAYR_bot,MachineLearning,1619380804.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 111,thi place share machin learn research paper journal articl read thi week relat research mean elabor give us insight otherwis could interest paper read pleas tri provid insight understand pleas post thing present wiki prefer link arxiv page pdf easili access pdf summari page way around ani pertin link previou week nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr week nmbr http www reddit com nmbrqyjiq week nmbr http www reddit com nmbrxwnmbr week nmbr http www reddit com nmbrildf week nmbr http www reddit com nmbrsnmbrknmbru week nmbr http www reddit com nmbrtnnmbrax week nmbr http reddit com nmbrsnmbrelnmbr week nmbr http reddit com bfsxnmbrz week nmbr http reddit com dnmbrvnonmbr week nmbr http reddit com fnmbrfnmbriq week nmbr http reddit com hltnmbro week nmbr http reddit com knmbrywb week nmbr http www reddit com nmbrsnmbrxqm week nmbr http www reddit com nmbracbnmbrt week nmbr http www reddit com nmbrjwde week nmbr http www reddit com nmbrabnmbri week nmbr http www reddit com nmbrwvjfk week nmbr http reddit com anmbropot week nmbr http reddit com blnmbrov week nmbr http reddit com denmbrhnmbr week nmbr http reddit com fnmbrfsnmbrz week nmbr http reddit com hunmbrzqnmbr week nmbr http reddit com khnmbrnx week nmbr http www reddit com nmbrtnmbrmqm week nmbr http www reddit com nmbrcwfbnmbr week nmbr http www reddit com nmbr week nmbr http www reddit com nmbrd week nmbr http www reddit com nmbrexnmbr week nmbr http reddit com anmbryaro week nmbr http reddit com bqlbnmbrv week nmbr http reddit com dkoxnmbr week nmbr http reddit com ffinmbrb week nmbr http reddit com iaznmbr week nmbr http reddit com kpsxtc week nmbr http www reddit com nmbrubnmbrkw week nmbr http www reddit com nmbrfcnmbrmh week nmbr http www reddit com nmbrhhhb week nmbr http www reddit com nmbrjsnmbr week nmbr http reddit com nmbraluh week nmbr http reddit com adnmbrssz week nmbr http reddit com bwnmbrjmnmbr week nmbr http reddit com drnmbrnca week nmbr http reddit com fnnmbrrnmbr week nmbr http reddit com ijjcep week nmbr http reddit com kzevku week nmbr http www reddit com nmbrxomfnmbr week nmbr http www reddit com nmbrhynmbrur week nmbr http www reddit com nmbrteiz week nmbr http www reddit com nmbrbnmbravnmbr week nmbr http reddit com nmbrtnnez week nmbr http reddit com ainmbrgi week nmbr http reddit com cnmbritkk week nmbr http reddit com dxshkg week nmbr http reddit com fvknmbrjnmbr week nmbr http reddit com isnmbrhjnmbr week nmbr http reddit com lnmbrlvg week nmbr http www reddit com nmbrzcyvk week nmbr http www reddit com nmbrkdnmbrvd week nmbr http www reddit com nmbrdnmbrnbnmbr week nmbr http www reddit com nmbrenmbrfxnmbr week nmbr http reddit com nmbrxnmbroj week nmbr http reddit com apnmbrctk week nmbr http reddit com cdnmbrgko week nmbr http reddit com enmbrnmyk week nmbr http reddit com gnmbreavg week nmbr http reddit com jnmbrxrnmbr week nmbr http reddit com ljxnmbrn week nmbr http www reddit com nmbrtnmbrmo week nmbr http www reddit com nmbrobnmbrdx week nmbr http www reddit com nmbrgngwc week nmbr http www reddit com nmbrhccnmbrc week nmbr http reddit com nmbrjmh week nmbr http reddit com aucinmbrc week nmbr http reddit com cjnmbrkyc week nmbr http reddit com ebnmbrlxk week nmbr http reddit com gcxnmbruf week nmbr http reddit com jnmbrcbf week nmbr http reddit com luqbxl week nmbr http www reddit com nmbrheol week nmbr http www reddit com nmbrrnmbryd week nmbr http www reddit com nmbrjgdva week nmbr http www reddit com nmbrkgcqr week nmbr http reddit com nmbrupnmbrg week nmbr http reddit com azjoht week nmbr http reddit com cpnmbrjex week nmbr http reddit com ehbfst week nmbr http reddit com glmnmbrsv week nmbr http reddit com jhzznmbrv week nmbr http reddit com mnmbrunmbrz week nmbr http www reddit com nmbrkvsu week nmbr http www reddit com nmbrttnmbrcz week nmbr http www reddit com nmbrmnmbrlnmbrv week nmbr http www reddit com nmbrnayri week nmbr http reddit com nmbrnnmbrrt week nmbr http reddit com bnmbrrnmbri week nmbr http reddit com cvdenmbra week nmbr http reddit com entcxi week nmbr http reddit com gunmbrtnmbrd week nmbr http reddit com jqjgonmbr week nmbr http reddit com mfnmbrmnmbru week nmbr http www reddit com nmbrsnmbroa week nmbr http www reddit com nmbrwhnmbrwb week nmbr http www reddit com nmbrpnmbrhanmbr week nmbr http www reddit com nmbrqelnmbrp week nmbr http reddit com nmbrcfnmbr week nmbr http reddit com bakewnmbr week nmbr http reddit com dnmbrgnmbrknmbr week nmbr http reddit com euctyw week nmbr http reddit com hddfnmbrj week nmbr http reddit com jznmbrevt week nmbr http reddit com moynmbrm upvot paper two week ago u evanatyourservic asam http arxiv org ab nmbr u awesomeai make art artifici intellig http www amazon com dp bnmbrjnmbrtnmbrhm besid rule fun
ML_WAYR_bot,MachineLearning,1616961605.0,[D] Machine Learning - WAYR (What Are You Reading) - Week 109,thi place share machin learn research paper journal articl read thi week relat research mean elabor give us insight otherwis could interest paper read pleas tri provid insight understand pleas post thing present wiki prefer link arxiv page pdf easili access pdf summari page way around ani pertin link previou week nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr week nmbr http www reddit com nmbrqyjiq week nmbr http www reddit com nmbrxwnmbr week nmbr http www reddit com nmbrildf week nmbr http www reddit com nmbrsnmbrknmbru week nmbr http www reddit com nmbrtnnmbrax week nmbr http reddit com nmbrsnmbrelnmbr week nmbr http reddit com bfsxnmbrz week nmbr http reddit com dnmbrvnonmbr week nmbr http reddit com fnmbrfnmbriq week nmbr http reddit com hltnmbro week nmbr http reddit com knmbrywb week nmbr http www reddit com nmbrsnmbrxqm week nmbr http www reddit com nmbracbnmbrt week nmbr http www reddit com nmbrjwde week nmbr http www reddit com nmbrabnmbri week nmbr http www reddit com nmbrwvjfk week nmbr http reddit com anmbropot week nmbr http reddit com blnmbrov week nmbr http reddit com denmbrhnmbr week nmbr http reddit com fnmbrfsnmbrz week nmbr http reddit com hunmbrzqnmbr week nmbr http reddit com khnmbrnx week nmbr http www reddit com nmbrtnmbrmqm week nmbr http www reddit com nmbrcwfbnmbr week nmbr http www reddit com nmbr week nmbr http www reddit com nmbrd week nmbr http www reddit com nmbrexnmbr week nmbr http reddit com anmbryaro week nmbr http reddit com bqlbnmbrv week nmbr http reddit com dkoxnmbr week nmbr http reddit com ffinmbrb week nmbr http reddit com iaznmbr week nmbr http reddit com kpsxtc week nmbr http www reddit com nmbrubnmbrkw week nmbr http www reddit com nmbrfcnmbrmh week nmbr http www reddit com nmbrhhhb week nmbr http www reddit com nmbrjsnmbr week nmbr http reddit com nmbraluh week nmbr http reddit com adnmbrssz week nmbr http reddit com bwnmbrjmnmbr week nmbr http reddit com drnmbrnca week nmbr http reddit com fnnmbrrnmbr week nmbr http reddit com ijjcep week nmbr http reddit com kzevku week nmbr http www reddit com nmbrxomfnmbr week nmbr http www reddit com nmbrhynmbrur week nmbr http www reddit com nmbrteiz week nmbr http www reddit com nmbrbnmbravnmbr week nmbr http reddit com nmbrtnnez week nmbr http reddit com ainmbrgi week nmbr http reddit com cnmbritkk week nmbr http reddit com dxshkg week nmbr http reddit com fvknmbrjnmbr week nmbr http reddit com isnmbrhjnmbr week nmbr http reddit com lnmbrlvg week nmbr http www reddit com nmbrzcyvk week nmbr http www reddit com nmbrkdnmbrvd week nmbr http www reddit com nmbrdnmbrnbnmbr week nmbr http www reddit com nmbrenmbrfxnmbr week nmbr http reddit com nmbrxnmbroj week nmbr http reddit com apnmbrctk week nmbr http reddit com cdnmbrgko week nmbr http reddit com enmbrnmyk week nmbr http reddit com gnmbreavg week nmbr http reddit com jnmbrxrnmbr week nmbr http reddit com ljxnmbrn week nmbr http www reddit com nmbrtnmbrmo week nmbr http www reddit com nmbrobnmbrdx week nmbr http www reddit com nmbrgngwc week nmbr http www reddit com nmbrhccnmbrc week nmbr http reddit com nmbrjmh week nmbr http reddit com aucinmbrc week nmbr http reddit com cjnmbrkyc week nmbr http reddit com ebnmbrlxk week nmbr http reddit com gcxnmbruf week nmbr http reddit com jnmbrcbf week nmbr http reddit com luqbxl week nmbr http www reddit com nmbrheol week nmbr http www reddit com nmbrrnmbryd week nmbr http www reddit com nmbrjgdva week nmbr http www reddit com nmbrkgcqr week nmbr http reddit com nmbrupnmbrg week nmbr http reddit com azjoht week nmbr http reddit com cpnmbrjex week nmbr http reddit com ehbfst week nmbr http reddit com glmnmbrsv week nmbr http reddit com jhzznmbrv week nmbr http reddit com mnmbrunmbrz week nmbr http www reddit com nmbrkvsu week nmbr http www reddit com nmbrttnmbrcz week nmbr http www reddit com nmbrmnmbrlnmbrv week nmbr http www reddit com nmbrnayri week nmbr http reddit com nmbrnnmbrrt week nmbr http reddit com bnmbrrnmbri week nmbr http reddit com cvdenmbra week nmbr http reddit com entcxi week nmbr http reddit com gunmbrtnmbrd week nmbr http reddit com jqjgonmbr week nmbr http www reddit com nmbrsnmbroa week nmbr http www reddit com nmbrwhnmbrwb week nmbr http www reddit com nmbrpnmbrhanmbr week nmbr http www reddit com nmbrqelnmbrp week nmbr http reddit com nmbrcfnmbr week nmbr http reddit com bakewnmbr week nmbr http reddit com dnmbrgnmbrknmbr week nmbr http reddit com euctyw week nmbr http reddit com hddfnmbrj week nmbr http reddit com jznmbrevt upvot paper two week ago u boy_named_su http arxiv org pdf nmbr pdf u vinay_kumarnmbr http acuv com blog machin learn suppli chain http acuv com blog machin learn suppli chain besid rule fun
Programmierer,MachineLearning,1616598438.0,[R] Mastering Real-Time Strategy Games with Deep Reinforcement Learning: Mere Mortal Edition,employ array techniqu includ novel form automat domain random curricula canonic spatial featur omnisci valu function network architectur design encod task specif invari train deep reinforc learn agent codecraft real time strategi game within hour singl gpu blog post http clemenswint com nmbr nmbr nmbr master real time strategi game deep reinforc learn mere mortal edit http clemenswint com nmbr nmbr nmbr master real time strategi game deep reinforc learn mere mortal edit code http github com cswinter deepcodecraft http github com cswinter deepcodecraft
kul_xjia,MachineLearning,1616341170.0,[R] Neighbor2Neighbor: Self-Supervised Denoising from Single Noisy Images,http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf
KirillTheMunchKing,MachineLearning,1617985631.0,[R] ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement - Explained,restyl residu base stylegan encod via iter refin http casual_gan nmbr great idea improv stylegan invers complex real imag build top recent enmbr psp paper author propos fast iter method imag invers latent space pretrain stylegan gener acheiv sota qualiti lower infer time core idea start averag latent vector w predict offset would make gener imag look like target repeat thi step new imag latent vector start point propos approach good invers obtain nmbr step detail http casual_gan nmbr invers awesom http preview redd sanmbrgunmbrdcnmbrsnmbr png width nmbr format png auto webp nmbranmbrabbbnmbrbnmbrbbnmbranmbrfnmbrcnmbrenmbrfdnmbrbbnmbrecnmbr p case familiar paper check http casual_gan nmbr
fripperML,MachineLearning,1617172367.0,"[D] What’s the simplest, most lightweight but complete and 100% open source MLOps toolkit? -> MY OWN CONCLUSIONS",although post thi summari thread http www reddit com r machinelearn comment mfcanmbrp d_whats_the_simplest_most_lightweight_but peopl find make visibl post anoth thread first thank reddit ml commun gener particular detail insight interest answer receiv past day learnt lot pictur head clearer post summari thing make sens opinion serv guidelin make decis bare summari gener advic start reduc set tool use one order flexibl chang adapt project new infrastructur provid could offer us thi someth could happen end end solut mainli two solut nmbr open sourc free instal use may solv requir ml practition hopswork http hopswork readthedoc io en stabl clearml http allegro ai clearml doc among thi two chose one right clearml hopswork might much complet clearml seem bigger commun behind easier instal use clearml someth take look case go one packag also like idea platform ui project python program flakenmbr http flakenmbr pycqa org en latest includ flakenmbr docstr mypi http mypi lang org black http black readthedoc io en stabl huge recommend googl style guid http googl github io styleguid pyguid html someth take look thi morn found thi guid http cjolowicz github io post hypermodern python nmbr setup might worth cover mani good practic also thi articl http martinheinz dev blog nmbr regard ide vscode visual studio recommend one vscode poetri http python poetri org also someth consid also one care current develop state veri promis mayb pip secur offici way ci deploy jenkin good tool although mayb easiest one gitlab drone circl easier use docker might total need huge recommend becom standard even mani librari reli exampl clearml doe addit work veri well jenkin switch svn git strongli recommend gitlab http gitlab com good option project scaffold cookiecutt http cookiecutt readthedoc io en nmbr nmbr kedro http kedro readthedoc io en stabl winner still think stick kedro templat becaus offer extra function like think project set pipelin run anyway cookiecutt templat veri good like thi one http github com tezromach python packag templat case use kedro clearml figur integr pipelin clearml task slack channel clearml team least possibl document sphinx http www sphinx doc org en master index html document total recommend googl style docstr napoleon http www sphinx doc org en master usag extens napoleon html veri use help thi cover document actual code document busi object project relat stuff could use jupyt notebook order everyth insid repo project registri clearml final chose otherwis migth use intern wiki repositori clear document data explor prepar use pyspark thing go big panda thing fit memori test expect great expect librari recommend nobodi told anyth instead unit test smoke test use pytest http doc pytest org en stabl check jenkin anyway kedro end project templat keep eye plugin http github com tamsanh kedro great great expect http github com great expect great_expect featur store data version mayb import begin dvc http dvc org doc look good easi use workflow engin orchestr case one otherwis import piec prefect mayb option like simplic luigi also tool like kedro also relat thi becaus tool defin pipelin doe care run pipelin deploy sever engin like luigi prefect airflow kubeflow model registri import depend sever consider mani model product model frecuent retrain lot model train test parallel model make real time predict perform critic ani previou point happen true model registri veri import piec mlop solut otherwis consid essenti experi import piec use clearml thi solv otherwis might tri mlflow http www mlflow org doc latest index html use kedro mlflow pipelinex http pipelinex readthedoc io en latest hydra http hydra cc doc intro interest addit defin configur although kedro doe nice way train apart classic librari case dl simplic pytorch light http www pytorchlightn ai first option anyway hardwar limit could issu model fit memori train must distribut problem least foreseen tensorflow pytorch way deal model serv fastapi http fastapi tiangolo com even simpler dlnmbrj http deeplearningnmbrj org use java need commun rest applic real time interest solut bentoml http github com bentoml bentoml cortex http www cortex dev take look high avail import take account redund node resili infraestructur kubernet could solut visual take look voila http voila readthedoc io en stabl use html streamlit http streamlit io model monitor could use jenkin pipelin ad hoc schedul process need tool
KirillTheMunchKing,MachineLearning,1617381315.0,[R] StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery - SOTA StyleGAN image editing,styleclip text driven manipul stylegan imageri http casual_gan nmbr thi idea eleg yet power author use recent clip model loss function train map network take text descript imag edit e g man long hair beyonc woman without makeup imag encod latent space pretrain stylegan gener predict offset vector transform input imag accord text descript edit http preview redd kemgnmbrbcfsqnmbr png width nmbr format png auto webp nmbrcnmbranmbrabenmbrefnmbrbafanmbrcanmbrcenmbrfnmbrabnmbrb p case familiar paper check http casual_gan nmbr
meldiwin,MachineLearning,1620241072.0,"[N] Joscha Bach ""cognitive Architectures""",hello everyon ieee soft robot podcast go joscha bach podcast ani question argument joscha pleas send http doc googl com form e nmbrfaipqlseginmbrwwnnryaxvkfvvrenmbrpbnmbrfknmbrhuusbislnmbrnnmbrbnmbrrnmbrebnmbrneg viewform vc nmbr c nmbr w nmbr flr nmbr gxid nmbr http doc googl com form e nmbrfaipqlseginmbrwwnnryaxvkfvvrenmbrpbnmbrfknmbrhuusbislnmbrnnmbrbnmbrrnmbrebnmbrneg viewform vc nmbr c nmbr w nmbr flr nmbr gxid nmbr thank http preview redd uxjjlnnmbrmcxnmbr png width nmbr format png auto webp dnmbrdbnmbrbfnmbrbnmbreenmbrenmbrdnmbrcenmbraanmbrb
HashRocketSyntax,MachineLearning,1616324158.0,[P] AIQC (deep learning framework) is now seeking collaborators.,aiqc open contributor link low hang fruit github issu http github com aiqc aiqc issu aiqc framework rapid reproduc deep learn aim drive adopt deep learn scientif research doe provid object orient python api similar orm serv bumper rail advanc entri level deep learn workflow high level api allow perform best practic machin learn simpli call aiqc pipelin aiqc experi http aiqc readthedoc io en latest notebook keras_multi label_classif html http preview redd nmbrbxqknmbrgnmbrdonmbr png width nmbr format png auto webp nmbrenmbraddbfbnmbrbcnmbrdnmbrbnmbrcenmbrcnmbrenmbrdnmbrbnmbr
aminnikanjam,MachineLearning,1617047762.0,"[R] A survey on ""Design Smells in Deep Learning Programs""",research group swat lab polytechniqu montréal supervis prof fouts khomh conduct survey design smell deep learn program prepar onlin survey take around nmbr nmbr minut complet ask relev sever observ design issu dl program look particip strong background experi research develop deep learn program special convolut network cnn pleas feel free particip find elig moreov could kindli share thi survey colleagu friend consid elig particip result thi survey publicli access arxiv org anonym form point survey ask name log ip address allow anonym would like know thi studi feel free contact us question link http form gle yedpqnmbrdxnmbrtaoxyklnmbr http form gle yedpqnmbrdxnmbrtaoxyklnmbr realli appreci time support best regard amin nikanjam amin nikanjam polymtl ca fouts khomh swat lab polytechniqu montréal montréal canada http swat polymtl ca http swat polymtl ca
skwaaaaat,MachineLearning,1617210746.0,[Discussion] Methods for interpreting the meta knowledge learned by meta-learning methods?,hi tri draw insight meta learn model e g task relationship summar share task structur etc specif exampl learn certain chemistri dataset good meta learn method implicitli learn share chemistri principl question could visual interpret learn meta knowledg find ani relev literatur thi topic could someon point right direct thank lot
Seankala,MachineLearning,1619520030.0,[D] Is there any work highlighting the effectiveness of using bilinear transformations for certain tasks?,recent read paper comput vision titl _learn deep bilinear transform fine grain imag represent zheng et al nmbr _ http arxiv org ab nmbr particular type bilinear transform coin group bilinear claim bilinear transform work well fine grain imag recognit work natur languag process particular relat extract also claim bilinear classifi layer work well curiou ani work detail _why_ thi may case materi read claim transform learn semant group learn pairwis factor usual end ani recommend opinion appreci thank
ydennisy,MachineLearning,1620044509.0,[D] Many Logistic Regression heads.,interest build find nn architectur would consist network view embed layer mani logreg head top one predict certain class purpos learn dens represent featur would good predict variou class henc loss lr head need propag network interest would thi architectur work well new unseen class similar domain problem space ha anyon come across model architectur implement
mLalush,MachineLearning,1618474344.0,[D] Why have the standard data formats in object detection remained as COCO/PASCAL VOC/YOLO as opposed to switching over to a nested columnar format?,imag classif earli standard gener user divid imag file differ train valid folder well sometim requir separ folder class label research seem held standard api deep learn librari eventu evolv allow flexibl usag necessarili requir user shuffl around imag file folder want adjust train valid setup keep train valid file differ folder probabl ha certain benefit reproduc research name make abundantli clear train val split wa perform howev thi convent enforc doe introduc someth barrier beginn look train model exist label data minim data wrangl thu exist librari api imag classif seem converg load refer filepath either list tabular columnar format encourag user perform train val split refer data thi allow maximum flexibl user data organ howev wish easili perform whatev augment wish perform split approach tutori adapt model custom dataset follow standard user defin dataload thi new standard howev doe seem prolifer user face object detect semant instanc segment librari might interject point nmbr data hierarch natur sever bound box polygon coordin rle may exist imag coco pascal voc yolo natur way store data nmbr store hierarch data nest columnar format introduc memori overhead nmbr data format csv tsv work well nest data none opinion convinc argument whi mani object detect librari need break convent evolv imag classif hierarch data easili store list nest cell datafram necessarili repeat row howev mani object exist given imag arrow http arrow apach org instal http arrow apach org instal librari exist store load nest columnar data insan think object detect librari api eventu inevit converg standard imag classif api whi alreadi establish standard entrench torchvis alreadi seem head http pytorch org tutori intermedi torchvis _tutori html http pytorch org tutori intermedi torchvision_tutori html say librari standard remain pleas organ data veri specif instruct execut thi script nmbr poorli document option arg
hardmaru,MachineLearning,1619877683.0,[R] Emerging Properties in Self-Supervised Vision Transformers,
Science_Squid,MachineLearning,1618565067.0,[D] AutoML MOOC,collabor group work automl develop free mooc thi topic like learn automl mooc live http learn ki campu org cours automl luhnmbr http learn ki campu org cours automl luhnmbr nmbr video overal nmbrh cover hyperparamet optim hpo neural architectur search na bayesian optim bo evolutionari algorithm ea meta learn automl cours includ quizz code exercis python r allow deepen expertis interest check trailer cours http youtu nmbrwzsnmbrtgwinmbrg http youtu nmbrwzsnmbrtgwinmbrg edit tri make appar cours free
akirp001,MachineLearning,1617202841.0,[D] Are there any practical reasons for learning about the Boltzmann machines and how they work?,three year ago use replic softmax text data requir special embed wa final abl appli someth topic spent ton time tri understand yet today even use case would probabl go hug face seem ani notabl paper breakthrough use part machin learn journey wa go last chapter gener model mit book certainli slog get lot wonder even worth spend anytim boltzman section
vonum,MachineLearning,1619692257.0,[D] Audio processing on mobile devices,hello ha anyon audio process mobil devic troubl find tool audio process tool use technolog use tensorflow js load make predict problem howev transform audio input microphon problem due abl find librari
yusuf-bengio,MachineLearning,1617269822.0,[D] Keras: Killed by Google,first thi rant tensorflow actual later disclaim work research project teano jax pt tf nmbr nmbr cours origin kera origin kera wa high level api specif machin learn wa realli nice collabor peopl less engin background api wa framework agnost main implement support multipl backend teano tensorflow ms cntk essenti api design resembl abstract modern high level framework pytorch lightn fast ai slightli differ design flavor e g kera model combin network metric train code singl object wherea framework usual separ network learner object huge advantag kera wa wa avail api stabl back nmbr nmbr think thi someth remark field move fast know stori googl announc plan incorpor tensorflow nmbr thi problem slowli kill kera nmbr reason nmbr dure time span thi merg kera api wa effect frozen make lag behind altern term featur nmbr releas tfnmbr came late top first version buggi even lack basic featur nmbr instead make hard cut tf nmbr nmbr googl decid better carri lot baggag crap tfnmbr make framework extrem bloat someth doe work get overwhelm long cryptic error messag stacktrac longer screen visual thi post realli intend funer kera api look forward know thought edit noth person googl far realli like impress contribut ml colab tpu jax stori kera tfnmbr realli frustrat like work past
hyunwoongko,MachineLearning,1616882340.0,[P] Openchat 1.1 is released! (support 30+ conversational model),http preview redd lakinmbrrlnmbrnpnmbr png width nmbr format png auto webp bdbnmbrbenmbrabfanmbrcnmbrenmbrenmbrdnmbranmbrb hello hyunwoongko made openchat artifici intellig convers framework openchat open sourc framework allow commun artifici intellig one line code today openchat ha updat version nmbr write thi articl unlik befor engin chang parlai support nmbr convers model want talk artifici intellig tri instal openchat inform plz visit http github com hyunwoongko openchat http github com hyunwoongko openchat thank
Pestocalypse,MachineLearning,1620144671.0,[N] Transformer and Capsule co-inventors launch new API-based NLP startup,announc http twitter com aidanngomez statu nmbr http twitter com aidanngomez statu nmbr articl http www theglobeandmail com busi articl toronto startup back ai expert aim bring googl qualiti http www theglobeandmail com busi articl toronto startup back ai expert aim bring googl qualiti world lead artifici intellig expert back toronto startup co found protégé ai luminari geoffrey hinton jeff dean attempt make easier human talk machin coher inc offici launch tuesday offer plug compani machin learn softwar internet upload three line code system provid access technolog http archiv dfsxl http www theglobeandmail com topic technolog coher claim softwar provid richer understand human languag includ semant sentiment tone earli investor includ prof hinton univers toronto professor googl engin fellow known godfath deep learn ian goodfellow appl head ai raquel urtasun chief scientist head uber atg research develop divis nvidia ai director sanja fidler ai pioneer fei fei li pieter abbeel toronto ai financi radic ventur wrote first chequ coher
HybridRxN,MachineLearning,1618034652.0,Machine learning is getting easier software engineering still hard [D],hi thi first discuss post current ml graduat student univers think thi http towardsdatasci com machin learn get easier softwar engin still hard dnmbrenmbrbcnmbr articl seek current machin learn role replac sophist framework year drive job job remain stabl complex demand advanc question enabl tool machin learn enthusiast student interest industri job focu thing difficult autom like data engin data augment devop reliabl interpret someth els kaggl style architectur stack may evid thi least nlp huggingfac autonlp product http huggingfac co autonlp gpt nmbr enabl applic http openai com blog gpt nmbr app realli curiou hear thought commun edit articl may behind paywal becaus medium use incognito outlin site editnmbr thi gptnmbr think one sampl think job market continu grow tool get easier still lot work think ml commun go figur make tool easier use also make power think see lot ml engin expert use tool necessarili expert underli algorithm think alway need peopl design implement new algorithm think also alway need peopl understand limit tool design experi test new way use tool
Combination-Fun,MachineLearning,1620065927.0,[R] Video explaining Swin Transformers,paper seri video present latest swin transform hierarch vision transform use shift window paper thi week hope use understand transform increasingli get use vision task http youtu tfyxjzbabenmbr http youtu tfyxjzbabenmbr
_conquistador,MachineLearning,1620076306.0,[P] Hi r/machinelearning! We created an AI-assisted video annotation tool that speeds up labelling time by 17x - looking for BETA testers to help us refine web application,part ml postgrad develop tool lab speed video label time nmbr nmbrx use shot classif human loop input e g person label frame algorithm handl rest look beta tester help refin platform addit real world use case besid earli access platform give ani earli tester free lifetim access onc launch pleas fill thi form get earli access http form gle cgwdnmbrxnvnmbrkwmnmbrynmbr http form gle cgwdnmbrxnvnmbrkwmnmbrynmbr
SherdyRavers,MachineLearning,1616770387.0,[R] I'm currently doing research about Gaussain Processes and I'm trying to develop a deeper understanding. My main concern is GP prior sampling,hard time understand gaussian process prior sampl articl medium use learn gaussian process articl link http towardsdatasci com understand gaussian process socrat way banmbrdnmbr http towardsdatasci com understand gaussian process socrat way banmbrdnmbr go start explain understand partconfus get probabl nmbr function use thi pdf equat call equat _nmbr http preview redd nmbrctmvnmbrsoydpnmbr png width nmbr format png auto webp nmbrbnmbrbnmbrenmbranmbrbbnmbrcdnmbrfanmbrfecnmbr http preview redd xmhxvnmbrsoydpnmbr png width nmbr format png auto webp nmbrebnmbrbnmbranmbrdfnmbrbnmbracnmbrafanmbrenmbrdcbanmbr plot function get probabl function use thi pdf graph call graph _nmbr becaus go ask question later http preview redd nmbrhnmbronmbredqydpnmbr png width nmbr format png auto webp nmbrbnmbrbanmbrfdacenmbrednmbrfnmbrcnmbrbnmbr assum prior sampl use nmbr data point nmbr function obtain put graph obtain call graph _nmbr http preview redd bnmbrbwlfdqydpnmbr png width nmbr format png auto webp nmbrdnmbrdfcnmbrdbnmbrcnmbrabnmbrfcenmbrednmbrcnmbranmbreenmbrenmbr p understand question becaus miss detail refer thsi articl miss detail articl link nmbr question nmbr train gp prior x x two data point rain data nmbr graph _nmbr doe gaussian distribut come also posit function x axi come standard deviat postion function result nmbr graph _nmbr axi result axi standardis e instead show actual result standardis result shown
King-Little,MachineLearning,1619775635.0,[D] M1 MacBooks versus Google Colab for deep learning,start get deep learn tf kera point decid want develop thesi project timeseri predict option pycharm macbook air mnmbr nmbr nmbr nmbrth gen intel inmbr linux desktop googl colab pleas let know question one faster better suit purops mnmbr got hype http machinelearn appl com updat ml comput train mac lot thought mnmbr would savag desktop acut hype bias purchas decis well onli slightli better like nmbr nmbrx faster cifarnmbr benchmark wonder worth effect nmbr nmbr gb ram left maco vs nmbr gb linux machin colab realli tell one win race sinc colab limit resourc demand also allow distribut fit cloud tpu would introduc extra code effort say doe ml appl silicon come hand limit http github com appl tensorflow_maco addit inform peculiar miniconda setup http github com appl tensorflow_maco issu nmbr lot issu http github com appl tensorflow_maco issu also sever one like train error etc problem would even recogn actual realli work perspect profession data scientist hope find clear indic choos
LynnHoHZL,MachineLearning,1619491098.0,[R] EigenGAN: Layer-Wise Eigen-Learning for GANs,post paper code new work eigengan unsupervisedli learn hierarch interpret dimens gan welcom discuss paper http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf code http github com lynnho eigengan tensorflow http github com lynnho eigengan tensorflow gender http redd nmbrcsinpunmvnmbr gif pose yaw http redd kfnmbrkonmbrcomvnmbr gif paint style http redd zncvnmbranmbrlomvnmbr gif hue http redd dlnmbrlaanomvnmbr gif
jj4646,MachineLearning,1619378764.0,[D] why are neural networks better than polynomial approximation?,ha anyon ever come across formal mathemat explan whi neural network power polynomi approxim result e g paper proven conclus show neural network certain advantag polynomi approxim
Yuqing7,MachineLearning,1616720149.0,[N] Tsinghua & MIT’s P-Tuning Boosts Performance on NLU Benchmarks,tsinghua mit research break stereotyp gpt gener understand languag show gpt compet bert model natur languag understand task use novel p tune method also improv bert perform shot supervis set quick read gpt understand tsinghua mit p tune boost perform nlu benchmark http syncedreview com nmbr nmbr nmbr gpt understand tsinghua mit p tune boost perform nlu benchmark paper gpt understand arxiv http arxiv org pdf nmbr pdf
austingwalters,MachineLearning,1619503940.0,[P] Data Profiler | What's in your data?,hello r machinelearn thought commun might interest project apart team ha work python librari call dataprofil http github com capitalon dataprofil project two object nmbr quickli accur cheapli identifi sensit data pii npi dataset nmbr gener data profil util downstream ml applic regard sensit data detect publish workshop paper model within librari sensit data detect high throughput neural network model financi institut http aaai kdf github io kdfnmbr asset pdf kdf_nmbr_paper_nmbr pdf addit sensit data detect librari also calcul statist featur gener characterist dataset thi ha help team quickli evalu dataset also enabl profil use downstream applic nifti featur commun may interest load file datafram singl command http capitalon github io dataprofil doc nmbr nmbr html data_read html identifi header format etc extend current entiti detect model transfer learn http capitalon github io dataprofil doc nmbr nmbr html data_label html extend data label transfer learn easi take onli line code retrain scratch model work structur csv tsv json etc unstructur data text possibl though tad rough add new custom model entiti detect http capitalon github io dataprofil doc nmbr nmbr html add_new_model_to_data_label html profil save load merg http capitalon github io dataprofil doc nmbr nmbr html profil html gener look feedback curiou commun think project
regalalgorithm,MachineLearning,1618964072.0,[D] New Tag for Self Promotion Content?,thi sub ha grown ha becom normal podcast youtub blog creator post link episod video post text post littl link content wa discuss http www reddit com r machinelearn comment jnmbrsnmbryw d_recent_increase_in_self_promotion_cont specif thi hald year ago done thi quit bit co runner two public podcast ai stop ago sinc felt potenti obnoxi spammi actual got call newslett post lol still see lot mayb salti wonder spirit thi sub want share idea perhap tag sp specif self promot thi would differenti post actual discuss sure much thi commun care thi gramt pretti easi differenti self promot post normal post base titl still felt like float idea someon wa sure cool obnoxi
throwaway_secondtime,MachineLearning,1618380124.0,"[D] Sam Altman, Founder of OpenAI, proposes a ""Wealth For All"" plan for dealing with AI disruption",http moor samaltman com
ScienTecht,MachineLearning,1619845553.0,[P] I created a way to learn machine learning through Jupyter,hey work new way help peopl practic machin learn concept sinc profession data scienc use jupyt notebook thought realli cool peopl learn interact jupyt notebook well written exercis guid build k nearest neighbor classifi scratch far know seen thi done elsewher pleas check http www confetti ai question nmbr nmbr utm_sourc reddit utm_medium web utm_campaign jupyterhub knn let know think
a_computer_pun,MachineLearning,1617902342.0,[Research] Companies for compiling training data,wa wonder anyon ani use compani use data retriev need retriev data machin learn train use sampl data event site train web scraper far look use fiverr data result pretti hit miss list look far idea whether use lionbridg ai amazon mechan turk clickwork appen globalm googl label servic basicai
this_username_is_tkn,MachineLearning,1620337867.0,[Research] Seeing use of ML for ordinary work puts a smile on my face.,object thi paper find altern convent method concret mix design find altern nmbr machin learn algorithm viz multi variabl linear regress support vector regress decis tree regress artifici neural network design concret mix desir properti origin articl http dx doi org nmbr scce nmbr nmbr
Caffeinated-Scholar,MachineLearning,1619117310.0,[R] Outcome-Driven Reinforcement Learning via Variational Inference,
aledinuso,MachineLearning,1618959406.0,[D] When do you start optimizing hyperparameters when trying out a new idea?,implement new idea find hard decid much time spend get work befor move next one would like know peopl optim hyperparamet alway befor abandon new approach like last thing alreadi level success
tdls_to,MachineLearning,1618660921.0,[N] Spotify Confidence - open source for analyzing a/b test data,think thi librari spotifi open sourc sound pretti use wonder anyon ha tri thi similar one ani recommend http github com spotifi confid
chasep255,MachineLearning,1617278214.0,[D] Using activity regularization instead of batch norm.,ani reason accomplish goal batch normal use activ regular basic would add penalti loss function layer activ doe mean zero varianc one two reason might prefer thi method tri train gan use batch norm behav differ infer dure train thi caus discrimin abl someth like nmbr accuraci gener also think ha nmbr accuraci solv thi use realli fast momentum nmbr doe seem like best solut ideal want someth behav dure train infer secondli onli nmbrgb vram rtx nmbr realli wish went nmbr thi pose tight constraint batch size depend size model understand batch norm work best larg batch least size nmbr usual train smaller batch realli think reason tri thi ani thought also unsur would best term add loss function wa think someth like follow may better way def normal_reg x return tf squar tf reduce_mean x tf squar tf math reduce_vari x nmbr
Purple-Ad-3492,MachineLearning,1619042230.0,[D] Thoughts on using VADER for sentiment analysis on texts other than social media?,given packag design sentiment analysi tune social media twitter nyto amazon movi review like thi tool sentiment rate nmbr nmbr scale limit seem constrain far classif system e word phrase pre set unlik sa tool word ad list would simpli classifi posit neutral neg nmbr nmbr scale vader tool wa construct score given rang base evalu nmbr nmbr token featur nmbr independ human seen harri potter book project subsect chapter use vader therefor first question pertain thought reliabl result http towardsdatasci com basic nlp text harri potter sentiment analysi nmbrbnmbrbnmbrd also look non english text translat e text origin written anoth languag use vader sentiment analysi rather find sort work around translat text themselv perhap translat lexicon txt file code exampl negat booster special_cas word list although say word translat would effect score english version mayb prevent hiccup method would translat first use anoth sa tool like dostoyevski russian
rahulkumar1210,MachineLearning,1618165092.0,[P] Footprint recognition using feature extraction algorithm,someon help thi project implement pleas repli implement flow chart attach imag python got stuck stage code error featur extract algorithm use princip compon analysi pca independ compon analysi ica linear discrimin analysi lda vggnmbr vggnmbr inceptionvnmbr resnetnmbr want use combin classifi knn svm one time want conclud compar result algorithm declar best process http preview redd tlqwjkznmbrflsnmbr png width nmbr format png auto webp fnmbrenmbrcdbdnmbrfnmbranmbranmbrdnmbrcfnmbreadcnmbrdnmbrcnmbr
sensetime,MachineLearning,1616860563.0,[D] Jürgen Schmidhuber's work on fast weights from 1991 is similar to linearized variants of Transformers,saw schmidhub tweet http twitter com schmidhuberai statu nmbr new blog post http peopl idsia ch juergen fast weight programm nmbr transform html post discuss schmidhub style work nmbr particular use fast weight principl would allow neural net learn program neural net mention method propos enabl fast weight chang addit outer product self invent activ pattern similar today self attent mechan use transform recent ha sever variant transform use linear approxim effici purpos work demonstr similar perform version softmax claim similar fast weight apart thi blog post schmidhub lab also publish articl recent thi topic linear transform secretli fast weight memori system http arxiv org ab nmbr thi paper also propos better way linear transform inspir techniqu fast weight day show improv compar linear variant transform think thi topic discuss would interest thi forum
VDevAGI,MachineLearning,1616668296.0,[D] Few-shot learning in practice.,although ton shot learn approach come recent year onli test omniglot miniimagenet like wa wonder method work practic use case instanc latest cvpr nmbr say sota shot paper use industri problem engin well known baselin approach like rf svm knn beat sota practic robust
begooboi,MachineLearning,1620577957.0,[D] How do we define a discriminative model?,gener model learn distribut data gener model approxim distribut data doe discrimin model learn
Equivalent-Choice-75,MachineLearning,1618590893.0,[D] ML PhD at top 5-10 ranked school vs RE at FAANG (Applied teams),hi tri decid ml phd nmbr nmbr cs school usa mle faang one appli team pure research team like fair googl brain go industri eventu goal two option prefer ml phd highli reput take nmbr year finish sure effort wait worth reward mle might cut edg work focu still product get decent amount engin research product titl role research engin though eventu love work place like deepmind ai drug discoveri ai climat chang etc toward thi benefici nmbr year phd start mle graduat way realli confus make thi decis thank
hellohihello__,MachineLearning,1616586780.0,[D] [P] Evaluation Metrics for Pre-Trained Faster R-CNN,hi everyon recent work creat social distanc detect model use detectronnmbr faster r cnn pre train weight use video dataset issu unabl perform evalu model know evalu precis recal map etc sinc pre train ani way perform evalu pre train faster r cnn ground truth valu dataset
ProbablyCloseEnough,MachineLearning,1620535166.0,[R] Slurm Interface Investigation Report,thi followup previou thread r slurm interfac survey nmbr minut http www reddit com r machinelearn comment lfnnmbrdnmbr r_slurm_interface_survey_nmbr_minut utm_sourc share utm_medium webnmbrx context nmbr r slurm interfac prototyp evalu survey nmbr minut http www reddit com r machinelearn comment mfnmbri r_slurm_interface_prototype_evaluation_survey_nmbr utm_sourc share utm_medium webnmbrx context nmbr respons survey help complet coursework human comput interact cours wa take thank first survey wa instanc needfind investig user interfac aim find demograph thing tri interfac context task impress interfac use certain target task thi case schedul comput job share comput resourc use slurm follow copi paper takeaway get survey result respond use command line interfac presum one slurm provid satisfi unsatisfi respond use slurm fewer nmbr time per week expect becaus expect comput job high enough complex worth schedul slurm insight might compromis bia explain intend take certain step control bias anticip limit time respons would gather respons therefor mechan intend use reduc bia implement one mechan wa provid survey mandarin addit english onli provid english becaus time verifi mandarin translat thu english liter user overrepres anoth mechan wa distribut survey differ commun becaus wa limit nmbr respons stop gather respons befor could send commun student take cs nmbr georgia tech r machinelearn http www reddit com r machinelearn reddit frequent machin learn research thu academ user research overrepres wa abl implement mechan inher survey design show question befor particip start survey ask question encourag certain respons execut one needfind activ observ nmbr particip target task give option explain action also perform heurist evalu slurm interfac target task base activ defin perform goal propos prototyp interfac new interfac maintain function common task user includ target task well determin avail partit charg id hardwar configur avail comput cluster criteria evalu whether user perform task time least accur effici compar command line interfac evalu criteria time keystrok click requir less time fewer keystrok click perform task predict reliabl time learnabl new user abl learn use within interfac perform least target task without script error caus forget key word syntax criterion evalu whether new user term access appropri file place perform least target task must requir onli mous click finger tap keyboard requir onli first time authent criterion evalu whether user interfac must compat client devic run linux prefer also window maco interfac must compat slurm server run linux compli term use criterion evalu whether instal use linux connect slurm server run linux develop interfac must cost nmbr hour develop time singl research ha limit experi graphic user interfac develop time wa sure whether implement interfac upon learn decreas import cost proceed brainstorm nmbr prototyp interfac use gut feel evalu anticip perform idea term function accuraci effici learnabl access compat complianc cost weight nmbr nmbr nmbr nmbr nmbr nmbr nmbr nmbr respect weight cost neg becaus lower better found top three idea nmbr simpl execut form nmbr dag organ job nmbr run configur avail ide third one wa present second survey thi figur http imgur com nmbrmnmbronoh wa present follow text consid interfac extens instal integr develop environ ide enabl schedul job way user would run local run configur configur set panel shown figur abov enabl chang common set enforc valid configur upon click run button interfac attempt schedul job thi figur http imgur com nmbrahnmbrzcx summar respons got survey becaus respond need perceiv interv respons option constant ani statist test still eyebal result inform subsequ round needfind main takeaway prototyp might meet effici requir expect greatest advantag propos interfac ha command line interfac determin user typic use seem accur learnabl memor fit better user workflow wa surpris mani respond expect perform target task somewhat slower none expect much quickli nmbr expect much slowli interpret would mani respond experienc use command line interfac would difficult outperform chang suggest feedback next iter thi prototyp subject develop tri increas effici howev demograph may find sacrific effici worth advantag area collect inform rel import aspect thi point cours assign chang investig differ interfac becom veri busi work sinc paid anyon continu thi investig becaus grade longer held hostag go leav thi
sarmientoj24,MachineLearning,1619179833.0,"[P] Is it possible to create a benchmark OSes performance in terms of ML training, prediction?",think possibl topic advanc os small research paper goal tri check perform evalu differ oper system ubuntu debian fedora mint window cento etc term train predict simpl ml model cnn rnn possibl benchmark focus oper system thi kind tool use benchmark exampl check cpu usag ram usag etc plan follow creat docker contain specifi os start tool benchmark measur start train nmbr start predict nmbr start train nmbr question would possibl seen paper tackl os effect machin learn train measur tool given outlin prefer methodolog
meldiwin,MachineLearning,1617817881.0,"[N] Dieter Fox "" The Next Generation Of Robotics"" New Episode",hello guy pleas feel free remov relev ieee soft robot podcast recent interview prof dieter fox would like feedback episod ani comment would help futur guest find episod audio http soundcloud com ieeera softrobot dieter fox next gener robot http soundcloud com ieeera softrobot dieter fox next gener robot video http youtu sstflcoadsc http youtu sstflcoadsc
ilovemouchou,MachineLearning,1619365371.0,[D] Need help figuring out job offers,got offer amazon research scientist posit one aw custom face team realli like idea work ml consult super divers project bit scare potenti pressur hard deadlin might come hand got offer googl data scientist posit one trust safeti team term work life balanc overal employe well googl amaz compani intern love afraid data scientist trust safeti could nich wa wonder easi would move anoth team within googl coupl year care much comp come academia ani tech job offer feel like lotteri compar postdoc salari growth opportun within compani posit would perceiv recruit futur also care flexibl remot work famili europ partner us would great abl spend extend period time contin anoth thing declin googl offer go amazon harder get googl later
MohamedRashad,MachineLearning,1620348992.0,[D] Is there an idea similar to SPP but for Convolutions ?,need way keep output last convolut layer fix nmbrxnmbr exampl whatev input size variabl input size fix featur map size anyon idea someth like thi
svantana,MachineLearning,1620286725.0,"[D] Is the concept of an 'epoch' being phased out, or even harmful?",notic trend paper report number train step rather epoch kinda make sens sinc dataset vari size dozen billion thi got think concept epoch potenti harm enforc idea data someth finit ideal minibatch train approxim iid sampl infinit dataset true distribut argument iid sampl train data recent saw someon wa scatterplot batch loss dure train thi inform standard loss per epoch plot could combin move averag latest k batch gaussian confid interv easili ad iid sampl ani leftov batch odd size edit reason thi came becaus model train two dataset differ loss wa struggl defin epoch dawn whi even use epoch sampl data batch work fine one less nest loop good health
fasttosmile,MachineLearning,1618593591.0,[R] Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little,http arxiv org ab nmbr
adcamuto,MachineLearning,1620562568.0,[R] Explicit Regularisation in Gaussian Noise Injections,thi work studi regularis induc neural network gaussian nois inject gni though inject extens studi appli data studi understand regularis effect induc appli network activ key find work deriv explicit regularis inject posit term ad loss function obtain marginalis inject nois thi regularis penalis network learn function high frequenc content fourier domain heavili regularis neural network layer closer output see figur illustr thi arxiv http arxiv org ab nmbr http arxiv org ab nmbr code http github com alexand camuto exp _reg _gni http github com alexand camuto exp_reg_gni figur illustr effect gni inject throughout network activ colour dot repres neuron activ add gni repres circl layer activ bar output layer gni induc network layer learn progress lower frequenc function repres sinusoid match colour correspond layer http preview redd yknmbrzwagnmbrynmbr png width nmbr format png auto webp fnmbrabnmbrccnmbrcanmbrdnmbrcnmbrdnmbranmbrebanmbra
SQL_beginner,MachineLearning,1617811685.0,[D] Feature Selection for Large Datasets,begin question would like quot paper ishawaran et al random forest surviv analysi data author veri concis outlin difficulti featur select e variabl includ statist model classic regress model thi problem somewhat allevi advanc model becaus method e classic regress model e g cox ph regress even though semi parametr often parametr nonlinear effect variabl must model transform expand design matrix includ special basi function often ad hoc approach stepwis regress use determin nonlinear effect exist identifi interact especi involv multipl variabl also problemat thi must done brute forc examin two way threeway interact e g must reli subject knowledg narrow search contrast difficulti handl automat use forest illustr eas rsf uncov complex data structur depth case studi prognost implic underweight overweight obes sever stabl coronari arteri diseas investig note complex pattern surround possibl revers causat underweight individu interact smoke unclear inflect point point increas bodi mass confer increas risk identifi possibl obes paradox among patient establish heart diseas increas bodi mass predict better surviv clarifi issu analyz larg cohort patient coronari arteri diseas undergo isol coronari arteri bypass surgeri use rsf random surviv forest identifi complex relationship long term surviv bodi mass renal kidney function smoke number intern coronari arteri bypass graft believ novel find help explain appar contradict previous report sourc http arxiv org pdf nmbr pdf essenti author claim tradit regress model struggl featur select newer model e g bag random forest abl better deal featur select rememb intro stat class somewhat tediou process determin variabl includ multipl linear regress model author describ rememb wa someth call cp mallow criteria potenti variabl repeatedli includ exclud regress model valu cp mallow criteria wa monitor final select variabl model wa decid basi thi criteria howev thi select process becom ineffici larg dataset understand correctli thi mean would refit model mani differ combin variabl result combinator explos larg number variabl like author mention also manual hard code interact term model e g log varnmbr varnmbrvarnmbr varnmbr varnmbrvarnmbr varnmbr varnmbr varnmbr etc infinit number potenti interact improp featur select also result unwant effect multicollinear last point would like bring although knowledg mathemat strong enough fulli substanti classic regress model said tendenc overfit know whi seen visual demonstr thi know mathemat explan behind thi empir observ poorli gener new data know whi classic regress model onli abl recogn linearli separ pattern data intuit understand thi e g draw circl red point smaller circl blue point fit red circl singl line separ two color know mathemat explan behind thi thi bring question featur select larg dataset advent technolog data becom bigger bigger everyday convolut neural network go method analyz pictur standard black white pictur said nmbr variabl wherea dna said even instanc sure must imposs address featur select done convent statist model pleas excus poor understand math understand newer statist model built method handl featur select problem instanc random forest randomli choos differ combin variabl see combin result better model perform exact random mechan uncorrel tree said also prevent multicollinear ahv heard creator random forest algorithm leo breiman claim theoret statist random forest definit fit ha desir error bound converg properti thi true meanwhil read data scienc blog go lie deep neural network abl automat learn consid use combin featur approxim target function correct want ask larg dataset sometim featur ani immedi mean e g patient blood pressur vs inform contain nmbrst pixel photograph ani real way handl featur select thi usual taken care statist model e g random forest neural network seen exampl onlin peopl attempt write massiv loop train model thousand variabl combin sure feasibl thi someon pleas provid comment thi thank
mikegartrell,MachineLearning,1619447583.0,[N] Deadline extended: Call for papers: KDD 2021 Workshop on Bayesian Causal Inference for Real-World Interactive Systems,http bcirwisnmbr github io http bcirwisnmbr github io august nmbr nmbr nmbr final workshop date tbd submiss deadlin extend may nmbr nmbr anywher earth format nmbr page extend abstract refer appendic acm proceed templat submiss websit http cmtnmbr research microsoft com bcirwisnmbr http cmtnmbr research microsoft com bcirwisnmbr increasingli use machin learn build interact system learn past action reward obtain theori suggest sever possibl approach contextu bandit reinforc learn calculu plain old bayesian decis theori theoret appropri practic approach causal infer interact system particularli interest case studi appli machin learn method interact system use bayesian likelihood base method discuss whi thi choic wa made term practic theoret argument also welcom submiss follow area offlin evalu recommend interact system comparison bayesian polici heurist approach offlin metric probabilist approach appli contextu bandit reinforc learn approach probabilist approach increment attribut non bayesian approach trade bayesian likelihood approach bayesian method product environ organ nichola chopin ensa mike gartrel criteo ai lab dawen liang netflix alberto lumbrera criteo ai lab david rohd criteo ai lab yixin wang uc berkeley
xdtolm,MachineLearning,1618772636.0,[P] VkFFT now supports OpenCL,hello creator vkfft gpu fast fourier transform librari latest updat ad opencl backend option addit vulkan cuda hip interest opencl fft feel free check ask ani question perform level backend github link http github com dtolm vkfft http github com dtolm vkfft
zy415,MachineLearning,1616513517.0,[D] IJCAI 2021 Paper Reviews,ijcai nmbr paper review suppos releas soon tomorrow creat discuss thread thi year review
gokuresearch,MachineLearning,1617167679.0,[D] Is it worth buying a GPU workstation as a graduate student?,graduat student pursu master thesi also hope pursu phd futur right laptop gtx nmbr help lot learn variou algorithm ml dl also indirectli help publish research paper well known confer dure undergradu grow comput requir dl wa wonder worth invest proper workstat nmbrx rtx nmbr similar high config graduat student alreadi part well fund research lab access gpu cluster lab research work love person experi explor latest research whenev possibl becaus current trend requir comput explor thing apart global chip shortag also concern lead increas gpu price overal therefor would like receiv ani kind suggest thought note admin pleas let know thi post scope
thisisdhruvagarwal,MachineLearning,1619340081.0,Bullet Physics vs Pandas3D [D],sinc know mujoco free henc wa look altern got bullet physic pandasnmbrd sure one use think easi learn one would prefer
techsucker,MachineLearning,1616957686.0,[R] Researchers at Lawrence Livermore National Laboratory (LLNL) Developed a Novel Deep Learning Framework for Symbolic Regression,lawrenc livermor nation laboratori llnl scientist develop novel framework accompani visual tool util deep reinforc learn symbol regress problem outperform baselin method benchmark problem paper wa recent accept oral present intern confer learn represent iclr nmbr paper research describ appli deep reinforc learn discret optim discret optim focus problem deal discret build block must combin particular order configur optim desir properti focus type discret optim call symbol regress symbol regress find short mathemat express fit data gather experi aim discov underli equat dynam physic process summari http www marktechpost com nmbr nmbr nmbr research lawrenc livermor nation laboratori llnl develop novel deep learn framework symbol regress http www marktechpost com nmbr nmbr nmbr research lawrenc livermor nation laboratori llnl develop novel deep learn framework symbol regress paper http openreview net forum id mnmbrqshnmbrkbqg http openreview net forum id mnmbrqshnmbrkbqg
user692646,MachineLearning,1620387919.0,[D] Element-wise multiplication instead of Convolution,consid use element wise multipl fundament oper net want know thi ha done befor literatur oper singl layer would work follow nmbr given x n input imag multipli element wise x n weight matrix nmbr add x n matrix bias output step nmbr nmbr comput non linear e g relu element wise output step nmbr nmbr use k x k averag pool kernel stride k sampl output step nmbr reason consid use thi oper instead conv layer becaus think conv layer bit regular problem mean convolut oper treat matrix vector multipl input conv layer imag shape column vector matrix would spars need could enforc sparsiti later lnmbr regular exampl ha thi sort oper consid befor literatur
regularized,MachineLearning,1620406026.0,[D] Have you heard of MBZUAI (Mohamed bin Zayed University of Artificial Intelligence)?,look faculti see veri promin ml research eric xing le song http mbzuai ac ae studi faculti sec http mbzuai ac ae studi faculti sec heard thi univers think professor realli base abu dhabi mayb someon cmu eric xing former univers gatech le song former univers comment
mistermysterioyster,MachineLearning,1618110169.0,[D] Paper Reading Group #017 - Adversarial vulnerabilities of human decision-making. (Link to full slides in comments!),
davex32,MachineLearning,1620599656.0,[P] Latest TensorFlow 2.5.0rc3 optimized wheels with CUDA 11 and Python3.9,built wheel new tensorflow nmbr nmbrrcnmbr cuda nmbr cudnn nmbr case anyon find use thi includ ssenmbr x avxnmbr fma instruct usual build skylak march thi case glibc nmbr architectur request depend avail whi thi use instal offici binari see warn like thi cpu support instruct thi tensorflow binari wa compil use avx avxnmbr http github com davidenun tensorflow wheel http github com davidenun tensorflow wheel case anyon find use contribut coffe addict support build relat project http github com sponsor davidenun http github com sponsor davidenun http ko fi com davidenun http ko fi com davidenun say hi davidelnun http twitter com davidelnun twitter
post_hazanko,MachineLearning,1618592038.0,[D] Filling in missing data for bad video on client end,think would interest applic start see make blurri imag becom super clear wonder would thing point integr model client side think web js video transmiss usual see local sourc crisp recipi littl wors make sens concern accur fill
Brian-Phan,MachineLearning,1620645877.0,[D] Is a Master (Msc) in Statistics a good path towards machine learning?,hi guy last undergrad year financ keen interest machin learn consid take master degre statist sinc research show ml requir ton statist background howev idk whether master statist optim compar cs ai sinc peopl say master statist cover much knowledg need cs ai much practic thank much advanc input realli appreci
thunder_jaxx,MachineLearning,1617344522.0,"[D] For Anyone Who Has Clocked More Than 50+ Days Of DL Model Training Time, Do You Use Anything Other Than Adam or AdamW?",almost ml project dl use adamw work fuck well question fellow redditor might train model frequent use differ optim whi tune beta valu conscious ever chosen use adam whi seen recent fanci optim like pcgrad http arxiv org pdf nmbr pdfhttp arxiv org pdf nmbr pdf never found need use use
brandonrussell757,MachineLearning,1619633167.0,[D] TP/FP Object Detection Question,hey everyon middl implement map metric scratch get detail data associ calcul map ie ap precis recal tp fp fn understand logic behind calcul tp fp tp class detect iou iou _thresh fp class detect iou iou _thresh question would calcul situat singl predict bound box overlap two ground truth bound box iou meet iou _thresh ground truth box initi thought would would rule one highest iou tp fp right thi assumpt
ilikepancakez,MachineLearning,1618923355.0,Generative Adversarial Transformers [R],
SubstantialRange,MachineLearning,1616789302.0,[D] What are the CASP competition equivalents for scientific fields other than protein folding?,critic assess protein structur predict bi annual contest measur progress comput method domain protein fold wa famous last year deepmind alphafold similar benchmark scientif field peopl may know
Firehead1971,MachineLearning,1617264663.0,[D] Collecting ideas and hot topics for possible PhD thesis,hi argentinian ml research begin hi dissert e choos suitabl interest topic think would bad could collect hot topic thu simpl overview exampl edg topic world right topic still shadow might come soon start write come mind transform model still hot topic neural network optim techniqu mathemat comparison basi ml integr differ area life health care road traffic mlop enterpris product environ doe look realiti make ml understand use ml teach ml comput vision certainli lot possibl also alreadi lot thing done fanci audio ml classif stuff recogn approach killer insect anim cross field ml biolog might continu thi list idea
Puzzleheaded-Drop297,MachineLearning,1617041579.0,"[D] EMNIST dataset down, network unreachable",use torchvis download emnist dataset thi moment someon send copi thank http www itl nist gov iaui vip cs _link emnist gzip zip http www itl nist gov iaui vip cs_link emnist gzip zip perhap need better way host dataset like thi dataset went back onlin
mistermysterioyster,MachineLearning,1616330212.0,[D] Paper Reading Group #014 - Accurate uncertainties for deep learning using calibrated regression.,
AlexCroft-n-Co,MachineLearning,1620629854.0,"[D] New to reddit. Delete or reddit?? Have deleted facebook, instagram and everything else. Your votes matters",privaci concern view poll http www reddit com poll nnmbrynmbrjz
dsmlthrowaway,MachineLearning,1617121603.0,[D] Looking for advice: hiring data practitioners,work larg compani focus suppli chain medium cost live citi start incorpor machin learn techniqu improv lot process good success goal cushion blow invest ha met look invest scale thi team hire mayb nmbr nmbr addit peopl rub matter realli sure attract right talent job need cut edg stuff busi problem valu immens get someth good enough door pragmat hacker enterpris come comp sci program background move data basic use tool without much depth knowledg busi domain knowledg know success appli ideal would love hire problem solver care busi gener valu accomplish think type posit start pop lot barrier entri decreas damndest time attract right peopl realli data scienc role data engin role ml role kind jack trade data practition call see ani similar post inde anyon know ani could cheat great question nmbr guy ani advic job titl post nmbr would expect salari rang like thi type posit midlevel data folk vs mid level program seem pay less want drive away anyon nmbr type phrase use make clear thi necessarili data scienc role ml role problem solv role around data hate anyon disappoint work
Yuqing7,MachineLearning,1618591151.0,[N] ETH Zurich Leverages Spiking Neural Networks To Build Ultra-Low-Power Neuromorphic Processors,research team eth zurich leverag exist spike base learn circuit propos biolog plausibl architectur highli success classifi distinct complex spatio tempor spike pattern work contribut design ultra low power mix signal neuromorph process system capabl distinguish spatio tempor pattern spike activ quick read error propag spike neural network compat neuromorph processor http syncedreview com nmbr nmbr nmbr eth zurich leverag spike neural network build ultra low power neuromorph processor paper error propag spike neural network compat neuromorph processor arxiv http arxiv org pdf nmbr pdf
ArulVendhan,MachineLearning,1617187489.0,[P] Hawking Date Time Parser is Open-Source Now,great pleasur announc natur languag date time parser use stanford corenlp backend open sourc check let us know feedback github http github com zoho hawk http github com zoho hawk blog http www zoho com blog gener zia nlp base hawk date time parser open sourc html http www zoho com blog gener zia nlp base hawk date time parser open sourc html tweet stanford univers http twitter com stanfordnlp http twitter com stanfordnlp statu nmbr nmbr http twitter com stanfordnlp statu nmbr nmbr nlp stanfordnlp datetimepars
TheElementsOf,MachineLearning,1620638064.0,[D] Trustworthiness in current AI applications,current research trustworthi current applic ai would like discuss thi issu believ veri import aspect ai use daili basi everyon main interest automot industri e trust self drive car weaker decis support system drive believ thi discuss benefici everyon especi mani peopl differ field contribut subject trust ethic never done one person organis pleas includ idea current futur problem mayb also refer see main problem trustworthi ai applic interpret black box model howev even research would somehow understand decis process model whi arriv decis ensur consum safe use machin set process possibl situat outcom anyway hand model interpret ensur consum data still privat interpret model problem privaci preserv explain pro con wide popul
strngelet,MachineLearning,1620054250.0,[P] Python library to boost T5 models speed up to 5x & reduce the model size by 3x,edit tnmbr text text transfer transform larg seqnmbrseq transform model ha encod decod pre train cnmbr coloss clean crawl corpu dataset flexibl fine tune varieti downstream task achiev state art result mani nlp benchmark tnmbr model use sever nlp task summar translat q text gener etc info model refer thi http ai googleblog com nmbr nmbr explor transfer learn tnmbr html articl googl want share thi new librari work open sourc link librari github repositori http github com kinmbran fasttnmbr pypi project http pypi org project fasttnmbr logo http preview redd eznmbrghvocnmbrxwnmbr png width nmbr format png auto webp nmbranmbranmbrbnmbrenmbrdnmbrbnmbrenmbrdnmbrenmbrdnmbr titl suggest increas infer speed ani pretrain tnmbr model also decreas model size singl line code librari instal pip instal fasttnmbr thi code snippet repositori readm give concis overview usag http preview redd nmbrwkzenmbrlnmbrxwnmbr png width nmbr format png auto webp fnmbracbnmbrenmbrenmbrbbnmbrbnmbrcenmbrdnmbrfnmbraanmbrbfnmbrecnmbr fasttnmbr librari export tnmbr model onnx past_key_valu quantiz run onnxruntim export onnx model support gener method huggingfac transform inferenc inform project refer repositori http github com kinmbran fasttnmbr reduc tnmbr model size nmbrx increas infer speed nmbrx
OnlyProggingForFun,MachineLearning,1620476125.0,[R] Learning to Relight Portraits based on the Background,novel per pixel light represent deep learn framework explicitli model diffus specular compon appear produc relit portrait convincingli render effect like specular highlight thi might great extens realist onlin zoom call background read articl http www louisbouchard ai background light watch video http youtu rvpnmbrtcf_yri whatev prefer refer pandey et al nmbr total relight learn relight portrait background replac doi nmbr nmbr http preview redd enonmbrppwvxnmbr png width nmbr format png auto webp nmbrdnmbrbbanmbrdbanmbrdnmbrdnmbranmbrefnmbrd
pcaversaccio,MachineLearning,1617109338.0,[R] Can Vision Transformers Learn without Natural Images?,
mamrollahi,MachineLearning,1616615847.0,"[D] Compare my word embedding models (Count based, PMI, SPPMI) #",go build model wiki dump dataset tri compar result wsnmbr word similar need check whether understand correct firstli need read text wiki file token abl build co occurr matrix go build co occurr matrix nmbr way base count base pmi base sppmi go build embed matrix use svd word embed matrix compar result wsnmbr way correct thank
New-Psychology-1148,MachineLearning,1620287525.0,[D] Why git is not enough for data science,hi r machinelearn http www reddit com r machinelearn wrote blog post http dagshub com blog use git data scienc whi git good enough day day job data scientist think lot potenti use git combin tool track code take advantag featur also help us track data model think thi git ml flow doe anyon know ani workflow http dagshub com blog use git data scienc http dagshub com blog use git data scienc tl dr git use almost everi softwar develop project track code file chang base thi abil track everi chang ha also tremend increas git adopt data scienc project thi post discuss nmbr benefit git data scienc nmbr gap limit git nmbr best practic use git data scienc project
PaganPasta,MachineLearning,1616769689.0,[D]Doubt in Bayes by Backprop,tri go thi work http arxiv org pdf nmbr pdf http arxiv org pdf nmbr pdf blundel et al veri familiar bayesian side thing dnn tri summar stuff understood much like also highlight thing fail understand help someon clarifi nmbr point estim base mle map give sort solut p w nmbr p w written bayesian form intract comput altern find proxi p w call variat posterior q w θ minim l θ w kl q w θ p w nmbr eq nmbr break known elbo form nmbr proposit nmbr introduc generalis gaussian parameteris trick understand intent behind somewhat get proof result part first term right hand express come help nmbr l θ w estim empir mont carlo sampl eq nmbr nmbr gaussian variat posterior estim part appli proposit nmbr practic howev eq nmbr nmbr stem proposit nmbr henc clear nmbr prior w p w author suggest sampl mixtur nmbr gaussian also appear param prior remain constant train nmbr lastli weight scheme contribut loss param likelihood vs complex gone coupl blog post proposit nmbr still unclear ani help appreci sorri advanc veri basic common knowledg
PsychologicalDemand0,MachineLearning,1617212778.0,[R] Explainability Guided Multi-Site COVID-19 CT Classification,happi share recent paper covid nmbr detect ct imag method achiev state art result multipl dataset sizabl margin explain guid multi site covid nmbr ct classif http arxiv org ab nmbr abstract radiologist examin chest ct effect way screen covid nmbr case thi work overcom three challeng autom thi process limit number supervis posit case ii lack region base supervis iii variabl across acquisit site challeng met incorpor recent augment solut call snapmix new patch embed techniqu perform test time stabil analysi three techniqu complementari base util heatmap produc class activ map cam explain method compar current state art obtain increas five percent fnmbr score site rel high number case gap twice larg site much fewer train imag joint work tal shaharabani lior wolf
ai_researcherr,MachineLearning,1617050577.0,[Discussion] AI and Memory Wall,brief blogpost analyz overhead train recent sota model especi transform argu memori soon becom main bottleneck train flop would great commun feedback thi whether agre disagre thi conclus http medium com riselab ai memori wall nmbrcbnmbrcbnmbrbnmbr http medium com riselab ai memori wall nmbrcbnmbrcbnmbrbnmbr tldr comput cost train recent sota transform base model nlp ha scale rate nmbrx nmbryr model paramet count scale nmbrx nmbryr contrast gpu tpu dram capac ha onli scale rate nmbrx nmbryr meantim peak hardwar flop ha scale rate nmbrx nmbryr put number perspect peak hardwar flop ha increas nmbr nmbrx dram interconnect bandwidth ha onli scale factor nmbrx past nmbr year exponenti continu forev delay exponenti rate nmbrx nmbryr feasibl long need rethink train deploy design ai model hardwar deal thi increasingli challeng memori wall
kaleb7589,MachineLearning,1617994609.0,[N] GTC 2021 Free Registration,free gtc nmbr registr http www nvidia com en us gtc ncid gtcsnmbr nvkasmith sign folk free amaz talk key note want miss
bendee983,MachineLearning,1619457034.0,[R] ThreeDWorld Transport Challenge -- Embodied AI,new challeng research ibm mit stanford aim provid realist simul environ train test rl model task motion plan tamp problem challeng take place threedworld environ visual audibl physic realist simul agent place insid multi room hous must locat carri object specifi destin within specifi number step agent two arm robot onli carri two item simultan environ also ha contain agent use carri multipl item onc agent must find right balanc explor carri task use contain etc accord research pure end end rl approach perform poorli challeng hand hybrid approach rl agent control rule base high level planner improv perform though problem still far solv challeng make use simplif term comput vision action state complex agent use magnet hand need handl object finger environ view first person though agent provid rgb depth segment map movement rotat limit specif increment nmbrm movement nmbr degre rotat challeng still open submiss present cvpr embed ai workshop june interest see new innov challeng usher full stori comment lead research http bdtechtalk com nmbr nmbr nmbr reinforc learn embodi ai http bdtechtalk com nmbr nmbr nmbr reinforc learn embodi ai challeng websit http tdw transport csail mit edu http tdw transport csail mit edu gym code tdw environ http github com chuangg tdw transport challeng starter code http github com chuangg tdw transport challeng starter code arxiv paper http arxiv org ab nmbr http arxiv org ab nmbr
SomeParanoidAndroid,MachineLearning,1617579186.0,[D] Practical tips for Active Learning (my approach does not outperform random sampling),hello fellow practition dataset classif label process output veri comput expens physic simul run everi datapoint propos incorpor activ learn framework limit amount data need implement approach es yarin gal et al deep bayesian activ learn imag data http arxiv org ab nmbr use mc dropout bayesian neural network take advantag abil quantifi uncertainti predict thi allow appli acquisit function pool unlabel data includ argmax datapoint train set everi iter problem function better randomli choos train instanc everi time dataset paramet set correspond figur show follow self explanatori believ specif paramet mc dropout cnn dropout_p nmbr higher valu make network less certain reg nmbre nmbr higher valu make network less certain mc_sampl nmbr higher number accur predict paramet activ learn iter initial_dataset_s nmbr nmbr train dataset nmbr datapoint training_set_incr nmbr mani new datapoint add pool everi iter training_epochs_per_iter nmbr refer train full dataset converg nmbr epoch experi differ valu run comparison take half day would veri grate anyon ha dealt situat befor ha ani pratic tip choos appropri valu guestim anyon welcom well briefli found increas initial_dataset_s nmbr training_epochs_per_iter nmbr doe provid ani advantag random sampl meddl regular valu howev doe help result show best get far comparison perform differ acquisit function function size dataset http preview redd nmbrbzrajnmbrprnmbrrnmbr png width nmbr format png auto webp nmbranmbrcffnmbracnmbrcbdnmbrccccnmbrcecnmbreenmbrbnmbrbnmbrbnmbrcbnmbr
Competitive-Rub-1958,MachineLearning,1620563385.0,[D] Are ViT's good enough for moderate/low data conditions?,og vit wa pretti data heavi improv data effici flavour ha ani signific advanc place like cifar nmbr without huge pre train dataset would hardli classifi imagenetnmbrk someth use real world nmbrk imag nmbr class million song dataset pre train nmbrk subset magnatun fine tune use ani latest visual transform standard cnn thank take time address queri
