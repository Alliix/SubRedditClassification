{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb65e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc772b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "allPosts = pd.read_csv('./../Data/all_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "088c6a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3809\n"
     ]
    }
   ],
   "source": [
    "allPosts = allPosts[allPosts['Post'].notna()]\n",
    "allPosts['Post'] = allPosts['Post'].astype(str)\n",
    "print(len(allPosts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16f8ae69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MachineLearning'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPosts.loc[3000]['Subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00f834b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I made a simple tool that lets you search a video \\\\*semantically\\\\* with AI. üéûÔ∏èüîç\\n\\n‚ú® Live web app: [http://whichframe.com](http://whichframe.com/) ‚ú®\\n\\nExample: Which video frame has a person with sunglasses and earphones?\\n\\nThe querying is powered by OpenAI‚Äôs CLIP neural network for performing \"zero-shot\" image classification and the interface was built with Streamlit.\\n\\nTry searching with text, image, or text + image and please share your discoveries!\\n\\nüëá More examples  \\n[https://twitter.com/chuanenlin/status/1383411082853683208](https://twitter.com/chuanenlin/status/1383411082853683208)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPosts.loc[3000]['Post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37ecdc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i made a simple tool that lets you search a video semantically with ai live web app url example which video frame has a person with sunglasses and earphones the querying is powered by openai clip neural network for performing zero shot image classification and the interface was built with streamlit try searching with text image or text image and please share your discoveries more examples url'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'\n",
    "numbers = '\\d+(\\.\\d+)?'\n",
    "posessivePronouns = '‚Äôs'\n",
    "apostrophe='‚Äô'\n",
    "someSigns ='\\\\n|\\\\r'\n",
    "punctuation = \"[^\\w\\s]\" \n",
    "whitespaces = '\\s+'\n",
    "leadTrailWhitespace = '^\\s+|\\s+?$'\n",
    "\n",
    "allPosts['Post_Parsed'] = allPosts['Post'].str.lower()\n",
    "allPosts['Post_Parsed'] = allPosts['Post_Parsed'].str.replace(urls,'url',regex=True)\n",
    "allPosts['Post_Parsed'] = allPosts['Post_Parsed'].str.replace(numbers,'nmbr',regex=True)\n",
    "allPosts['Post_Parsed'] = allPosts['Post_Parsed'].str.replace(posessivePronouns,'',regex=True)\n",
    "allPosts['Post_Parsed'] = allPosts['Post_Parsed'].str.replace(apostrophe,'',regex=True)\n",
    "allPosts['Post_Parsed'] = allPosts['Post_Parsed'].str.replace(someSigns,'',regex=True)\n",
    "allPosts['Post_Parsed'] = allPosts['Post_Parsed'].str.replace(punctuation,' ',regex=True)\n",
    "allPosts['Post_Parsed'] = allPosts['Post_Parsed'].str.replace(whitespaces,' ',regex=True)\n",
    "allPosts['Post_Parsed'] = allPosts['Post_Parsed'].str.replace(leadTrailWhitespace,'',regex=True)\n",
    "\n",
    "allPosts.loc[3000]['Post_Parsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "890702af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "with open('./../stop_words_no_punct.data', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    stop_words_no_punct = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38ebc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'made simple tool lets search video semantically ai live web app url example video frame person sunglasses earphones querying powered openai clip neural network performing zero shot image classification interface built streamlit try searching text image text image please share discoveries examples url'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "post_without_stop_words = []\n",
    "\n",
    "for post in allPosts.Post_Parsed:\n",
    "    text_tokens = word_tokenize(post)\n",
    "    tokens_without_stop_words = [word for word in text_tokens if not word in stop_words_no_punct]\n",
    "    post_without_stop_words.append((\" \").join(tokens_without_stop_words))\n",
    "\n",
    "allPosts['Post_Parsed'] = post_without_stop_words\n",
    "\n",
    "allPosts.loc[3000]['Post_Parsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84625db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Stemmer into an object\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5682084",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_text_list = []\n",
    "\n",
    "for post in allPosts.Post_Parsed:\n",
    "    \n",
    "    # Create an empty list containing Stemmed words\n",
    "    stemmed_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = post\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to Stem\n",
    "    for word in text_words:\n",
    "        stemmed_list.append(ps.stem(word))\n",
    "        \n",
    "    # Join the list\n",
    "    stemmed_text = \" \".join(stemmed_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    stemmed_text_list.append(stemmed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19d2c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allPosts['Post_Parsed_PS'] = stemmed_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3389d9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'made simpl tool let search video semant ai live web app url exampl video frame person sunglass earphon queri power openai clip neural network perform zero shot imag classif interfac built streamlit tri search text imag text imag pleas share discoveri exampl url'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPosts.loc[3000]['Post_Parsed_PS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc5c13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51414efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text_list = []\n",
    "\n",
    "for post in allPosts.Post_Parsed:\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = post\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a2bc4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "allPosts['Post_Parsed_LM'] = lemmatized_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2475d9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'make simple tool let search video semantically ai live web app url example video frame person sunglasses earphones query power openai clip neural network perform zero shoot image classification interface build streamlit try search text image text image please share discoveries examples url'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPosts.loc[3000]['Post_Parsed_LM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "948ae6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "allPosts.to_csv('all_posts_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0117c026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
